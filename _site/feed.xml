<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>YZH.home</title>
    <description>yzh's blog,use Jekyll and github pages.</description>
    <link>http://localhost:4000https://yzhihao.github.io//</link>
    <atom:link href="http://localhost:4000https://yzhihao.github.io//feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 13 Nov 2017 23:42:07 +0800</pubDate>
    <lastBuildDate>Mon, 13 Nov 2017 23:42:07 +0800</lastBuildDate>
    <generator>Jekyll v3.6.2</generator>
    
      <item>
        <title>Neural generative question answering</title>
        <description>&lt;h1 id=&quot;neural-generative-question-answering&quot;&gt;Neural Generative Question Answering&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;本文提出了一个基于神经网络的生成式问答模型（GenQA），该模型能够结合知识库信息，针对简单事实问句自动生成自然语言回答。GenQA模型基于序列到序列学习模型的编码-解码框架（encoder-decoder 框架），创新性的将问答任务与自然语言生成任务结合。本文基于结合知识库的问答对数据上进行了实验，实验结果表明GenQA能够处理问句的多样性问题，并且作出流畅的句式回答，相同数据集上效果优于其他对比方法。&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;GenQA模型由三个重要模块组成：Interpreter，Enquirer和Answerer。模型的整体框架见下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Neural_Generative_QA.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先，Interpreter接收自然语言问句作为输入，采用带GRU的双向RNN模型，输出一个对问句的表示并存储在短时记忆中。在每个 t 时刻针对每个词向量x&lt;sub&gt;t&lt;/sub&gt; ，会输出一个隐状态h&lt;sub&gt;t&lt;/sub&gt; 。最终问句表示的长度即为句子长度，在每个时刻 t 包括了隐状态向量h，词向量x以及词自身的信息。问句表示将作为Enquirer以及Answerer的输入。&lt;/p&gt;

&lt;p&gt;Enquirer的工作是根据知识库的长时记忆的知识以及输入的问句，获取正确的三元组。Enquirer首先使用简单的&lt;strong&gt;基于term-level&lt;/strong&gt;的匹配在知识库中寻找合适的三元组候选，然后计算这些候选三元组与问题之间的相似度，归一化后将分数向量 r 作为Enquirer的输出：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Neural_Generative_QA1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Enquirer模块中，本文提出了两种计算问题与三元组之间相似度的模型，第一种是双线性模型，相似度建模方式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Neural_Generative_QA2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中x表示问题序列中的词向量的均值，u表示三元组中subject与predicate向量的均值，M是要学的参数矩阵。这种模型记为GenQA。&lt;/p&gt;

&lt;p&gt;另一种方法是基于CNN的模型，这种模型记为GenQA_CNN。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Neural_Generative_QA3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中h为问句序列经过单层CNN后得到的向量表示，u表示三元组中subject与predicate向量的均值，两个向量拼接经过MLP得到最终的相似度得分。&lt;/p&gt;

&lt;p&gt;Answerer接受上两个模块的输入，在知识库的指导下生成自然语言，如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Neural_Generative_QA4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;生成过程基于普通序列到序列模型的框架，使用RNN的decoder，在 t 时刻基于 (t-1) 时刻的隐状态、t 时刻的上下文向量（context vector）生成当前词。上下文向量是基于注意力模型从三元组和问句向量中学习到的。Answerer模块会使用一个逻辑斯蒂回归判断当前需要生成的是普通的词，还是知识库中的实体词，也就是三元组的object。&lt;strong&gt;逻辑斯蒂回归&lt;/strong&gt;使用当前时刻隐状态作为输入，输出0时生成普通的词，生成普通词的模型与带注意力的序列到序列学习模型方法一致；输出1时，根据Enquirer模块的定长输出向量 r 作为输入，生成对应知识库三元组中的object词,注意这里是&lt;strong&gt;借鉴了copynet的做法&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验&quot;&gt;实验&lt;/h2&gt;

&lt;h2 id=&quot;related-workdiscussion&quot;&gt;RELATED WORK+discussion&lt;/h2&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;
</description>
        <pubDate>Mon, 31 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/31/Neural-Generative-Question-Answering.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/31/Neural-Generative-Question-Answering.html</guid>
        
        
      </item>
    
      <item>
        <title>知识图谱的表示学习</title>
        <description>&lt;h1 id=&quot;知识图谱的表示学习&quot;&gt;知识图谱的表示学习&lt;/h1&gt;

&lt;p&gt;网络表示学习的典型思路是：先构建一个关于节点、关系表示的目标函数（能量函数或者损失函数），然后使用SGD等优化算法进行优化。最典型的算法是TransE，从TranE算法中又延伸出来了众多其他的算法，包括：TransH、TransR、PTransE、TransSparse、TransD。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;translation的思想，即h的向量表示通过与r的向量表示进行一个操作可以近似得到r的向量表示。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这几年的研究不断扩展基于translation思想的知识图谱表示方法，在解决1对N、N对1之后，又考虑了关系路径、实体类型，链接预测、三元组分类等任务的效果得到不断提升。&lt;/p&gt;

&lt;h2 id=&quot;transe&quot;&gt;TransE&lt;/h2&gt;

&lt;p&gt;TransE的算法使用了一个简单的线性运算构建目标函数，但是实验效果表明，TransE比之前一些涉及大量矩阵运算、非线性函数的方法效果更好。
假设网络图中的边表示为三元组(h,r,t)，其中h、r、t分别是起始节点、关系、末尾节点的向量表示。TransE的学习目标是使得，&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Representation_Learning_kg.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;。使用&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Representation_Learning_kg1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;,这里p可以取1或者2,也就是使用L1范数或者L2范数来表示损失。&lt;/p&gt;

&lt;p&gt;TransE目标函数为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Representation_Learning_kg2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;S’是通过对原来的三元组随机替换h或者t得到的噪声三元组。优化过程中采用了NCE(Noise Contrastive Estimation)思想，尽量使得噪声三元组的损失大于正确三元组的损失加上一个margin \gamma。&lt;/p&gt;

&lt;p&gt;为了防止训练过程通过增大实体表示的norm大小来减少损失函数，这里限制所有的向量模长为1。&lt;/p&gt;

&lt;h2 id=&quot;transh&quot;&gt;TransH&lt;/h2&gt;

&lt;p&gt;TransE使用同一个向量来表示同一种关系，难以体现1对多、多对多、多对1的关系中的多样性。因此TransH将关系表示为超平面(hyperplane，比整体空间少一个维度的子空间，例如三维空间中的二维平面）上的一个向量。也就是，弥补TransE上的不能一对多的缺陷。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Representation_Learning_kg3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;具体的做法就是&lt;/p&gt;

&lt;h2 id=&quot;transr&quot;&gt;TransR&lt;/h2&gt;

&lt;p&gt;TransE和TransH将实体和关系都用同一个空间中的向量进行表示，&lt;strong&gt;TransR中实体和关系的表示位于两个空间&lt;/strong&gt;。在计算损失函数的时候，先使用一个线性变化将实体的表示映射到关系表示空间，在计算损失函数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Representation_Learning_kg4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;论文中还提出了一个&lt;strong&gt;CTransR。每个关系r对应于多个向量和映射矩阵，从而保证表示多样化的关系&lt;/strong&gt;。先对关系r所连接的实体对进行聚类，每个类别c对应于一个向量表示。也就是说，这里是在适应两个实体间多种不同关系的情况。&lt;/p&gt;

&lt;h2 id=&quot;transd&quot;&gt;TransD&lt;/h2&gt;

&lt;p&gt;这个是在TransR的基础上做了一个扩展。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Representation_Learning_kg4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;与其他方法的比较：TransR方法中每个关系都对应一个投影矩阵，而TransD方法中投影向量是两个实体对应的向量与关系对应的向量组成，&lt;strong&gt;复杂度更低&lt;/strong&gt;。TransH中每个关系对应一个投影向量，投影向量完全取决于关系，而TransD中，投影矩阵由实体与关系共同决定，具有&lt;strong&gt;更好的建模能力&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;transparse&quot;&gt;TranSparse&lt;/h2&gt;

&lt;p&gt;这个是在TransR上做了一个改进。&lt;/p&gt;

&lt;h2 id=&quot;ptranse&quot;&gt;PTransE&lt;/h2&gt;

&lt;p&gt;PTransE在学习向量表示的时候，不仅考虑了单独的关系，还考虑了路径信息。路径信息在某些情况下对于知识库的补全非常有用，例如从可以推测出关系。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;这是一个好的表示方式，因为不止考虑到三元组的向量，还考虑到路径的向量。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;tkrl&quot;&gt;TKRL&lt;/h2&gt;

&lt;p&gt;TKRL(Type-embodied Knowledge Representation Learning)是考虑了实体类型的层次结构来学习知识图谱上的实体向量与关系向量。与TransD相同，TKRL先将实体与关系表示成向量，然后使用两个投影矩阵将实体向量投影到关系向量所在的空间。&lt;/p&gt;

</description>
        <pubDate>Sat, 29 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/29/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/29/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0.html</guid>
        
        
      </item>
    
      <item>
        <title>Variational approaches for auto Encoding generative adversarial networks</title>
        <description>&lt;h1 id=&quot;variational-approaches-for-auto-encoding-generative-adversarial-networks&quot;&gt;Variational Approaches for Auto-Encoding Generative Adversarial Networks&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;机器学习研究领域，生成式对抗网络（GAN）在学习生成模型方面占据着统治性的地位，在使用图像数据进行训练的时候，GAN能够生成视觉上以假乱真的图像样本。但是这种灵活的算法也伴随着优化的不稳定性，导致模式崩溃（mode collapse）。将自动编码器(auto-encoder)与GAN相结合，能够使模型更好的表示所有被训练的数据，以&lt;strong&gt;阻止模式崩溃。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验&quot;&gt;实验&lt;/h2&gt;

&lt;h2 id=&quot;related-workdiscussion&quot;&gt;RELATED WORK+discussion&lt;/h2&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;

</description>
        <pubDate>Thu, 27 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/27/Variational-Approaches-for-Auto-Encoding-Generative-Adversarial-Networks.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/27/Variational-Approaches-for-Auto-Encoding-Generative-Adversarial-Networks.html</guid>
        
        
      </item>
    
      <item>
        <title>Sequence to backward and forward sequences</title>
        <description>&lt;h1 id=&quot;sequence-to-backward-and-forward-sequences&quot;&gt;Sequence to Backward and Forward Sequences&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;本文旨在提出一种叫做content introducing的方法来生成短文本reply，一共分为两个step，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Sequence_Backward_chatbot.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;step 1 给定query之后，预测一个keyword作为reply的topic，这个topic词性是名词，这里的keyword并不能捕捉复杂的语义和语法，而只是根据query的每个词来预估出一个PMI（Pointwise Mutual Information）最高的名词作为keyword，两个单词之间的PMI由下式计算：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Sequence_Backward_chatbot1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每个单词与query之间的PMI由下式计算：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Sequence_Backward_chatbot2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;虽然数学上不太严谨，但后面的实验表明用这个来计算结果还是不错的。&lt;/p&gt;

&lt;p&gt;step 2 本文的模型叫做Sequence To Backward and Forward Sequences，首先进行backward step，给定一个query，用encoder表示出来得到一个context，decoder的部分首先给定keyword作为第一个词，然后进行decoding，生成的这部分相当于keyword词前面的部分；接下来进行的是forward step，也是一个典型的seq2seq，用encoder将query表示成context，然后给定backward生成的话和keyword作为decoder的前半部分，继续decoding生成后半部分。整个的流程这样简单描述下：&lt;/p&gt;

&lt;p&gt;query + keyword =&amp;gt; backward sequence&lt;/p&gt;

&lt;p&gt;query + keyword + backward sequence(reverse) =&amp;gt; forward sequence&lt;/p&gt;

&lt;p&gt;reply = backward (reverse) sequence + keyword + forward sequence&lt;/p&gt;

&lt;p&gt;传统的seq2seq模型都是从第一个词生成到最后一个词，无法生成指定词，而本文的模型可以生成指定词，并且该词可以出现在reply的任意位置。&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验&quot;&gt;实验&lt;/h2&gt;

&lt;p&gt;实验中数据集是从百度贴吧上爬下来的对话数据，规模有500k的query reply pairs，PMI统计是由100M的query reply paris。&lt;/p&gt;

&lt;h2 id=&quot;related-workdiscussion&quot;&gt;RELATED WORK+discussion&lt;/h2&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;
</description>
        <pubDate>Wed, 26 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/26/Sequence-to-Backward-and-Forward-Sequences.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/26/Sequence-to-Backward-and-Forward-Sequences.html</guid>
        
        
      </item>
    
      <item>
        <title>Learning through dialogue interactions by asking questions</title>
        <description>&lt;h1 id=&quot;learning-through-dialogue-interactions-by-asking-questions&quot;&gt;Learning through Dialogue Interactions by Asking Questions&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;是end-to-end学习交互对话代理的第一步，当一个学生被老师提问，但他对答案并不确定时，他可以向老师请求详细点的说名或者给些提示。一个好的agent（learn/bot/student）也应当有&lt;strong&gt;这种能力可以和一个对话参与者（teacher/user）进行交互&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;（1）learner在理解对话者的文本表面形式时会出现问题，例如一个问题的描述；&lt;/p&gt;

&lt;p&gt;（2）learner在推理上会出现问题，例如在即将回应的问题上，learner不能检索并联系相关的知识；&lt;/p&gt;

&lt;p&gt;（3）learner在起初就缺乏回答问题的必要知识源，也就说learner已经学习的知识源不包含需要的信息。&lt;/p&gt;

&lt;p&gt;上面说到的那三种情况都有可能通过与对话参与者交互来解决。一些交互可以被用来学习，以便在未来的对话中有更好的表现形式&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（1）问题澄清：当bot无法理解user的文本语意时。（2）知识操作：bot需要借助一个现有的基本知识库做推理。（3）知识获取：bot的知识库时不完整的，需要补充。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;h3 id=&quot;question-clarification问题澄清&quot;&gt;Question Clarification（问题澄清）&lt;/h3&gt;

&lt;p&gt;这里有两种情况：&lt;/p&gt;

&lt;p&gt;（i）问题的释义：student会请求（例如：what do you mean）请求teacher使用没有拼写错误的解释语句来澄清该问题。&lt;/p&gt;

&lt;p&gt;（ii）问题的确认：student会通过类似“Do you mean which film Tom appear in”的方式来确认带有拼写错误的问题是否对应一条没有拼写错误的问题&lt;/p&gt;

&lt;h3 id=&quot;knowledge-operation知识操作&quot;&gt;Knowledge Operation（知识操作）&lt;/h3&gt;

&lt;p&gt;请求相关的知识（Task 3）：bot会直接请求teacher指出相关的KB事实；&lt;/p&gt;

&lt;p&gt;知识的验证（Task 4）：bot会请教teacher的问题是否和KB 中一个具体的fact相关&lt;/p&gt;

&lt;p&gt;具体如下图:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Asking_Questions_chatbot.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;knowledge-acquisition知识获取&quot;&gt;Knowledge Acquisition（知识获取)&lt;/h3&gt;

&lt;p&gt;细看图3。例如给定一个问题：“Which movie did Tom star in ?”，缺少的部分可以是teacher正在询问的实体（简称为question entity，该例子中的问题实体是Tom），相关实体（starred actors），问题的答案（Forrest Gump），或者者三者都有。&lt;/p&gt;

&lt;p&gt;在所有的例子中，&lt;strong&gt;由于相关知识库的缺乏，bot很难给出正确答案。它就需要teacher给出正确的答案来学到缺失的这部分知识。Teacher给出答案后会继续问其他的问题。Teacher然后再返回重问该问题，这时候bot就需要给出一个答案了，因为这个实体不再是未见过的了&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Missing Question Entity&lt;/strong&gt;：teacher正在提问中的实体在基本知识库中缺失。所有包含该question entity的KB facts将对bot隐藏。例如Task 5中的图3，因为teacher的问题中含有Tom实体，那么包含Tom实体的KB facts将对bot不可见。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Missing Answer Entity&lt;/strong&gt;：对于bot来说，问题的answer entity是不可知的。那么所有含有answer entity的KB facts将会被隐藏。因此在图3的Task 6中，所有包含“Forrest Gump”的KB facts将对bot不可见。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Missing Relation Entity&lt;/strong&gt;：相关类型对于bot来说是未知的。在图3的Task 7中，所有和starred actors相关的KB facts对bot是不可见的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Missing Triples&lt;/strong&gt;：对于同时出现question entity，answer entity 和relation entity的所有KB facts对bot不可见。如图3的Task 8.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Missing Everything&lt;/strong&gt;：对包含question entity，answer entity 和relation entity中任意一种的所有KB facts都将对bot不可见。如图3的Task 9.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Asking_Questions_chatbot1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;traintest-regime训练测试规则&quot;&gt;Train/Test Regime（训练/测试规则）&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;第一，我们想要测试下提问问题的有效性。第二，我们想要训练我们的student bot在什么时候提问，并且问什么问题。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;为了能够完成这两个目标，我们使用了两种方法来探索着训练我们的模型：&lt;strong&gt;Offline Supervised Learning 和 Online Reinforcement Learning。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;offline-supervised-learning&quot;&gt;Offline Supervised Learning&lt;/h3&gt;

&lt;p&gt;使用线下监督环境训练我们student模型的目的主要是测试&lt;strong&gt;提出问题能力的有效性.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们采纳的第一个学习策略是基于Reward的模拟策略（简称vanilla-MemN2N） (Weston, 2016)。在训练时，该模型将student提供的答案做最大化对数似然估计（丢弃那些错误答案的示例）。候选的答案是在记忆中出现的词，这也就意味着bot只能从它之前看过的知识库中预测实体。&lt;/p&gt;

&lt;p&gt;我们也使用了MemN2N的一个变体，称为“context MemN2N”（Cont-MemN2N for short），即我们将每个词向量&lt;strong&gt;用该词向量和该词周围出现的其他词向量的平均值来替换。&lt;/strong&gt;我们使用前面和后面的单词作为上下文，上下文单词的数量是在dev集合上选择的超参数。&lt;/p&gt;

&lt;p&gt;模型 vanilla-MemN2N 和 Cont-MemN2N 的共同问题是它们只能利用bot的答案作为信息，而忽略了teacher的反馈。因此，我们提出了一个可以联合预测bot答案和teacher反馈的模型（可以简称为TrainQA（+FP））。Bot的答案可以使用vanilla-MemN2N来预测，teacher的反馈可以使用ForwardPrediction(FP)模型（Jason Weston. Dialog-based language learning. arXiv preprint arXiv:1604.06045, 2016）来反馈。我们建议读者可以细读下FP模型的细节。在训练时，模型可以同时从teacher的反馈预测和具有正向reward的答案中学习。在测试时，模型将只能预测bot的答案。
在第四章节的TestModelAQ设定中，模型需要决定要问什么问题，我们这里同样使用vanilla-MemN2N，输入question和上下文，然后输出bot要问的问题。&lt;/p&gt;

&lt;h3 id=&quot;online-reinforcement-learningrl&quot;&gt;Online Reinforcement Learning（RL）&lt;/h3&gt;

&lt;p&gt;我们也探索了student学习&lt;strong&gt;在何时提问和提问什么内容的能力，换句话说就是student怎样学习。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;student在每次交流时都会提出问题，这样感觉还不错，因为对student问题的回答中会包含一些额外的信息，但我们并不想让我们的模型学习这种行为。因为当现实中的student提问时，总会有一个这种行为的成本。这种成本可以视为&lt;strong&gt;teacher耐心的反应&lt;/strong&gt;。或者更一般的人机交互间的影响：&lt;strong&gt;如果bot总是请求解释问题，那么用户就不会发现bot的优点。&lt;/strong&gt;Student对何时提问和提问什么应该有一定的判断力。例如：如果student对答案很自信，那么就没有必要在提问了；或者如果老师的问题太难，即使解释了也不助于你得到正确答案，那么就也没必要提问。&lt;/p&gt;

&lt;p&gt;一个二元的vanilla-MemN2N（可以视为）模型用来决定bot是否需要提问，即为了给teacher答复，bot是否需要问一些东西。第二个MemN2N模型用来决定bot的回答，可以视为。对应QA和AQ两种不同的模型，这也就意味这bot会根据它是否选择提问而使用两种不同的模型作为最后答案的预测。&lt;/p&gt;

&lt;h2 id=&quot;实验&quot;&gt;实验&lt;/h2&gt;

&lt;h2 id=&quot;related-workdiscussion&quot;&gt;RELATED WORK+discussion&lt;/h2&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;

</description>
        <pubDate>Tue, 25 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/25/Learning-through-Dialogue-Interactions-by-Asking-Questions.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/25/Learning-through-Dialogue-Interactions-by-Asking-Questions.html</guid>
        
        
      </item>
    
      <item>
        <title>Hierarchical recurrent attention network for response generation</title>
        <description>&lt;h1 id=&quot;hierarchical-recurrent-attention-network-for-response-generation&quot;&gt;Hierarchical Recurrent Attention Network for Response Generation&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;在生成式模型上注重的多轮对话上下文信息，对历史信息进行建模&lt;/li&gt;
  &lt;li&gt;提出一种Hierarchical Recurrent Attention Network，注重在word level的信息提取。&lt;/li&gt;
  &lt;li&gt;在人工测评和Evaluation Metrics（Perplexity）上实现了state of the art&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;Hierarchical_Recurrent_network&lt;/p&gt;

&lt;p&gt;这个模型主要分为三个部分，分别是Word Level Encoder，Hierarchical Attention and Utterance Encoder，decoder and Response。&lt;/p&gt;

&lt;p&gt;简单来说：首先是用Word Level Encoder將上下文转变成hidden vectors。然后，在生成每一个词时，分层的注意力机制分别在词级的attention和话语级的attention提取相应的重要成分。在其中多个word level attention 将会把自己提取到的上下文信息 uploaded 到一个 utterance level encoder，重新综合上下文信息。最后变成综合当前query输入给decoder生成对话。&lt;/p&gt;

&lt;p&gt;下面是三个部分详细说明：&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验&quot;&gt;实验&lt;/h2&gt;

&lt;h2 id=&quot;related-workdiscussion&quot;&gt;RELATED WORK+discussion&lt;/h2&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;

&lt;p&gt;不足：&lt;/p&gt;
</description>
        <pubDate>Mon, 24 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/24/Hierarchical-Recurrent-Attention-Network-for-Response-Generation.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/24/Hierarchical-Recurrent-Attention-Network-for-Response-Generation.html</guid>
        
        
      </item>
    
      <item>
        <title>A persona Based neural conversation model</title>
        <description>&lt;h1 id=&quot;a-persona-based-neural-conversation-model&quot;&gt;A Persona-Based Neural Conversation Model&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;本文针对的问题是开头说的&lt;strong&gt;多轮对话中response不一致的问题&lt;/strong&gt;，这个问题很关键，多轮对话在工程应用中的意义更大，一致性是一个基础问题，解决不好，效果就会非常地差。本文针对这个问题，&lt;strong&gt;将user identity（比如背景信息、用户画像，年龄等信息）考虑到model中&lt;/strong&gt;，构建出一个个性化的seq2seq模型，为不同的user，以及同一个user对不同的对象对话生成不同风格的response。&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;h3 id=&quot;speaker-model&quot;&gt;Speaker Model&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Persona-Based_chatbot.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图是Speaker Model的架构示意图，是一个典型的seq2seq模型，不同的地方在于&lt;strong&gt;在decoding部分增加了一个speaker embedding，类似于word embedding&lt;/strong&gt;，只是说对用户进行建模。因为无法对用户的信息显式地进行建模，所以用了一种embedding的方法，通过训练来得到speaker向量，下面左边的图是speaker向量在二维平面上的表示，&lt;strong&gt;具有相似背景信息的user就会很接近，与word向量一个道理，注意这里的一个好处就是如果相近的user的其中一个的属性若在训练时没有现示的训练到，也会因向量相近而可以在测试的时候回答出（答案就是其相近的user一样即可）&lt;/strong&gt;。decoding部分计算lstm各个gate用下式，vi表示speaker embedding,是在训练时通过反向传播训练。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Persona-Based_chatbot1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;speaker-addressee-model&quot;&gt;Speaker-Addressee Model&lt;/h3&gt;

&lt;p&gt;第二个模型是Speaker-Addressee Model，这个模型与上一个模型思想是一致的，只是考虑了一种更加细致的情况，在多人多轮对话（电视剧）中，每个人对不同的人说话style是不同的，所以应该在这类问题中需要考虑说话的对象，用V(i,j)来表示speaker i和j之间的这种关系，decoding部分计算如下式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Persona-Based_chatbot2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验&quot;&gt;实验&lt;/h2&gt;

&lt;h2 id=&quot;related-workdiscussion&quot;&gt;RELATED WORK+discussion&lt;/h2&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;

&lt;p&gt;不足：
太依赖于数据集，能明确在特定位置加入keyword是很有局限的。&lt;/p&gt;

</description>
        <pubDate>Thu, 20 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/20/A-Persona-Based-Neural-Conversation-Model.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/20/A-Persona-Based-Neural-Conversation-Model.html</guid>
        
        
      </item>
    
      <item>
        <title>Assigning identity to a chatting machine</title>
        <description>&lt;h1 id=&quot;assigning-personalityidentity-to-a-chatting-machine-for-coherent-conversation-generation&quot;&gt;Assigning Personality/Identity to a Chatting Machine for Coherent Conversation Generation&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;对于 chatbot 的发展，我们给出了两个长期的研究目标：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;我们希望它能从任务驱动型到闲聊都能够有&lt;strong&gt;较好的回复&lt;/strong&gt;随着大数据时代的不断发展，闲聊机器人系统可以用更丰富的对话数据进行训练；并且为避免繁杂的人工定义，在大数据上可以自动聚类或抽取对话行为等信息。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;能够更加&lt;strong&gt;有一致的人格&lt;/strong&gt;，并且能够有较高的“情商”，即聊天机器人的个性化情感抚慰、心理疏导和精神陪护等能力。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;本文的创新点主要有两点:&lt;/p&gt;

&lt;p&gt;第一，作者尝试为闲聊机器人定义一个固定的角色/身份。本文只是一个初步的探索，在未来的工作中会尝试定义机器人的属性、个性、语言风格等，甚至可以为机器人的实时想法进行建模，从而达到更好的前后文一致性。&lt;/p&gt;

&lt;p&gt;第二，作者提出了一个新颖的生成模型用于识别并回答与机器人自身相关的问题，巧妙地运用不一致的训练数据，训练出具有一致性回复的聊天机器人。&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;首先，此文为闲聊机器人设定了固定的属性，包括但不限于姓名、性别、爱好等。这些属性被整理为 &amp;lt;Key, Value&amp;gt; 的形式，当机器人被问及与自身属性相关的问题时，应生成与自身属性相一致的回复。如下图所示：此文为 chatbot 设定为一个名叫汪仔的三岁男孩，他热爱动漫，特长是弹钢琴。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Identity_chatbot.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那么，研究面临的挑战是什么呢？实际上是主要来&lt;strong&gt;源于数据属性的不一致性，一方面是训练数据相互之间不一致，另一方面是训练数据与机器人不一致。&lt;/strong&gt;例如，考虑训练数据中针 对“爱好”的回答，有喜欢篮球的，有喜欢足球的，还有喜欢羽毛球的，这些回答本身就不具有一致性；然而我们机器人的爱好可能是游泳，这与训练数据也不一致。如何使用这些不一致的数据训练模型，成为了此研究最大的挑战。&lt;/p&gt;

&lt;p&gt;如何解决上述问题呢？本文提出了&lt;strong&gt;位置检测器（Position Detector），注意这个只在训练时有用，因为只是在找到目标回答中的替换词&lt;/strong&gt;，它着眼于在训练数据中定位属性值的位置。作者基于词向量的相似度实现 Position Detector 模块。例如，在“我 /喜欢”这句话中，由于“篮球”和“游泳”的词向量距离最近，所以断定“篮球”为属性值。此外，本文还将提出一种&lt;strong&gt;基于语言模型的方法定位属性值的位置&lt;/strong&gt;，以追求更好的性能。 &lt;strong&gt;当 Position Detector 定位到 Reply 中的属性值后，可以通过替换的方法将消除训练数据的不一致性。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方法思路介绍：&lt;/strong&gt;如下图所示，本文模型包含三个重要的子模块。首先，为了判断给定的 Post 是否涉及机器人自身的属性，以及涉及了哪一条属性，属性检测器（Profile Detector）将对给定的 Post 进行分类。训练 Profile Detector 的过程中使用了带有噪音的监督数据。若分类结果不涉及机器人属性，则使用传统方法 seq2seq 解码。若分类结果涉及机器人属性，则使用双向解码器（Bidirectional Decoder）以属性值为中心进行双向解码。Bidirectional Decoder 是通过与属性相关的 &amp;lt;Post, Response&amp;gt; 数据训练的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Identity_chatbot1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;▲ 图3：整个过程的生成图解&lt;/p&gt;

&lt;p&gt;训练的时候因为很多训练数据里的属性都不是机器人的真实属性，于是使用&lt;strong&gt;机器人属性去做生成的 response 与训练数据的 response 会有不一致&lt;/strong&gt;，所以就想到了&lt;strong&gt;用 position detector 替换一下消除这种不一致&lt;/strong&gt;。因此，需要使用位置检测器（Position Detector）对训练过程做特殊的预处理，Position Detector 可以在训练数据中定位属性值的位置，从而解决在训练与测试过程中的落差。需要注意的是，Position Detector 在测试的过程中不参与生成（generation）过程。具体情况如下图所示，给定一对 &amp;lt;x，y&amp;gt;，Position Detector 将会预测属性值钢琴（Piano）会被小提琴-4（violin）这一位置所替代，该位置将会被用于训练 Bidirectional Decoder。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Identity_chatbot2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;▲ 图4：模型的训练过程&lt;/p&gt;

&lt;p&gt;细节剖析：其中的编码器（Encoder）是将 post 编码成向量，以便后续深度生成模型利用。属性检测器（Profile Detector）在这里有两个目的：&lt;strong&gt;一是判断给定的 Post 是否涉及机器人自身的属性，二是判断涉及了哪一条属性，将检测到的属性 &amp;lt;key,value&amp;gt; 放入相应的解码器中。&lt;/strong&gt;双向解码器（Bidirectional Decoder）的目的是生成一个涉及机器人属性的反应 （Response(y)），在测试阶段以机器人的属性值（Profile Value）为起点来生成整个序列。双向解码器这一点是受到了牟力立同学在 2016 年发表的一篇论文（Mou et al., 2016）[1] 启发，&lt;strong&gt;他们的工作是通过双向解码器生成包含限制条件的回复。与之不同的是，在训练过程中我们使用了 Position Detector 去预测关键词的位置，取代了（Mou et al., 2016）工作中随机替换关键词训练 Decoder 的方法。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验&quot;&gt;实验&lt;/h2&gt;

&lt;h2 id=&quot;related-workdiscussion&quot;&gt;RELATED WORK+discussion&lt;/h2&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;

&lt;p&gt;这篇文章讲的是给机器一个人格，这个思路是非常好的，更加细化，我们转变思路，不同于这篇中的是对不同的机器进行建模，或许我们可以让机器对不同的人进行建模，这样来实现正真的个性化。&lt;/p&gt;
</description>
        <pubDate>Tue, 18 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/18/Assigning-Identity-to-a-Chatting-Machine.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/18/Assigning-Identity-to-a-Chatting-Machine.html</guid>
        
        
      </item>
    
      <item>
        <title>When kg meets chatbots</title>
        <description>&lt;h1 id=&quot;when-kg-meets-chatbots&quot;&gt;When KG meets Chatbots&lt;/h1&gt;

&lt;h2 id=&quot;chatbot历史&quot;&gt;chatbot历史&lt;/h2&gt;

&lt;p&gt;ELIZA诞生于1966年，开发者为MIT的Joseph Weizenbaum。它是一个模拟罗杰斯心理治疗的BASIC程序，是自然语言处理方面的先驱者。&lt;/p&gt;

&lt;p&gt;A.L.I.C.E，起源于美国国防部DARPA的一个项目，它诞生于符号AI鼎盛时期，&lt;strong&gt;基于规则和模板来处理问句理解和回复逻辑。&lt;/strong&gt;他对Chatbots的后续发展起到了非常深远的影响。它的一个贡献是定义了AIML，一种类XML的声明式语言，可以用来编写各种问答对，甚至多轮对话的对话逻辑。这种做法&lt;strong&gt;对于数据规模小，且领域知识相对充足的情况下，非常利于解决冷启动并提供表现不错的对话体验，同时也是对当前基于机器学习尤其是深度学习方法的一种补充。&lt;/strong&gt;不仅可用来积累数据，也可以提供可解释性更强，且能针对个别用例做针对性地在线干预和修正。所以，到目前为止，大部分商用聊天机器人尤其是特定领域的对话应用沿用了这一思路。&lt;/p&gt;

&lt;p&gt;图灵测试是指测试者在与被测试者（一个人和一台机器）隔开的情况下，通过一些装置（如键盘）向被测试者随意提问。进行一系列&lt;strong&gt;时长为5分钟的测试后，如果有超过30%的测试者不能确定出被测试者是人还是机器，&lt;/strong&gt;那么这台机器就通过了测试，并被认为具有人类智能&lt;/p&gt;

&lt;h2 id=&quot;聊天机器人的分类&quot;&gt;聊天机器人的分类&lt;/h2&gt;

&lt;p&gt;对聊天机器人按照功能和交互方式等二个维度可以进一步细分为四类。&lt;strong&gt;交互方式可以分为主动交互或被动交互&lt;/strong&gt;。目前大家接触到的大部分聊天机器人都属于被动交互的范畴，即由用户发起对话，机器理解对话并作出相应的响应。而主动交互能更好体现机器人和用户之间的对等关系，即&lt;strong&gt;通过共享或推荐用户感兴趣或热点事件等由机器人首先发起。&lt;/strong&gt;目前主动交互更多作为传统交互方式的一种补充，作为辅助手段，并&lt;strong&gt;未大规模&lt;/strong&gt;得到广泛使用。&lt;strong&gt;从功能角度来看，聊天机器人可以细分为以闲聊为主的聊天，问答和面向任务或目标的对话。&lt;/strong&gt;其中，若根据场景切分，闲聊可以进一步分为情感交流和针对客观话题的讨论。问答系统需要不仅考虑如What、Who、Which、Where和When等事实型问答（Factoid QA），也需要考虑如How和Why等非事实型问答。&lt;em&gt;如：小冰是一个基于搜索的回复检索系统。通过各种基于深度学习的语义匹配算法，从海量的问答对语料中返回最佳的回复（Message response而非Answer）&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在主动交互性的聊天机器人有可做之处！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;为什么需要-kg&quot;&gt;为什么需要 KG&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;知识图谱也被广泛用于各种问答交互场景中&lt;/strong&gt;
Watson背后依托DBpedia和Yago等百科知识库和WordNet等语言学知识。类似地，Alexa也依托其早年收购的True Knowledge公司所积累的知识库；Siri则利用DBpedia和可计算的知识服务引擎WolframAlpha；狗尾草公司推出的虚拟美少女机器人琥珀虚颜则用到了首个中文链接知识库Zhishi.me。伴随着机器人和IoT设备的智能化浪潮，智能厨房、智能驾驶和智能家居等应用层出不穷。无独有偶，百度推出的Duer OS和Siri的进化版Viv背后也都有海量知识库的支撑。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;KG也越来越多地被用于辅助决策。&lt;/strong&gt;这里无外乎是通过对文本、多媒体和各种传感器产生的原始数据流建立更加规范的数据表达，通过语义抽取、数据链接&lt;strong&gt;形成更多机器可理解的语义知识&lt;/strong&gt;，从而将原本异构分散的各种数据转变为机器可计算的大数据。通过可计算机的大数据，人们更容易发现领域或行业内原先不为人知的规律或一些有趣的模式，从而更好地做出决策。Plantir就是这方面的成功应用典范，而ImageNet及Visual Genome等数据项目则极大地推进了图像语义理解和推理的进程。在构建用于辅助决策的知识图谱形成可计算大数据的过程中，如何将符号推理与统计学习有机结合起来，即碎片化的知识图谱上的推理和深度学习决策模型结合起来，形成所谓的Local Knowledge Powered Global Learning是非常有趣而富有挑战的研究课题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;KG也可辅助通用人工智能（Artificial General Intelligence，AGI），即在常识推理方面起到作用。&lt;/strong&gt;过去人们常用图灵测试对机器的智能进行评估，近年来，Winograd Schema Challenge逐渐进入大家的视线。这里举一个指代消解的例子。指代消解是一个经典NLP任务，旨在将代词指向具名实体。例如，Thetrophy would not fit in the brown suitcase because itwas too big (small).What was too big(small)? 当我们描述it是big时，人们很容易理解这时候是在说奖杯（trophy）；而当it与small搭配时，我们也很容易识别出在抱怨suitcase太小。这个看似非常容易的问题，却难倒了机器，这是因为人具有非常庞大的世界知识（world knowledge）和常识知识（common-sense knowledge）。当我们仅采用NLP技术来努力理解并给出答案时，正确率仅50%；当结合知识时，正确率提升到了60%，而及格线是90%。因此，我们离真正的通用智能还有很漫长的路要走，需要更多的技术突破和数据积累才能完成这项挑战。&lt;/p&gt;

&lt;h2 id=&quot;需要什么样的-kg&quot;&gt;需要什么样的 KG&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;首先，Chatbot需要更加个性化的知识图谱。&lt;/strong&gt;除了前面提到的实体KG和兴趣KG等开放领域的稀疏大图，我们也需要&lt;strong&gt;构建机器人KG和用户KG等个性化稠密小图。&lt;/strong&gt;机器人或Agent需要图谱来建模和展示它的自我认知能力，而&lt;strong&gt;用户图谱则可被看作是更精细化的用户画像的知识表现&lt;/strong&gt;。例如，机器人如“琥珀.虚颜”，有情感状态，喜好，技能等知识维度。同理，用户则需要表达其职业状态和生活轨迹等信息。需要强调的是，无论是个性化小图还是开放域大图，&lt;strong&gt;都不是独立存在的&lt;/strong&gt;，需要将它们融合在一起，才能发挥更大 的价值。机器人喜欢吃的食物则需要和实体KG中的食谱图谱关联，而与用户形成经纪人、好友等社会关系，同时爱好方面则和兴趣图谱又关联在一起，可以实现机器人社交、机器人-用户社交和用户社交网络的统一连接。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;其次，我们的世界不仅仅是静态的，而是动态地反映各种事物在时空上的变化&lt;/strong&gt;。因此，我们不仅仅需要刚刚谈到的静态图谱，而是需要思考如何表示和&lt;strong&gt;应用动态图谱。&lt;/strong&gt;对于一个机器人，它从早到晚会做不同的事情，也就是有自己的生活规则。我们该如何刻画生活轨迹呢？这就需要我们在图谱中体现时态知识。另一个例子，用户行程，即对于用户图谱，需要记住用户各种已经发生、正在星星或即将发生的事件。图谱中的行程不仅仅是一个关系或属性，而是一个由多元（N-ary）组成的事件。我们需要定义多种事件类型，并刻画时间和空间两个维度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第三，机器人不能只是冷冰冰的回答用户的问题或帮助用户完成特定功能。它需要感知用户的情感并在输出答案回复的同时伴随着相应的情感，这样才更加拟人化&lt;/strong&gt;。我们发现，之前构建的知识图谱大多是客观的，即描述一些客观的事实。如何在结合个性化图谱时，能包括一些主观知识，进而刻画机器人或用户的情感元素。例如，用户说：“我心情不好”。这属于闲聊中的情感表达范畴。这时需要将用户当前的心情状态更新到用户图谱的对应维度数值中。相应地，机器人也会有自己的心情、体力，甚至和用户之间的好感度关联。当此时，机器人心情不错，同时和用户很亲密时，它就会主动关心用户。这样结合机器人和用户情感因素的动态回复会更加温馨和贴合场景。当在多轮对话时，用户进一步说：“来一首快乐的歌吧”。需要进一步结合音乐知识KG（快乐作为歌曲的曲风或风格标签）和用户KG中的音乐偏好，推荐用户喜好的欢快的歌。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第四，我们发现聊天机器人为了完成很多功能需要对接外部服务或开放API。&lt;/strong&gt;此时，图谱就需要从传统的关系型知识图谱（刻画二元关系）扩展到&lt;strong&gt;支持动态服务的动态图谱（刻画多元关系，事件属于服务图谱的一个特例&lt;/strong&gt;）。另一方面，如何刻画服务之间的各种关系（如因果、时序依赖等）也是图谱扩展过程中需要考虑的。例如，当完成了订餐，会有很多Follow-up的服务（订花或预约车等）可作为后续服务被消费。建立这些服务之间的关联对于进行精准的多轮对话过程中的场景切换是非常有必要的。&lt;/p&gt;

&lt;p&gt;总而言之，我们需要基于不同来源异构的数据来构建包含多类别且体现动态和个性化的知识图谱。这其中包括来自互联网的数据来刻画世界知识，用户数据来刻画画像知识，以及针对&lt;strong&gt;机器人的各种基本属性、社会关系、情感状态、兴趣爱好、以及日常生活等静态和动态知识。&lt;/strong&gt;而我们得到的融合图谱是时空坐标中针对特定交互场景和时间节点的一个镜像。&lt;/p&gt;

&lt;h2 id=&quot;图谱的构建和储存&quot;&gt;图谱的构建和储存&lt;/h2&gt;

&lt;p&gt;从更技术的角度来说，我们需要考虑知识图谱将如何构建。这里不仅包含如何结合文本、多媒体、半结构化、结构化知识、服务或API，以及时态知识等的统一知识表示。在此基础上，需要进一步考虑如何结合结构化（如关系型数据库）、半结构化（HTML或XML）和非结构化（文本、图像等）多源异质数据源来分别构建通用事实类（各种领域相关实体知识）、常识类、用户个人记忆类、机器人自我认知类和服务任务类知识库等。针对不同类型的数据和不同种类的知识构建，有相应的构建技术，如针对结构化数据的知识映射、针对半结构化知识的包装器（Wrapper），以及针对非结构化知识的文本挖掘和自然语言处理。文本挖掘充分利用Web或大规模语料库的冗余信息来发现隐含的模式；而自然语言处理更多是做各种知识抽取（开放或确定schema的）。为了得到融合的图谱，我们除了离线的多源异构的知识融合，还需要额外考虑服务任务类动态知识的对象绑定，这块工作往往是在线完成的，相当于根据不同的交互，在线动态扩充知识图谱并实例化的过程&lt;/p&gt;

&lt;p&gt;所构建的知识图谱既包括事实类和常识类的静态全局大图、服务任务类动态图谱，也有对于每个用户不同的用户图谱和机器人KG。随着用户数量的增加，用户图谱的数量也随之增加。这些图互相隔离，但每个均与全局图谱关联来提供个性化的聊天机器人的对话问答服务。每个用户图谱+机器人KG又随着交互不断填充和更新其中的节点和边，导致此类图谱的读写频度均非常高。面对这样的图谱，我们该如何选择存储方案呢？从工程应用的角度，我们更愿意站在巨人的肩膀上，选择一个现有数据库或几个数据库的组合来形成高效的图谱存储。&lt;/p&gt;

&lt;p&gt;注意：这里所谓的存储，不仅仅是将知识存放的问题，而是考虑存储之后是否可以根据图谱的规模、读写特点和查询推理等基础在线操作的效率等多个因素来考量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MongoDB，作为面向文档（Document Oriented）的NoSQL代表，&lt;/strong&gt;他支持无模式（Schemaless）的数据建模方式，即不要求一开始就将Schema都确定，而可以按需进行添加或修改。这对于需求经常变更或一开始对领域不是完全了解的情况下，支持自底向上方式的知识管理。不过MongoDB仅支持数据库级别的锁，写入速度受限。对于读并发的提高，可以使用基于数据分片（Data Sharding）的分布式版本。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;关系型数据库MySQL应用广泛，&lt;/strong&gt;也被用于Apache Jena（HP开源的RDF数据库）中TDB的存储引擎。而Elasticsearch支持图谱上的简单模式（如单关系或链式）查询，适合如Facebook Graph Search或聊天机器人中大部分口语对话，因此也是面向聊天对话的知识图谱存储方案之一；&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Neo4j是知名的图数据库，&lt;/strong&gt;不同于RDF数据库，它的数据模型是属性图（property graph），基于图遍历（graph traversal）来实现各种查询功能，对于大部分熟悉面向对象编程的工程师来说非常容易上手。基于上述任何一个数据库或多个数据库的组合来满足知识图谱的管理都是工程做法。从研究的角度来说，希望做一个统一的存储和查询引擎，需要支持多租户（multi-tenant）环境下的海量个人和机器人知识图谱管理，以及融合个人图谱和全局知识上的查询分解、分布式环境下的查询路由和子查询执行，以及结果融合等操作。&lt;/p&gt;

&lt;h2 id=&quot;kg-应用&quot;&gt;KG 应用&lt;/h2&gt;

&lt;p&gt;第一个应用叫&lt;strong&gt;实体识别和链接。实体识别称为Named Entity Recognition，简称为NER&lt;/strong&gt;。在传统NLP任务中，仅能识别PERSON（人物）、LOCATION（地点）、ORGANIZATION（组织机构）、DATE（时间日期）等有限类别。在实际应用中，NER的主要挑战在于识别大量细粒度实体类型，比如以Schema.org作为实体类别的分类体系，这里有很多标注数据充足的大类，也有很多缺乏标注数据的小类，如何保证在小类上的识别准确率。此外，分类体系是有层次结构的，如何保证底层的细粒度类别上有令人满足的识别率。&lt;strong&gt;例句“我想听一首海阔天空”中的“海阔天空”通过NER任务可以识别为是一个音乐作品。&lt;/strong&gt;仅仅这样是无法执行对话意图“音乐点播”的，我们需要进一步将候选链接到知识图谱中的给定实体，这一过程称为Entity Linking。这里的核心在于歧义消解，一般借助于候选周围的其他实体或用语作为上下位来帮助去歧义。如果如例子所示，仍然无法明确是哪个实体，可通过反问来引导用户来给出更明确的实体指引。在实体链接过程中，我们所面临的挑战在于如何应对新兴实体（Emerging Entity）和实体的新兴说法（各种新说法和别名）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;聊天机器人依赖于NLP，而大量NLP任务可转换为有监督的分类或序列标注问题&lt;/strong&gt;。我们往往会为特定任务下标注数据的缺乏或不充足而发愁，这一点在利用深度学习时尤为严重。这时，也将推出&lt;strong&gt;知识图谱的第二个典型应用，叫做数据增强，也就是说 Data Augmentation。&lt;/strong&gt;具体来说，通过将知识图谱与文本语料库关联，形成大量弱标注数据。这在关系抽取或事件抽取等任务上应用广泛。例如，对于三元组&amp;lt;琥珀，喜欢吃，葡萄&amp;gt;，通过一定的泛化，我们将琥珀转换为PERSON，即在Web上收集PERSON和葡萄共现的描述片段，这些描述片段可能代表人物喜欢吃葡萄的特定模式（蓝色例句），也可能代表噪声（红色）。如何通过聚类分析中的异常点检测或噪声建模等方式将弱标注语料中的噪声识别并剔除。当然，包含一定比例的随机噪声，对于模型训练是一定帮助的，可以保证模型具有一定的泛化能力和鲁棒性。使用Web作为关联的语料库，主要看中Web上描述比较多样化，且信息具有冗余性，可以在保证覆盖率的同时确保数据的分布贴近真实情况。然而对于以语音作为主要交互方式的口语化聊天对话场景，我们仍然需要考虑从Web语料上学习到的模式或训练得到的模型如何进一步迁移适配。&lt;/p&gt;

&lt;p&gt;第三个应用就是&lt;strong&gt;知识问答（KB-QA）。其中句理解的难点在于NLU，而候选答案生成则与检索过程关联，至于答案融合和排序，则重点考虑各种基于证据的收集和学习排序算法。&lt;/strong&gt;这里我们看一个真实的例子，比如说“你觉得胡海泉这个人怎么样？”，这是一个意见询问类查询（opinion query），此时可以有很多回答，为了使得答案的多样化，除了利用摘要技术（summarization）从百科站点中得到“胡海泉是个歌坛巨星呀”之外，通过机器人KG中的经纪人关系，可以显式表明琥珀和他的关系。更进一步，可以通过琥珀记忆和技能关联，主动推荐“海泉给琥珀写的歌”。当用户给予明确的回复时，将表演自己的才艺，即唱自己的歌。在我们所描述的知识图谱下支持问答，需要额外考虑：&lt;/p&gt;

&lt;p&gt;1）如何统一对实体、问句、图像、上下文进行统一的表示，映射到同构的语义空间中？
2）知识库永远不可能是完备的，如何从KB-QA扩展到支持知识库和Web的混合QA场景下，并提供精准的数据源选择和语义解析？
3）如何评估问句的复杂程度，并从单一知识库查询扩展到多知识库查询？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;知识问答中非常有挑战的是Multi-KB环境下的问答。&lt;/strong&gt;这对问句分解和知识源选择等都提出了更高的要求。更有挑战的是：不仅仅一句很复杂的话会涉及多个KB，即使对于很简单的话，往往在聊天的多轮交互中，会逐步涉及不同方面的KB，甚至需要在某个看似不经意的回复中用到某个KB。在研制小白的多轮对话中，需要考虑属性询问、反问、记忆、反馈、基于跨库属性比对后的评论，基于上下文的问答、事实类知识图谱查询、对复杂问题的导流、推理联想，调教以及用户类知识图谱的查询等。例子“我靠，居然比姚明还高”就是一个多知识库问答之后的回复生成。其中，姚明身高属于事实类知识库、“我靠”等惊讶的回复，是通过常识知识库了解到很少有人身高超过2.26米，而通过用户个人知识，其身高数值比姚明还高，而返回“比姚明还高”的回复片段，最后通过融合，得到最终的返回。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第四个KG的应用就是联想和推理。这里我列举了三种推理，但实际情况下不局限于这三种。第一种是空间推理，比如说“桌子上面有电脑，电脑旁边有水杯”，然后问，“桌子上面有什么”，正确的回答是电脑和水杯。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;桌子上有水杯是通过空间位置的判断得到的。空间推理在地理类问答和智能家居控制等应用中有非常广泛的应用。第二种是答案类型推理。答案类型（Answer Type）作为一种很重要的证据，对问答的准确性有很大的作用。这里的推理包括实例推理（如例子中乒乓球是一种运动）、上下位推理（白色家电是一种家电）和互斥推理（空调和电视没有交集）等。第三种是场景推理，即结合场景业务规则和相关常识知识进行一些联想。例如空调需要一定时间之后才能制冷，而用户在这段时间感到热时可以吃一些冷饮。除了这三类，冲突检测对于聊天机器人尤其是用户记忆很有价值。这里不仅包括前面提及的类别之间的互斥定义，还可以包括关系单值或数量约束，甚至形成很多由推理得到的事实和显式定义的事实组成的冲突关系链。这些对推理机的表达能力提出了更高的要求。&lt;/p&gt;

</description>
        <pubDate>Mon, 17 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/17/When-KG-meets-Chatbots.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/17/When-KG-meets-Chatbots.html</guid>
        
        
      </item>
    
      <item>
        <title>N Gram模型</title>
        <description>
</description>
        <pubDate>Sun, 16 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/16/N-Gram%E6%A8%A1%E5%9E%8B.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/16/N-Gram%E6%A8%A1%E5%9E%8B.html</guid>
        
        
      </item>
    
      <item>
        <title>Kbqa</title>
        <description>&lt;h1 id=&quot;kbqa&quot;&gt;KBQA&lt;/h1&gt;

&lt;h2 id=&quot;什么是kbqa&quot;&gt;什么是KBQA&lt;/h2&gt;

&lt;p&gt;知识库问答（knowledge base question answering,KB-QA）即给定自然语言问题，通过对问题进行语义理解和解析，进而利用知识库进行查询、推理得出答案。如下图所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/KBQA1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（注：该图片来自中科院刘康老师在知识图谱与问答系统前沿技术研讨会中的报告）&lt;/p&gt;

&lt;p&gt;与&lt;strong&gt;对话系统、对话机器人的交互式对话不同&lt;/strong&gt;，KB-QA具有以下特点：&lt;/p&gt;

&lt;p&gt;答案：回答的答案是知识库中的实体或实体关系，或者no-answer（即该问题在KB中找不到答案），当然这里答案不一定唯一，比如 中国的城市有哪些 。而对话系统则回复的是自然语言句子，有时甚至需要考虑上下文语境。&lt;/p&gt;

&lt;p&gt;评价标准：回召率 (Recall)，精确率 (Precision) ，F1-Score。而对话系统的评价标准以人工评价为主，以及BLEU和Perplexity。&lt;/p&gt;

&lt;h2 id=&quot;知识库问答的主流方法&quot;&gt;知识库问答的主流方法&lt;/h2&gt;

&lt;p&gt;传统的主流方法可以分为三类：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;语义解析（Semantic Parsing)&lt;/strong&gt;：该方法是一种偏linguistic的方法，主体思想是&lt;strong&gt;将自然语言转化为一系列形式化的逻辑形式（logic form）,通过对逻辑形式进行自底向上的解析，得到一种可以表达整个问题语义的逻辑形式，通过相应的查询语句（类似lambda-Caculus）在知识库中进行查询，从而得出答案。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;信息抽取（Information Extraction）&lt;/strong&gt;：该类方法通过提取问题中的实体，通过在知识库中查询该实体可以得到以该实体节点为中心的知识库子图，子图中的每一个节点或边都可以作为候选答案，通过观察问题依据&lt;strong&gt;某些规则或模板&lt;/strong&gt;进行信息抽取，得到问题&lt;strong&gt;特征向量,也就是一个带有该问题特征的一个向量&lt;/strong&gt;，建立分类器通过输入问题特征向量对候选答案进行筛选，从而得出最终答案。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;向量建模（Vector Modeling）&lt;/strong&gt;: &lt;strong&gt;该方法思想和信息抽取的思想比较接近，&lt;/strong&gt;根据问题得出候选答案，把问题和候选答案都映射为分布式表达（Distributed Embedding），通过训练数据对该分布式表达进行训练，使得问题和正确答案的向量表达的得分（通常以点乘为形式）尽量高，得出最终答案。注意和信息抽取的不同在于这个方式是对候选回答和问题都进行向量建模，然后结合，得分最高的就为答案！&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;深度学习（Deep Learning）:这本身并不是一类方式，只是其中的方法&lt;/strong&gt;：比如使用卷积神经网络对向量建模方法进行提升,或者使用卷积神经网络对语义解析方法进行提升，或者使用长短时记忆网络（Long Short-Term Memory，LSTM），卷积神经网络（Convolutional Neural Networks，CNNs）进行实体关系分类。&lt;/p&gt;

&lt;p&gt;现在比较常用的是使用&lt;strong&gt;记忆网络（Memory Networks），注意力机制（Attention Mechanism）&lt;/strong&gt;进行KB-QA。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/KBQA2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（注：该图片来自中科院刘康老师在知识图谱与问答系统前沿技术研讨会中的报告）&lt;/p&gt;

&lt;h2 id=&quot;知识库问答的数据集&quot;&gt;知识库问答的数据集&lt;/h2&gt;

&lt;p&gt;KB-QA问题的Benchmark数据集——WebQuestion。&lt;/p&gt;

&lt;p&gt;该数据集由Berant J, Chou A, Frostig R, et al.在13年的论文Semantic Parsing on Freebase from Question-Answer Pairs中公开。&lt;/p&gt;

&lt;p&gt;作者首先使用Google Suggest API获取以wh-word（what，who，why，where，whose…）为开头且只包含一个实体的问题，以“where was Barack Obama born?”作为问题图谱的起始节点，以Google Suggest API给出的建议作为新的问题，通过宽度优先搜索获取问题。具体来讲，对于每一个队列中的问题，通过对它删去实体，删去实体之前的短语，删去实体之后的短语形成3个新的query，将这三个新query放到google suggest中，每个query将生成5个候选问题，加入搜索队列，直到1M个问题被访问完。如下图所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/KBQA.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（注：该图片来自Google Suggest）&lt;/p&gt;

&lt;p&gt;获取完问题后，随机选取100K个问题交给Amazon Mechanical Turk (AMT)的工人，让工人回答答案。注意，这里对答案进行了限制，让AMT的工人只能把答案设置为Freebase上的实体（entity），实体列表，值（value）或者no-answer。&lt;/p&gt;

&lt;p&gt;最终，得到了5,810组问题答案对，其词汇表包含了4,525个词。并且，WebQuestion还提供了每个答案对应知识库的主题节点（topic node）。&lt;/p&gt;

&lt;p&gt;可以看出WebQuestion的问题与freebase是不相关的，更加偏向自然语言，也更多样化。这里给出一些例子&lt;/p&gt;

&lt;p&gt;“What is James Madison most famous for?”&lt;/p&gt;

&lt;p&gt;“What movies does Taylor Lautner play in?”&lt;/p&gt;

&lt;p&gt;“What music did Beethoven compose?”&lt;/p&gt;

&lt;p&gt;“What kind of system of government does the United States have?”&lt;/p&gt;

&lt;h2 id=&quot;基于向量建模的kbqa&quot;&gt;基于向量建模的KBQA&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;该文章使用了卷积神经网络的一种变体（作者称为multi-column）从三个方面（答案路径Answer Path，答案上下文信息Answer Context，答案的类型Answer Type）对问题和答案的分布式表达进行学习，使得该分布式表达相比之前的向量建模方法能够包含更多有效的特征。&lt;/p&gt;

&lt;p&gt;首先是对于问题的向量化。对问题的向量化，传统向量建模方法采用了类似词袋模型的方式，相当于它并未考虑问题的语言顺序（比如 “谢霆锋的爸爸是谁？” 谢霆锋是谁的爸爸？ 这两个问题用该方法得到的表达是一样的，然而这两个问题的意思显然是不同的）。&lt;/p&gt;

&lt;p&gt;对于这个缺陷，我们可以使用深度学习的模型对问题进行向量化，比如使用循环神经网络（Recurrent Nerual Networks, RNNs）、卷积神经网络（Counvoulutional Nerual Networks, CNNs ）等模型提取问题特征，这样的方式考虑了语言的顺序，并且提取特征的能力也更加强大。&lt;/p&gt;

&lt;p&gt;第二个缺陷是，在对答案进行向量化的时候，直接将答案的路径（问题主题词到答案实体的路径）和上下文信息（答案实体周围的知识库子图）一起作为答案特征，通过multi-hot的方式对答案进行向量化。事实上，这样的形式不利于模型区分答案的特征（仅仅根据答案的multi-hot向量是不好区分哪些是答案的类型，哪些来自答案的上下文，哪些来自问题主题词到答案实体的路径）。&lt;/p&gt;

&lt;p&gt;因此我们可以将问题的特征表示拆解开，用三个向量分别表示答案的三个特征，即答案路径（Answer Path），答案上下文信息（Answer Context），答案类型（Answer Type），对于每一个答案特征向量，都用一个卷积网络去对问题进行特征提取，将提取出的分布式表达和该答案对应特征向量的分布式表达进行点乘，这样我们就可以得到一个包含三部分的得分函数：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/KBQA4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中q代表问题，a代表答案，f&lt;sub&gt;i&lt;/sub&gt;(q)代表问题经过卷积神经网络输出的分布式表达，g&lt;sub&gt;i&lt;/sub&gt;(a)表示答案在对应特征下的分布式表达。&lt;/p&gt;

&lt;p&gt;有了得分函数，我们就可以像向量建模方法一样，通过定义margin-based ranking损失函数对模型参数进行训练。&lt;/p&gt;

&lt;h2 id=&quot;基于记忆网络的kb-qa&quot;&gt;基于记忆网络的KB-QA&lt;/h2&gt;

&lt;p&gt;其整体思想是将知识库里的知识存储到记忆模块M中，问题经过输入模块I转化为分布式表达，输出模块O选择与问题最相关的支撑记忆（由于SimpleQustions的问题只依赖一个知识，所以只需要选择一条记忆），回答模块R将该记忆对应三元组的宾语作为最终答案输出。最后，为了测试记忆网络的泛化能力，在模型训练完毕后，我们将Reverb中提取的三元组,它的知识三元组是自然语言形式，如(“Obama”, “was also born in”, “August 1961”)，知识三元组抽取自ClueWeb）作为新的知识，用泛化模块G将新知识存储到记忆模块中，在不经过re-training的情况下使用该记忆回答问题，测试模型的泛化性能。&lt;/p&gt;
</description>
        <pubDate>Sat, 15 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/15/KBQA.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/15/KBQA.html</guid>
        
        
      </item>
    
      <item>
        <title>怎么做科研</title>
        <description>&lt;h1 id=&quot;怎么做科研&quot;&gt;怎么做科研？&lt;/h1&gt;

&lt;p&gt;昨天听了张振杰教授一个讲座，对于我这个科研小白来说，很有必要做一个总结，很多的道理虽然现在感受不深的，但也是可以即时思考，为之后的研究工作少犯错，犯低级错误而准备！&lt;/p&gt;

&lt;p&gt;结合教授的讲解和我一些理解。总结如下&lt;/p&gt;

&lt;h2 id=&quot;什么是好的科研工作&quot;&gt;什么是好的科研工作：&lt;/h2&gt;

&lt;p&gt;大道至简的具有终结性科研工作的:能用极简的方式发现和揭示事物运行的规律。&lt;strong&gt;布鞋院士李小文曾说过，“科学本身就应该追求简单性原则，任何事情都是越简单越好。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;引领方向的具有很强的启发性的科研工作:一项工作足以“指点江山、开创天地”，就像深度学习&lt;a href=&quot;https://arxiv.org/abs/1406.2661&quot;&gt;GAN&lt;/a&gt;在2014年提出，而自此开始，GAN就越来越火，原因就是GAN的思想极具启发性和创新性！&lt;/p&gt;

&lt;p&gt;填补空白的而又具有实用性的科研工作:发现了前人未发现之重要规律。需要强调的是，并不是所有填补空白的科研都是好工作，有的工作毫无意义，也就是毫无实用性的工作。&lt;/p&gt;

&lt;h2 id=&quot;课题的选择&quot;&gt;课题的选择&lt;/h2&gt;

&lt;p&gt;新瓶还是新酒?若新瓶代表的是研究对象，研究领域的新，新问题，新硬件，新应用。而新酒指的是研究方法的新，比如：新算法，新分析，新实现。那在选择自己的课题的时候，应该怎么权衡呢？&lt;/p&gt;

&lt;p&gt;首先是瓶子，也就是研究领域需要多新?当太早进入一个新领域的时候，你应该需要搞明白：&lt;strong&gt;1.这个课题会流行起来吗?2.这个课题会流行多久?&lt;/strong&gt;而当太晚的进入一个领域的时候，你应该需要知道：&lt;strong&gt;1.这个领域提高空间还有吗?2.剩下的问题还能解决吗?&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;寻找新瓶子或者新酒的几种思路&quot;&gt;寻找新瓶子或者新酒的几种思路：&lt;/h3&gt;

&lt;p&gt;应用扩展：当在寻找idea的时候，可以从应用驱动的角度去需找，举个例子：在2005年社交网络刚刚起来的时候，J Leskovec等人就抓住机遇，做了第一个在社交网络上构建等研究。发表了&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=1081893&quot;&gt;Graphs over time: densification laws, shrinking diameters and possible explanations&lt;/a&gt;。这个就是在应用的角度来需找idea。以应用上去需找灵感时，需要搞懂以下问题：&lt;strong&gt;1.实际应用是否非常需要,2.没有现成的解法,3.应用有多重要?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;适用性拓展：这个指的是我们在需找idea的时候，需要去思考，在之前的方法有无其局限性，然后其局限性在哪里？在找到其适用局限性之后试图扩展适用性，但同时需要搞清楚这样的扩展是不是有必要。&lt;/p&gt;

&lt;p&gt;维度拓展：依我之见，维度指的是领域的维度，维度拓展也就是在领域上的扩展，也就是在外部因素的改变时，比如现在的云计算、新硬件GPU的发展，我们能不能把之前算法不能处理的问题。比如在&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=1454152&quot;&gt;Mars: a MapReduce framework on graphics processors&lt;/a&gt;,就是在GUP刚刚火的时候，把MapReduce放到GPU那里去计算。&lt;/p&gt;

&lt;p&gt;交叉拓展：这个也就是我们是否可以把若干个概念的结合去做。当然，在这个时候就需要解决应用范围是否过窄的问题。&lt;/p&gt;

&lt;p&gt;总之：我们要&lt;strong&gt;多看一些不同领域的文章&lt;/strong&gt;，去了解了解不同领域的进展，了解工业界的进展。当然现在信息那么发达，我们可以轻松的去获得这样的知识，比如通过公众号，知乎等等！&lt;/p&gt;

&lt;h2 id=&quot;研究的手法&quot;&gt;研究的手法&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/life/howresearch.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上图：不是每一个工作都一定需要创新的技术，大部分成功的工作都是(新瓶,旧酒)或者(旧瓶,新酒)的组合。在我们研究的时候，也是说一定要新瓶又是新酒，更多的是在一个问题上找到一个新的方法，或者用一个方法去解决一个新的问题！&lt;/p&gt;

&lt;p&gt;下图是爱因斯坦的一句话，是值得科研人员思考的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/life/howresearch1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后我们要学会&lt;strong&gt;容忍失败&lt;/strong&gt;，这个道理虽然简单，但是对于我们人来说特别是高科研的人来说是真理。&lt;/p&gt;

&lt;p&gt;那我们肯定会问方法失败了怎么办?总结三点:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;理解失败的原因，算法、实现、假设，是在哪里出现了问题?&lt;/li&gt;
  &lt;li&gt;在这个方法失败之后，我们能不能换一个问题，怎么寻找问题，使用上面的方法比如交叉扩展，比如再增加假设。&lt;/li&gt;
  &lt;li&gt;最后，该放手就放手。虽然这个真的很难，俗话说，自己的idea，自己的工作，在自己看来，就像是自己的孩子一样的宝贵，轻易放弃绝非易事。但是及时放手也是一种智慧！&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;另外科研不要做的太Straighforward，科研就是存在很多不确定性的。对于计算机来说，如果你都知道你在之后特定的时间你能做成什么样子，那就不叫科研了，那应该叫做开发！&lt;/p&gt;

&lt;p&gt;最后我们在和导师或者同学讨论的时候，要多多做自我批评，很多人都是在讨论的时候会滔滔不绝的讲自己方法的正确性，当然，也许科学家都是有些偏执的，自己肯定要坚决认为自己方法的可行性。但是另一方面，在和别人有分歧式，真的要多做自己的反省。同时扩展自己的思路，做到从research到innovation。&lt;/p&gt;

&lt;h2 id=&quot;论文的发表&quot;&gt;论文的发表&lt;/h2&gt;

&lt;p&gt;在论文发表，首先是考虑投到哪里去？一定要顶级会议和期刊吗?答案是：是的。二三流的会议真的就像毒品一样，它可以让你充满自信，但也会让你的科研水平定格不高。当你一直都是发二三流的会议久，甚至也就只会，只能二三流的会议。&lt;/p&gt;

&lt;p&gt;当然，怎么知道自己的工作是否是A类的工作这个要和自己的老板商量。我觉得，最重要是那个心态，要有一个追求极至的心态，做到最好的心态，而不是有点成果就停止，开始发论文需求满足感。&lt;/p&gt;

&lt;p&gt;在投稿之后，那么很有可能是被拒的…这个时候结合审稿人的评语，当然，那些评语不一定真实，因为审稿人只会给出他觉得是拒绝你的最安全的理由，不一定就是真的理由。比如，你一开始假设就是错的，整篇论文在审稿人眼里真的是非常水，但他可能不会直说你的工作太烂了，而可能说你的实验做的不好被拒。所以在看审稿人的评语的时候，要客观的看。自己论文被拒要搞明白是否是实验的问题，假设的问题，数据的问题，甚至是写作的问题！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/life/howresearch2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;写作真的重要吗？是的，&lt;strong&gt;写作真的重要&lt;/strong&gt;。我们在写英文论文的时候，一定要写的明白，清晰。如上图，上面的那个例子给人第一感觉就是表达不清晰，&lt;em&gt;在中文中的会不能直接翻译成will，在这里使用将来时是不合适的&lt;/em&gt;。下面的那个例子就是在变量命名方面，那个ps最好改成一个英文字母或者拉丁字母比较好！当然，这个也不是一两天就能练成的，要多练。&lt;/p&gt;

&lt;h2 id=&quot;后续的发展&quot;&gt;后续的发展&lt;/h2&gt;

&lt;p&gt;若自己的论文被接受了，在参加会议或者其其他交流会的时候，这个是一个好的推销自己工作的时候。在演讲的时候要注意的是少一些套路，不要为了推销而推销，把自己的工作技术说的太详细，而是要多一些motivation。把自己的思路是如何产生的，如何想到的说多点。对听者也是很有启发性的，他们也很愿意听你的演讲！&lt;/p&gt;

&lt;p&gt;在参加各种会议的时候，多和同行交流，同时要注重海报，因为去会议的时候很多人都是先看海报的，那我们只有把海报做好，才能更好的推销自己的工作。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;怎么找个好问题，好方法，怎么知道自己的工作如何：这个就是要和你老板好好讨论&lt;/p&gt;

&lt;p&gt;怎么想个好方法，找到创新点：这个要多看多看点不同的论文，多用批判性的思维去思考问题！&lt;/p&gt;

&lt;p&gt;怎么写得一手好文章：这个就是要多写,唯手熟尔。&lt;/p&gt;

&lt;p&gt;怎么让方法变得实用：参加开源社区，开源自己的工作&lt;/p&gt;

</description>
        <pubDate>Fri, 14 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/14/%E6%80%8E%E4%B9%88%E5%81%9A%E7%A7%91%E7%A0%94.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/14/%E6%80%8E%E4%B9%88%E5%81%9A%E7%A7%91%E7%A0%94.html</guid>
        
        
      </item>
    
      <item>
        <title>Knowledge graph</title>
        <description>&lt;h1 id=&quot;knowledge-graph综述&quot;&gt;knowledge Graph综述&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;这篇主要是这篇：&lt;a href=&quot;http://tie.istic.ac.cn/ch/reader/create_pdf.aspx?file_no=201701002&amp;amp;flag=1&amp;amp;journal_id=qbgc&amp;amp;year_id=2017&quot;&gt;知识图谱研究进展&lt;/a&gt;的笔记的想法&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;详细引用请查看原文章&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;知识图谱的基础知识&quot;&gt;知识图谱的基础知识：&lt;/h2&gt;

&lt;p&gt;三元组是知识图谱的一种通用表示方式,即
G = (E,R,S) ,其中 E = {e&lt;sub&gt;1&lt;/sub&gt;,e&lt;sub&gt;2&lt;/sub&gt;…e&lt;sub&gt;|E|&lt;/sub&gt;} 是知识库中的&lt;strong&gt;实体&lt;/strong&gt;集合,共包含|E|种不同实体; R = {r&lt;sub&gt;1&lt;/sub&gt;, r&lt;sub&gt;2&lt;/sub&gt;…r&lt;sub&gt;|E|&lt;/sub&gt;}是知识库中的&lt;strong&gt;关系&lt;/strong&gt;集合,共包含|E|种不同关系;S ⊆ E × R × E 代表知识库中的三元组集合。三元组的基本形式主要包括实体1、关系、实体2和概念、属性、属性值等,实体是知识图谱中的最基本元素,不同的实体间存在不同的关系。概念主要指集合、类别、对象类型、事物的种类,例如人物、地理等;属性主要指对象可能具有的属性、特征、特性、特点以及参数,例如国籍、生日等;属性值主要指对象指定属性的值,例如中国、1988-09-08等。每个实体(概念的外延)可用一个全局唯一确定的ID来标识,每个属性-属性值对(attribute-value pair,AVP)可用来刻画实体的内在特性,而关系可用来连接两个实体,刻画它们之间的关联。&lt;/p&gt;

&lt;p&gt;就覆盖范围而言,知识图谱也可分为通用知识图谱和行业知识图谱。通用知识图谱注重广度,强调融合更多的实体,较行业知识图谱而言,其准确度不够高,并且受概念范围的影响,很难借助本体库对公理、规则以及约束条件的支持能力规范其实体、属性、实体间的关系等。通用知识图谱主要应用于智能搜索等领域。行业知识图谱通常需要依靠特定行业的数据来构建,具有特定的行业意义。行业知识图谱中,实体的属性与数据模式往往比较丰富,需要考虑到不同的业务场景与使用人员。&lt;/p&gt;

&lt;h2 id=&quot;构建知识图谱&quot;&gt;构建知识图谱&lt;/h2&gt;

&lt;p&gt;为了阐述如何构建知识图谱，本文给出了构建知识图谱的技术地图，该技术地图如图1所示。整个技术图主要分为三个部分，第一个部分是知识获取，主要阐述如何从&lt;strong&gt;非结构化、半结构化、以及结构化数据中获取知识&lt;/strong&gt;。第二部是数据融合，主要阐述如何将&lt;strong&gt;不同数据源获取的知识进行融合构建数据之间的关联&lt;/strong&gt;。第三部分是知识计算及应用，这一部分关注的是基于知识图谱计算功能以及基于知识图谱的应用。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 知识获取&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在信息社会，信息可以划分为两大类。一类信息能够&lt;strong&gt;用数据或统一的结构加以表示，我们称之为结构化数据&lt;/strong&gt;，如数字、符号；而另一类信息&lt;strong&gt;无法用数字或统一的结构表示&lt;/strong&gt;，如文本、图像、声音、网页等，我们称之为非结构化数据。结构化数据属于非结构化数据，是非结构化数据的特例&lt;/p&gt;

&lt;p&gt;在处理&lt;strong&gt;非结构化数据&lt;/strong&gt;方面，首先要对用户的非结构化数据&lt;strong&gt;提取正文&lt;/strong&gt;。目前的互联网数据存在着大量的广告，正文提取技术希望有效的过滤广告而只保留用户关注的文本内容。当得到正文文本后，需要&lt;strong&gt;通过自然语言技术识别文章中的实体。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实体识别通常有两种方法，一种是用户本身有一个知识库则可以使用实体链接将文章中可能的候选实体链接到用户的知识库上。另一种是当用户没有知识库则需要使用命名实体识别技术识别文章中的实体。若文章中存在实体的别名或者简称还需要构建实体间的同义词表，这样可以使不同实体具有相同的描述。在识别实体的过程中可能会用到分词、词性标注，以及深度学习模型中需要用到分布式表达如词向量。同时为了得到不同粒度的知识还可能需要提取文中的关键词，获取文章的潜在主题等。&lt;/p&gt;

&lt;p&gt;当用户获得实体后，则需要关注&lt;strong&gt;实体间的关系，我们称为实体关系识别，&lt;/strong&gt;有些实体关系识别的方法会利用句法结构来帮助确定两个实体间的关系，因此在有些算法中会利用依存分析或者语义解析。如果用户不仅仅想获取实体间的关系，&lt;strong&gt;还想获取一个事件的详细内容，&lt;/strong&gt;那么则需要确定事件的触发词并获取事件相应描述的句子，同时识别事件描述句子中实体对应事件的角色。&lt;/p&gt;

&lt;p&gt;在处理&lt;strong&gt;半结构化数据&lt;/strong&gt;方面，主要的工作是通过包装器学习半结构化数据的抽取规则。&lt;strong&gt;由于半结构化数据具有大量的重复性的结构，因此对数据进行少量的标注，&lt;/strong&gt;可以让机器学出一定的规则进而在整个站点下使用规则对同类型或者符合某种关系的数据进行抽取。最后当用户的数据存储在生产系统的数据库中时，需要通过ETL工具对用户生产系统下的数据进行重新组织、清洗、检测最后得到符合用户使用目的数据。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. 知识融合&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当知识从各个数据源下获取时&lt;strong&gt;需要提供统一的术语将各个数据源获取的知识融合成一个庞大的知识库。提供统一术语的结构或者数据被称为本体，本体不仅提供了统一的术语字典，还构建了各个术语间的关系以及限制。&lt;/strong&gt;本体可以让用户非常方便和灵活的根据自己的业务建立或者修改数据模型。通过数据映射技术建立本体中术语和不同数据源抽取知识中词汇的映射关系，进而将不同数据源的数据融合在一起。&lt;/p&gt;

&lt;p&gt;同时不同源的实体可能会指向现实世界的同一个客体，这时需要使用实体匹配将不同数据源相同客体的数据进行融合。不同本体间也会存在某些术语描述同一类数据，那么对这些本体间则需要&lt;strong&gt;本体融合技术把不同的本体融合。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最后融合而成的知识库&lt;strong&gt;需要一个存储、管理的解决方案&lt;/strong&gt;。知识存储和管理的解决方案会根据用户查询场景的不同采用不同的存储架构如 NoSQL 或者关系数据库。同时大规模的知识库也符合大数据的特征，因此需要传统的大数据平台如 Spark 或者 Hadoop 提供高性能计算能力，支持快速运算。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.知识计算及应用&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;知识计算主要是根据图谱提供的信息得到更多隐含的知识&lt;/strong&gt;，如通过本体或者规则推理技术可以获取数据中存在的隐含知识；而链接预测则可预测实体间隐含的关系；同时使用社会计算的不同算法在知识网络上计算获取知识图谱上存在的社区，提供知识间关联的路径；通过不一致检测技术发现数据中的噪声和缺陷。通过知识计算知识图谱可以产生大量的智能应用如可以提供精确的用户画像为精准营销系统提供潜在的客户；提供领域知识给专家系统提供决策数据，给律师、医生、公司 CEO 等提供辅助决策的意见；提供更智能的检索方式，使用户可以通过自然语言进行搜索；当然知识图谱也是问答必不可少的重要组建。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/knowledge_Graph.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上图可以看出，知识图谱涉及到的技术非常多，每一项技术都需要专门去研究，而且已经有很多研究成果。由于篇幅的限制，本文重点介绍知识图谱构建和知识计算的几个核心技术。&lt;/p&gt;

&lt;h2 id=&quot;实体关系识别技术&quot;&gt;实体关系识别技术&lt;/h2&gt;

&lt;p&gt;最初实体关系识别任务在 1998 年 MUC（Message Understanding Conference）中以 MUC-7 任务被引入，目的是通过填充关系模板槽的方式抽去文本中特定的关系。1998 后，在 ACE（Automatic Content Extraction）中被定义为关系检测和识别的任务；2009 年 ACE 并入 TAC (Text Analysis Conference)，关系抽取被并入到 KBP（knowledgeBase Population）领域的槽填充任务。从关系任务定义上，分为&lt;strong&gt;限定领域（Close Domain）和开放领域（Open IE）&lt;/strong&gt;；从方法上看，实体关系识别了&lt;strong&gt;从流水线识别方法逐渐过渡到端到端的识别方法。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;基于统计学的方法将从文本中识别实体间关系的问题转化为分类问题。&lt;/strong&gt;基于统计学的方法在实体关系识别时需要加入实体关系上下文信息确定实体间的关系，然而基于监督的方法&lt;strong&gt;依赖大量的标注数据&lt;/strong&gt;，因此半监督或者无监督的方法受到了更多关注。&lt;/p&gt;

&lt;h2 id=&quot;知识融合技术&quot;&gt;知识融合技术&lt;/h2&gt;

&lt;p&gt;知识融合（knowledge fusion）指的是将&lt;strong&gt;多个数据源抽取的知识进行融合。&lt;/strong&gt;与传统数据融合（datafusion）[29]任务的主要不同是，知识融合可能使用多个知识抽取工具为每个数据项从每个数据源中抽取相应的值，而数据融合未考虑多个抽取工具[30]。由此，知识融合除了应对抽取出来的事实本身可能存在的噪音外，还比数据融合多引入了一个噪音，就是不同抽取工具通过实体链接和本体匹配可能产生不同的结果。另外，知识融合还需要考虑本体的融合和实例的融合。&lt;/p&gt;

&lt;h2 id=&quot;实体链接技术&quot;&gt;实体链接技术&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;歧义性和多样性&lt;/strong&gt;是自然语言的固有属性，也是实体链接的根本难点。&lt;strong&gt;如何挖掘更多、更加有效的消歧证据，设计更高性能的消歧算法依然是实体链接系统的核心研究问题，&lt;/strong&gt;值得进一步研究。下面按照不同的实体消歧方法进行分类。&lt;/p&gt;

&lt;h2 id=&quot;知识推理技术&quot;&gt;知识推理技术&lt;/h2&gt;

&lt;p&gt;知识库推理可以粗略地分为&lt;strong&gt;基于符号的推理和基于统计的推理&lt;/strong&gt;。在人工智能的研究中，基于符号的推理一般是&lt;strong&gt;基于经典逻辑（一阶谓词逻辑或者命题逻辑）或者经典逻辑的变异（比如说缺省逻辑）&lt;/strong&gt;。基于符号的推理可以从一个已有的知识图谱，&lt;strong&gt;利用规则&lt;/strong&gt;，推理出新的实体间关系，还可以对知识图谱进行逻辑的冲突检测。基于统计的方法一般&lt;strong&gt;指关系机器学习方法，&lt;/strong&gt;通过统计规律从知识图谱中学习到新的实体间关系。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;知识图谱是知识工程的一个分支，以知识工程中语义网络作为理论基础，并且结合了机器学习，自然语言处理和知识表示和推理的最新成果，在大数据的推动下受到了业界和学术界的广泛关注。知识图谱对于解决大数据中文本分析和图像理解问题发挥重要作用。目前，知识图谱研究已经取得了很多成果，形成了一些开放的知识图谱。但是，知识图谱的发展还存在&lt;strong&gt;以下障碍。首先，虽然大数据时代已经产生了海量的数据，但是数据发布缺乏规范，而且数据质量不高，从这些数据中挖掘高质量的知识需要处理数据噪音问题。其次，垂直领域的知识图谱构建缺乏自然语言处理方面的资源，特别是词典的匮乏使得垂直领域知识图谱构建代价很大。最后，知识图谱构建缺乏开源的工具，目前很多研究工作都不具备实用性，而且很少有工具发布。通用的知识图谱构建平台还很难实现。&lt;/strong&gt;&lt;/p&gt;

</description>
        <pubDate>Thu, 13 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/13/knowledge-Graph.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/13/knowledge-Graph.html</guid>
        
        
      </item>
    
      <item>
        <title>Theano</title>
        <description>&lt;h1 id=&quot;theano&quot;&gt;theano&lt;/h1&gt;

&lt;h2 id=&quot;基本用法&quot;&gt;基本用法&lt;/h2&gt;

&lt;p&gt;在 theano 中学会定义矩阵 matrix 和功能 function 是一个比较重要的事, 我们在这里简单的提及了一下在 theano 将要运用到的东西.&lt;/p&gt;

&lt;p&gt;theano 和 tensorflow 类似，都是基于建立神经网络每个组件，在组件联系起来，数据放入组件，得到结果。&lt;/p&gt;

&lt;p&gt;首先, 我们这次需要加载 theano 和 numpy 两个模块, 并且使用 theano 来创建 function.&lt;/p&gt;

&lt;p&gt;import numpy as np
import theano.tensor as T
from theano import function
定义X和Y两个常量 (scalar)，把结构建立好之后，把结构放在function，在把数据放在function。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# basic&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dscalar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 建立 x 的容器&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dscalar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 建立 y 的容器&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;     &lt;span class=&quot;c&quot;&gt;#  建立方程&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 使用 function 定义 theano 的方程,&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 将输入值 x, y 放在 [] 里,  输出值 z 放在后面&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 将确切的 x, y 值放入方程中&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 5.0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;使用 theano 中 的 &lt;code class=&quot;highlighter-rouge&quot;&gt;pp (pretty-print)&lt;/code&gt; 能够打印出原始方程:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 
&lt;span class=&quot;c&quot;&gt;# (x + y)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;定义矩阵，以及利用矩阵做相关运算:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dmatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 矩阵 x 的容器&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dmatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 矩阵 y 的容器&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# 定义矩阵加法&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 定义方程&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; 
        &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
[[ 10.  11.  12.  13.]
 [ 14.  15.  16.  17.]
 [ 18.  19.  20.  21.]]
&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;搭建神经网络的一层&quot;&gt;搭建神经网络的一层&lt;/h2&gt;

&lt;p&gt;例如，以下的两行代码，就表示了一个具有两层神经元的神经网络：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# to define the layer like this:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nnet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;l2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其中，第一层网络我们命名为l1, 输入变量为inputs, 输入为1维，输出为10维，也就是说l, 含有10个神经元或节点； 激活函数为theano.tensor.nnet.relu函数, 当然我们也可以针对不同的问题选用别的函数, 例如theano.tensor.nnet.nnet.sigmoid。&lt;/p&gt;

&lt;p&gt;第二层网络的输入是第一层网络的输出l1.outputs, 所以输入的维度是10，输出是1维，激活函数我们采用one,也就是说我们采用默认的线形激活函数， l2层含有1个神经元，也就是网络的输出神经元。&lt;/p&gt;

&lt;p&gt;以上的代码，描述并构建了一个1-10-1的神经网络（inputs-l1-l2）。&lt;/p&gt;

&lt;p&gt;接下来我们来具体的实现Layer类的代码：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_function&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wx_plus_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation_function&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_function&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_function&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wx_plus_b&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wx_plus_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这段代码中，我们最关心的就是这个类的构造函数&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;def __init__(self, inputs, in_size, out_size, activation_function=None)&lt;/code&gt;
和之前的例子一致，我们采用了相同的输入变量名。&lt;/p&gt;

&lt;p&gt;接着，我们定义了W,b来代表该神经网络层的输入权值和偏置值，我们把W初始化为 由符合均值为0， 方差为1高斯分布的随机变量值组成的in_size-by-out_size的矩阵; b初始化为值为0.1的out_put-by-1的向量。 (当然，我们也可以采用不同的初始化方法，这里我们暂时不讨论初始化权值对最终神经网络训练的影响)。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;首先我们要计算所有神经元的输入矩阵, 也就是输入inputs与输入权值W的点乘（dot product）在加上偏置值b：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;self.Wx_plus_b = T.dot(inputs, self.W) + self.b&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;然后，我们需要根据我们构造神经层指定的激活函数类型activation_function,来计算神经层的输出向量。 这里我们假设如果activation_function是None， 那就是该层神经元采用线形输出；如果是其他Theano的激活函数，就把Wx_plus_b作为该层激活函数的输入，同时函数的输出即为神经层的输出：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation_function&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_function&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_function&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wx_plus_b&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wx_plus_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们就成功的定义了神经网络的最最重要的结构–神经层Layer。&lt;/p&gt;

&lt;h2 id=&quot;创建分类神经网络模型&quot;&gt;创建分类神经网络模型&lt;/h2&gt;

&lt;h4 id=&quot;导入模块并创建数据&quot;&gt;导入模块并创建数据&lt;/h4&gt;

&lt;p&gt;引入需要使用的Python包：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano.tensor&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;先定义一个功能，用来计算分类问题的准确率，即预测的类别中有多少是和实际类别一样的，计算出百分比。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;correct_prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;equal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;correct_prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;correct_prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;用 &lt;code class=&quot;highlighter-rouge&quot;&gt;randn&lt;/code&gt; 随机生成数据集。 D 中的 &lt;code class=&quot;highlighter-rouge&quot;&gt;input_values&lt;/code&gt; 是 400 个样本，784 个&lt;code class=&quot;highlighter-rouge&quot;&gt;feature&lt;/code&gt;。 &lt;code class=&quot;highlighter-rouge&quot;&gt;target_class&lt;/code&gt; 是有两类，0 和 1。 要做的是，用神经网络训练数据学习哪些输入对应 0，哪些对应 1.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;n&quot;&gt;rng&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;             &lt;span class=&quot;c&quot;&gt;# training 数据个数&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;feats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;         &lt;span class=&quot;c&quot;&gt;# input 的 feature 数&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 生成随机数: D = (input_values, target_class)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rng&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rng&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;建立模型&quot;&gt;建立模型&lt;/h4&gt;

&lt;p&gt;接下来，定义神经网络。&lt;/p&gt;

&lt;p&gt;先定义一个大的图片，编辑好图片的小部件，再把训练数据集放到图片中去自动地训练。&lt;/p&gt;

&lt;p&gt;定义 x 和 y，相当于 placeholder。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 定义 x y 容器&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dmatrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;x&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dvector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;初始化 weights 和 bias。 有多少 features 就生成多少个 weights， 今天只是用最基本的 input 和 output 层的神经网络，如果想用 hidden layer 可以参考上一节课的例子。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 初始化 weights and biases&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rng&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;w&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;b&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;定义激活函数，交叉熵。 p_1 是用 sigmoid 求的概率，输入越小，则概率值越接近 0，越大则越接近 1，等于 0 则值为 0.5. p_1 &amp;gt; 0.5 时，预测值为 True，即为 1。 然后计算针对每个 sample 的交叉熵 xent。 再计算整批数据的 cost，为了减小 overfitting，这里加入了 L1-正则化。 接下来可以计算 weights 和 bias 的梯度 gW, gb。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;p_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nnet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# sigmoid 激励函数&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;xent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 交叉熵&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# xent 也可以使用下面这个达到一样的效果&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# xent = T.nnet.binary_crossentropy(p_1, y) &lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# l2 正则化&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;激活网络&quot;&gt;激活网络。&lt;/h4&gt;

&lt;p&gt;学习率需要小于 1. 接下来定义两个函数 train 和 predict，方法和上一节课的类似。 outputs 可以输出两个 prediction 和交叉熵损失的平均值 xent.mean。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()],&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;训练模型&quot;&gt;训练模型&lt;/h4&gt;

&lt;p&gt;接下来训练模型。 用训练集的 feature 和 target 训练模型，输出预测值和损失 pred, err。 每 50 步打印一次损失和准确率。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;c&quot;&gt;# Training&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cost:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;accuracy:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])))&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最后打印出预测值与实际值进行比较。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;target values for D:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;prediction on D:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
cost: 11.677533008109728
accuracy: 0.52
cost: 6.1946164642562636
accuracy: 0.6175
cost: 3.012375762498935
accuracy: 0.725
cost: 1.3340537876600198
accuracy: 0.8275
cost: 0.4690120202455575
accuracy: 0.9075
...


target values for D:
[1 1 0 1 0 1 0 1 1 1 1 1 .....]

prediction on D:
[1 1 0 1 0 1 0 1 1 1 1 1 .....]
&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Wed, 12 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/12/theano.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/12/theano.html</guid>
        
        
      </item>
    
      <item>
        <title>Topic aware neural response generation </title>
        <description>&lt;h1 id=&quot;topic-aware-neural-response-generation&quot;&gt;Topic Aware Neural Response Generation&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;文中描述的 TA-Seq2Seq 模型的核心思想是通过&lt;strong&gt;引入 LDA 模型结合 Seq2Seq 模型&lt;/strong&gt;来产生更有信息含量、更为多样性及更话题相关的对话回答。&lt;/p&gt;

&lt;p&gt;其采用的思路是在现有的带 Attention 的 Encoder-Decoder 模型架构上，通过 &lt;strong&gt;joint输入信息的 attention 和 topic attention&lt;/strong&gt;来共同影响对话的回答的生成。&lt;/p&gt;

&lt;p&gt;主要思路是意图通过&lt;strong&gt;引入先验知识到 Seq2Seq 模型来产生更高质量的回答。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Topic_Aware_chat.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图就是它的模型架构。说下它的实现思路：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;topic 的获取&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Topic_Aware_chat.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;就是计算改topic下的词分布情况。&lt;/p&gt;

&lt;p&gt;第一	步：获取 topic word 的 embedding vector 用新浪微博语料训练 TwitterLDA 模型，算法是 collapsed Gibbs sampling。消息输入后，模型给出所属 topic，&lt;strong&gt;取该 topic 下的 top100 作为消息的 topic words，&lt;/strong&gt;删除通用词后，将这些 topic words 转为各自的向量表示。其中，每个 topic word 的向量是通过计算 topic word 在所有 topic 下的&lt;strong&gt;归一化频率得到的（文中 Eq. 4,&lt;/strong&gt;，每个 topic word 对应的 vector 维度取决与 LDA 模型设置的 topic 数量；&lt;/p&gt;

&lt;p&gt;第二步：通过 BiGRU 网络对输入消息做 encode得到一系列的h&lt;sub&gt;i&lt;/sub&gt;；&lt;/p&gt;

&lt;p&gt;根据第 1 步得到 input message 的 topic vector（&lt;strong&gt;也就是K&lt;sub&gt;i&lt;/sub&gt;&lt;/strong&gt;），结合第 2 步得到的 last hidden state（也就是h5），通过 MLP 网络和 softmax 层得到 topic attention，即得到了各 topic word 的权重；&lt;/p&gt;

&lt;p&gt;构造由 message attention 和 topic attention 联合影响的解码概率（文中 Eq. 6），该概率可突出 topic words 的作用。基于这个概率进行 token 解码；&lt;/p&gt;

&lt;p&gt;与标准的 seq2seq+attention 模型相比，TA-Seq2Seq 模型的解码过程由 ci 和 oi 共同参与，特别地，在解码第 1 个输出 token 时，c0 插入了先验 topic 信息，因此本文模型可以提高首次解码的质量，从而对整个解码结果的质量产生正向影响。 百度贴吧数据集上的实验结果表明，本文提出的 TA-Seq2Seq 模型达到了 state-of-the-art 的效果，优于 Li Jiwei 提出的 Seq2Seq-MMI 模型。&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;h3 id=&quot;topic-word-acquisition&quot;&gt;Topic word acquisition&lt;/h3&gt;

&lt;p&gt;Twitter LDA:&lt;/p&gt;

&lt;p&gt;topic 和 topic word 是使用文中说的 Twitter LDA 在微博数据集上训练得到的，训练完之后每个 topic 实际上就是由&lt;strong&gt;词分布表示&lt;/strong&gt;的，这里选择了词分布中概率最高的 100 个词作为这个 topic 的 topic words；2. 训练好之后，对于一个输入 X，可以根据这个模型判断 X 属于哪个 topic，然后选择对应的 topic words 送到后续的模型中产生 response。&lt;/p&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;
</description>
        <pubDate>Wed, 12 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/12/Topic-Aware-Neural-Response-Generation.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/12/Topic-Aware-Neural-Response-Generation.html</guid>
        
        
      </item>
    
      <item>
        <title>Emotional chatting machine </title>
        <description>&lt;h1 id=&quot;emotional-chatting-machine-emotional-conversation-generation-with-internal-and-external-memory&quot;&gt;Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;首次将情感因素引入了基于深度学习的生成式对话系统&lt;/strong&gt;，提出了基于记忆网络的情感对话系统 Emotional Chatting Machine (ECM) ，在传统的 Sequence to Sequence 模型的基础上，ECM 使用了静态的情感向量嵌入表示，动态的情感状态记忆网络和情感词外部记忆的机制，使得 ECM 可以根据用户的输入以及指定情感分类输出相应情感的回复语句。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Emotional Chatting Machine1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;模型的总体框架如上图所示，用户问题输入为“What a lovely day!”，通过 Encoder 将其编码为隐向量表示 h，然后通过注意力机制，&lt;strong&gt;结合 decoder 的状态向量 s 在生成不同的词时，对问题的隐向量表示 h 的不同部分的信息选择性的加强，得到向量 c。&lt;/strong&gt;指定情感类别为“Happiness”，经过索引得到&lt;strong&gt;情感类别嵌入向量，初始的情感状态记忆向量和相应的情感词表。&lt;/strong&gt;decoder接受经过注意力机制的&lt;strong&gt;问题向量 c，情感类别嵌入向量和初始的情感状态记忆向量作为输入&lt;/strong&gt;，通过循环神经网络生成下个词的生成概率 o，之后&lt;strong&gt;再经过情感词表对情感词和非情感词的加权&lt;/strong&gt;，得到最终词的生成概率，通过采样即可得到输出“Haha, so happy today!”。&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;
</description>
        <pubDate>Tue, 11 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/11/Emotional-Chatting-Machine.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/11/Emotional-Chatting-Machine.html</guid>
        
        
      </item>
    
      <item>
        <title>A knowledge Grounded neural conversation model </title>
        <description>&lt;h1 id=&quot;a-knowledge-grounded-neural-conversation-model&quot;&gt;A Knowledge-Grounded Neural Conversation Model&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;提出来一种新颖的，完全有数据驱动的，并且&lt;strong&gt;基于背景知识（knowledge-grounded）的神经对话模型。&lt;/strong&gt;该论文意在没有槽位填充下&lt;strong&gt;产生内容更加丰富的回应。&lt;/strong&gt;论文实验中以对话记录和外部的“事实”为条件，通过常见的seq2seq方法使模型在开放领域的设置中变的通用和可行。在人工测评中，论文的方法相&lt;strong&gt;比传统的seq2seq能输出更加丰富的信息。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;当前构建全数据驱动的对话模型所面临的的挑战是在已存在的对话数据库中，没有一个可以包括世界的所有知识。尽管这些数据库近年在不断的丰富，但和百科，评论或其他形式的数据相比还远远不够。&lt;/p&gt;

&lt;p&gt;为了吸收为了向回复中灌输和对话上下文相关的事实信息，我们提出了一种知识场模型（如下图）。首先我们有一个&lt;strong&gt;可用的world facts，&lt;/strong&gt;这是一个’原生’的文本实体（例如百科，评论），并&lt;strong&gt;以命名实体作为关键词进行索引&lt;/strong&gt;。然后在&lt;strong&gt;给定的对话历史或者source sequence S中，识别S的“focus”（即特征词）&lt;/strong&gt;。这些foucs可以被用于关键词匹配或更先进的方法中，例如实体链（entity linking）或命名实体识别。这样query就可以检索到所有上下文相关的facts： F = {f1, f2, f3, ….., fk}&lt;strong&gt;注意：这里检索到是一个fact是对应词袋的一个向量(但是这里的facts是句子)&lt;/strong&gt;。最后将对话对和相关的facts都喂到神经架构中去训练。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Knowledge-Grounded_dialogue.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;相比传统的seq2seq响应生成方法，这种知识场方法更具有综合性，因为它使我们&lt;strong&gt;关心的那些具有差异的实体不用去学相同的对话模型。（）&lt;/strong&gt;在实际中，即使给出一个在训练中没有出现过的实体（也就意味着在词典中也没有该实体），在这种情况下，我们的方法也能够依赖相关的facts来生成一个适当的响应。这也说明我们能够在不用重新训练整个模型的情况下通过facts来丰富我们的系统。&lt;/p&gt;

&lt;p&gt;我们通过&lt;strong&gt;多任务并发式的学习方法&lt;/strong&gt;将对话数据和场数据及少量的非正式交换（例如对“hi, how are you”的回应）自然的联系起来。其中的两种类型任务是我们多任务中最具特点的：&lt;/p&gt;

&lt;p&gt;（1）一个纯粹的会话任务，该任务使用无fact encoder的（S,R）获得模型。其中S表示对话记录，R表示响应回复；&lt;/p&gt;

&lt;p&gt;（2）另外一个任务使用（{f1,….,fk,S},R）训练样例来获得最终的模型。&lt;/p&gt;

&lt;p&gt;这种去耦合的两种训练条件有以下几种优势：首先，它允许我们先使用对话库来做预训练，再以预训练获得的模型为基础做多任务训练。再个，它能给我们灵活性的揭露不同类型的会话数据。最后，一个有趣的观点是可以在任务（2）中使用facts中的一条fact（R=fi）来替换响应，这就使得任务（2）更像一个自编码器（autoencoder），可以帮助模型产生更具丰富的内容。&lt;/p&gt;

&lt;h3 id=&quot;facts-encoder&quot;&gt;Facts Encoder&lt;/h3&gt;

&lt;p&gt;模型中的&lt;strong&gt;Facts Encoder与记忆网络模型&lt;/strong&gt;相似。记忆网络模型被广泛应用到QA中，通过保存在记忆中的事实来做推断。这篇使用&lt;strong&gt;组合记忆来塑造和一个指定问题相关的facts&lt;/strong&gt;。在我们案例中，当一个实体在对话中被提到，那么就会基于用户输入和对话历史对facts进行检索和加权并最终生成一个答案。&lt;/p&gt;

&lt;p&gt;在我们的适应性 记忆网络中，我们使用了一个RNN encoder将输入的sequence，&lt;strong&gt;注意在这里也就是query而不是facts&lt;/strong&gt;转化为一个&lt;strong&gt;向量&lt;/strong&gt;，而不是使用之前记忆网络中使用的词袋表示法。这能够使我们在输入的不同部分之间能够更好的&lt;strong&gt;利用词间的依赖性（inter lexical dependencies），并且能够使记忆网络模型（facts encoder）更加直接的适应Seq2Seq模型。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;p&gt;我们给出一个sentence集合S={s1,s2,s3,…..,sn}和一个fact集合F={f1,f2,…..,fk}。fact集合是和对话记录（即S）相关的。RNN encoder按token依次读入一条sequence，并更新它的隐藏状态（hidden state）。读入整条sequence后，RNN encoder的隐藏状态 u就是这条sequence的概要。通过使用一个RNN encoder， 我们可以获得源sequence更丰富的表示。
我们首先假设u是一个d维的向量，&lt;strong&gt;ri是fi的v维词袋&lt;/strong&gt;表示。基于记忆网络，我们有：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Knowledge-Grounded_dialogue1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（公式1，2，3是求解相关fact条目i的向量，公式4将所有相关facts向量整合，公式5是将相关的facts向量与encoder向量整合）
其中 A,C是记忆网络的参数。然后，不同于原来版本的记忆网络，我们使用了一个善于生成响应的RNN decoder。RNN的隐藏态使用&lt;code class=&quot;highlighter-rouge&quot;&gt;u^&lt;/code&gt;来初始化，而&lt;code class=&quot;highlighter-rouge&quot;&gt;u^&lt;/code&gt;整合了输入sequence和相关知识场，最后通过该隐藏态来预测响应sequence的逐词生成。&lt;/p&gt;

&lt;p&gt;为了替代公式5中的求和方式，我们也实验了串联方式，但求和方式的效果更好一些。&lt;strong&gt;(Weston et al., 2014)的记忆网络模型可以看做是一个多层结构。在该任务中，我们只用到了一层，因为不需要多层次的归纳。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;
</description>
        <pubDate>Sun, 09 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/07/09/A-Knowledge-Grounded-Neural-Conversation-Model.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/07/09/A-Knowledge-Grounded-Neural-Conversation-Model.html</guid>
        
        
      </item>
    
      <item>
        <title>VAE--Variational autoencoder</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#vaevariational-autoencoder&quot; id=&quot;markdown-toc-vaevariational-autoencoder&quot;&gt;VAE–Variational autoencoder&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#得到vae核心等式二&quot; id=&quot;markdown-toc-得到vae核心等式二&quot;&gt;得到VAE核心等式（二）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#得到vae核心等式理解二&quot; id=&quot;markdown-toc-得到vae核心等式理解二&quot;&gt;得到VAE核心等式（理解二）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#variational-auto-encoder&quot; id=&quot;markdown-toc-variational-auto-encoder&quot;&gt;Variational Auto-encoder&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#理解vae二&quot; id=&quot;markdown-toc-理解vae二&quot;&gt;理解VAE（二）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#为什么深度学习那么强大&quot; id=&quot;markdown-toc-为什么深度学习那么强大&quot;&gt;为什么深度学习那么强大&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;vaevariational-autoencoder&quot;&gt;VAE–Variational autoencoder&lt;/h1&gt;

&lt;p&gt;同GAN类似，其最重要的idea是基于一个令人惊叹的数学事实：对于一个目标概率分布，给定任何一种概率分布，总存在一个可微的可测函数，将其映射到另一种概率分布，使得这种概率分布与目标的概率分布任意的接近。&lt;/p&gt;

&lt;p&gt;可测函数之间的编解码？什么样的可测函数？可测函数是测度论中的概念，它是真实世界的随机事件到数学世界的随机事件的映射。&lt;/p&gt;

&lt;p&gt;在生成手写数字时，一个直观的方法是手工构造隐含因素（笔画粗细、笔尖的角度、写者的书写习惯等）的概率分布，但是现实是这些因素是无穷的，不能手工构造。VAE巧妙地避开了这个问题，利用一个联合高斯分布作为隐含可测函数的分布（这个隐含可测函数将上面所说的所有现实世界影响写字样式的隐含因素映射到欧式空间中去了），随即将问题转化为学习一个从隐含可测函数（隐含变量）到一个所希望生成样本的映射。&lt;/p&gt;

&lt;p&gt;后面我们会看到，这个过程就是解码过程。可以想象，这个映射会极为复杂。我们自然会想到利用深度学习强大的函数拟合能力来学习这个映射。如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中z是隐含变量（隐含可测函数），将其输入到某种解码器，输出f(z)，使得f(z)尽可能在保证样本多样性的同时与真实样本相似。&lt;/p&gt;

&lt;p&gt;但是如何通过学习得到这样的解码器呢？&lt;/p&gt;

&lt;h2 id=&quot;得到vae核心等式二&quot;&gt;得到VAE核心等式（二）&lt;/h2&gt;

&lt;p&gt;这就需要我们回归到目标函数中去考虑问题了。我们仅仅已知一些现成的样本S={x(i),i=1,…,m}，比如，回到我们的例子，我们仅仅已知0-9这些手写体图片的样本，希望生成一些具有多样性类似的样本。那么自然会想到利用极大似然法来估计可学习的参数Θ，即&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不失一般性，我们下面只针对单样本x进行讨论（略去其指标和可学习参数）。上面的似然函数仅仅是关于x的函数，我们需要想办法凑出隐变量z来。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;其中q(z&lt;/td&gt;
      &lt;td&gt;x)是给定样本下z的某一个条件概率分布。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;这一步变换值得深思，为什么选用一个条件概率分布呢，而不选用q(z)或者p(z&lt;/td&gt;
      &lt;td&gt;x)呢？&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;因为q(z)的选取范围太大，我们&lt;strong&gt;更感兴趣的是那些更有可能生成x的隐变量z&lt;/strong&gt;；关于p(z&lt;/td&gt;
      &lt;td&gt;x)，p(⋅)可以认为是真实的概率分布，我们很难得到，我们希望做的是通过q(⋅)去逼近p(⋅)，因此前者可以理解为某一种近似的概率分布。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;我们继续进行推导，&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们考查其中的第一项，利用贝叶斯公式&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;得到vae核心等式理解二&quot;&gt;得到VAE核心等式（理解二）&lt;/h2&gt;

&lt;p&gt;在这里讲的东西其实有另外一种解释，那种解释更加的容易理解，如下&lt;/p&gt;

&lt;p&gt;我们选择了KL散度这个指标用来衡量两者的相近程度。由于两边都是可以看作针对z的概率分布，因此用KL散度这个指标实际上非常合适。&lt;/p&gt;

&lt;p&gt;所以就有了：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder14.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们做一下贝叶斯公式的变换，就得到了：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder15.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;再将和z无关的项目从积分符号中拿出来，就得到了：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder16.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;variational-auto-encoder&quot;&gt;Variational Auto-encoder&lt;/h2&gt;

&lt;p&gt;左右整理一下，就得到了，这样我们就推导出VAE的一个核心等式，&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面可以开始建模了。由前面的讨论（利用一个联合高斯分布作为隐含可测函数的分布），&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;同样，q(z&lt;/td&gt;
      &lt;td&gt;x)和p(x&lt;/td&gt;
      &lt;td&gt;z)用联合高斯去建模，&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder.png7&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;自然地，问题就转化成了用神经网络学习四种映射关系。但是，即使做了这样的建模，对于DKL(q(z&lt;/td&gt;
      &lt;td&gt;x)&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;p(z&lt;/td&gt;
      &lt;td&gt;x))，我们仍然难以给出其闭式解（归一化因子是一个复杂的多重积分）。因此只能退而求其次，我们对其做缩放&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder8.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对对数似然的下界进行最大化。&lt;/p&gt;

&lt;p&gt;进一步推导，我们将前面建模的概率模型带入这个下界中去。注意到在实际实现过程中，为了简化起见，Λ(z)取与z无关的单位阵I，于是有&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder9.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最大化这个下界等价于最小化&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder10.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中Θ为四个待学习映射的可学习参数集合。&lt;/p&gt;

&lt;p&gt;至此，整个的学习框架就清晰了，如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder11.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结起来，&lt;strong&gt;整个训练框架就是在对样本x进行编解码。Q是将样本x编码为隐变量z，而P又将隐含变量z解码成f(z)，进而最小化重构误差&lt;/strong&gt;。训练的目的是学习出&lt;strong&gt;编码器的映射函数和解码器的映射函数&lt;/strong&gt;，所以训练过程实际上是在进行变分推断，即寻找出某一个函数来优化目标。因此取名为变分自编码器VAE(Variational Auto-encoder).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;什么叫做变分：变分其实就是一句话：用简单的分布q去近似复杂的分布p
就是选择合适的分布（函数）来逼近真实的后验概率分布（对于多个隐藏因子的情况，就是联合分布）。因为是概率分布，所以相似度或者距离就用KL值来表达。也因此，可以把这理解成一个泛函问题。所以它是一种Approximate Inference的方法。之所以approximate, 是因为这时Exact Inference计算复杂度太高（求后验概率的贝叶斯公式中分母的问题）。而Approximate的时候可以从特定的distribution family中选取q, 来方便计算。
大多数情况下后验分布很难求啊。如果后验概率好求解的话我们直接EM就搞出来了&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;关注具体实现的读者可能会发现在“解码器Decoder到μ(x)和Σ(x)”这个阶段从技术上没办法进行梯度反传。的确如此，上图只是作为帮助大家理解的示意图，而真正实现过程中，我们需要利用&lt;strong&gt;重参数化&lt;/strong&gt;这个trick，如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder12.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;重参数化这个名字听起来很神秘，其实就是基于下面的一个简单的数学事实： 
如果z∼N(μ,Σ)，那么随机变量z可以写成&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder13.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中ϵ∼N(0,I).&lt;/p&gt;

&lt;p&gt;利用重参数化这个trick，我们成功地规避了这个问题。&lt;/p&gt;

&lt;h2 id=&quot;理解vae二&quot;&gt;理解VAE（二）&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder16.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Variational_autoencoder17.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;为什么深度学习那么强大&quot;&gt;为什么深度学习那么强大&lt;/h2&gt;

&lt;p&gt;许多优秀的深度学习模型，它们达到了非常好的精度和效果。众人曾十分认真地分析过为什么这些模型的效果这么好，结论是深度模型的非线性拟合能力确实很强。不管曾经多么复杂的问题，一个深度模型出马，立刻把问题解决的八九不离十。
VAE也是利用了这个特点，我们用深度模型去拟合一些复杂的函数，从而解决实际问题。&lt;/p&gt;

</description>
        <pubDate>Mon, 05 Jun 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/06/05/VAE-Variational-autoencoder.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/06/05/VAE-Variational-autoencoder.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>End-to-End Task-Completion Neural Dialogue Systems</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#end-to-end-task-completion-neural-dialogue-systems&quot; id=&quot;markdown-toc-end-to-end-task-completion-neural-dialogue-systems&quot;&gt;End-to-End Task-Completion Neural Dialogue Systems&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#主要贡献&quot; id=&quot;markdown-toc-主要贡献&quot;&gt;主要贡献&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#论文背景&quot; id=&quot;markdown-toc-论文背景&quot;&gt;论文背景&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#网络结构原理&quot; id=&quot;markdown-toc-网络结构原理&quot;&gt;网络结构原理&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#算法流程和讲解&quot; id=&quot;markdown-toc-算法流程和讲解&quot;&gt;算法流程和讲解&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#实验过程和结果&quot; id=&quot;markdown-toc-实验过程和结果&quot;&gt;实验过程和结果（）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#related-work加上discussion&quot; id=&quot;markdown-toc-related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#文章解读和评价&quot; id=&quot;markdown-toc-文章解读和评价&quot;&gt;文章解读和评价&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;end-to-end-task-completion-neural-dialogue-systems&quot;&gt;End-to-End Task-Completion Neural Dialogue Systems&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;本文使用监督学习和强化学习的技术以端到端的方式训练完成任务型的对话系统，主要的贡献有以下三点：&lt;/p&gt;

&lt;p&gt;1.鲁棒性：本文提出一种神经对话系统，具有更强的鲁棒性，能够根据强化学习在&lt;strong&gt;未知的情况下&lt;/strong&gt;自动选择用户的动作；&lt;/p&gt;

&lt;p&gt;2.灵活性：允许用户在对话过程中发起对话，使用户可以更加灵活的与系统进行交互，；（也就是可以自己定义动作？，不太理解。。。）&lt;/p&gt;

&lt;p&gt;3.可重现性：本文演示了如何使用任务特定数据集并模拟用户以端到端方式评估RL对话代理，从而确保了系统的可重现性。有自己开源的代码，并且凸显出在各种任务上的都可以迁移。&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;系统框架：&lt;/p&gt;

&lt;p&gt;该系统主要由用户议程模型、自然语言生成模块、语义理解模块、对话管理模块几部分组成，系统框图如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/end_end_Task_Completion.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;1.用户议程模型&lt;/p&gt;

&lt;p&gt;在对话过程中，用户模拟器包含一个紧凑的类似与堆栈的表示，这就是用户的议程，在这过程中用户的状态s_{u} 作为议程A和目标G的决定因素，其中目标G是由限制集合C和请求集合R成。在时间为t的每一步时间段内，用户模拟器根据用户当前的状态s_{u,t} 和上一节点多用户代理的动作a_{m,t-1} 来预测下一用户的动作a_{u,t} 从而更新该时刻用户的状态s’_{u,t} 。&lt;/p&gt;

&lt;p&gt;2.自然语言生成（NLG）&lt;/p&gt;

&lt;p&gt;自然语言生成：即根据用户的对话行动，生成自然语言文本。为了控制给定有限的标记数据的用户模拟的质量，本文采用包括基于模板的NLG和基于模型的NLG的混合方法，其中基于模型的NLG使用序列到序列模型在标记的数据集上训练。它采用对话行为作为输入，并通过LSTM解码器产生具有插槽占位符的句子草图。然后执行后处理扫描，以将槽位占位符替换为它们的实际值。在LSTM解码器中，我们应用波束搜索，其在生成下一个令牌时迭代地考虑前k个最佳子句。&lt;/p&gt;

&lt;p&gt;在这个混合的模型中，如果用户对话的动作可以在预先设置的语句模板中找到的话，系统就是用基于模版的NLG，否则的话，系统就采用基于模型的NLG。这种混合的方法通过提供简单的模板从而提高了NLG的性能，而这正是机器学习不能够很好支持的地方。&lt;/p&gt;

&lt;p&gt;3.语意理解模块（LU）&lt;/p&gt;

&lt;p&gt;语言理解（LU）：LU的一个主要任务是自动将用户的查询域与该域中特定的意图一起分类，并在一组时隙中填充以形成语义帧。流行的IOB（in-out-begin）格式用于表示槽标签。LU组件由单个LSTM实现，该单个LSTM同时执行意图预测和槽缝填充。使用反向传播训练LSTM模型的权重以最大化训练集标签的条件似然概率。预测标签集是IOB格式槽标签和意图标签的级联集合；因此，可以使用监督方式在标记的数据集中使用所有可用的对话动作和对话对来训练该模型。IOB格式标签示例如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/end_end_Task_Completion01.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;4.对话管理模块（DM）&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;符号LU输出以对话行为形式（或语义帧）传递到DM。经典DM包括两个阶段，对话状态追踪和策略的学习。给定LU符号输出，形成查询以与数据库交互以检索可用结果。状态跟踪器将根据数据库的可用结果和最新的用户对话操作进行更新。然后跟踪器准备策略学习的状态表示，其中包括最近的用户动作，最新代理动作，数据库结果，转向信息以及历史对话轮次等。在从状态跟踪器输入的状态上，策略学习是生成下一个可用的系统动作\pi (s&lt;/td&gt;
      &lt;td&gt;a)。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;p&gt;端到端的强化学习：&lt;/p&gt;

&lt;p&gt;本文采用强化学习的方式，以端到端的训练方式，来学习得到系统的策略。策略决策方式采用DQN算法（Deep Q Learning），将用户的状态s_{t} 作为状态跟踪器的输入，输出Q(s_{t} ,a;\theta )。其中应用了DQN的两个重要的方法：目标网络的使用和经验池的回放（经验池的回放策略可以在对话的设置中进行改变）。&lt;/p&gt;

&lt;p&gt;在训练过程中，使用了\epsilon -greedy算法来进行探索和具有动态改变缓冲区大小的经验重放缓冲区。在每个模拟对话中，系统模拟N个对话并将这些状态转化为四元组(s_{t} ,a_{t} ,r_{t} ,s_{t+1} )添加到经验缓冲区中以用于训练。在一次模拟时隙中，当前的DQN网络将被更新许多次（根据batch的大小和当前经验缓冲区的大小）。在最后一次模拟时隙中，目标网络将被替换成当前的DQN网络。&lt;/p&gt;

&lt;p&gt;经验回放策略对于强化学习是十分重要的，因此该系统采用了一种热启动的方式来进行经验回放。一般来说，我们认为DQN的初始性能不足以产生良好的经验重放元组，一次我们不会将其放到经验池中，知道RL代理道道一定的成功率之后在放到经验池中（例如：可以先用规则的代理产生经验重放元组）。在每次的模拟中，该系统估计当前DQN代理的成功率（通过多次模拟用户），如果当前DQN代理由于目标网络，则经验回放缓冲池将被激活。&lt;/p&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;p&gt;实验和讨论：&lt;/p&gt;

&lt;p&gt;该系统是一个任务型对话系统，任务是帮助用户预定电影票。在对话过程中，对话系统收集用户的欲望信息，并最终预定电影票。然后环境基于（1）电影是否被预订以及（2）电影是否满足用户约束，在对话结束二元结果（成功或失败）。原始对话数据由Amazon Mechanical Turk得到，总共标记了280个对话，平均对话圈数约为11。&lt;/p&gt;

&lt;p&gt;在DM训练中进行了两组实验，即采用两种输入格式来训练RL代理：（1）语义帧：基于用户动作的语义帧训练或测试策略时，使用噪声信道用于模拟用户和代理之间的LU错误和噪声通信的噪声。（2）自然语言：当训练或测试自然语言层面的政策时，LU和NLG可能引入噪声。实验的结果如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/end_end_Task_Completion1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从结果来看，RL代理明显优于基于规则的代理，显示了神经对话系统的潜力，可以完成显示世界的任务，并通过与用户的交互自主的进行改进。此外对比两图可以看出端到端的系统达到稳定需要更长的时间来适应LU和NLG的噪声，这表明维持系统的鲁棒性的困难。而该系统与上述困难一致的增长趋势也更好的表明了该系统在现实生活应用情境下的鲁棒性。&lt;/p&gt;

&lt;p&gt;系统得到的对话结果如下（基于规则的代理和RL代理）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/end_end_Task_Completion2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;p&gt;之前的end to end，比如基于Memory network的那个模型，因为他们是sl来训练的，这样就需要大量的数据，不然就很容易过拟合。&lt;/p&gt;

&lt;p&gt;本文提出了一种端到端学习框架，用于任务完成对话系统。 我们的实验表明，强化学习系统的性能优于基于规则的代理，并具有更好的鲁棒性，以允许在真实世界任务完成方案中与用户进行自然交互。&lt;/p&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;
</description>
        <pubDate>Fri, 02 Jun 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/06/02/End-to-End-Task-Completion-Neural-Dialogue-Systems.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/06/02/End-to-End-Task-Completion-Neural-Dialogue-Systems.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Learning End-to-End Goal-Oriented Dialog</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#learning-end-to-end-goal-oriented-dialog&quot; id=&quot;markdown-toc-learning-end-to-end-goal-oriented-dialog&quot;&gt;Learning End-to-End Goal-Oriented Dialog&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#主要贡献&quot; id=&quot;markdown-toc-主要贡献&quot;&gt;主要贡献&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#论文背景&quot; id=&quot;markdown-toc-论文背景&quot;&gt;论文背景&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#网络结构原理&quot; id=&quot;markdown-toc-网络结构原理&quot;&gt;网络结构原理&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#算法流程和讲解&quot; id=&quot;markdown-toc-算法流程和讲解&quot;&gt;算法流程和讲解&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#实验过程和结果&quot; id=&quot;markdown-toc-实验过程和结果&quot;&gt;实验过程和结果（）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#related-work加上discussion&quot; id=&quot;markdown-toc-related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#文章解读和评价&quot; id=&quot;markdown-toc-文章解读和评价&quot;&gt;文章解读和评价&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;learning-end-to-end-goal-oriented-dialog&quot;&gt;Learning End-to-End Goal-Oriented Dialog&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;这篇论文主要是讲解了End-to-End 模型（基于Memory）在Goal-Oriented Dialog system的的优缺点。并用 restaurant reservation来进行说明。 提出（1）favors reproducibility and comparisons, and （2） is lightweight and easy to use的模型标准。在传统的每一小部分（具体如下图）都用上把bAbI tasks use that to gauge the strengths and weaknesses of current end-to-end systems with no domain knowledge.而不是改进模型。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/End_Goal_Oriented_Dialog.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;也就是说：这个模型其实就是在验证Memory network 在dialogue systems 上也是有用的!&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Memory_network.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图是Memory network 的一个架构图。在QA方面，这个结构是比较有用的，体现出了其不错的性质。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Memory_network1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;p&gt;对话数据：文中所用数据并非全部为真实数据，有5个task都是simulated conversation. simulation的方法是，用43种pattern生成user utterance，用20种pattern生成bot utterance。（显然，和真实场景比还是太少了。。。）另一组真实task数据是从Dialog State Tracking Challenge的订餐数据中转过来的（并没有用数据中标注的dialog state）。
Database: 每个restaurant的property包括：{口味，地点，价格区间，桌子大小（int，不是list），地址，电话，打分}&lt;/p&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;p&gt;由于之前或者现在的模型大多是分成小部分的，也就是说其模型数据也是基于之前的模型的，很少可以直接用于end to end 训练的。&lt;/p&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;
</description>
        <pubDate>Sat, 27 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/27/Learning-End-to-End-Goal-Oriented-Dialog.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/27/Learning-End-to-End-Goal-Oriented-Dialog.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Deep Reinforcement Learning for Dialogue Generation</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#deep-reinforcement-learning-for-dialogue-generation&quot; id=&quot;markdown-toc-deep-reinforcement-learning-for-dialogue-generation&quot;&gt;Deep Reinforcement Learning for Dialogue Generation&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#主要贡献&quot; id=&quot;markdown-toc-主要贡献&quot;&gt;主要贡献&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#论文背景&quot; id=&quot;markdown-toc-论文背景&quot;&gt;论文背景&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#网络结构原理&quot; id=&quot;markdown-toc-网络结构原理&quot;&gt;网络结构原理&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#算法流程和讲解&quot; id=&quot;markdown-toc-算法流程和讲解&quot;&gt;算法流程和讲解&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#实验过程和结果&quot; id=&quot;markdown-toc-实验过程和结果&quot;&gt;实验过程和结果（）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#related-work加上discussion&quot; id=&quot;markdown-toc-related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#文章解读和评价&quot; id=&quot;markdown-toc-文章解读和评价&quot;&gt;文章解读和评价&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;deep-reinforcement-learning-for-dialogue-generation&quot;&gt;Deep Reinforcement Learning for Dialogue Generation&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;现在学术界中bot领域流行的解决方案是seq2seq，本文针对这种方案抛出两个问题：&lt;/p&gt;

&lt;p&gt;1、用MLE作为目标函数会导致容易生成类似于“呵呵呵”的reply，grammatical、safe但是没有营养，没有实际意义的话。&lt;/p&gt;

&lt;p&gt;2、用MLE作为目标函数容易引起对话的死循环，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Reinforcement_Dialogue.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;解决这样的问题需要bot框架具备以下的能力：&lt;/p&gt;

&lt;p&gt;1、整合开发者自定义的回报函数，来达到目标。&lt;/p&gt;

&lt;p&gt;2、生成一个reply之后，可以定量地描述这个reply对后续阶段的影响。&lt;/p&gt;

&lt;p&gt;所以，本文提出用&lt;strong&gt;seq2seq+增强学习（pg），设计了特殊的回报R，来生成对话&lt;/strong&gt;的思路来解决这个问题。&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;说到增强学习，就不得不提增强学习的四元素：&lt;/p&gt;

&lt;p&gt;Action：&lt;strong&gt;这里的action是指生成的reply，action空间是无限大的&lt;/strong&gt;，因为可以reply可以是任意长度的文本序列。&lt;/p&gt;

&lt;p&gt;State：这里的&lt;strong&gt;state是指[pi,qi]，即上一轮两个人的对话表示。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Policy：policy是指给定state之后各个action的概率分布。可以表示为：&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Reinforcement_Dialogue1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Reward：reward表示每个action获得的回报，本文自定义了三种reward。&lt;/p&gt;

&lt;p&gt;1.Ease of Answering：&lt;/p&gt;

&lt;p&gt;这个reward指标主要是说生成的reply一定是容易被回答的。本文用下面的公式来计算容易的程度：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Reinforcement_Dialogue2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其实就是&lt;strong&gt;给定这个reply之后，生成的下一个reply是dull的概率大小。这里所谓的dull就是指一些“呵呵呵”的reply&lt;/strong&gt;，比如“I don’t know what you are talking about”等没有什么营养的话，作者手动给出了这样的一个dull列表。&lt;/p&gt;

&lt;p&gt;2.Information Flow：&lt;/p&gt;

&lt;p&gt;生成的reply尽量和之前的不要重复。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Reinforcement_Dialogue3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里的h是bot的reply表示，i和i+1表示该bot的前后两轮。这个式子表示&lt;strong&gt;同一个bot两轮的对话越像reward越小。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;3.Semantic Coherence&lt;/p&gt;

&lt;p&gt;这个指标是用来&lt;strong&gt;衡量生成reply是否grammatical和coherent。&lt;/strong&gt;如果只有前两个指标，很有可能会得到更高的reward，但是生成的句子并不连贯或者说不成一个自然句子。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Reinforcement_Dialogue4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里采用&lt;strong&gt;互信息来确保生成的reply具有连贯性。最终的reward由这三部分加权求和计算得到。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;增强学习的几个要素介绍完之后，接下来就是如何仿真的问题，本文采用两个bot相互对话的方式进行。&lt;/p&gt;

&lt;p&gt;step 1 监督学习。将数据中的每轮对话当做target，将之前的两句对话当做source进行seq2seq训练得到模型，这一步的结果作为第二步的初值。&lt;/p&gt;

&lt;p&gt;step 2 增强学习。因为seq2seq会容易生成dull reply，如果直接用seq2seq的结果将会导致增强学习这部分产生的reply也不是非常的diversity，从而无法产生高质量的reply。所以，这里&lt;strong&gt;用MMI(Maximum Mutual Information，这里与之前Jiwei Li的两篇paper做法一致)来生成更加diversity的reply&lt;/strong&gt;，然后将生成最大互信息reply的问题转换为一个增强学习问题，这里的互信息score作为reward的一部分（r3）。用第一步训练好的模型来初始化policy模型，给定输入[pi,qi]，生成一个候选列表作为action集合，集合中的每个reply都计算出其MMI score，这个score作为reward反向传播回seq2seq模型中，进行训练。整个仿真过程如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Reinforcement_Dialogue5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;两个bot在对话，初始的时候给定一个input message，然后bot1根据input生成5个候选reply，依次往下进行，因为每一个input都会产生5个reply，随着turn的增加，&lt;strong&gt;这里设置的最多是5turn&lt;/strong&gt;，reply会指数增长，这里在每轮对话中，通过sample来选择出5个作为本轮的reply。&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;p&gt;接下来就是评价的部分，自动评价指标一共两个：&lt;/p&gt;

&lt;p&gt;1、对话轮数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Reinforcement_Dialogue6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;很明显，增强学习生成的对话轮数更多。&lt;/p&gt;

&lt;p&gt;2、diversity&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Reinforcement_Dialogue7.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;增强学习生成的词、词组更加丰富和多样。&lt;/p&gt;

&lt;p&gt;下图给出了一个MMI seq2seq与RL方法的对比结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Reinforcement_Dialogue8.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;RL不仅仅在回答上一个提问，而且常常能够提出一个新的问题，让对话继续下去，所以对话轮数就会增多。原因是，RL在选择最优action的时候回考虑长远的reward，而不仅仅是当前的reward。&lt;/p&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;p&gt;受这篇文章的启发&lt;a href=&quot;&quot;&gt; A network-based end-to-end trainable task-oriented dialogue system&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Continuously learning neural dialogue management&lt;/a&gt;这篇文章首次讲RL放于chatbot&lt;/p&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;

&lt;p&gt;本文是一篇探索性的文章，将seq2seq与RL整合在一起解决bot的问题是一个不错的思路，很有启发性，尤其是用RL可以将问题考虑地更加长远，获得更大的reward。用两个bot相互对话来产生大量的训练数据也非常有用，在实际工程应用背景下数据的缺乏是一个很严重的问题，如果有一定质量的bot可以不断地模拟真实用户来产生数据，将deep learning真正用在bot中解决实际问题就指日可待了。&lt;/p&gt;

&lt;p&gt;RL解决bot问题的文章在之前出现过一些，但都是人工给出一些feature来进行增强学习，随着deepmind用seq2seq+RL的思路成功地解决video games的问题，这种seq2seq的思想与RL的结合就成为了一种趋势，朝着data driven的方向更进一步。&lt;/p&gt;
</description>
        <pubDate>Sat, 27 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/27/Deep-Reinforcement-Learning-for-Dialogue-Generation.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/27/Deep-Reinforcement-Learning-for-Dialogue-Generation.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>End-to-end LSTM-based dialog control</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#end-to-end-lstm-based-dialog-control-optimized-with-supervised-and-reinforcement-learning&quot; id=&quot;markdown-toc-end-to-end-lstm-based-dialog-control-optimized-with-supervised-and-reinforcement-learning&quot;&gt;End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#主要贡献&quot; id=&quot;markdown-toc-主要贡献&quot;&gt;主要贡献&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#论文背景&quot; id=&quot;markdown-toc-论文背景&quot;&gt;论文背景&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#网络结构原理&quot; id=&quot;markdown-toc-网络结构原理&quot;&gt;网络结构原理&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#算法流程和讲解&quot; id=&quot;markdown-toc-算法流程和讲解&quot;&gt;算法流程和讲解&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#实验过程和结果&quot; id=&quot;markdown-toc-实验过程和结果&quot;&gt;实验过程和结果（）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#related-work加上discussion&quot; id=&quot;markdown-toc-related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#文章解读和评价&quot; id=&quot;markdown-toc-文章解读和评价&quot;&gt;文章解读和评价&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;end-to-end-lstm-based-dialog-control-optimized-with-supervised-and-reinforcement-learning&quot;&gt;End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;1.Dialogue的状态是隐藏在LSTM里了。这样可以Model非常多的状态。&lt;/p&gt;

&lt;p&gt;2.结合了传统的Supervised Learning的Tracking模式和RL的模式。&lt;/p&gt;

&lt;p&gt;3.模型是端到端训练，和传统的有很大的不同。&lt;/p&gt;

&lt;p&gt;4.程序员的接口定义得相对比较清晰。&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;文章的开头很有意思，先是从一个大家熟知的场景开始介绍，一个经验丰富的客服是如何带一个新入职的客服。四个阶段：&lt;/p&gt;

&lt;p&gt;1、告诉新客服哪些”controls”是可用的，比如：如何查找客户的信息，如何确定客户身份等等。
2、新客服从老客服做出的good examples中模仿学习。
3、新客服开始试着服务客户，老客服及时纠正他的错误。
4、老客服放手不管，新客服独自服务客户，不断学习，不断积累经验。&lt;/p&gt;

&lt;p&gt;本文的框架就是依照上面的过程进行设计的：&lt;/p&gt;

&lt;p&gt;1、开发者提供一系列备选的actions，包括response模板和一些API函数，用来被bot调用。(这个也就是需要外界给模型的一些数据)
2、由专家提供一系列example dialogues，用RNN来学习。
3、用一个模拟user随机产生query，bot进行response，专家进行纠正。
4、bot上线服务，与真实客户进行对话，通过反馈来提高bot服务质量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/supervised_reinforcement_dialog.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;three components of our model are a recurrent neural network; targeted and well-encapsulated software implementing domain-specific functions; and a language understanding module.&lt;/p&gt;

&lt;p&gt;共13步：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;用户提供Utterance（也就是一句话）。&lt;/li&gt;
  &lt;li&gt;从Utterance中提取Entity。 for example, identifying “Jason Williams” as a &lt;name&gt; entity&lt;/name&gt;&lt;/li&gt;
  &lt;li&gt;Entity Input模块从提取的Entity中Resolve数据库中具体的Entity。 in this example, it maps from the text “Jason Williams” to a specific row in a database&lt;/li&gt;
  &lt;li&gt;从（2）、（3）以及API Call，以及（10）模块的输出提取一组Feature Vector。&lt;/li&gt;
  &lt;li&gt;Feature Vector输入到LSTM里，输出一个Template Action的Distribution。&lt;/li&gt;
  &lt;li&gt;从Developer来的Code产生Action Mask，比如当电话号码还没Identity的时候要mask掉打电话操作。&lt;/li&gt;
  &lt;li&gt;把需要mask的action，概率置零。&lt;/li&gt;
  &lt;li&gt;重新把（7）的结果Re-normalize。&lt;/li&gt;
  &lt;li&gt;从Distribution中选出一个Action。（无RL模式下，选最大概率的action；有RL模式下，从概率分布里采样）&lt;/li&gt;
  &lt;li&gt;进入Entity Output模块，进行Entity替换。&lt;/li&gt;
  &lt;li&gt;如果现在的Action是API，那走（12）。如果是Text，就走（13）。&lt;/li&gt;
  &lt;li&gt;调用程序员写好的API接口。&lt;/li&gt;
  &lt;li&gt;返回文字(response)，等待用户再次输入。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;那么在这个系统中，分工如下是这样的。开发程序员，需要提供（6）、（12）、（13也就是response模板）以及Entity Input（3）和Entity Output（10）（这里也就是数据库）。领域专家需要提供少量（&lt;strong&gt;这里是20个，这样必然很容易过拟合，文中给的也是语法结构非常简单的样本&lt;/strong&gt;）对话样本。然后LSTM可以通过Supervised Learning的方法学习或者通过Reinforcement Learning中的Policy Gradient来进行交互式学习。&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;p&gt;在task-oriented dialog systems中，有两个主要的问题，分别是 state tracking和action selection。state tracking表示的是之前的关键信息，而action selection表示的在之后的一个行为选择，这两个步骤都涉及到了一些外部的数据&lt;/p&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;
</description>
        <pubDate>Sat, 27 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/27/End-to-end-dialog-control-optimized.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/27/End-to-end-dialog-control-optimized.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Chatbot</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chatbot&quot; id=&quot;markdown-toc-chatbot&quot;&gt;Chatbot&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#语料和词汇资源&quot; id=&quot;markdown-toc-语料和词汇资源&quot;&gt;语料和词汇资源&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#词性标注&quot; id=&quot;markdown-toc-词性标注&quot;&gt;词性标注&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#问答机器人&quot; id=&quot;markdown-toc-问答机器人&quot;&gt;问答机器人&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#提问处理模块&quot; id=&quot;markdown-toc-提问处理模块&quot;&gt;提问处理模块&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#检索模块&quot; id=&quot;markdown-toc-检索模块&quot;&gt;检索模块&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#答案抽取模块&quot; id=&quot;markdown-toc-答案抽取模块&quot;&gt;答案抽取模块&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#聊天机器人的关键技术&quot; id=&quot;markdown-toc-聊天机器人的关键技术&quot;&gt;聊天机器人的关键技术&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#分类&quot; id=&quot;markdown-toc-分类&quot;&gt;分类&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#goal-driven-dialog-system&quot; id=&quot;markdown-toc-goal-driven-dialog-system&quot;&gt;goal-driven dialog system&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#slu&quot; id=&quot;markdown-toc-slu&quot;&gt;SLU&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;chatbot&quot;&gt;Chatbot&lt;/h1&gt;

&lt;h2 id=&quot;语料和词汇资源&quot;&gt;语料和词汇资源&lt;/h2&gt;

&lt;p&gt;NLTK（开源中文自然语言处理工具包）包含多种语料库，也可以使用自己的语料库,具体的查看&lt;a href=&quot;http://www.shareditor.com/blogshow/?blogId=65&quot;&gt;NLTK语料库&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;词性标注&quot;&gt;词性标注&lt;/h2&gt;

&lt;p&gt;nltk提供了比较好的英文标注，中文的话只有繁体的，但中文中有比较强的一种叫做jiaba的分词工具，也可以做到词性标注的目的。当然也可以自动标注。
具体查看&lt;a href=&quot;http://www.shareditor.com/blogshow/?blogId=67&quot;&gt;词性标注&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;对于一句话有分词，词性标注，语法文法分析&lt;/p&gt;

&lt;h2 id=&quot;问答机器人&quot;&gt;问答机器人&lt;/h2&gt;

&lt;p&gt;有三个重要模块：提问处理模块、检索模块、答案抽取模块&lt;/p&gt;

&lt;h3 id=&quot;提问处理模块&quot;&gt;提问处理模块&lt;/h3&gt;

&lt;p&gt;查询关键词生成：查询关键词生成，就是从你的提问中提取出关键的几个关键词，因为我本身是一个空壳子，需要去网上查找资料才能回答你，而但网上资料那么多，我该查哪些呢？所以你的提问就有用啦，我找几个中心词，再关联出几个扩展词，上网一搜，一大批资料就来啦，当然这些都是原始资料，我后面要继续处理。&lt;/p&gt;

&lt;p&gt;答案类型确定：再说答案类型确定，这项工作是为了确定你的提问属于哪一类的，如果你问的是时间、地点，和你问的是技术方案，那我后面要做的处理是不一样的。&lt;/p&gt;

&lt;p&gt;句法和语义分析：最后再说这个句法和语义分析，这是对你问题的深层含义做一个剖析，比如你的问题是：聊天机器人怎么做？那么我要知道你要问的是聊天机器人的研发方法&lt;/p&gt;

&lt;h3 id=&quot;检索模块&quot;&gt;检索模块&lt;/h3&gt;

&lt;p&gt;检索模块跟搜索引擎比较像，就是根据查询关键词所信息检索，返回句子或段落，这部分就是下一步要处理的原料&lt;/p&gt;

&lt;h3 id=&quot;答案抽取模块&quot;&gt;答案抽取模块&lt;/h3&gt;

&lt;p&gt;答案抽取模块可以说是计算量最大的部分了，它要通过分析和推理从检索出的句子或段落里抽取出和提问一致的实体，再根据概率最大对候选答案排序，注意这里是“候选答案”噢，也就是很难给出一个完全正确的结果，很有可能给出多个结果，最后还在再选出一个来&lt;/p&gt;

&lt;h2 id=&quot;聊天机器人的关键技术&quot;&gt;聊天机器人的关键技术&lt;/h2&gt;

&lt;p&gt;1）海量文本知识表示：网络文本资源获取、机器学习方法、大规模语义计算和推理、知识表示体系、知识库构建；&lt;/p&gt;

&lt;p&gt;2）问句解析：中文分词、词性标注、实体标注、概念类别标注、句法分析、语义分析、逻辑结构标注、指代消解、关联关系标注、问句分类（简单问句还是复杂问句、实体型还是段落型还是篇章级问题）、答案类别确定；&lt;/p&gt;

&lt;p&gt;3）答案生成与过滤：候选答案抽取、关系推演（并列关系还是递进关系还是因果关系）、吻合程度判断、噪声过滤&lt;/p&gt;

&lt;p&gt;现在的主要是基于自然语言理解就是把浅层分析加上句法分析、语义分析都融入进来做的补充和改进。然后形成一个聊天机器人&lt;/p&gt;

&lt;h2 id=&quot;分类&quot;&gt;分类&lt;/h2&gt;

&lt;p&gt;对话系统按功能性分为goal-driven dialog system（比如功能机器人，Contana，出门问问）和open domain dialog system（比如闲聊机器人，小冰）。&lt;/p&gt;

&lt;p&gt;依据答案的不同数据来源，问答系统可划分为基于结构化数据的问答系统、基于自由文本的问答系统、以及基于问答对的问答系统。&lt;/p&gt;

&lt;p&gt;此外，按照答案的生成反馈机制划分，问答系统可以分为基于检索式的问答系统和基于生成式的问答系统。&lt;/p&gt;

&lt;h2 id=&quot;goal-driven-dialog-system&quot;&gt;goal-driven dialog system&lt;/h2&gt;

&lt;p&gt;（下面的图片来来自&lt;a href=&quot;http://home.cse.ust.hk/~kxmo/materials/SurveyTaskDS.pdf&quot;&gt;ppt&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;主要分成四个部分，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/chatbot.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在若是这样的一段话：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/chatbot1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面就是每个小任务的输入输出和作用：&lt;/p&gt;

&lt;h2 id=&quot;slu&quot;&gt;SLU&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/chatbot2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里现在的解决方式&lt;strong&gt;主要集中于slot-filling problem，因为 Intention Classification是比较简单的分类。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Slot-filling Method: CRF&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/chatbot3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/chatbot4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/chatbot5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后其实，在每一个阶段都是有很多不同的方法来达到一个比较好的结果，下面就是一览表。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/chatbot6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但随着end To end 的发展，现在也有一些模型是直接end To end的模式的。我做的话也应该是end to end的模式的。至于他们之间方法的比较详细请看下面的表&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/chatbot7.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/chatbot8.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 26 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/26/Chatbot.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/26/Chatbot.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Hybrid Code Networks</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#hybrid-code-networks-practical-and-efficient-end-to-end-dialog-control-with-supervised-and-reinforcement-learning&quot; id=&quot;markdown-toc-hybrid-code-networks-practical-and-efficient-end-to-end-dialog-control-with-supervised-and-reinforcement-learning&quot;&gt;Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#主要贡献&quot; id=&quot;markdown-toc-主要贡献&quot;&gt;主要贡献&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#论文背景&quot; id=&quot;markdown-toc-论文背景&quot;&gt;论文背景&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#网络结构原理&quot; id=&quot;markdown-toc-网络结构原理&quot;&gt;网络结构原理&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#算法流程和讲解&quot; id=&quot;markdown-toc-算法流程和讲解&quot;&gt;算法流程和讲解&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#实验过程和结果&quot; id=&quot;markdown-toc-实验过程和结果&quot;&gt;实验过程和结果（）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#related-work加上discussion&quot; id=&quot;markdown-toc-related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#文章解读和评价&quot; id=&quot;markdown-toc-文章解读和评价&quot;&gt;文章解读和评价&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;hybrid-code-networks-practical-and-efficient-end-to-end-dialog-control-with-supervised-and-reinforcement-learning&quot;&gt;Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;混合代码网络（HCN）最大的特色是在传统的&lt;strong&gt;端对端训练&lt;/strong&gt;中，通过软件编程引入领域知识模块和行为模板，&lt;strong&gt;仅需更少训练数据&lt;/strong&gt;，就取得同等甚至更优成绩。&lt;/p&gt;

&lt;p&gt;实验证明，HCN可以通过监督学习，强化学习或两者的混合进行优化。&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Hybrid_dialog.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;模型包含四部分：RNN, domain-specific software, domain-specific action templates, a conventional entity extraction module. 行为模板可以是文字对话或者调用API。&lt;/p&gt;

&lt;p&gt;下面介绍模型的工作流程:&lt;/p&gt;

&lt;p&gt;框架从步骤1输入对话开始，分别得到句子的词袋向量，句子的embedding；从实体抽取模块抽取实体，通过“实体追踪”模块追踪实体值，返回动作掩码（action mask），指示在当前时序中哪一个动作被允许执行，比如当目标电话号码未知时，打电话的API将会被禁止，动作掩码可以作为辨别动作有用的上下文特征。以上得到的特征向量拼接作为RNN的输入。RNN之后经过密连接层和softmax，输出向量维度为动作模板的数量，与Action mask点乘，结果的概率重新进行规范化。步骤12选择行为，如果训练用RL的探索模式，行为是所有可能的动作采样；否则挑选最大概率的动作执行。之后在“实体输出”模块，替换上具体实体值，组织回答句子；控制分支根据行为类别不同调用API或者返回文本应答，整个循环完成。&lt;/p&gt;

&lt;p&gt;现在的模型和之前不同的地方在于所使用的RNN不仅可以储存之前的状态和选择下一步的动作（也就是生成的下一个bot的对话动作），在HCN中，rnn使用 developer-provided 的action templates，这样可以降低模型的复杂度。&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;p&gt;非端到端在Task-oriented dialog systems中的缺点在于complexity，还有就是每个阶段的训练都需要specialized labels。&lt;/p&gt;

&lt;p&gt;但同时端到端的话lack a general mechanism for injecting domain knowledge and constraints。也就是领域知识很难被模型吸收。&lt;/p&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;
</description>
        <pubDate>Thu, 25 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/25/Hybrid-Code-Networks.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/25/Hybrid-Code-Networks.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>A network Based end To End trainable task Oriented dialogue system </title>
        <description>&lt;h1 id=&quot;a-network-based-end-to-end-trainable-task-oriented-dialogue-system&quot;&gt;A Network-based End-to-End Trainable Task-oriented Dialogue System&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/End_Network_Dialogue.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;1、Intent Network&lt;/p&gt;

&lt;p&gt;这个部分可以理解为seq2seq的encoder部分，将用户的输入encode成一个vector z&lt;sub&gt;t&lt;/sub&gt;。encoder部分分别用了lstm和cnn两种模型对该输入进行建模。这两种句子表示的方法在之前的文章中都有介绍。&lt;/p&gt;

&lt;p&gt;2、Belief Trackers&lt;/p&gt;

&lt;p&gt;这个部分又被称作是Dialogue State Tracking(DST)，是task-oriented bot的核心部件。本文的Belief Trackers具有以下的作用：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;支持各种形式的自然语言被映射成一个有限slot-value对集合中的元素，用于在数据库中进行query。&lt;/li&gt;
  &lt;li&gt;追踪bot的state，避免去学习那些没有信息量的数据。&lt;/li&gt;
  &lt;li&gt;使用了一种weight tying strategy，可以极大地减少训练数据的需求。&lt;/li&gt;
  &lt;li&gt;易扩展新的组件。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/End_Network_Dialogue1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个组件的输入时用户的input，&lt;strong&gt;输出是一个informable slot和requestable slot的概率分布&lt;/strong&gt;，这里的informable slot是指food，price range和area（以订餐为例），用来约束数据库中的查询，requestable slot是指address，phone，postcode等一些可以被询问的值。这里会定义一个针对具体task的知识图谱，来表示这些slot之间的关系，每个slot都会定义一个tracker，tracker的模型如上图所示，包括一个CNN&lt;strong&gt;特征提取模块&lt;/strong&gt;和一个Jordan型的RNN模块，&lt;strong&gt;CNN不仅仅对当前的input进行处理，还对上一轮的user input进行处理，综合起来作为RNN的输入。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这个组件的意义在于获取到预先定好的知识图谱中每个slot的分布，就是说弄清楚用户在这轮对话中的需求是哪个词或者词组。&lt;/p&gt;

&lt;p&gt;3、Database Operator&lt;/p&gt;

&lt;p&gt;数据库查询的输入来自于Belief Trackers的输出，即各种slot的概率分布，取最大的那个作为DB的输入，进行查询，获取到相应的值。&lt;/p&gt;

&lt;p&gt;4、Policy Network&lt;/p&gt;

&lt;p&gt;这个组件是像一个胶水，起到粘合其他上面三个组件的作用。输入是上面三个组件的输出，输出是一个向量。&lt;/p&gt;

&lt;p&gt;5、Generation Network&lt;/p&gt;

&lt;p&gt;最后一个组件是生成模型，本质上是一个语言模型，输入是Policy Network的输出，输出是生成的response，再经过一些处理之后可以返回给用户了。这里的处理主要是将response中的slot，比如s.food还原成真实的值。生成部分用简单的LSTM-LM可以做，用Attention Model也可以做，效果会更好。&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;p&gt;数据的准备这部分，利用了众包进行收集，一共采用了680轮对话作为训练数据，数据库中保存了99个饭馆，3个informable slots和7个requestable slots。
训练分为两个阶段，第一阶段是训练belief trackers，得到模型之后，更新参数，对生成网络中的语言模型进行训练，得到full model，batch size取1。
bot模型自动评价这块是一个非常难的事情，本文选择了BLEU score、entity matching rate和objective task success rate，本文模型均取得了不错的结果。另外，通过人工评价对本文模型和rule-based进行了对比，结果看下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/End_Network_Dialogue2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后paper给出了一种生成的句子向量的二维图，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/End_Network_Dialogue3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;几乎同一类话都被聚集到了相似的位置上，验证了模型的有效性。&lt;/p&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;

&lt;p&gt;开放域的bot只是根据query生成一句response，虽然质量可以做到很高，但实用价值不大。面向具体业务的闭域bot一直难以应用seq2seq的解决方案在于，无法将大量的专业信息建模到模型中来，包括：历史信息，用户身份信息，业务信息等等，本文打开了一扇窗，就是将具体的业务信息和历史信息加到了模型中，并且通过将对话中的slot词转换为一些slot表示，就好比构建了很多的模板，降低了对训练数据的需求，避免了seq2seq在应用时存在的问题。如果再考虑上Jiwei Li的那篇&lt;a href=&quot;https://arxiv.org/pdf/1603.06155.pdf&quot;&gt;A Persona-Based Neural Conversation Model&lt;/a&gt;,(&lt;a href=&quot;https://rsarxiv.github.io/2016/07/10/A-Persona-Based-Neural-Conversation-Model-PaperWeekly/&quot;&gt;解读&lt;/a&gt;)中对用户信息的建模，bot的实用价值就会更大，用data来解决真正的业务问题就会更进一步。&lt;/p&gt;
</description>
        <pubDate>Thu, 25 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/05/25/A-Network-based-End-to-End-Trainable-Task-oriented-Dialogue-System.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/05/25/A-Network-based-End-to-End-Trainable-Task-oriented-Dialogue-System.html</guid>
        
        
      </item>
    
      <item>
        <title>逆强化学习(二)--基于最大熵的方法</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#逆强化学习二基于最大熵的方法&quot; id=&quot;markdown-toc-逆强化学习二基于最大熵的方法&quot;&gt;逆强化学习(二)–基于最大熵的方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;逆强化学习二基于最大熵的方法&quot;&gt;逆强化学习(二)–基于最大熵的方法&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/2Inverse_Reinforcement.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/2Inverse_Reinforcement1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/2Inverse_Reinforcement2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/2Inverse_Reinforcement3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;参考文献：&lt;/p&gt;

&lt;p&gt;[1] Ziebart, B., Maas, A., Bagnell, A., and Dey, A. (2008). Maximum Entropy Inverse Reinforcement Learning. In Proceedings of The Twenty-third AAAI Conference on Arti cial Intelligence (AAAI’08), pages 1433-1438.&lt;/p&gt;

&lt;p&gt;[2] Boularias, A., Kober, J., and Peters, J. Relative entropy inverse reinforcement learning. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2011.&lt;/p&gt;
</description>
        <pubDate>Sat, 20 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/20/%E9%80%86%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0(%E4%BA%8C)-%E5%9F%BA%E4%BA%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E7%9A%84%E6%96%B9%E6%B3%95.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/20/%E9%80%86%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0(%E4%BA%8C)-%E5%9F%BA%E4%BA%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E7%9A%84%E6%96%B9%E6%B3%95.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>逆强化学习(一)--最大边际法</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#逆强化学习一最大边际法&quot; id=&quot;markdown-toc-逆强化学习一最大边际法&quot;&gt;逆强化学习(一)–最大边际法&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#什么是逆向强化学习&quot; id=&quot;markdown-toc-什么是逆向强化学习&quot;&gt;什么是逆向强化学习？&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#逆向强化学习的分类&quot; id=&quot;markdown-toc-逆向强化学习的分类&quot;&gt;逆向强化学习的分类&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#如何学习回报函数&quot; id=&quot;markdown-toc-如何学习回报函数&quot;&gt;如何学习回报函数？&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;逆强化学习一最大边际法&quot;&gt;逆强化学习(一)–最大边际法&lt;/h1&gt;

&lt;h2 id=&quot;什么是逆向强化学习&quot;&gt;什么是逆向强化学习？&lt;/h2&gt;

&lt;p&gt;前面我们已经讲过强化学习。强化学习是求累积回报期望最大时的最优策略，在求解过程中立即回报是人为给定的。然而，在很多任务中，尤其是&lt;strong&gt;复杂的任务中，立即回报很难指定。那么该如何得到这些回报函数呢？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;因为在利用强化学习算法的时候，我们都假设回报函数是人为给定的。回报函数如何给定呢？这有&lt;strong&gt;很强的主观性和经验性。&lt;/strong&gt;回报函数的不同会导致最优策略的不同。所以回报函数非常重要。但是当任务很复杂时，我们往往难以人为给出回报函数。比如在自动驾驶中，回报函数可能是信号灯、前面汽车，周边环境等各个因素的函数，我们很难人为给定这个回报函数。而且，在执行不同的任务时，回报函数也不同。所以，回报函数是阻碍强化学习算法得到普遍应用的一大障碍。&lt;strong&gt;逆向强化学习就是为解决学习回报函数的问题而提出来的。只有解决了这个问题，强化学习算法才能得到大规模应用。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们人类在完成复杂的任务时，根本就没考虑回报函数。但是，这并不是说人在完成任务时就没有回报函数。可以这么说，其实人在完成具体任务时&lt;strong&gt;有隐形的回报函数。&lt;/strong&gt;所以，一种指定回报函数的方法是从&lt;strong&gt;人的示例中学到隐形的回报函数。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;可是，这种回报函数怎么学呢？&lt;/p&gt;

&lt;p&gt;这就需要进行建模了。逆向强化学习的提出者Ng是这么想的：专家在完成某项任务时，其决策往往是最优的或接近最优的，那么可以这样假设，当所有的策略所产生的累积回报期望都不比专家策略所产生的累积回报期望大时，强化学习所对应的回报函数就是根据示例学到的回报函数。&lt;/p&gt;

&lt;p&gt;因此，&lt;strong&gt;逆向强化学习可以定义为从专家示例中学到回报函数。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;逆向强化学习的分类&quot;&gt;逆向强化学习的分类&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Inverse_Reinforcement.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果将最开始逆向强化学习的思想用数学的形式表示出来，那么这个问题可以归结为最大边际化问题。如图10.1所示，这是强化学习最早的思想。根据这个思想发展起来的算法包括：学徒学习（Apprenticeship learning）,MMP方法（Maximum Margin Planning）,结构化分类（SCIRL）和神经逆向强化学习（NIRL）.&lt;/p&gt;

&lt;p&gt;最大边际形式化的&lt;strong&gt;最大缺点是很多时候不存在单独的回报函数使得专家示例行为既是最优的又比其他任何行为好很多，或者有很多不同的回报函数会导致相同的专家策略，也就是说这种方法无法解决歧义的问题。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;基于概率模型的方法可以解决歧义性的问题。学者们利用概率模型又发展出了很多逆向强化学习算法，如最大熵逆向强化学习、相对熵逆向强化学习、最大熵深度逆向强化学习，基于策略最优的逆向强化学习等等。&lt;/p&gt;

&lt;h2 id=&quot;如何学习回报函数&quot;&gt;如何学习回报函数？&lt;/h2&gt;

&lt;p&gt;其实逆向强化学习来源于模仿学习。模仿学习本身是一个很大的主题。小孩子在学习走路的时候，模仿大人们进行学习。人在学习很多技能的时候都是从模仿开始的。但有人只模仿到了表面，而有人模仿到了精髓。最早的模仿学习是行为克隆，它只模仿到了表面。在行为克隆中，人的示例轨迹被记录下来，下次执行时恢复该轨迹。行为克隆的方法只能模仿轨迹，无法进行泛化。而&lt;strong&gt;逆向强化学习是从专家（人为）示例中学到背后的回报函数，能泛化到其他情况，因此属于模仿到了精髓。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Inverse_Reinforcement1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Inverse_Reinforcement2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Inverse_Reinforcement3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Inverse_Reinforcement4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Inverse_Reinforcement5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Inverse_Reinforcement6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Inverse_Reinforcement7.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Inverse_Reinforcement8.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 19 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/19/%E9%80%86%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/19/%E9%80%86%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Sequence To Sequence learning as beam Search optimization</title>
        <description>&lt;h1 id=&quot;sequence-to-sequence-learning-as-beam-search-optimization&quot;&gt;Sequence-to-Sequence Learning as Beam-Search Optimization&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;首先是seq2seq models的三个问题：&lt;/p&gt;

&lt;p&gt;(1)&lt;strong&gt;Exposure Bias&lt;/strong&gt;: the model is never exposed to its own errors during training, and so the inferred histories at test-time do not resemble the gold training histories.&lt;/p&gt;

&lt;p&gt;(2)**Loss-Evaluation Mismatch: **training uses a word-level loss, while at test-time we target improving sequence-level evaluation metrics, such as BLEU.&lt;/p&gt;

&lt;p&gt;(3)&lt;strong&gt;the concern of label bias:（标注偏置问题）&lt;/strong&gt;since word probabilities at each time-step are locally normalized, guaranteeing that successors of incorrect histories receive the same mass as do the successors of the true history.我的详细看&lt;a href=&quot;&quot;&gt;Conditional random fields: Probabilistic models for segmenting and labeling sequence data.&lt;/a&gt; –不理解&lt;/p&gt;

&lt;p&gt;在一定程度上解决了上面的三个问题：对于第一个问题是采用了一种新的网络结构。第二个问题和第三个问题就是采用beam search training scheme来解决的。这个用attention seq2seq对对比实验。&lt;/p&gt;

&lt;p&gt;也就是说：beam-search是全局解码算法，其实我们的目的是要得到概率最大的句子，很显然在每一步都取概率最大的词或者直接sample并不能保证最后生成的句子概率是最大的，这个其实是一个图上的最优路径问题，应该是一个动态规划问题而不是一个贪心问题，但是每一步解码时都会有词表大小这么多个节点，想要得到全局最优解搜索空间太大，所以采用beam-search来减少搜索空间，从而得到一个接近最优解的解&lt;/p&gt;

&lt;p&gt;注意这个approach的灵感来自&lt;a href=&quot;https://www.isi.edu/~marcu/papers/daume05laso.pdf&quot;&gt;Learning as Search Optimization: Approximate Large Margin Methods for Structured Prediction&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;p&gt;首先说明的是sqe2seq是 Encoder-decoder框架的一类&lt;a href=&quot;&quot;&gt;On the properties of neural machine translation: Encoder-decoder approaches.&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;p&gt;定义一个函数：&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Beam_Search.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;代表在t-1的hidden-state和input representation x的得分。在实验中 ，是除去了final softmax transforation (which transforms nnormalized scores into robabilities)。然后直接输出unnormalized scores，这样就解决了label bias problem。&lt;/p&gt;

&lt;p&gt;模型将会选择整体cores最高的序列。这里的方法借鉴了&lt;a href=&quot;&quot;&gt;LaSO-like&lt;/a&gt;，这个方法就叫做beam search optimization (BSO)&lt;/p&gt;

&lt;p&gt;论文首先是定义了Search-Based Loss，&lt;/p&gt;

&lt;p&gt;在实验中，首先是计算候选句子集合S中的得分。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Beam_Search1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后定义了全局的loss函数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Beam_Search2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了优化这个loss函数。这个算法分为两个部分，首先是Forward: Find Violations，找到候选句子集合S.然后是Backward: Merge Sequences。用反向传播的方式更新权重中&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Forward: Find Violations：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;下面的图解解释了在第一步是怎么找到候选句子s的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Beam_Search3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Backward: Merge Sequences&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;下面就是这个算法的整体：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Beam_Search4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;p&gt;文中用的是encoder和decode的框架模型，用了attention机制。然后作者在细节方面。首先是不能random initialization&lt;/p&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;
</description>
        <pubDate>Thu, 18 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/05/18/Sequence-to-Sequence-Learning-as-Beam-Search-Optimization.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/05/18/Sequence-to-Sequence-Learning-as-Beam-Search-Optimization.html</guid>
        
        
      </item>
    
      <item>
        <title>Pathwise DerivaMves (DPG,DDPG)</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#pathwise-derivamves-dpgddpg&quot; id=&quot;markdown-toc-pathwise-derivamves-dpgddpg&quot;&gt;Pathwise DerivaMves (DPG,DDPG)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;pathwise-derivamves-dpgddpg&quot;&gt;Pathwise DerivaMves (DPG,DDPG)&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Pathwise_DerivaMves.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Pathwise_DerivaMves1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Pathwise_DerivaMves3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Pathwise_DerivaMves4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Pathwise_DerivaMves5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 16 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/16/Pathwise-DerivaMves-(DPG,DDPG).html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/16/Pathwise-DerivaMves-(DPG,DDPG).html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title> professor forcing: a new algorithm for training recurrent networks</title>
        <description>&lt;h1 id=&quot;professor-forcing-a-new-algorithm-for-training-recurrent-networks&quot;&gt;Professor Forcing: A New Algorithm for Training Recurrent Networks&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;Teacher Forcing 算法通过将被观察到的序列值作为训练过程中的输入和使用该网络自己的提前一步的预测（one-step-ahead predictions）来进行多步采样（multi-step sampling）。我们在这里介绍 Professor Forcing 算法，其使用了对抗域适应（adversarial domain adaptation）来&lt;strong&gt;促进训练网络的动态（dynamics）在训练网络时和从网络中进行多个时间步骤的采样时一样&lt;/strong&gt;。将 Professor Forcing 应用到了语言建模、在原始波形的声音合成、手写生成和图像生成上。我们的实验表明 Professor Forcing 可用作正则化器（regularizer），其能提升在字符级 Penn Treebank 和序列的 MNIST 上的测试似然（test likelihood）。我们还发现该模型可以定性地改进样本，尤其是当要进行大量时间步骤的采样时。这也得到了人类对样本质量的评估的支持。&lt;strong&gt;讨论了 Professor Forcing 和 Scheduled Sampling 之间的权衡。我们产生了 T-SNE，表明 Professor Forcing 能成功使训练过程和采样过程中的网络动态更为相似。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;p&gt;By far the most popular training strategy is via the maximum likelihood principle. In the RNN literature, this form of training is also known as teacher forcing。参见这篇&lt;a href=&quot;https://arxiv.org/abs/1409.3215&quot;&gt;Sequence to Sequence Learning with Neural Networks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;teacher forcing有Exposure Bias的问题，然后在之后有很多论文都试图解决这个问题，其中&lt;a href=&quot;&quot;&gt;Scheduled sampling for sequence prediction with recurrent neural networks&lt;/a&gt;就是其中一个，但是Scheduled sampling导致的问题就是biased estimator。但这确实也有改进之前teacher forcing的问题。&lt;/p&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;这个网络收GAN的启发，&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Professor_Forcing.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先G网路has single hidden layer of gated recurrent units (GRU),&lt;/p&gt;

&lt;p&gt;然后D网络是bidirectional recurrent neural network。对于D网络MLP has three layers, each composing an affine transformation and a rectifier (ReLU). Finally, the output layer composes an affine transformation and a sigmoid that outputs D(b).&lt;/p&gt;

&lt;p&gt;在实验中，因为D网络太好或者太差都不利于判别G网络。所以在这个实验中，D网络只有在75%-99%的时候才有用。优化器用的是Adam algorithm&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;p&gt;对于D网络来说，它的loss函数是&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Professor_Forcing1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于maximize the likelihood网络，它的loss函数就是negative log-likelihood objective，如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Professor_Forcing2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于free-running model 它的loss函数是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Professor_Forcing3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;free-running model的loss函数或者就是这样的&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Professor_Forcing4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In our experiments we either perform stochastic gradient steps on NLL+Cf or on NLL+Cf+Ct
to update the generative RNN parameters, while we always do gradient steps on C d to update the discriminator parameters.&lt;/p&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;p&gt;在这篇论文中，说这样的方式就像一个regularizer，这种方式的话，收敛更加的快速，也更加的稳定。&lt;/p&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;
</description>
        <pubDate>Tue, 16 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/05/16/Professor-Forcing-A-New-Algorithm-for-Training-Recurrent-Networks.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/05/16/Professor-Forcing-A-New-Algorithm-for-Training-Recurrent-Networks.html</guid>
        
        
      </item>
    
      <item>
        <title>Policy Optimization</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#policy-optimization&quot; id=&quot;markdown-toc-policy-optimization&quot;&gt;Policy Optimization&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#强化学习分类&quot; id=&quot;markdown-toc-强化学习分类&quot;&gt;强化学习分类&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#策略搜索&quot; id=&quot;markdown-toc-策略搜索&quot;&gt;策略搜索&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#策略搜索的分类&quot; id=&quot;markdown-toc-策略搜索的分类&quot;&gt;策略搜索的分类&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cross-entropy-method&quot; id=&quot;markdown-toc-cross-entropy-method&quot;&gt;Cross Entropy Method&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;policy-optimization&quot;&gt;Policy Optimization&lt;/h1&gt;

&lt;h2 id=&quot;强化学习分类&quot;&gt;强化学习分类&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Optimization.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;策略搜索&quot;&gt;策略搜索&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Optimization1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在值函数的方法中，我们迭代计算的是值函数，然后根据值函数对策略进行改进；而在策略搜索方法中，我们直接对策略进行迭代计算，也就是迭代更新参数值，直到累积回报的期望最大，此时的参数所对应的策略为最优策略。&lt;/p&gt;

&lt;p&gt;在正式讲解策略搜索方法之前，我们先比较一下值函数方法和直接策略搜索方法的优缺点。其实正因为直接策略搜索方法比值函数方法拥有更多的优点，我们才有理由或才有动机去研究和学习及改进直接策略搜索方法：&lt;/p&gt;

&lt;p&gt;（1） 直接策略搜索方法是对策略进行参数化表示，与值函数方中对值函数进行参数化表示相比，策略参数化更简单，有更好的收敛性。&lt;/p&gt;

&lt;p&gt;（2） 利用值函数方法求解最优策略时，策略改进需要求解&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Optimization2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;，当要解决的问题动作空间很大或者动作为连续集时，该式无法有效求解。&lt;/p&gt;

&lt;p&gt;（3） 直接策略搜索方法经常采用的随机策略，能够学习随机策略。可以将探索直接集成到策略之中。&lt;/p&gt;

&lt;p&gt;当然与值函数方法相比，策略搜索方法也普遍存在一些缺点，比如：&lt;/p&gt;

&lt;p&gt;（1） 策略搜索的方法容易&lt;strong&gt;收敛到局部最小值。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;（2） 评估单个策略时并不充分，&lt;strong&gt;方差较大。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;策略搜索的分类&quot;&gt;策略搜索的分类&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Optimization3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;策略搜索方法按照是否利用模型可以分为无模型的策略搜索方法和基于模型的策略搜索方法。&lt;/p&gt;

&lt;p&gt;其中无模型的策略搜索方法根据策略是&lt;strong&gt;采用随机策略还是确定性策略分为随机策略搜索方法和确定性策略搜索方法。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;随机策略搜索方法最先发展起来的是策略梯度方法；然而策略梯度方法存在着学习速率难以确定等问题，为了解决这个问题学者们提出了基于统计学习的方法，基于路径积分的方法，回避学习速率问题。&lt;/p&gt;

&lt;p&gt;而TRPO并没有回避这个问题，而是找到了替代损失函数，利用优化方法局部找到使得损失函数单调的步长&lt;/p&gt;

&lt;h2 id=&quot;cross-entropy-method&quot;&gt;Cross Entropy Method&lt;/h2&gt;

&lt;p&gt;简单到不行，而且某些简单场景效果拔群，参见文章（Tetris是俄罗斯方块）
&lt;a href=&quot;http://nipg.inf.elte.hu/publications/szita06learning.pdf&quot;&gt;Learning Tetris with the Noisy Cross-Entropy Method&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;算法也很简单&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Optimization3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;意思就是，根据episodic的rewards排序，选top p%的policy parameters称之为elite set, 做gaussian distribution fitting，得到elite set的policy parameter的mean和variance。据此mean 和 variance产生新的一组policy parameter, 再做评估，选出top p%，以此类推。
&lt;strong&gt;采用evolution的思想，淘汰表现不好的策略，让表现好的策略繁衍出更好的策略，再做淘汰，以此类推，这就是CEM。&lt;/strong&gt;&lt;/p&gt;

</description>
        <pubDate>Mon, 15 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/15/Policy-Optimization.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/15/Policy-Optimization.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>pytorch基础</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#pytorch基础&quot; id=&quot;markdown-toc-pytorch基础&quot;&gt;pytorch基础&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#数据的读取&quot; id=&quot;markdown-toc-数据的读取&quot;&gt;数据的读取&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#dataloader&quot; id=&quot;markdown-toc-dataloader&quot;&gt;DataLoader&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#模型构建&quot; id=&quot;markdown-toc-模型构建&quot;&gt;模型构建&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#模型的算法训练&quot; id=&quot;markdown-toc-模型的算法训练&quot;&gt;模型的算法训练，&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#训练结果的保存及其可视化&quot; id=&quot;markdown-toc-训练结果的保存及其可视化&quot;&gt;训练结果的保存及其可视化&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;pytorch基础&quot;&gt;pytorch基础&lt;/h1&gt;

&lt;p&gt;在建立一个模型时。以我的理解来看，就是分为四个部分：数据的读取，模型的构建，模型的算法训练，训练结果的保存及其可视化，最后是对模型的泛化预测。所以下面就是按照这样的5个部分来记录怎么学习pytorch的。&lt;/p&gt;

&lt;h2 id=&quot;数据的读取&quot;&gt;数据的读取&lt;/h2&gt;

&lt;h3 id=&quot;dataloader&quot;&gt;DataLoader&lt;/h3&gt;

&lt;p&gt;DataLoader 是 torch 给你用来包装你的数据的工具. 所以你要讲自己的 (numpy array 或其他) 数据形式装换成 Tensor, 然后再放进这个包装器中. 使用 DataLoader 有什么好处呢? 就是他们帮你有效地迭代数据, 举例:&lt;/p&gt;

&lt;p&gt;举例说明：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
	&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manual_seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# reproducible&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;      &lt;span class=&quot;c&quot;&gt;# 批训练的数据个数&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;       &lt;span class=&quot;c&quot;&gt;# x data (torch tensor)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;       &lt;span class=&quot;c&quot;&gt;# y data (torch tensor)&lt;/span&gt;

	&lt;span class=&quot;c&quot;&gt;# 先转换成 torch 能识别的 Dataset&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;torch_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TensorDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_tensor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_tensor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

	&lt;span class=&quot;c&quot;&gt;# 把 dataset 放入 DataLoader&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;      &lt;span class=&quot;c&quot;&gt;# torch TensorDataset format&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;      &lt;span class=&quot;c&quot;&gt;# mini batch size&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;               &lt;span class=&quot;c&quot;&gt;# 要不要打乱数据 (打乱比较好)&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;num_workers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;              &lt;span class=&quot;c&quot;&gt;# 多线程来读数据&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# 训练所有!整套!数据 3 次&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 每一步 loader 释放一小批数据用来学习&lt;/span&gt;
			&lt;span class=&quot;c&quot;&gt;# 假设这里就是你训练的地方...&lt;/span&gt;

			&lt;span class=&quot;c&quot;&gt;# 打出来一些数据&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Epoch: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'| Step: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'| batch x: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
				  &lt;span class=&quot;n&quot;&gt;batch_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'| batch y: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

	&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
	Epoch:  0 | Step:  0 | batch x:  [ 6.  7.  2.  3.  1.] | batch y:  [  5.   4.   9.   8.  10.]
	Epoch:  0 | Step:  1 | batch x:  [  9.  10.   4.   8.   5.] | batch y:  [ 2.  1.  7.  3.  6.]
	Epoch:  1 | Step:  0 | batch x:  [  3.   4.   2.   9.  10.] | batch y:  [ 8.  7.  9.  2.  1.]
	Epoch:  1 | Step:  1 | batch x:  [ 1.  7.  8.  5.  6.] | batch y:  [ 10.   4.   3.   6.   5.]
	Epoch:  2 | Step:  0 | batch x:  [ 3.  9.  2.  6.  7.] | batch y:  [ 8.  2.  9.  5.  4.]
	Epoch:  2 | Step:  1 | batch x:  [ 10.   4.   8.   1.   5.] | batch y:  [  1.   7.   3.  10.   6.]
	&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看出, 每步都导出了5个数据进行学习. 然后每个 epoch 的导出数据都是先打乱了以后再导出.&lt;/p&gt;

&lt;p&gt;真正方便的还不是这点. 如果我们改变一下 BATCH_SIZE = 8, 这样我们就知道, step=0 会导出8个数据, 但是, step=1 时数据库中的数据不够 8个, 这时怎么办呢:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
	&lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;      &lt;span class=&quot;c&quot;&gt;# 批训练的数据个数&lt;/span&gt;

	&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
			&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Epoch: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'| Step: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'| batch x: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
				  &lt;span class=&quot;n&quot;&gt;batch_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'| batch y: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
	&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
	Epoch:  0 | Step:  0 | batch x:  [  6.   7.   2.   3.   1.   9.  10.   4.] | batch y:  [  5.   4.   9.   8.  10.   2.   1.   7.]
	Epoch:  0 | Step:  1 | batch x:  [ 8.  5.] | batch y:  [ 3.  6.]
	Epoch:  1 | Step:  0 | batch x:  [  3.   4.   2.   9.  10.   1.   7.   8.] | batch y:  [  8.   7.   9.   2.   1.  10.   4.   3.]
	Epoch:  1 | Step:  1 | batch x:  [ 5.  6.] | batch y:  [ 6.  5.]
	Epoch:  2 | Step:  0 | batch x:  [  3.   9.   2.   6.   7.  10.   4.   8.] | batch y:  [ 8.  2.  9.  5.  4.  1.  7.  3.]
	Epoch:  2 | Step:  1 | batch x:  [ 1.  5.] | batch y:  [ 10.   6.]
	&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这时, 在 step=1 就只给你返回这个 epoch 中剩下的数据就好了.&lt;/p&gt;

&lt;h2 id=&quot;模型构建&quot;&gt;模型构建&lt;/h2&gt;

&lt;p&gt;有两种方式：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
			&lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
			&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
			&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

		&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;net1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# 这是我们用这种方式搭建的 net1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面就是一般的构造神经网路模型的方式，就是创建一个类，然后的，在 __init__中构建好大概的骨架，然后在forward（）这个函数中选择用什么样的激活函数。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
Net (
  (hidden): Linear (1 -&amp;gt; 10)
  (predict): Linear (10 -&amp;gt; 1)
)
&quot;&quot;&quot;&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# net architecture&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
		&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;         &lt;span class=&quot;c&quot;&gt;# input shape (1, 28, 28)&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;              &lt;span class=&quot;c&quot;&gt;# input height&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;            &lt;span class=&quot;c&quot;&gt;# n_filters&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;              &lt;span class=&quot;c&quot;&gt;# filter size&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;                   &lt;span class=&quot;c&quot;&gt;# filter movement/step&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;                  &lt;span class=&quot;c&quot;&gt;# if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1&lt;/span&gt;
			&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;                              &lt;span class=&quot;c&quot;&gt;# output shape (16, 28, 28)&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;                      &lt;span class=&quot;c&quot;&gt;# activation&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# choose max value in 2x2 area, output shape (16, 14, 14)&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;         &lt;span class=&quot;c&quot;&gt;# input shape (1, 28, 28)&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;     &lt;span class=&quot;c&quot;&gt;# output shape (32, 14, 14)&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;                      &lt;span class=&quot;c&quot;&gt;# activation&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;                &lt;span class=&quot;c&quot;&gt;# output shape (32, 7, 7)&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# fully connected layer, output 10 classes&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# flatten the output of conv2 to (batch_size, 32 * 7 * 7)&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;CNN&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPool2d&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dilation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPool2d&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dilation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1568&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们会发现 cnn中 多显示的模型结构中，他把激励函数也一同纳入进去了, 但是 net1 中, 激励函数实际上是在 forward() 功能中才被调用的. 这也就说明了, 相比 cnn这种构造方式,output = cnn(b_x)               # cnn output net1 的好处就是, 你可以根据你的个人需要更加个性化你自己的前向传播过程, 比如(RNN). 不过如果你不需要七七八八的过程, 相信 类似cnn这种构造。形式更适合你.&lt;/p&gt;

&lt;h2 id=&quot;模型的算法训练&quot;&gt;模型的算法训练，&lt;/h2&gt;

&lt;p&gt;一般训练模型的模板代码如下：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cnn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# optimize all cnn parameters&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;                       &lt;span class=&quot;c&quot;&gt;# the target label is not one-hotted&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EPOCH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
		&lt;span class=&quot;o&quot;&gt;......&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;               &lt;span class=&quot;c&quot;&gt;# net output&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# cross entropy loss&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# clear gradients for this training step&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;                 &lt;span class=&quot;c&quot;&gt;# backpropagation, compute gradients&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;                &lt;span class=&quot;c&quot;&gt;# apply gradients&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;也就是选取优化器加上loss函数，然后在循环的时候计算梯度，进行反向传播等等等….&lt;/p&gt;

&lt;h2 id=&quot;训练结果的保存及其可视化&quot;&gt;训练结果的保存及其可视化&lt;/h2&gt;

&lt;p&gt;保存模型的两种方式：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'net.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 保存整个网络&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'net_params.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# 只保存网络中的参数 (速度快, 占内存少)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;提取模型：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  	&lt;span class=&quot;c&quot;&gt;# restore entire net1 to net2 这种方式将会提取整个神经网络, 网络大的时候可能会比较慢.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;net2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'net.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;net2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  	&lt;span class=&quot;c&quot;&gt;# 将保存的参数复制到 net3  这种方式将会提取所有的参数, 然后再放到你的新建网络中.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;net3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'net_params.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;net3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Sat, 13 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//python/2017/05/13/pytorch%E5%9F%BA%E7%A1%80.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//python/2017/05/13/pytorch%E5%9F%BA%E7%A1%80.html</guid>
        
        <category>Machine Learning</category>
        
        <category>Python</category>
        
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Adversarial Learning for Neural Dialogue Generation</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#adversarial-learning-for-neural-dialogue-generation&quot; id=&quot;markdown-toc-adversarial-learning-for-neural-dialogue-generation&quot;&gt;Adversarial Learning for Neural Dialogue Generation&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#主要贡献&quot; id=&quot;markdown-toc-主要贡献&quot;&gt;主要贡献&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#论文背景&quot; id=&quot;markdown-toc-论文背景&quot;&gt;论文背景&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#网络结构原理&quot; id=&quot;markdown-toc-网络结构原理&quot;&gt;网络结构原理&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#算法流程和讲解&quot; id=&quot;markdown-toc-算法流程和讲解&quot;&gt;算法流程和讲解&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#adversarial-evaluation&quot; id=&quot;markdown-toc-adversarial-evaluation&quot;&gt;adversarial evaluation&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#实验过程和结果&quot; id=&quot;markdown-toc-实验过程和结果&quot;&gt;实验过程和结果（）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#related-work加上discussion&quot; id=&quot;markdown-toc-related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;adversarial-learning-for-neural-dialogue-generation&quot;&gt;Adversarial Learning for Neural Dialogue Generation&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;把GAN放在对话系统上，有有较好的提升。&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;p&gt;之前的对话模型的问题如下：over-simplified，responses are highly dull and generic repetitive and short-sighted，而要解决这些问题，首先是要回答下面的几个问题：what are the crucial aspects that define an ideal conversation, how can we quantitatively measure them, and how can we incorporate them into a machine learning system?&lt;/p&gt;

&lt;p&gt;之前有做过&lt;a href=&quot;https://arxiv.org/abs/1606.01541&quot;&gt;Deep reinforcement learning for dialogue generation&lt;/a&gt;提出过三个标准来衡量好坏，但问题在于，这样的方法manually defined reward functions can’t possibly cover all crucial aspects and can lead to suboptimal generated utterances，简单来说就是不能cover所有主要层次导致的次优等生成对话。&lt;/p&gt;

&lt;p&gt;好的对话系统应该是人类无法识别是人类还是机器的，这个也是第一篇人工智能论文中提到的&lt;a href=&quot;http://www.worldofai.com/bbs/simple/?t59.html&quot;&gt;Turing test中文版&lt;/a&gt;，所以借鉴GAN的博弈的思想，也就是让真实的和机器生成的放在一起来对抗博弈。&lt;/p&gt;

&lt;p&gt;实验证明是可以做的比普通的seq2seq的结果要好！&lt;/p&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;因为本文是用于开放式对话生成，所以文中的生成器采用seq2seq模型 (而非普通的LSTM模型)。 判别器则采用了hierarchical encoder (而非CNN)。&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Adversarial_Dialogue.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总体来说，本文的思路和SeqGAN是大体一样的，但是有几处不同和改进的地方：&lt;/p&gt;

&lt;p&gt;采取了两种方法为完全生成或者部分生成的序列计算reward。除了 Monte Carlo search (与SeqGAN相似) 方法，本文新提出了一个能对部分生成的序列进行reward计算的方法。早期产生的部分(partially)序列会出现在许多的训练数据中，比如生成的第一个token y_1将会出现在所有的部分生成 (partially generated) 的序列里。这样使用所有完全 (fully) 和部分 (partially) 解码的序列来训练判别器会造成overfitting。所以本文借鉴阿尔法狗的思路，采用仅仅分别从正(positive)序列 y+ 和负(negative)序列y-的每个子序列中随机地选取一个 sample来训练判别器D。这个方法比Monte Carlo search更快速，但是也会使得判别器更弱，更不准确。&lt;/p&gt;

&lt;p&gt;在训练G的时候同时还用了Teacher-Forcing（MLE）的方法，这点和后面的MaliGAN有异曲同工之处。为什么要这样做的原因是在对抗性训练的时候，G不会直接接触到真实的目标序列（gold-standard target sequence），当G生成了质量很差的序列的时候（生成质量很好的序列其实相当困难），而D又训练得很好，G就会通过得到的Reward知道自己生成的序列很糟糕，但却又不知道怎么令自己生成更好的序列， 这样就会导致训练崩溃，也就是会随机的sample，很不稳定（&lt;strong&gt;这也正是seqGAN中的问题&lt;/strong&gt;）。所以借鉴这篇文章&lt;a href=&quot;http://papers.nips.cc/paper/6099-professor-forcing-a-new-algorithm-for-training-recurrent-networks.pdf&quot;&gt;Professor Forcing: A New Algorithm for Training Recurrent Networks&lt;/a&gt;，通过对抗性训练更新G的参数之后，还通过传统的MLE就是用真实的序列来更新G的参数。类似于有一个“老师”来纠正G训练过程中出现的偏差，类似于一个regularizer。&lt;/p&gt;

&lt;h3 id=&quot;adversarial-evaluation&quot;&gt;adversarial evaluation&lt;/h3&gt;

&lt;p&gt;作者出的对抗评估，借鉴的是第一次发表的在&lt;a href=&quot;&quot;&gt;Generating sentences from a continuous space&lt;/a&gt;和之后的一个调查&lt;a href=&quot;&quot;&gt;Adversarial evaluation of dialogue models. In NIPS 2016 Work shop on Adversarial Training.&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;需要注意的是这个模型在train和test的时候有有对抗评估，在train的时候很明显，但是在test的时候是借助在外的sample，如果不能判别说明这个模型只有50%的正确率。&lt;/p&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;p&gt;部分实验结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Adversarial_Dialogue1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;p&gt;这篇文章是&lt;a href=&quot;&quot;&gt; Deep reinforcement learning for dialogue generation&lt;/a&gt;的一个扩展。在传统的&lt;a href=&quot;&quot;&gt; A network-based end-to-end trainable task-oriented dialogue system.&lt;/a&gt;做了改进。RL在对话系统中&lt;a href=&quot;&quot;&gt;Continuously Learning Neural Dialogue Management&lt;/a&gt;是首先结合对话系统的。&lt;a href=&quot;&quot;&gt;Online Sequence-to-Sequence Active Learning for Open-Domain Dialogue Generation&lt;/a&gt;这篇是一篇在线对话系统训练的模型。&lt;/p&gt;

&lt;p&gt;##　文章解读和评价&lt;/p&gt;

&lt;p&gt;值得思考的地方：文中只尝试用判别器的结果作为reward, 结合 原文作者之前在dialogue system文中提出的其他reward机制(e.g., mutual information)会不会提高效果？&lt;/p&gt;

</description>
        <pubDate>Sat, 13 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/13/Adversarial-Learning-for-Neural-Dialogue-Generation.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/13/Adversarial-Learning-for-Neural-Dialogue-Generation.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>An actor Critic algorithm for sequence prediction</title>
        <description>&lt;h1 id=&quot;an-actor-critic-algorithm-for-sequence-prediction&quot;&gt;An Actor-Critic Algorithm for Sequence Prediction&lt;/h1&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;The contributions of the paper can be summarized as follows: 1) we describe how RL methodology like the actor-critic approach can be applied to supervised learning problems with structured outputs; and 2) we investigate the performance and behavior of the new method on both a synthetic task and a real-world task of machine translation, demonstrating the improvements over maximum-likelihood and REINFORCE brought by the actor-critic training.&lt;/p&gt;

&lt;p&gt;主要就是RL在nlp的应用是怎么实现，第二就是分析了这种方法的效果比之前极大似然和REINFORCE的好。&lt;/p&gt;

&lt;p&gt;当前对数似然训练方法受限于他们的训练和测试之间的差异模式,即RNN在training时接受ground truth input，但testing时却接受自己之前的output，这两个setting不一致会导致error accumulate，这篇论文&lt;strong&gt;解决这个问题，这个问题也叫做exposure bias问题。&lt;/strong&gt;这使得一个更接近训练阶段的test过程，允许直接优化为特定任务的评分，如BLEU。&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;p&gt;在这个论文之前，传统的机器翻译或者其他语言模型，大都是用encoder-decoder框架加上attention机制来做的。&lt;/p&gt;

&lt;p&gt;当然这篇论文也是encoder-decoder加attention机制，只不过在训练上是用actor-critic算法来做。其中，因为attention机制有很多形式，具体的看&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/05/06/Encoder-Decoder%E6%A1%86%E6%9E%B6.html&quot;&gt;这篇博文&lt;/a&gt;，在这篇论文中用的是soft attention mechanism&lt;/p&gt;

&lt;p&gt;具体来说这个机制的公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/An_Actor_Critic_Algorithm3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;p&gt;首先是&lt;a href=&quot;https://arxiv.org/pdf/1511.06732.pdf&quot;&gt;Sequence level training with recurrent neural networks&lt;/a&gt; 这篇用REINFORCE algorithm做语言模型,其缺点就是：&lt;strong&gt;高方差加上不能挖掘出the availability of the ground-truth，The approach also relies on a curriculum learning scheme.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当然，之前&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.323.8169&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Structured prediction with reinforcement learning&lt;/a&gt;这篇Standard value-based RL algorithms like SARSA and OLPOMDP have also been applied to structured prediction 同样的是do not use the ground-truth for value prediction.&lt;/p&gt;

&lt;p&gt;还有就是一些Imitation learning，但是不好的原因在于&lt;strong&gt;A limitation is that the token k for the ground-truth answer is used as the target at step k,&lt;/strong&gt; which might not always be the optimal strategy.（这个//TODO，暂时还没有搞懂。）&lt;/p&gt;

&lt;p&gt;一些approaches that aim to approximate the gradient of the expected score，这些方式的缺点都是在于not include the ground-truth as well，优点并不好。（这里看出bais exposure是一个大问题）&lt;/p&gt;

&lt;p&gt;最后是method is to optimize a global sequence cost with respect to the selection and pruning behavior of the beam search procedure itself。比如这篇&lt;a href=&quot;https://arxiv.org/abs/1606.02960&quot;&gt;Sequence-to-Sequence Learning as Beam-Search Optimization&lt;/a&gt;但它是designed specifically for the precise inference procedure involved. 也就是为精确推导而作的。&lt;/p&gt;

&lt;p&gt;总结：之前大部分文章都是不能解决bais exposure问题。这个文章解决了这个问退。&lt;/p&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;结构如图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/An_Actor_Critic_Algorithm.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从神经网络结构看：actor和critic都是encoder和decoder的结构。actor中中encoder输入的是X（若在机器翻译中就是原始序列），decoder输出生成的序列（在机器翻译中就是输出序列），然后生成的每一词都输入到critic对这些序列进行评价。其中critic的encoder输入的是Y（若在机器翻译中就是翻译后的序列），decoder输入的就是attention机制生成的input summary加上actor的当下生成词，输出的就是对当下生成词的一个评价！具体的看下面的算法流程图。&lt;/p&gt;

&lt;p&gt;从传统的RL来看，状态就是actor中的decoder之前的序列，动作就是下一个生成词，这个critic对这个动作进行评价，返回的就是Q，也就是reward。&lt;/p&gt;

&lt;p&gt;怎么解决bais exposure问题：&lt;strong&gt;从结构中看，就是在训练的时候actor和测试的时候一样，都是用previous guesses 去生成下来的序列。然后ground-truth tokens用于critic的value prediction。也就是充分利用了ground-truth tokens&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;p&gt;具体的算法流程如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/An_Actor_Critic_Algorithm1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/An_Actor_Critic_Algorithm2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note that we use the probability rather than the log probability in this formula (which is more typical in RL applications) as we are summing over actions rather than taking an expectation. Intuitively, this equality corresponds to increasing the probability of actions that give high values, and decreasing the probability of actions that give low values&lt;/p&gt;

&lt;p&gt;注意到这里采用的不是log probability，而是probability，因为他们是求和而不是期望。可以在做实验的时候做下log probability的&lt;/p&gt;

&lt;h3 id=&quot;一些trick&quot;&gt;一些trick&lt;/h3&gt;

&lt;p&gt;（1）应用的是&lt;strong&gt;Temporal-difference learning&lt;/strong&gt;来评估策略，这个应该不算是一个trick，而是在actor-critic中本来就有的。&lt;/p&gt;

&lt;p&gt;（2）其次是trick是Applying deep RL techniques，首先是如果Q是非线性的话，就会产生梯度偏离的问题，为了解决这个问题作者借鉴&lt;a href=&quot;https://arxiv.org/abs/1509.02971&quot;&gt;Continuous control with deep reinforcement learning&lt;/a&gt;，使用了一个额外的target network，他们试图remove掉target network ，但那样的效果不好。然后也需要注意的是两个模型都用到对方的output来训练自己。这个容易造成的结果就是creates a potentially dangerous feedback loop（危险反复循环）。解决问题就是借鉴&lt;a href=&quot;https://arxiv.org/abs/1509.02971&quot;&gt;Continuous control with deep reinforcement learning&lt;/a&gt;，sample一些prediction来保证他们真正的训练到。&lt;/p&gt;

&lt;p&gt;(3)然后是trick是Dealing with large action spaces，This can be alleviated by putting constraints on the critic values for actions that are rarely sampled. We found experimentally that shrinking the values of these rare actions is necessary for the algorithm to converge。也就是在跟新critic的时候加上一个类似正则化的项，这个的作用就是缩小那些几乎不出现的动作的价值，降低critic的output的方差。这个trick在&lt;a href=&quot;https://arxiv.org/abs/1511.07275&quot;&gt;Learning simple algorithms from examples&lt;/a&gt;也有用到。这个trick具体如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/An_Actor_Critic_Algorithm5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（4）最后的trick是Reward shaping&lt;/p&gt;

&lt;h2 id=&quot;实验过程和结果未复现&quot;&gt;实验过程和结果（未复现）&lt;/h2&gt;

&lt;p&gt;论文给了两个实验，一个是spelling correction task另一个是machine translation。评价标准是BLUE&lt;/p&gt;

&lt;p&gt;在machine translation中&lt;/p&gt;

&lt;p&gt;##　文章解读和评价&lt;/p&gt;

</description>
        <pubDate>Sat, 13 May 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/05/13/An-Actor-Critic-Algorithm-for-Sequence-Prediction.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/05/13/An-Actor-Critic-Algorithm-for-Sequence-Prediction.html</guid>
        
        
      </item>
    
      <item>
        <title>MaliGAN</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#maligan&quot; id=&quot;markdown-toc-maligan&quot;&gt;MaliGAN&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#主要贡献&quot; id=&quot;markdown-toc-主要贡献&quot;&gt;主要贡献&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#论文背景&quot; id=&quot;markdown-toc-论文背景&quot;&gt;论文背景&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#网络结构原理&quot; id=&quot;markdown-toc-网络结构原理&quot;&gt;网络结构原理&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#算法流程和讲解&quot; id=&quot;markdown-toc-算法流程和讲解&quot;&gt;算法流程和讲解&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#实验过程和结果&quot; id=&quot;markdown-toc-实验过程和结果&quot;&gt;实验过程和结果（）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#related-work加上discussion&quot; id=&quot;markdown-toc-related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#文章解读和评价&quot; id=&quot;markdown-toc-文章解读和评价&quot;&gt;文章解读和评价&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;maligan&quot;&gt;MaliGAN&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1702.07983&quot;&gt;论文原文&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;主要贡献&quot;&gt;主要贡献&lt;/h2&gt;

&lt;p&gt;提出一个全新的G的目标函数。并用于NLP中，结合了比之前的MC更好的一种减小方差的方法，使得效果更好。&lt;/p&gt;

&lt;h2 id=&quot;论文背景&quot;&gt;论文背景&lt;/h2&gt;

&lt;p&gt;在这篇论文的背景和其他GAN FOR NLP一样都是讲述了一些进程。不过有点不同的是这篇论文和之前的&lt;a href=&quot;&quot;&gt;Boundary-Seeking Generative Adversarial Networks&lt;/a&gt;是一起的，也就是这里的G的目标函数和那里的是一样的。&lt;/p&gt;

&lt;p&gt;下面简单的讲述那个构造函数的由来。&lt;/p&gt;

&lt;p&gt;这个BGAN的Intuition就是：令G去学习如何生成在D决策边界的样本，所以才叫做boundary-seeking。作者有一个特别的技巧：如图，当D达到最优的时候，满足如下条件，Pdata是真实的分布，Pg是G生成的分布。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/MaliGAN2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们对它进行一点微小的变换：这个形式厉害之处在于，尽管我们没有完美的G，但是仍然可以通过对Pg赋予权重来得到真实的分布，这个比例就是如图所示，基于该G的最优D和（1-D）之比。当然我们很难得到最优的D，但我们训练的D越接近最优D，bias越低。而训练D（标准二分类器）要比G简单得多，因为G的目标函数是一个会随着D变动而变动的目标。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/MaliGAN3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在BGAN这篇文章中给出了一些解释&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/MaliGAN5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而在maliGAN中，应用了这种G函数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/MaliGAN4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其实在一开始的BGAN中，作者就有讲它应用在Discrete variables中，只是在这个的话，没有长序列的生成，但在maliGAN中，扩展到生成序列中，需要解决的问题就是减小方差的呃问题。&lt;/p&gt;

&lt;h2 id=&quot;网络结构原理&quot;&gt;网络结构原理&lt;/h2&gt;

&lt;p&gt;这个网路的结构和之前GAN差别不大，也就是在这篇论文中，主要的还是在算法上的改进吧。&lt;/p&gt;

&lt;h2 id=&quot;算法流程和讲解&quot;&gt;算法流程和讲解&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/GAN_FOR_NLP3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这篇论文的主要贡献如下：&lt;/p&gt;

&lt;p&gt;1.为G&lt;strong&gt;构造一个全新的目标函数，用到了Importance Sampling，将其与D的output结合起来，令训练过程更加稳定同时梯度的方差更低。&lt;/strong&gt;尽管这个目标函数和RL的方法类似，但是相比之下更能够降低estimator的方差（强烈建议看原文的3.2 Analysis，分析了当D最优以及D经过训练但并没有到最优两种情况下，这个新的目标函数仍然能发挥作用）&lt;/p&gt;

&lt;p&gt;2.生成较长序列的时候需要用到多次random sampling，所以文章还&lt;strong&gt;提出了两个降低方差的技巧&lt;/strong&gt;：第一个是蒙特卡罗树搜索，这个大家都比较熟悉; 第二个受到这个文章的启发&lt;a href=&quot;https://arxiv.org/abs/1511.06732&quot;&gt;Sequence level training with recurrent neural networks&lt;/a&gt;文章称之为Mixed MLE-Mali Training，就是从真实数据中进行抽样，若序列长度大于N，则固定住前N个词，然后基于前N个词去freely run G产生M个样本，一直run到序列结束。&lt;/p&gt;

&lt;p&gt;基于前N个词生成后面的词的原因在于条件分布Pd比完整分布要简单，同时能够从真实的样本中得到较强的训练信号。然后逐渐减少N（在实验三中N=30, K=5， K为步长值，训练的时候每次迭代N-K）&lt;/p&gt;

&lt;h2 id=&quot;实验过程和结果&quot;&gt;实验过程和结果（）&lt;/h2&gt;

&lt;p&gt;作者给出了实验数据，比SeqGAN的效果要更好，看BLEU score.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/MaliGAN1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;related-work加上discussion&quot;&gt;RELATED WORK加上discussion&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.02960&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;文章解读和评价&quot;&gt;文章解读和评价&lt;/h2&gt;

&lt;p&gt;主要是在RL和这个不同方法上进行讨论，之前的RL方法存在的&lt;strong&gt;梯度难以从D传到G和本身的不稳定&lt;/strong&gt;。现在作者提出了一种新的方式来做。这个文章在作者看来就是在用RL类似的方法，用importance sampling+mixed training&lt;/p&gt;

</description>
        <pubDate>Fri, 12 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/12/MaliGAN.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/12/MaliGAN.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>TensorFlow 基础</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#tensorflow-基础&quot; id=&quot;markdown-toc-tensorflow-基础&quot;&gt;TensorFlow 基础&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#基本概念&quot; id=&quot;markdown-toc-基本概念&quot;&gt;基本概念：&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#tensor&quot; id=&quot;markdown-toc-tensor&quot;&gt;Tensor&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#计算的过程&quot; id=&quot;markdown-toc-计算的过程&quot;&gt;计算的过程&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#构建图&quot; id=&quot;markdown-toc-构建图&quot;&gt;构建图&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#在一个会话中启动图&quot; id=&quot;markdown-toc-在一个会话中启动图&quot;&gt;在一个会话中启动图&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#指定机器设备&quot; id=&quot;markdown-toc-指定机器设备&quot;&gt;指定机器设备&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#交互式使用&quot; id=&quot;markdown-toc-交互式使用&quot;&gt;交互式使用&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#变量&quot; id=&quot;markdown-toc-变量&quot;&gt;变量&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#fetch&quot; id=&quot;markdown-toc-fetch&quot;&gt;Fetch&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#数据读取&quot; id=&quot;markdown-toc-数据读取&quot;&gt;数据读取&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#feed-机制&quot; id=&quot;markdown-toc-feed-机制&quot;&gt;feed 机制&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#从文件读取数据&quot; id=&quot;markdown-toc-从文件读取数据&quot;&gt;从文件读取数据&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#预加载数据-在tensorflow图中定义常量或变量来保存所有数据仅适用于数据量比较小的情况&quot; id=&quot;markdown-toc-预加载数据-在tensorflow图中定义常量或变量来保存所有数据仅适用于数据量比较小的情况&quot;&gt;预加载数据： 在TensorFlow图中定义常量或变量来保存所有数据(仅适用于数据量比较小的情况)。&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#saving-variables&quot; id=&quot;markdown-toc-saving-variables&quot;&gt;Saving Variables&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#restoring-variables&quot; id=&quot;markdown-toc-restoring-variables&quot;&gt;Restoring Variables&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;tensorflow-基础&quot;&gt;TensorFlow 基础&lt;/h1&gt;

&lt;h2 id=&quot;基本概念&quot;&gt;基本概念：&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;使用图 (graph) 来表示计算任务.
在被称之为 会话 (Session) 的上下文 (context) 中执行图.
使用 tensor 表示数据.
通过 变量 (Variable) 维护状态.
使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;tensor&quot;&gt;Tensor&lt;/h3&gt;

&lt;p&gt;TensorFlow 程序使用 tensor 数据结构来代表所有的数据, 计算图中, 操作间传递的数据都是 tensor. 你可以把 TensorFlow tensor 看作是一个 n 维的数组或列表. 一个 tensor 包含一个静态类型 rank, 和 一个 shape.&lt;/p&gt;

&lt;h3 id=&quot;计算的过程&quot;&gt;计算的过程&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象&lt;/li&gt;
  &lt;li&gt;TensorFlow 程序通常被组织成一个构建阶段和一个执行阶段. 在构建阶段, op 的执行步骤 被描述成一个图. 在执行阶段, 使用会话执行执行图中的 op.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;例如： 通常在构建阶段创建一个图来表示和训练神经网络, 然后在执行阶段反复执行图中的训练 op.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;构建图&quot;&gt;构建图&lt;/h3&gt;

&lt;p&gt;Python 库中, op 构造器的返回值代表被构造出的 op 的输出, 这些返回值可以传递给其它 op 构造器作为输入.&lt;/p&gt;

&lt;p&gt;TensorFlow Python 库有一个默认图 (default graph), op 构造器可以为其增加节点. 这个默认图对 许多程序来说已经足够用了.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;这里就是说我们直接引入TensorFlow就是一个默认图&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import tensorflow as tf

# 创建一个常量 op, 产生一个 1x2 矩阵. 这个 op 被作为一个节点
# 加到默认图中.
#
# 构造器的返回值代表该常量 op 的返回值.
matrix1 = tf.constant([[3., 3.]])

# 创建另外一个常量 op, 产生一个 2x1 矩阵.
matrix2 = tf.constant([[2.],[2.]])

# 创建一个矩阵乘法 matmul op , 把 'matrix1' 和 'matrix2' 作为输入.
# 返回值 'product' 代表矩阵乘法的结果.
product = tf.matmul(matrix1, matrix2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;默认图现在有三个节点, 两个 constant() op, 和一个matmul() op. 为了真正进行矩阵相乘运算, 并得到矩阵乘法的 结果, 你必须在会话里启动这个图.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;想着，tf进行一次的操作，就有一个op，也就是一个节点&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;在一个会话中启动图&quot;&gt;在一个会话中启动图&lt;/h3&gt;

&lt;p&gt;构造阶段完成后, 才能启动图. 启动图的第一步是创建一个 Session 对象, 如果无任何创建参数, 会话构造器将启动默认图.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 启动默认图.
sess = tf.Session()

# 调用 sess 的 'run()' 方法来执行矩阵乘法 op, 传入 'product' 作为该方法的参数. 
# 上面提到, 'product' 代表了矩阵乘法 op 的输出, 传入它是向方法表明, 我们希望取回
# 矩阵乘法 op 的输出.
#
# 整个执行过程是自动化的, 会话负责传递 op 所需的全部输入. op 通常是并发执行的.
# 
# 函数调用 'run(product)' 触发了图中三个 op (两个常量 op 和一个矩阵乘法 op) 的执行.
#
# 返回值 'result' 是一个 numpy `ndarray` 对象.
result = sess.run(product)
print result
# ==&amp;gt; [[ 12.]]

# 任务完成, 关闭会话.
sess.close()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Session 对象在使用完后需要关闭以释放资源. 除了显式调用 close 外, 也可以使用 “with” 代码块 来自动完成关闭动作.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;with tf.Session() as sess:
  result = sess.run([product])
  print result
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;在实现上, TensorFlow 将图形定义转换成分布式执行的操作, 以充分利用可用的计算资源(如 CPU 或 GPU). 一般你不需要显式指定使用 CPU 还是 GPU, TensorFlow 能自动检测. 如果检测到 GPU, TensorFlow 会尽可能地利用找到的第一个 GPU 来执行操作.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;指定机器设备&quot;&gt;指定机器设备&lt;/h2&gt;

&lt;p&gt;如果机器上有超过一个可用的 GPU, 除第一个外的其它 GPU 默认是不参与计算的. 为了让 TensorFlow 使用这些 GPU, 你必须将 op 明确指派给它们执行. with…Device 语句用来指派特定的 CPU 或 GPU 执行操作:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;with tf.Session() as sess:
  with tf.device(&quot;/gpu:1&quot;):
    matrix1 = tf.constant([[3., 3.]])
    matrix2 = tf.constant([[2.],[2.]])
    product = tf.matmul(matrix1, matrix2)
    ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;设备用字符串进行标识. 目前支持的设备包括:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“/cpu:0”: 机器的 CPU.&lt;/li&gt;
  &lt;li&gt;“/gpu:0”: 机器的第一个 GPU, 如果有的话.&lt;/li&gt;
  &lt;li&gt;“/gpu:1”: 机器的第二个 GPU, 以此类推.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;交互式使用&quot;&gt;交互式使用&lt;/h3&gt;
&lt;p&gt;文档中的 Python 示例使用一个会话 Session 来 启动图, 并调用 Session.run() 方法执行操作.&lt;/p&gt;

&lt;p&gt;为了便于使用诸如 IPython 之类的 Python 交互环境, 可以使用 InteractiveSession 代替 Session 类, 使用 Tensor.eval() 和 Operation.run() 方法代替 Session.run(). 这样可以避免使用一个变量来持有会话.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 进入一个交互式 TensorFlow 会话.
import tensorflow as tf
sess = tf.InteractiveSession()

x = tf.Variable([1.0, 2.0])
a = tf.constant([3.0, 3.0])

# 使用初始化器 initializer op 的 run() 方法初始化 'x' 
x.initializer.run()

# 增加一个减法 sub op, 从 'x' 减去 'a'. 运行减法 op, 输出结果 
sub = tf.sub(x, a)
print sub.eval()
# ==&amp;gt; [-2. -1.]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;变量&quot;&gt;变量&lt;/h2&gt;

&lt;p&gt;Variables for more details. 变量维护图执行过程中的状态信息. 下面的例子演示了如何使用变量实现一个简单的计数器.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 创建一个变量, 初始化为标量 0.
state = tf.Variable(0, name=&quot;counter&quot;)

# 创建一个 op, 其作用是使 state 增加 1

one = tf.constant(1)
new_value = tf.add(state, one)
update = tf.assign(state, new_value)

# 启动图后, 变量必须先经过`初始化` (init) op 初始化,
# 首先必须增加一个`初始化` op 到图中.
init_op = tf.initialize_all_variables()

# 启动图, 运行 op
with tf.Session() as sess:
  # 运行 'init' op
  sess.run(init_op)
  # 打印 'state' 的初始值
  print sess.run(state)
  # 运行 op, 更新 'state', 并打印 'state'
  for _ in range(3):
    sess.run(update)
    print sess.run(state)

# 输出:

# 0
# 1
# 2
# 3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;代码中 assign() 操作是图所描绘的表达式的一部分, 正如 add() 操作一样. 所以在调用 run() 执行表达式之前, 它并不会真正执行赋值操作.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;要注意的是update = tf.assign(state, new_value)这一句，因为add是构建，没有run之前都不会复制&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;通常会将一个统计模型中的参数表示为一组变量. 例如, 你可以将一个神经网络的权重作为某个变量存储在一个 tensor 中. 在训练过程中, 通过重复运行训练图, 更新这个 tensor.&lt;/p&gt;

&lt;h2 id=&quot;fetch&quot;&gt;Fetch&lt;/h2&gt;

&lt;p&gt;为了取回操作的输出内容, 可以在使用 Session 对象的 run() 调用 执行图时, 传入一些 tensor, 这些 tensor 会帮助你取回结果. 在之前的例子里, 我们只取回了单个节点 state, 但是你也可以取回多个 tensor:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;input1 = tf.constant(3.0)
input2 = tf.constant(2.0)
input3 = tf.constant(5.0)
intermed = tf.add(input2, input3)
mul = tf.mul(input1, intermed)

with tf.Session() as sess:
  result = sess.run([mul, intermed])
  print result

# 输出:
# [array([ 21.], dtype=float32), array([ 7.], dtype=float32)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意是数组&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;需要获取的多个 tensor 值，在 op 的一次运行中一起获得（而不是逐个去获取 tensor）。&lt;/p&gt;

&lt;h2 id=&quot;数据读取&quot;&gt;数据读取&lt;/h2&gt;

&lt;h3 id=&quot;feed-机制&quot;&gt;feed 机制&lt;/h3&gt;

&lt;p&gt;供给数据(Feeding)： 在TensorFlow程序运行的每一步， 让Python代码来供给数据。&lt;/p&gt;

&lt;p&gt;TensorFlow 提供了 feed 机制, 该机制 可以临时替代图中的任意操作中的 tensor 可以对图中任何操作提交补丁, 直接插入一个 tensor.&lt;/p&gt;

&lt;p&gt;feed 使用一个 tensor 值临时替换一个操作的输出结果. 你可以&lt;strong&gt;提供 feed 数据作为 run() 调用的参数. **feed 只在调用它的方法内有效, 方法结束, feed 就会消失. **最常见的用例是将某些特殊的操作指定为 “feed” 操作, 标记的方法是使用 tf.placeholder() 为这些操作创建占位符.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;例子如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;input1 = tf.placeholder(tf.float32)
input2 = tf.placeholder(tf.float32)
output = tf.mul(input1, input2)

with tf.Session() as sess:
  print sess.run([output], feed_dict={input1:[7.], input2:[2.]})

# 输出:
# [array([ 14.], dtype=float32)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;for a larger-scale example of feeds. 如果没有正确提供 feed, placeholder() 操作将会产生错误. MNIST 全连通 feed 教程 (source code) 给出了一个更大规模的使用 feed 的例子.&lt;/p&gt;

&lt;h3 id=&quot;从文件读取数据&quot;&gt;从文件读取数据&lt;/h3&gt;

&lt;p&gt;从文件读取数据： 在TensorFlow图的起始， 让一个输入管线从文件中读取数据。&lt;/p&gt;

&lt;p&gt;这个详细可以看&lt;a href=&quot;http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/reading_data.html#AUTOGENERATED-reading-from-files&quot;&gt;数据读取&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;读取CSV 文件时，是&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;filename_queue = tf.train.string_input_producer([&quot;file0.csv&quot;, &quot;file1.csv&quot;])

reader = tf.TextLineReader()
key, value = reader.read(filename_queue)

# Default values, in case of empty columns. Also specifies the type of the
# decoded result.
record_defaults = [[1], [1], [1], [1], [1]]
col1, col2, col3, col4, col5 = tf.decode_csv(
	value, record_defaults=record_defaults)
features = tf.concat(0, [col1, col2, col3, col4])

with tf.Session() as sess:
  # Start populating the filename queue.
  coord = tf.train.Coordinator()
  threads = tf.train.start_queue_runners(coord=coord)

  for i in range(1200):
	# Retrieve a single instance:
	example, label = sess.run([features, col5])

  coord.request_stop()
  coord.join(threads)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;预加载数据-在tensorflow图中定义常量或变量来保存所有数据仅适用于数据量比较小的情况&quot;&gt;预加载数据： 在TensorFlow图中定义常量或变量来保存所有数据(仅适用于数据量比较小的情况)。&lt;/h3&gt;

&lt;p&gt;上面是一种方式，当然还有另为一种方式就是输入列队来喂入数据的。&lt;/p&gt;

&lt;h2 id=&quot;saving-variables&quot;&gt;Saving Variables&lt;/h2&gt;

&lt;p&gt;Create a Saver with tf.train.Saver() to manage all variables in the model.&lt;/p&gt;

&lt;p&gt;也就是暂存结果的操作。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Create some variables.
v1 = tf.Variable(..., name=&quot;v1&quot;)
v2 = tf.Variable(..., name=&quot;v2&quot;)
...
# Add an op to initialize the variables.
init_op = tf.global_variables_initializer()

# Add ops to save and restore all the variables.
saver = tf.train.Saver()

# Later, launch the model, initialize the variables, do some work, save the
# variables to disk.
with tf.Session() as sess:
  sess.run(init_op)
  # Do some work with the model.
  ..
  # Save the variables to disk.
  save_path = saver.save(sess, &quot;/tmp/model.ckpt&quot;)
  print(&quot;Model saved in file: %s&quot; % save_path)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;restoring-variables&quot;&gt;Restoring Variables&lt;/h2&gt;

&lt;p&gt;The same Saver object is used to restore variables. Note that when you restore variables from a file you do not have to initialize them beforehand.&lt;/p&gt;

&lt;p&gt;也就是在重新使用的方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Create some variables.
v1 = tf.Variable(..., name=&quot;v1&quot;)
v2 = tf.Variable(..., name=&quot;v2&quot;)
...
# Add ops to save and restore all the variables.
saver = tf.train.Saver()

# Later, launch the model, use the saver to restore variables from disk, and
# do some work with the model.
with tf.Session() as sess:
  # Restore variables from disk.
  saver.restore(sess, &quot;/tmp/model.ckpt&quot;)
  print(&quot;Model restored.&quot;)
  # Do some work with the model
  ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Fri, 12 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//python/2017/05/12/TensorFlow-%E5%9F%BA%E7%A1%80.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//python/2017/05/12/TensorFlow-%E5%9F%BA%E7%A1%80.html</guid>
        
        <category>Machine Learning</category>
        
        <category>Python</category>
        
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>自动文摘</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#自动文摘&quot; id=&quot;markdown-toc-自动文摘&quot;&gt;自动文摘&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#自动文摘分类&quot; id=&quot;markdown-toc-自动文摘分类&quot;&gt;自动文摘分类&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#extractive-summarization&quot; id=&quot;markdown-toc-extractive-summarization&quot;&gt;Extractive Summarization&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#abstractive&quot; id=&quot;markdown-toc-abstractive&quot;&gt;Abstractive&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#evaluation&quot; id=&quot;markdown-toc-evaluation&quot;&gt;Evaluation&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#abstractive-summarization细节&quot; id=&quot;markdown-toc-abstractive-summarization细节&quot;&gt;abstractive summarization细节&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#neural-summarization&quot; id=&quot;markdown-toc-neural-summarization&quot;&gt;Neural Summarization&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;自动文摘&quot;&gt;自动文摘&lt;/h1&gt;

&lt;h2 id=&quot;自动文摘分类&quot;&gt;自动文摘分类&lt;/h2&gt;

&lt;p&gt;自动文摘的方法主要分为两大类，extractive和abstractive。前者是目前最主流、应用最多、最容易的方法，后者相对来说更有一种真正人工智能的味道。还有另外一种分类方法是，单文档摘要和多文档摘要，前者是后者的基础，但后者不只是前者结果简单叠加那么简单。&lt;/p&gt;

&lt;h2 id=&quot;extractive-summarization&quot;&gt;Extractive Summarization&lt;/h2&gt;

&lt;p&gt;抽取式的方法基于一个假设，一篇文档的核心思想可以用文档中的某一句或几句话来概括。那么摘要的任务就变成了找到文档中最重要的几句话，也就是&lt;strong&gt;一个排序的问题&lt;/strong&gt;。它主要是排序的问题，输出的是排序后的结果。&lt;strong&gt;因为各个句子都是从不同的段落中选择出来的，如果只是生硬地连起来生成摘要的话，很难保证句子之间的衔接和连贯。保证可读性是一件很难的事情。&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;由于研究的方向是人工智能，所以对于这个方式不多研究！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;abstractive&quot;&gt;Abstractive&lt;/h2&gt;

&lt;p&gt;主要包含的难点是：&lt;/p&gt;

&lt;p&gt;1、理解文档。所谓理解，和人类阅读一篇文章一样，可以&lt;strong&gt;说明白文档的中心思想，涉及到的话题&lt;/strong&gt;等等。&lt;/p&gt;

&lt;p&gt;2、&lt;strong&gt;可读性强&lt;/strong&gt;。可读性是指生成的摘要要能够连贯（Coherence）与衔接（Cohesion），通俗地讲就是人类读起来几乎感觉不出来是AI生成的（通过图灵测试）。&lt;/p&gt;

&lt;p&gt;3、简练总结。在理解了文档意思的基础上，提炼出最核心的部分，用&lt;strong&gt;最短的话讲明白全文的意思。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;近几年随着Deep Learning的火爆，研究者们利用一些最新的研究成果来做summarization，比如attention model，比如rnn encoder-decoder框架，在一定程度上实现了abstractive，但还是处于研究初期，效果还不算很好。&lt;/p&gt;

&lt;h2 id=&quot;evaluation&quot;&gt;Evaluation&lt;/h2&gt;

&lt;p&gt;自动文摘最大的一个难点是评价问题，如何有效地、合理地评价一篇文摘的效果是一个很难的问题。&lt;/p&gt;

&lt;p&gt;一个是人工评价，这个的误差度比较高，时间成本又高，效率又太低了。所以一般都不适合。&lt;/p&gt;

&lt;p&gt;另一个是自动评价，计算机评价效果，需要给定参考摘要作为标准答案，通过制定一些规则来给生成的摘要打分。现有的评价标准存在的一个重要问题在于没有考虑语义层面上的相似，评价extractive还好，但评价abstractive就会效果不好了。在词、句子甚至段落这个层面上的表示学习研究的非常多，也有很多的state-of-the-art的结果，所以做语义层面上的评价并不难。&lt;/p&gt;

&lt;h2 id=&quot;abstractive-summarization细节&quot;&gt;abstractive summarization细节&lt;/h2&gt;

&lt;p&gt;abstractive是学术界研究的热点，尤其是Machine Translation中的encoder-decoder框架和attention mechanism十分火热，大家都试着将abstractive问题转换为sequence-2-sequence问题，套用上面两种技术，得到state-of-the-art结果，2015年来已经有许多篇paper都是这种套路，于是就有了下面的吐槽：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/abstractive_summarization.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;neural-summarization&quot;&gt;Neural Summarization&lt;/h2&gt;

&lt;p&gt;涉及到Encoder-Decoder框架和Attention机制的博文请看&lt;a href=&quot;&quot;&gt;这篇&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;使用deep learning技术来做abstractive summarization的paper屈指可数，大体的思路也类似，大概如下：&lt;/p&gt;

&lt;p&gt;0、首先将自动文摘的问题构造成一个seq2seq问题，通常的做法是将某段文本的first sentence作为输入，headlines作为输出，本质上变成了一个headlines generative问题。&lt;/p&gt;

&lt;p&gt;1、选择一个big corpus作为训练、测试集。自动文摘的技术没有太成熟的一个重要原因在于没有一个成熟的大规模语料。一般来说都选择Gigawords作为训练、测试集，然后用DUC的数据集进行验证和对比。&lt;/p&gt;

&lt;p&gt;2、选择一个合适的encoder，这里可以选simple rnn，lstm rnn，gru rnn，simple birnn，lstm birnn，gru birnn，deep rnn，cnn，以及各种各样的cnn。不同model之间的组合都是一种创新，只不过创新意义不太大。用encoder将输入文本表示成一个向量。&lt;/p&gt;

&lt;p&gt;3、选择一个合适的decoder，decoder的作用是一个language model，用来生成summary words。&lt;/p&gt;

&lt;p&gt;4、设计一个合适的attention model。不仅仅基于encoder last hidden state vector和上文来预测输出文本序列，更要基于输入中“注意力”更高的词来预测相应的词。&lt;/p&gt;

&lt;p&gt;5、设计一个copy net。只要是语言模型都会存在相同的问题，比如out-of-vocabulary词的处理，尤其是做新闻类摘要的生成时，很多词都是人名、机构名等专有名词，所以这里需要用copy net 将输入中的词copy过来生成输出。在生成中文摘要问题上，将words降维到characters可以避免oov的问题，并且取得不错的结果。&lt;/p&gt;

</description>
        <pubDate>Wed, 10 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/10/%E8%87%AA%E5%8A%A8%E6%96%87%E6%91%98.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/10/%E8%87%AA%E5%8A%A8%E6%96%87%E6%91%98.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Skip-Thought Vectors</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#skip-thought-vectors&quot; id=&quot;markdown-toc-skip-thought-vectors&quot;&gt;Skip-Thought Vectors&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#模型结构&quot; id=&quot;markdown-toc-模型结构&quot;&gt;模型结构&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#表示未登录词-词汇表扩展&quot; id=&quot;markdown-toc-表示未登录词-词汇表扩展&quot;&gt;表示未登录词-词汇表扩展。&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#future-work&quot; id=&quot;markdown-toc-future-work&quot;&gt;future work&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;skip-thought-vectors&quot;&gt;Skip-Thought Vectors&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://cn.arxiv.org/pdf/1506.06726v1.pdf&quot;&gt;论文原文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;word level表示已经有太多无监督模型，然而sentence level表示大多仍停留在监督模型的范畴内，比如之前分享过的RNN、CNN、RCNN等模型来表示一个句子，主要是针对具体的分类任务来构造句子向量，仅适用于本任务，不具有一般性。之前，Tomas Mikolov（word2vec的作者）提出了一种类似于Word2vec的paragraph vector，也是一种无监督模型，但并不能很好地扩展来用。&lt;/p&gt;

&lt;p&gt;本文旨在提出一个通用的&lt;strong&gt;无监督句子表示模型，借鉴了word2vec中skip-gram模型，通过一句话来预测这句话的上一句和下一句。&lt;/strong&gt;本文的模型被称为skip-thoughts，生成的向量称为skip-thought vector。模型采用了当下流行的端到端框架，通过搜集了大量的小说作为训练数据集，将得到的模型中encoder部分作为feature extractor，可以给任意句子生成vector。&lt;/p&gt;

&lt;h2 id=&quot;模型结构&quot;&gt;模型结构&lt;/h2&gt;

&lt;p&gt;本文的模型，参考下图来理解：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Skip_Thought_Vectors.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;模型分为两个部分，一个是encoder，一个是两个decoder，分别decode出当前句子的上一句和下一句。&lt;/p&gt;

&lt;p&gt;encoder-decoder框架可参看&lt;a href=&quot;&quot;&gt;这篇博文&lt;/a&gt;，这里不再赘述。本文采用了GRU-RNN作为encoder和decoder，encoder部分的最后一个词的hidden state作为decoder的输入来生成词。这里用的是最简单的网络结构，并没有考虑复杂的多层网络、双向网络等提升效果。decoder部分也只是一个考虑了encoder last hidden state的语言模型，并无其他特殊之处，只是有两个decoder，是一个one maps two的情况，但计算方法一样。模型中的目标函数也是两个部分，一个来自于预测下一句，一个来自于预测上一句。如下式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Skip_Thought_Vectors1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;表示未登录词-词汇表扩展&quot;&gt;表示未登录词-词汇表扩展。&lt;/h2&gt;

&lt;p&gt;如果测试数据中有未登录词，如何表示这个未登录词？针对这个问题，本文提出了一种词汇表扩展的方法来解决这个问题。&lt;/p&gt;

&lt;p&gt;借鉴于Tomas Mikolov的一篇文章&lt;a href=&quot;https://arxiv.org/pdf/1309.4168.pdf&quot;&gt;Exploiting Similarities among Languages for Machine Translation&lt;/a&gt;中解决机器翻译missing words问题的思路，对本文训练集产生的词汇表V(RNN)进行了扩展，具体的思路可参考Mikolov的文章，达到的效果是建立了大数据集下V(Word2Vec)和本文V(RNN)之间的映射，V(Word2Vec)的规模远远大于V(RNN)，本文中V(RNN)包括了20000个词，V(Word2Vec)包括了930000多个词，成功地解决了这一问题，使得本文提出的无监督模型有大的应用价值。文中给出了一个例子，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Skip_Thought_Vectors2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当然，词汇表扩展有很多方法，比如不同词，而用字符来作为基本元素，这种思路在语言模型中也常常被用到。&lt;/p&gt;

&lt;p&gt;最后，作者在Semantic relateness、Paraphrase detection、Image-sentence ranking和classification任务中进行了测试和对比，验证了本文模型的效果。最后还给出了在多个数据集上对句子聚类的可视化结果，以及用decoder部分生成一段话。&lt;/p&gt;

&lt;h2 id=&quot;future-work&quot;&gt;future work&lt;/h2&gt;

&lt;p&gt;关于未来的改进，作者有几点想法：&lt;/p&gt;

&lt;p&gt;用更深的encoder和decoder网络。&lt;/p&gt;

&lt;p&gt;用更大的窗口，而不仅仅预测上一句和下一句。&lt;/p&gt;

&lt;p&gt;试着将sentence替换成paragraph。&lt;/p&gt;

&lt;p&gt;换一些别的encoder来做，比如用CNN。&lt;/p&gt;

&lt;p&gt;每个想法都可能会是未来另一篇牛paper的思路。&lt;/p&gt;

&lt;p&gt;看过了很多的decoder，有char-level，word-level和sentence-level，我有一个小小的想法是，到底哪种level生成的paragraph更出色呢？速度方面，不必比较了，sentence-level一定要快一些，但是质量方面呢？文中最后给出了一个本文模型生成的demo，如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Skip_Thought_Vectors4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;本文作者还开源了该模型的实现代码。&lt;/p&gt;

</description>
        <pubDate>Tue, 09 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/09/Skip-Thought-Vectors.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/09/Skip-Thought-Vectors.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>图像标注</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#图像标注&quot; id=&quot;markdown-toc-图像标注&quot;&gt;图像标注&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#当前水平和意义&quot; id=&quot;markdown-toc-当前水平和意义&quot;&gt;当前水平和意义&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#图像标注数据集&quot; id=&quot;markdown-toc-图像标注数据集&quot;&gt;图像标注数据集&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#图像标注评价标准&quot; id=&quot;markdown-toc-图像标注评价标准&quot;&gt;图像标注评价标准&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#perplexity&quot; id=&quot;markdown-toc-perplexity&quot;&gt;Perplexity&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bleu&quot; id=&quot;markdown-toc-bleu&quot;&gt;BLEU&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#rouge&quot; id=&quot;markdown-toc-rouge&quot;&gt;ROUGE&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#meteor&quot; id=&quot;markdown-toc-meteor&quot;&gt;METEOR&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cider&quot; id=&quot;markdown-toc-cider&quot;&gt;CIDEr&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#图像标注模型发展&quot; id=&quot;markdown-toc-图像标注模型发展&quot;&gt;图像标注模型发展&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#m-rnn模型&quot; id=&quot;markdown-toc-m-rnn模型&quot;&gt;m-RNN模型&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#nic模型&quot; id=&quot;markdown-toc-nic模型&quot;&gt;NIC模型&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;图像标注&quot;&gt;图像标注&lt;/h2&gt;

&lt;p&gt;看图说话。就像老师要求小朋友们在看图说话作业中完成的任务一样，我们也希望算法能够根据图像给出能够描述图像内容的自然语言语句&lt;/p&gt;

&lt;h2 id=&quot;当前水平和意义&quot;&gt;当前水平和意义&lt;/h2&gt;

&lt;p&gt;当前水平：&lt;strong&gt;貌似接近人类，其实差距尚大。&lt;/strong&gt;,只是由于评判标准的问题，在一些论文中说差不多接近人类或者说差不多超过人类，但所用的评价标准似乎不那么的，自动评价标准的目前都是尽量让自己的计算结果能够和人类判断结果相关。评价标准是一个问题，这个值得思考！&lt;/p&gt;

&lt;p&gt;意义和价值：图像标注问题如果能够得到很好的解决，那么价值是显而易见的，可以应用到&lt;strong&gt;图像检索，儿童教育和视力受损人士的生活辅助等方面。&lt;/strong&gt;而从学术的角度来看，当前图像标注问题的研究，促使人工智能领域的两大领域，计算机视觉和自然语言处理很好地结合，这种跨子领域的结合能够催生出更让人惊艳的方法吗？&lt;/p&gt;

&lt;h2 id=&quot;图像标注数据集&quot;&gt;图像标注数据集&lt;/h2&gt;

&lt;p&gt;首先是：Microsoft COCO Caption数据集，在&lt;a href=&quot;https://arxiv.org/abs/1504.00325&quot;&gt;Microsoft COCO Captions: Data Collection and Evaluation Server&lt;/a&gt;中，作者们详细介绍了他们基于MS COCO数据集构建MS COCO Caption数据集的工作。现在大部分论文也是按照这个数据集来做实验的。&lt;/p&gt;

&lt;p&gt;然后Flickr8K和30K：数据量上的劣势，确实使Flickr数据集正逐渐失宠，14年论文中几乎都使用，现在一些高水平论文仅在补充文档中展示甚至不采用&lt;/p&gt;

&lt;p&gt;PASCAL 1K：是大名鼎鼎的PASCAL VOC challenge图像数据集的一个子集，每张图像人工标注了5个描述语句。一般说来，这个数据集只是用来测试的。&lt;/p&gt;

&lt;h2 id=&quot;图像标注评价标准&quot;&gt;图像标注评价标准&lt;/h2&gt;

&lt;h3 id=&quot;perplexity&quot;&gt;Perplexity&lt;/h3&gt;

&lt;p&gt;perplexity定义为：&lt;/p&gt;

&lt;p&gt;images_Perplexity&lt;/p&gt;

&lt;p&gt;在图片标注领域来说，好的例子请看&lt;a href=&quot;https://zhuanlan.zhihu.com/p/22408033&quot;&gt;这篇博文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;将每个单词的可能性都降低一些，就会发现perplexity值会升高。这就说明：&lt;strong&gt;当模型对于下一个生成单词的确信程度降低时，perplexity值反而升高。我们当然是期望一个模型对于它预测的单词能比较有把握啊，所以perplexity值是越低越好。&lt;/strong&gt;也就是说，这个分数越低，那困惑度就越低，模型也就越好。&lt;/p&gt;

&lt;h3 id=&quot;bleu&quot;&gt;BLEU&lt;/h3&gt;

&lt;p&gt;BLEU是Bilingual Evaluation Understudy的缩写。这个计算标准在图像标注结果评价中使用是很广泛的，但是它的设计初衷并不是针对图像标注问题，而是针对机器翻译问题，它是用于分析待评价的翻译语句和参考翻译语句之间n元组的相关性的。直白地来说，它的核心思想就是：&lt;strong&gt;机器翻译语句与人类的专业翻译语句越接近就越好。一句话：BLEU得分越高越好。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;rouge&quot;&gt;ROUGE&lt;/h3&gt;

&lt;p&gt;ROUGE是一个设计用来评价文本摘要算法的自动评价标准集，其中有3个评价标准，分别是ROUGE-N，ROUGE-L和ROUGE-S。&lt;strong&gt;一句话：ROUGE得分越高越好。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;meteor&quot;&gt;METEOR&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;METEOR是用来评价机器翻译输出的标准。&lt;/strong&gt;该方法基于一元组的精度和召回的调和平均（Harmonic mean），召回的权重比精度要高一点。这个标准还有一些其他标准没有的特性，设计它是为了解决BLEU存在的一些问题。它与人类判断相关性高，而且和BLEU不同，它不仅在整个集合，而且在句子和分段级别，也能和人类判断的相关性高。在全集级别，它的相关性是0.964，BLEU是0.817。在句子级别，它的相关性最高到了0.403。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一句话：METEOR得分越高越好。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;cider&quot;&gt;CIDEr&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;CIDEr是专门设计出来用于图像标注问题的，&lt;/strong&gt;它是通过对每个n元组进行Term Frequency Inverse Document Frequency (TF-IDF) 权重计算，来衡量图像标注的一致性的&lt;/p&gt;

&lt;p&gt;一句话：CIDEr得分越高越好。&lt;/p&gt;

&lt;h2 id=&quot;图像标注模型发展&quot;&gt;图像标注模型发展&lt;/h2&gt;

&lt;p&gt;其实时间也并不长，将CNN和RNN结合的模型用于解决图像标注问题的研究最早也就从2014开始提出，在2015年开始对模型各部分组成上进行更多尝试与优化，到2016年CVPR上成为一个热门的专题。&lt;/p&gt;

&lt;p&gt;在这个发展中，将&lt;strong&gt;RNN和CNN结合的核心思路没变&lt;/strong&gt;，变化的是使用了更好更复杂的CNN模型，效果更好的LSTM，图像特征输入到RNN中的方式，以及更复合的特征输入等。正由于其发展时间跨度较短，通过阅读该领域的一些重要文章，可以相对轻松地理出大牛们攻城拔寨的思路脉络，这对我们自己从事研究的思路也会有所启发&lt;/p&gt;

&lt;h3 id=&quot;m-rnn模型&quot;&gt;m-RNN模型&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/images_caption1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;nic模型&quot;&gt;NIC模型&lt;/h3&gt;

&lt;p&gt;模型的结构如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/images_caption.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图像特征部分是换汤不换药：我们可以看见，图像经过卷积神经网络，最终还是变成了特征数据（就是特征向量）出来了。唯一的不同就是这次试用的CNN不一样了，取得第几层的激活数据不一样了，归根结底，出来的还是特征向量；&lt;/p&gt;

&lt;p&gt;但是！图像特征只在刚开始的时候输入了LSTM，后续没有输入，这点和m-RNN模型是不同的！&lt;/p&gt;

&lt;p&gt;单词输入部分还是老思路：和m-RNN模型一样，每个单词采取了独热（one-hot）编码，用来表示单词的是一个维度是词汇表数量的向量。向量和矩阵W_e相乘后，作为输入进入到LSTM中。&lt;/p&gt;

&lt;p&gt;使用LSTM来替换了RNN。LSTM是什么东西呢，简单地来说，可以把它看成是效果更好RNN吧。为什么效果更好呢？因为它的公式更复杂哈哈😝（并不是）。&lt;/p&gt;

</description>
        <pubDate>Mon, 08 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/08/%E5%9B%BE%E5%83%8F%E6%A0%87%E6%B3%A8.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/08/%E5%9B%BE%E5%83%8F%E6%A0%87%E6%B3%A8.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Connection of RL AND GAN</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#connection-of-rl-and-gan&quot; id=&quot;markdown-toc-connection-of-rl-and-gan&quot;&gt;Connection of RL AND GAN&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#connecting-generative-adversarial-network-and-actor-critic-methods&quot; id=&quot;markdown-toc-connecting-generative-adversarial-network-and-actor-critic-methods&quot;&gt;Connecting generative adversarial network and actor-critic methods&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#概述&quot; id=&quot;markdown-toc-概述&quot;&gt;概述&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bilevel-optimization-problems&quot; id=&quot;markdown-toc-bilevel-optimization-problems&quot;&gt;bilevel optimization problems&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#gans-as-a-kind-of-actor-critic&quot; id=&quot;markdown-toc-gans-as-a-kind-of-actor-critic&quot;&gt;GANs as a kind of Actor-Critic&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#stabilizing-strategies&quot; id=&quot;markdown-toc-stabilizing-strategies&quot;&gt;Stabilizing Strategies&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;connection-of-rl-and-gan&quot;&gt;Connection of RL AND GAN&lt;/h1&gt;

&lt;h2 id=&quot;connecting-generative-adversarial-network-and-actor-critic-methods&quot;&gt;Connecting generative adversarial network and actor-critic methods&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.01945.pdf&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;概述&quot;&gt;概述&lt;/h3&gt;

&lt;p&gt;Actor-critic methods  : 许多RL方法 (e.g., policy gradient) 只作用于policy 或者 value function。Actor-critic方法则结合了policy-only和value function-only 的方法。 其中critic用来近似或者估计value function，actor 被称为policy structure, 主要用来选择action。Actor-critic是一个on-policy的学习过程。Critic模型的结果用来帮助提高actor policy的性能。&lt;/p&gt;

&lt;p&gt;GAN和actor-critic具有许多相似之处。&lt;strong&gt;Actor-critic模型中的actor功能类似于GAN中的generator， 他们都是用来take an action or generate a sample。Actor-critic模型中的critic则类似于GAN中的discriminator, 主要用来评估 actor or generator 的输出。&lt;/strong&gt;这篇论文主要贡献在于从不同的角度来说明了GAN和actor－critic模型的相同与不同点，从而鼓励研究GAN的学者和研究actor-critic模型的学者合作研发出通用、稳定、可扩展的算法，或者从各自的研究中获取灵感。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Connection_RL_AND_GAN.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;bilevel-optimization-problems&quot;&gt;bilevel optimization problems&lt;/h2&gt;

&lt;p&gt;Both GANs and AC can be seen as bilevel or two-time-scale optimization problems, where one model is optimized with respect to the optimum of another model:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Connection_RL_AND_GAN1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;他们的共同思想&lt;strong&gt;都是互相优化，其中一个模型的优化关于另个的最优。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In some AC methods, the critic provides a lower-variance baseline for policy gradient methods than estimating the value from returns. In this case even a bad estimate of the value function can be useful, as the policy gradient will be unbiased no matter what baseline is used. In other AC methods, the policy is updated with respect to the approximate value function, in which case pathologies similar to those in GANs can result. If the policy is optimized with respect to an incorrect value function, it may lead to a bad policy which never fully explores the space, preventing a good value function from being found and leading to degenerate solutions.&lt;/p&gt;

&lt;p&gt;有一类AC方法会可以给policy gradient methods提供比评估价值函数更小的基准方差的价值回报，这个时候就算是不好的评估也是有用的，因为其实无bais的（//TODO）。&lt;/p&gt;

&lt;p&gt;而另外的一类中，评估价值函数会直接影响policy gradient methods，这一类就类似于GANS。也就是&lt;strong&gt;critic网络或者GAN中的D网络的评价直接会影响actor或者GAN中的G网络，正向的评价会使得网络变得更好，但是不好的评估回报也会导致不好的引导。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;gans-as-a-kind-of-actor-critic&quot;&gt;GANs as a kind of Actor-Critic&lt;/h2&gt;

&lt;p&gt;GANs can be seen as a modified actor-critic method with blind actors in stateless MDPs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Connection_RL_AND_GAN3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Connection_RL_AND_GAN4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;两者的G网络/actor网络在优化的时候都是用D网络或者critic网络提供的梯度信息&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;GANS可以看作是状态无限，然后actors是blind的一种特殊的MDP。原因是：在这里动作集合就是在每个像素生成器所给的值，状态就是生成的图片，因为生成图片的是无关联的，也就是现在生成的图片和未来生成的图片无关，这就导致了状态的无限性（&lt;strong&gt;也就是在任何的pixel上的数值是连续的，也就是体现在生成图片的无限性&lt;/strong&gt;）。actors是blind是因为它不知道环境的任何状态知识。还有就是当给系统展示real image的时候，actor应该参数不变，&lt;em&gt;在GANS体现在达到均衡吧，这个时候生成器就不改变它的权重了（我觉得）&lt;/em&gt;。在actor-critic中体现的就是reword为一是，参数不需要太大的改变。&lt;/p&gt;

&lt;p&gt;当然他们之间存在不同点：AC算法并不是同一个loss在不同方向上的优化，所用的loss函数不同的。gradient的来源也不同，更新actor-critic更像是正交而不是对抗的（在最后一段），GANS对环境是部分观测的，具体看第二段和第三段。&lt;/p&gt;

&lt;h2 id=&quot;stabilizing-strategies&quot;&gt;Stabilizing Strategies&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;GAN和AC算法都是不稳定的&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Having reviewed the basics of GANs, actor-critic algorithms and their extensions, here we discuss the “tricks of the trade” used by each community to make them work. The different methods are summarized in Table 1. While not meant as an exhaustive list, we have included those that we believe have either made the largest impact in their fields or have the greatest potential for crossover between fields.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Connection_RL_AND_GAN2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Mon, 08 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/08/Connection-of-RL-AND-GAN.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/08/Connection-of-RL-AND-GAN.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Encoder-Decoder框架</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#encoder-decoder框架&quot; id=&quot;markdown-toc-encoder-decoder框架&quot;&gt;Encoder-Decoder框架&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#seq2sqeq-优化&quot; id=&quot;markdown-toc-seq2sqeq-优化&quot;&gt;seq2sqeq 优化&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#取词策略&quot; id=&quot;markdown-toc-取词策略&quot;&gt;取词策略&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#max策略和sample策略&quot; id=&quot;markdown-toc-max策略和sample策略&quot;&gt;max策略和sample策略&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#max策略和sample策略的一些优缺点&quot; id=&quot;markdown-toc-max策略和sample策略的一些优缺点&quot;&gt;max策略和sample策略的一些优缺点&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#beam-search策略&quot; id=&quot;markdown-toc-beam-search策略&quot;&gt;beam-search策略&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#attention-思想&quot; id=&quot;markdown-toc-attention-思想&quot;&gt;Attention 思想&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#attention研究进展&quot; id=&quot;markdown-toc-attention研究进展&quot;&gt;Attention研究进展&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#recurrent-models-of-visual-attention&quot; id=&quot;markdown-toc-recurrent-models-of-visual-attention&quot;&gt;Recurrent Models of Visual Attention&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#attention-based-rnn-in-nlp&quot; id=&quot;markdown-toc-attention-based-rnn-in-nlp&quot;&gt;Attention-based RNN in NLP&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#effective-approaches-to-attention-based-neural-machine-translation&quot; id=&quot;markdown-toc-effective-approaches-to-attention-based-neural-machine-translation&quot;&gt;Effective Approaches to Attention-based Neural Machine Translation&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#attention-based-cnn-in-nlp&quot; id=&quot;markdown-toc-attention-based-cnn-in-nlp&quot;&gt;Attention-based CNN in NLP&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#总结&quot; id=&quot;markdown-toc-总结&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;encoder-decoder框架&quot;&gt;Encoder-Decoder框架&lt;/h1&gt;

&lt;p&gt;encoder-decoder模型的想法很简单：&lt;strong&gt;对于RNN语言模型，在我们计算输出序列E的概率时，先另一个RNN处理源序列F，来计算语言模型的初始状态。encoder-decoder的含义是：通过第一个神经网络来“编码”F的信息到一个隐层状态，在使用第二个神经网络来预测E“解码”该隐层到输出序列。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;模型结构如图&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;encoder层的处理单元是RNN(f)，decoder层是RNN(e)，对decoder层的输出采用softmax来获得时刻t输出该隐层的概率，上图的公式为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;mt是输入词序列ft的embedding table；ht是隐层输出，pt是得到的概率。&lt;strong&gt;可以看出encoder和decoder的区别在于：encoder的隐层初始值是零，而decoder层的初始值是encoder层的最终输出向量，这意味着decoder层获得了源序列的所有语义信息。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在每次decoder出一个et时，我们将其embedding和输出hidden state连结输入到下一个RNN单元，直到解码到句尾标记。（hidden state经过softmax后得到的概率向量的维度为词典维，类似于one-hot representation，每一维代表词典中的一个词，概率最高即为预测得到的词）&lt;/p&gt;

&lt;p&gt;模型的训练目标则是期望这个由Encoder得到的向量能够cover整个句子的语义，从研究人员做的大量实验来看我们发现这样的结构确实可以使得Encoder得到的向量cover&lt;strong&gt;整个句子信息。&lt;/strong&gt;同时Decoder-RNN又能很好的生成一句话。&lt;strong&gt;模型cost function为Decoder产生的句子的交叉熵。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;seq2sqeq-优化&quot;&gt;seq2sqeq 优化&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder8n.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在训练的时候，&lt;strong&gt;我们需要的是直接用MLE去优化-log值，得到极大似然估计。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;取词策略&quot;&gt;取词策略&lt;/h2&gt;

&lt;p&gt;在rnn语言模型（rnnlm）中，测试（生成）过程就是利用已经训练好的RNNLM来生成一段文本。具体过程为，首先输入一个初始词用于触发（这个词可以简单的控制生成的内容，比如想生成与“人工智能”相关的内容，那么初始输入就是“人工智能”。倘若想让机器完全自动生成，那么第一个输入就是“start”），然后模型给出一个输出Y1，（这个Yi是词表上所有词的概率分布根据这个概率分布），由这个概率分布，我们通过某种策略（max或者sample策略，后面会详细介绍）选取得到一个词X1，然后再次将X1输入到RNN中，得到Y2，再得到X2，如此往复，至到得到“end”（或者达到最大循环次数）结束生成。&lt;/p&gt;

&lt;h3 id=&quot;max策略和sample策略&quot;&gt;max策略和sample策略&lt;/h3&gt;

&lt;p&gt;max策略和sample策略。注：这里的sample策略不是很理解的话，可以看下这篇论文&lt;a href=&quot;https://papers.nips.cc/paper/5956-scheduled-sampling-for-sequence-prediction-with-recurrent-neural-networks.pdf&quot;&gt;Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks&lt;/a&gt;其实这两种策略就是如何根据一个概率分布来选择一个词，比如模型在第i个step输出了一个词表上的概率分布Yi，然后我们需要根据这个分布从词表中选择一个词。max策略，顾名思义，就是选择概率值最大的那个词，而sample策略就是根据每个词的概率进行采样。很显然这两种策略的最大区别就是max策略是固定的，也就是第一个词定了之后生成的文本一定是一模一样的，而sample策略则不然，具有一定的随机性，所以即使第一个词固定后每次生成的文本也是不一样的。&lt;/p&gt;

&lt;h3 id=&quot;max策略和sample策略的一些优缺点&quot;&gt;max策略和sample策略的一些优缺点&lt;/h3&gt;

&lt;p&gt;max策略的优势就是能够最大化保证句子的通顺，因为选取概率最大的那个词一定是最“通顺”的（概率最大的），但带来的问题就是会出现重复，这个也比较好理解，从生成的整个句子的角度来考虑，&lt;strong&gt;max策略会倾向生成概率比较大的句子，而从训练的角度来讲概率大的句子一定是那些出现次数比较多的，因而导致了生成的句子比较固定。&lt;/strong&gt;对于这一问题的解决方法，就是采用另外一种生成策略——sample策略，这也是karpathy的char-rnn代码中默认的生成策略。&lt;strong&gt;sample策略引入一定的随机性，会很有效的避免重复现象的出现，但会牺牲一定的连贯性（通顺度），所以有的人做法是利用sample策略生成一堆候选，然后再训练一个反向RNNLM，利用方向RNNLM和正向RNNLM（用于生成句子的模型）给出的概率值对候选句子进行ranking。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;beam-search策略&quot;&gt;beam-search策略&lt;/h2&gt;

&lt;p&gt;max和sample策略是每一步使用的策略，而beam-search是全局解码算法，其实我们的目的是要得到概率最大的句子，很显然在每一步都取概率最大的词并不能保证最后生成的句子概率是最大的，&lt;strong&gt;这个其实是一个图上的最优路径问题，应该是一个动态规划问题而不是一个贪心问题，&lt;/strong&gt;但是每一步解码时都会有词表大小这么多个节点，想要得到全局最优解搜索空间太大，所以采用beam-search来减少搜索空间，从而得到一个接近最优解的解，为了解决sample策略不连贯的问题，将sample策略和beam-search进行了结合，在每一步解码时用sample得到一些候选，然后选择整体概率高的top-N个结果，就是将我们熟知的beam-search中选最大的N个作为候选的方法改成了按照概率采用N个作为候选。&lt;/p&gt;

&lt;h2 id=&quot;attention-思想&quot;&gt;Attention 思想&lt;/h2&gt;

&lt;p&gt;传统的Encoder-Decoder缺点是，无论之前的context有多长，包含多少信息量，最终都要被压缩成一个几百维的vector。这意味着context越大，最终的state vector会丢失越多的信息。&lt;/p&gt;

&lt;p&gt;事实上，因为context在输入时已知，一个模型完全可以在decode的过程中利用context的全部信息,或者部分信息而不仅仅是最后一个state。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;而Attention的思想，即在得到Encoder向量后，在进行Decoder的时候模型不仅会用到向量还会用到每个词对应的RNN隐层向量。&lt;/strong&gt;这里多插入一句，Attention其实是一种思想，它可以有多种实现方式。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;attention思想知识一种思想，有多种实现方式，有很多类别，比如soft和hard的区分（这两者的区分主要在于sotf得到attention的上下文C&lt;sub&gt;i&lt;/sub&gt;是通过加权和得到的，其中的比重最大可以看成是对齐的！而hard的attention的上下文C是固定的一个或者几个的encoder隐状态构成的，用分类表示是否选取莫个隐状态）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;attention研究进展&quot;&gt;Attention研究进展&lt;/h3&gt;

&lt;p&gt;Attention机制最早是在视觉图像领域提出来的，应该是在九几年思想就提出来了，但是真正火起来应该算是google mind团队的这篇论文&lt;a href=&quot;https://arxiv.org/abs/1406.6247&quot;&gt;Recurrent Models of Visual Attention&lt;/a&gt;，他们在RNN模型上使用了attention机制来进行图像分类。随后，Bahdanau等人在论文&lt;a href=&quot;https://arxiv.org/abs/1409.0473&quot;&gt;《Neural Machine Translation by Jointly Learning to Align and Translate》&lt;/a&gt; 中，使用类似attention的机制在机器翻译任务上将翻译和对齐同时进行，他们的工作算是是第一个提出attention机制应用到NLP领域中。接着类似的基于attention机制的RNN模型扩展开始应用到各种NLP任务中。最近，如何在CNN中使用attention机制也成为了大家的研究热点。下图表示了attention研究进展的大概趋势。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;recurrent-models-of-visual-attention&quot;&gt;Recurrent Models of Visual Attention&lt;/h3&gt;

&lt;p&gt;在介绍NLP中的Attention之前，我想大致说一下图像中使用attention的思想。就具代表性的这篇论文&lt;a href=&quot;https://arxiv.org/abs/1406.6247&quot;&gt;Recurrent Models of Visual Attention&lt;/a&gt;，他们研究的动机其实也是受到人类注意力机制的启发。人们在进行观察图像的时候，其实并不是一次就把整幅图像的每个位置像素都看过，大多是根据需求将注意力集中到图像的特定部分。而且人类会根据之前观察的图像学习到未来要观察图像注意力应该集中的位置。下图是这篇论文的核心模型示意图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;该模型是在传统的RNN上加入了attention机制（即红圈圈出来的部分），通过attention去学习一幅图像要处理的部分，每次当前状态，都会根据前一个状态学习得到的要关注的位置l和当前输入的图像，去处理注意力部分像素，而不是图像的全部像素。这样的好处就是更少的像素需要处理，减少了任务的复杂度。可以看到图像中应用attention和人类的注意力机制是很类似的，接下来我们看看在NLP中使用的attention。&lt;/p&gt;

&lt;h2 id=&quot;attention-based-rnn-in-nlp&quot;&gt;Attention-based RNN in NLP&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1409.0473&quot;&gt;《Neural Machine Translation by Jointly Learning to Align and Translate》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇论文算是在NLP中第一个使用attention机制的工作。他们把attention机制用到了神经网络机器翻译（NMT）上，NMT其实就是一个典型的sequence to sequence模型，也就是一个encoder to decoder模型，传统的NMT使用两个RNN，一个RNN对源语言进行编码，将源语言编码到一个固定维度的中间向量，然后在使用一个RNN进行解码翻译到目标语言，传统的模型如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这篇论文提出了基于attention机制的NMT，模型大致如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图中我并没有把解码器中的所有连线画玩，只画了前两个词，后面的词其实都一样。可以看到基于attention的NMT在传统的基础上，它把源语言端的每个词学到的表达（传统的只有最后一个词后学到的表达）和当前要预测翻译的词联系了起来，这样的联系就是通过他们设计的attention进行的，在模型训练好后，根据attention矩阵，我们就可以得到源语言和目标语言的对齐矩阵了。具体论文的attention设计部分如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到他们是使用一个感知机公式来将目标语言和源语言的每个词联系了起来，然后通过soft函数将其归一化得到一个概率分布，就是attention矩阵。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder7.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从结果来看相比传统的NMT（RNNsearch是attention NMT，RNNenc是传统NMT）效果提升了不少，最大的特点还在于它可以可视化对齐，并且在长句的处理上更有优势。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;在这里的可视化对齐值得是，比如在NMT中，就是两种语言中的单词翻译对应，当然可能顺序是不一样的&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;effective-approaches-to-attention-based-neural-machine-translation&quot;&gt;Effective Approaches to Attention-based Neural Machine Translation&lt;/h3&gt;

&lt;p&gt;这篇论文是继上一篇论文后，一篇很具代表性的论文，他们的工作告诉了大家attention在RNN中可以如何进行扩展，这篇论文对后续各种基于attention的模型在NLP应用起到了很大的促进作用。在论文中他们提出了两种attention机制，一种是全局（global）机制，一种是局部（local）机制。&lt;/p&gt;

&lt;p&gt;首先我们来看看global机制的attention，其实这和上一篇论文提出的attention的思路是一样的，它都是对源语言对所有词进行处理，不同的是在计算attention矩阵值的时候，他提出了几种简单的扩展版本。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder8.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在他们最后的实验中general的计算方法效果是最好的。&lt;/p&gt;

&lt;p&gt;我们再来看一下他们提出的local版本。主要思路是为了减少attention计算时的耗费，作者在计算attention时并不是去考虑源语言端的所有词，而是根据一个预测函数，先预测当前解码时要对齐的源语言端的位置Pt，然后通过上下文窗口，仅考虑窗口内的词。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder9.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;里面给出了两种预测方法，local-m和local-p，再计算最后的attention矩阵时，在原来的基础上去乘了一个pt位置相关的高斯分布。作者的实验结果是局部的比全局的attention效果好。&lt;/p&gt;

&lt;p&gt;这篇论文最大的贡献我觉得是首先告诉了我们可以如何扩展attention的计算方式，还有就是局部的attention方法。&lt;/p&gt;

&lt;h3 id=&quot;attention-based-cnn-in-nlp&quot;&gt;Attention-based CNN in NLP&lt;/h3&gt;

&lt;p&gt;随后基于Attention的RNN模型开始在NLP中广泛应用，不仅仅是序列到序列模型，各种分类问题都可以使用这样的模型。那么在深度学习中与RNN同样流行的卷积神经网络CNN是否也可以使用attention机制呢？《ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs》 [13]这篇论文就提出了3中在CNN中使用attention的方法，是attention在CNN中较早的探索性工作。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder10.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;传统的CNN在构建句对模型时如上图，通过每个单通道处理一个句子，然后学习句子表达，最后一起输入到分类器中。这样的模型在输入分类器前句对间是没有相互联系的，作者们就想通过设计attention机制将不同cnn通道的句对联系起来。&lt;/p&gt;

&lt;p&gt;第一种方法ABCNN0-1是在卷积前进行attention，通过attention矩阵计算出相应句对的attention feature map，然后连同原来的feature map一起输入到卷积层。具体的计算方法如下。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder11.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第二种方法ABCNN-2是在池化时进行attention，通过attention对卷积后的表达重新加权，然后再进行池化，原理如下图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder12.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第三种就是把前两种方法一起用到CNN中，如下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder13.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这篇论文提供了我们在CNN中使用attention的思路。现在也有不少使用基于attention的CNN工作，并取得了不错的效果。&lt;/p&gt;

&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;

&lt;p&gt;最后进行一下总结。Attention在NLP中其实我觉得可以看成是一种自动加权，它可以把两个你想要联系起来的不同模块，通过加权的形式进行联系。目前主流的计算公式有以下几种：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder14.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过设计一个函数将目标模块mt和源模块ms联系起来，然后通过一个soft函数将其归一化得到概率分布。&lt;/p&gt;

&lt;p&gt;目前Attention在NLP中已经有广泛的应用。它有一个很大的优点就是可以可视化attention矩阵来告诉大家神经网络在进行任务时关注了哪些部分。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/encoder_decoder15.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不过在NLP中的attention机制和人类的attention机制还是有所区别，它基本还是需要计算所有要处理的对象，并额外用一个矩阵去存储其权重，其实增加了开销。而不是像人类一样可以忽略不想关注的部分，只去处理关注的部分。&lt;/p&gt;

&lt;p&gt;参考博文：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://geek.csdn.net/news/detail/50558&quot;&gt;深度学习和自然语言处理中的attention和memory机制&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/robert-	dlut/p/5952032.html&quot;&gt;注意力机制（Attention Mechanism）在自然语言处理中的应用&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Sat, 06 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/06/Encoder-Decoder%E6%A1%86%E6%9E%B6.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/06/Encoder-Decoder%E6%A1%86%E6%9E%B6.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>图像生成模型概述-GAN</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#图像生成模型概述-gan&quot; id=&quot;markdown-toc-图像生成模型概述-gan&quot;&gt;图像生成模型概述-GAN&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#maximum-likelihood-estimation&quot; id=&quot;markdown-toc-maximum-likelihood-estimation&quot;&gt;Maximum likelihood estimation&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#a-taxonomy-of-deep-generative-models&quot; id=&quot;markdown-toc-a-taxonomy-of-deep-generative-models&quot;&gt;A taxonomy of deep generative models&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#explicit-density-models&quot; id=&quot;markdown-toc-explicit-density-models&quot;&gt;Explicit density models&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#implicit-density-models&quot; id=&quot;markdown-toc-implicit-density-models&quot;&gt;Implicit density models&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#comparing-gans-to-other-generative-models&quot; id=&quot;markdown-toc-comparing-gans-to-other-generative-models&quot;&gt;Comparing GANs to other generative models&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#gan的发展现状和研究方向&quot; id=&quot;markdown-toc-gan的发展现状和研究方向&quot;&gt;GAN的发展现状和研究方向。&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;图像生成模型概述-gan&quot;&gt;图像生成模型概述-GAN&lt;/h1&gt;

&lt;h2 id=&quot;maximum-likelihood-estimation&quot;&gt;Maximum likelihood estimation&lt;/h2&gt;

&lt;p&gt;To simplify the discussion somewhat, we will focus on generative models that work via the principle of maximum likelihood.Some generative models do not use maximum likelihood by default, but can be made to do so (GANs fall into this category).&lt;/p&gt;

&lt;p&gt;也就是说GAN也是以极大似然来建模的一种生成模型。而与庞大的真实数据相比，&lt;strong&gt;*概率生成模型的参数个数要远远小于数据的数量。因此，在训练过程中，生成模型会被强迫去发现数据背后更为简单的统计规律，从而能够生成这些数据。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/generation_model_cv.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意两点，（1）是在计算极大似然的时候，用log的方式（2）是优化极大似然都可以看所是在缩小KL散度。&lt;/p&gt;

&lt;h2 id=&quot;a-taxonomy-of-deep-generative-models&quot;&gt;A taxonomy of deep generative models&lt;/h2&gt;

&lt;p&gt;If we restrict our attention to deep generative models that work by &lt;strong&gt;maximizing the likelihood&lt;/strong&gt;, we can compare several models by contrasting the ways that they compute either the likelihood and its gradients, or approximations to these quantities. As mentioned earlier, many of these models are often used with principles other than maximum likelihood, but we can examine the maximum likelihood variant of each of them in order to reduce the amount of distracting differences between the methods&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/generation_model_cv1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上图，我们关注用极大似然的方式建模的话，有上面的一些种类，每一类都有他们的优缺点。&lt;/p&gt;

&lt;h2 id=&quot;explicit-density-models&quot;&gt;Explicit density models&lt;/h2&gt;

&lt;p&gt;The main difficulty present in explicit density models is &lt;strong&gt;designing a model that can capture all of the complexity of the data to be generated while still maintaining computational tractability.&lt;/strong&gt; There are two different strategies used to confront this challenge: &lt;strong&gt;(1) careful construction of models whose structure guarantees their tractability, as described in section next, and (2) models that admit tractable approximations to the likelihood and its gradients, as described in section next&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;explicit density models 又分为tractable explicit models和逼近的explicit model，怎么理解呢，tractable explicit model通常可以直接通过数学方法来建模求解，而基于逼近的explicit model通常无法直接对数据分布进行建模，可以利用数学里的一些近似方法来做数据建模， 通常基于逼近的explicit model分为确定性（变分方法：如VAE的lower bound）和随机性的方法（马尔科夫链蒙特卡洛方法）。&lt;/p&gt;

&lt;p&gt;VAE lower bound：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/generation_model_cv2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;VAE依靠的是传统的&lt;strong&gt;概率图模型的框架&lt;/strong&gt;，通过一些适当的&lt;strong&gt;联合分布&lt;/strong&gt;的概率逼近，简化整个学习过程，使得所学习到的模型能够很好地解释所观测到的数据。&lt;/p&gt;

&lt;h2 id=&quot;implicit-density-models&quot;&gt;Implicit density models&lt;/h2&gt;

&lt;p&gt;Some models can be trained &lt;strong&gt;without even needing to explicitly define a density functions.&lt;/strong&gt; These models instead offer a way to train the model while interacting only indirectly with p model , usually by sampling from it.&lt;/p&gt;

&lt;h2 id=&quot;comparing-gans-to-other-generative-models&quot;&gt;Comparing GANs to other generative models&lt;/h2&gt;

&lt;p&gt;生成对抗式网络（GAN）能够有效地解决很多生成式方法的缺点，主要包括：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;并行产生samples；&lt;/li&gt;
  &lt;li&gt;生成式函数的限制少，如无需合适马尔科夫采样的数据分布（Boltzmann machines），生成式函数无需可逆、latent 3. code需与sample同维度（nonlinear ICA）；&lt;/li&gt;
  &lt;li&gt;无需马尔科夫链的方法（Boltzmann machines， GSNs）；&lt;/li&gt;
  &lt;li&gt;相对于VAE的方法，无需variational bound；&lt;/li&gt;
  &lt;li&gt;GAN比其他方法一般来说性能更好。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;At the same time, GANs have taken on a new disadvantage: training them requires finding the Nash equilibrium of a game, which is a more difficult problem than optimizing an objective function.&lt;/p&gt;

&lt;p&gt;当然，GAN还存在缺点，比如说容易模型崩塌，训练不稳定等。&lt;/p&gt;

&lt;h2 id=&quot;gan的发展现状和研究方向&quot;&gt;GAN的发展现状和研究方向。&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Non-convergence&lt;/li&gt;
  &lt;li&gt;Evaluation of generative models&lt;/li&gt;
  &lt;li&gt;Discrete outputs&lt;/li&gt;
  &lt;li&gt;Semi-supervised learning&lt;/li&gt;
  &lt;li&gt;Using the code&lt;/li&gt;
  &lt;li&gt;Developing connections to reinforcement learning&lt;/li&gt;
  &lt;li&gt;Plug and Play Generative Networks&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;总的研究方向有上面的几个。&lt;/p&gt;

</description>
        <pubDate>Fri, 05 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/05/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/05/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>SeqGAN</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#seqgan&quot; id=&quot;markdown-toc-seqgan&quot;&gt;SeqGAN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#主要问题&quot; id=&quot;markdown-toc-主要问题&quot;&gt;主要问题&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#importance-sampling&quot; id=&quot;markdown-toc-importance-sampling&quot;&gt;importance sampling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#seqgan-sequence-generative-adversarial-nets-with-policy-gradient&quot; id=&quot;markdown-toc-seqgan-sequence-generative-adversarial-nets-with-policy-gradient&quot;&gt;SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#seqgan的ralated-work-and-dissection&quot; id=&quot;markdown-toc-seqgan的ralated-work-and-dissection&quot;&gt;SeqGAN的ralated work and dissection&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#网络结构和训练&quot; id=&quot;markdown-toc-网络结构和训练&quot;&gt;网络结构和训练&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#seqgan实验&quot; id=&quot;markdown-toc-seqgan实验&quot;&gt;seqGAN实验&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#seqgan的存在问题&quot; id=&quot;markdown-toc-seqgan的存在问题&quot;&gt;seqGAN的存在问题&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;seqgan&quot;&gt;SeqGAN&lt;/h2&gt;

&lt;p&gt;主要想记录生成序列的gan在nlp的应用。主要是下面两篇论文
&lt;a href=&quot;https://arxiv.org/pdf/1609.05473v5.pdf&quot;&gt;SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient&lt;/a&gt;
&lt;a href=&quot;https://arxiv.org/pdf/1702.07983v1.pdf&quot;&gt;Maximum-Likelihood Augmented Discrete Generative Adversarial Networks&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;主要问题&quot;&gt;主要问题&lt;/h2&gt;

&lt;p&gt;GAN最开始是设计用于生成连续数据，但是自然语言处理中我们要用来生成离散tokens的序列。在生成离散tokens的序列时，会产生如下的问题：&lt;/p&gt;

&lt;p&gt;1.因为生成器(Generator，简称G)需要利用从判别器(Discriminator，简称D)得到的梯度进行训练，而G和D都需要完全可微，碰到有离散变量的时候## Maximum-Likelihood Augmented Discrete Generative Adversarial Networks（MaliGAN）&lt;/p&gt;

&lt;p&gt;这篇论文的主要贡献如下：&lt;/p&gt;

&lt;p&gt;1.为G&lt;strong&gt;构造一个全新的目标函数，用到了Importance Sampling，将其与D的output结合起来，令训练过程更加稳定同时梯度的方差更低。&lt;/strong&gt;尽管这个目标函数和RL的方法类似，但是相比之下更能够降低estimator的方差（强烈建议看原文的3.2 Analysis，分析了当D最优以及D经过训练但并没有到最优两种情况下，这个新的目标函数仍然能发挥作用）&lt;/p&gt;

&lt;p&gt;2.生成较长序列的时候需要用到多次random sampling，所以文章还&lt;strong&gt;提出了两个降低方差的技巧&lt;/strong&gt;：第一个是蒙特卡罗树搜索，这个大家都比较熟悉; 第二个文章称之为Mixed MLE-Mali Training，就是从真实数据中进行抽样，若序列长度大于N，则固定住前N个词，然后基于前N个词去freely run G产生M个样本，一直run到序列结束。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/GAN_FOR_NLP3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;importance-sampling&quot;&gt;importance sampling&lt;/h2&gt;

&lt;p&gt;就会有问题，只用BP不能为G提供训练的梯度。在&lt;strong&gt;GAN中我们通过对G的参数进行微小的改变，令其生成的数据更加“逼真”。若生成的数据是基于离散的tokens，D给出的信息很多时候都没有意义，&lt;/strong&gt;因为和图像不同。图像是连续的，微小的改变可以在像素点上面反应出来，但是你对tokens做微小的改变，在对应的dictionary space里面可能根本就没有相应的tokens.&lt;/p&gt;

&lt;p&gt;2.GAN只可以对已经生成的完整序列进行打分，而对一部分生成的序列，如何判断它现在生成的一部分的质量和之后生成整个序列的质量也是一个问题。&lt;/p&gt;

&lt;h2 id=&quot;seqgan-sequence-generative-adversarial-nets-with-policy-gradient&quot;&gt;SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient&lt;/h2&gt;

&lt;p&gt;在这篇论文中，针对上面第一个问题，首先是将D的输出作为Reward，然后用Policy Gradient Method来训练G,也就是用D的输出作为Reward作为指导来改变Policy Gradient的方向，这也符合对抗网络的思想。针对第二个问题，通过蒙特卡罗搜索，针对部分生成的序列，用一个Roll-Out Policy（也是一个LSTM）来Sampling完整的序列，再交给D打分，最后对得到的Reward求平均值。&lt;/p&gt;

&lt;h2 id=&quot;seqgan的ralated-work-and-dissection&quot;&gt;SeqGAN的ralated work and dissection&lt;/h2&gt;

&lt;p&gt;之前his is due to the generator network in GAN is designed to be able to adjust the output continuously, which does not work on discrete data generation，也就是说作者说它不适合做text生成。&lt;/p&gt;

&lt;p&gt;详细请看reddit&lt;a href=&quot;http://goo.gl/Wg9DR7&quot;&gt;Generative adversarial networks for text.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The most popular way of training RNNs is to maximize the likelihood of each token in the training data whereas (Bengio et al. 2015) pointed out that the discrepancy between training and generating makes the maximum likelihood estimation suboptimal and proposed scheduled sampling strategy (SS). Later(Huszár 2015) theorized that the objective function underneath SS is improper and explained the reason why GANs tend to generate natural looking samples in theory. Consequently, the GANs have great potential but are not practically feasible to discrete probabilistic models currently.&lt;/p&gt;

&lt;p&gt;上面的一段话摘自ralated work，这里说明了RNN的bias exposure的问题和在&lt;a href=&quot;&quot;&gt;How (not) to train your generative model: Scheduled sampling, likelihood, adversary&lt;/a&gt;说明了之前ss策略的不合理性和GAN的generate natural-looking samples。也就是说GAN存在潜力，只是在现实中没有表现。&lt;/p&gt;

&lt;p&gt;在这篇文章中提到&lt;a href=&quot;&quot;&gt;Data generation as sequential decision making&lt;/a&gt;,序列可以表示成为一个a sequential decision making process, which can be potentially be solved by reinforcement learning techniques. 也就是这种问题可以由RL的方式来解决，当然，事实也是如此。现在很多的论文也是通过rl的方式来解决。&lt;/p&gt;

&lt;p&gt;受到阿尔法狗的启发，因为reward都是对整体的，所以同样的应用了蒙特卡洛搜索，引用的是这个：&lt;a href=&quot;&quot;&gt;A survey of monte carlo tree search methods&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MLE:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/GAN_FOR_NLP10.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;传统的LSTM generator模型，其实就是语言模型。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DAD（一种MLE的改进模型）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Scheduled sampling for sequence prediction with recurrent neural networks.&lt;/p&gt;

&lt;p&gt;改进MLE的训练过程，解决生成模型decode阶段的exposure bias问题，即在训练过程中逐渐用预测输出替代实际输出作为下一个词的输入。&lt;/p&gt;

&lt;h2 id=&quot;网络结构和训练&quot;&gt;网络结构和训练&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/GAN_FOR_NLP.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;1。左图为GAN网络训练的步骤1，即根据真实样本和伪造样本训练判别器D网 络，这里的D网络用的CNN实现。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;用到的判别器（Discriminator）是卷积神经网络（CNN），而不是递归神经网络（RNN），这可能是一个不错的选择，因为Tong Zhang 就曾经使用CNN 做文本分类任务，&lt;strong&gt;相比 RNN，CNN 更好训练一些，最终训练得到的判别器非常有效，与之相关的问题优化起来也相对容易些。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;2、右图为GAN网络训练的步骤2，根据D网络回传的判别概率通过增强学习更新G网络，这里的G网络用的LSTM实现。&lt;/p&gt;

&lt;p&gt;3、已知G网络的更新策略是增强学习，而增强学习的三个要素点状态state，action，reward。&lt;/p&gt;

&lt;p&gt;本文state指的当前timestep之前的decode结果，也就是lstm随机生成的t个词，action指的当前待解码词，也就是第t个词，D网络判别伪造数据的置信度即为奖励，伪造数据越逼真则相应奖励越大，但该奖励是总的奖励，分配到每个词选择上的reward则采用了以下的近似方法。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/GAN_FOR_NLP1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;简单解释，即&lt;strong&gt;当解码到t时，即对后面T-t个timestep采用蒙特卡洛搜索搜索出N条路径，将这N条路径分别和已经decode的结果组成N条完整输出，然后将D网络对应奖励的平均值作为reward.&lt;/strong&gt;因为当t=T时无法再向后探索路径，所以直接以完整decode结果的奖励作为reward。蒙特卡洛搜索是指在选择下一个节点的时候用蒙特卡洛采样的方式，而蒙特卡洛采样是指根据当前输出词表的置信度随机采样。&lt;/p&gt;

&lt;p&gt;算法结构如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/GAN_FOR_NLP2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过G网络生成sequence用D网络去评判，得到reward。&lt;/p&gt;

&lt;p&gt;根据（4）计算得到每个action选择得到的奖励并求得累积奖励的期望，以此为loss function，并求导对网络进行梯度更新。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/GAN_FOR_NLP5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;5、以下是标准的D网络误差函数，训练目标是最大化识别真实样本的概率，最小化误识别伪造样本的概率。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/GAN_FOR_NLP4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后还像提一下的是，后来的&lt;a href=&quot;https://arxiv.org/pdf/1701.06547.pdf&quot;&gt;Adversarial Learning for Neural Dialogue Generation&lt;/a&gt;用了Policy Gradient Method来对GAN进行训练，和SeqGAN的方法并没有很大的区别，主要是用在了Dialogue Generation这样困难的任务上面。还有两点就是：第一点是除了用蒙特卡罗搜索来解决部分生成序列的问题之外，因为MC Search比较耗费时间，还可以训练一个特殊的D去给部分生成的序列进行打分（这里其实应该是联想到actor critic的做法）。但是从实验效果来看，MC Search的表现要更好一点。&lt;/p&gt;

&lt;p&gt;最后说下在论文中的rollout policy 是什么？取自AlphaGo’s paper中&lt;/p&gt;

&lt;p&gt;The rollout policy … is a linear softmax policy based on fast, incrementally computed, local pattern-based features …&lt;/p&gt;

&lt;p&gt;也可以参看&lt;a href=&quot;https://stats.stackexchange.com/questions/201927/whats-rollout-policy-in-alphagos-paper&quot;&gt;这个回答&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;seqgan实验&quot;&gt;seqGAN实验&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/GAN_FOR_NLP11.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;随机初始一个lstm生成器A，随机生成一部分训练数据，来训练各种生成模型，最后让各种生成模型随机产生一批验证数据，用生成器A去校验这些验证数据是否符合自己的分布。具体方式就是假设验证数据是a,b,c,。将a输入A查看输出b的概率p(b/a)，再输入c查看p(c/a,b)然后用以下标准评判。评判标准：负对数似然也就是交叉熵。&lt;/p&gt;

&lt;h2 id=&quot;seqgan的存在问题&quot;&gt;seqGAN的存在问题&lt;/h2&gt;

</description>
        <pubDate>Tue, 02 May 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/02/SeqGAN,MaliGAN.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/05/02/SeqGAN,MaliGAN.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>蒙特卡洛树搜索 MCTS</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#蒙特卡洛树搜索-mcts&quot; id=&quot;markdown-toc-蒙特卡洛树搜索-mcts&quot;&gt;蒙特卡洛树搜索 MCTS&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#基本算法&quot; id=&quot;markdown-toc-基本算法&quot;&gt;基本算法&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#节点选择&quot; id=&quot;markdown-toc-节点选择&quot;&gt;节点选择&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#bandits-和-ucb&quot; id=&quot;markdown-toc-bandits-和-ucb&quot;&gt;Bandits 和 UCB&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#exploitation-和-exploration&quot; id=&quot;markdown-toc-exploitation-和-exploration&quot;&gt;Exploitation 和 Exploration&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#mcts-和-uct&quot; id=&quot;markdown-toc-mcts-和-uct&quot;&gt;MCTS 和 UCT&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#优点&quot; id=&quot;markdown-toc-优点&quot;&gt;优点&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#aheuristic&quot; id=&quot;markdown-toc-aheuristic&quot;&gt;Aheuristic&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#asymmetric&quot; id=&quot;markdown-toc-asymmetric&quot;&gt;Asymmetric&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#缺点&quot; id=&quot;markdown-toc-缺点&quot;&gt;缺点&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#行为能力&quot; id=&quot;markdown-toc-行为能力&quot;&gt;行为能力&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#速度&quot; id=&quot;markdown-toc-速度&quot;&gt;速度&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#提升&quot; id=&quot;markdown-toc-提升&quot;&gt;提升&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#领域知识&quot; id=&quot;markdown-toc-领域知识&quot;&gt;领域知识&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#领域独立&quot; id=&quot;markdown-toc-领域独立&quot;&gt;领域独立&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;蒙特卡洛树搜索-mcts&quot;&gt;蒙特卡洛树搜索 MCTS&lt;/h1&gt;

&lt;p&gt;这个关于MCTS的&lt;a href=&quot;https://www.lri.fr/~sebag/Slides/InvitedTutorial_CP12.pdf&quot;&gt;ppt&lt;/a&gt;值得一看&lt;/p&gt;

&lt;h1 id=&quot;基本算法&quot;&gt;基本算法&lt;/h1&gt;

&lt;p&gt;基本的 MCTS 算法非常简单：根据模拟的输出结果，按照节点构造搜索树。其过程可以分为下面的若干步：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/MCTS1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;1.选择 Selection：从根节点 R 开始，递归选择最优的子节点（后面会解释）直到达到叶子节点 L。&lt;/p&gt;

&lt;p&gt;2.扩展 Expansion：如果 L 不是一个终止节点（也就是，不会导致博弈游戏终止）那么就创建一个或者更多的字子节点，选择其中一个 C。&lt;/p&gt;

&lt;p&gt;3.模拟 Simulation：从 C 开始运行一个模拟的输出，直到博弈游戏结束。&lt;/p&gt;

&lt;p&gt;4.反向传播 Backpropagation：用模拟的结果输出更新当前行动序列。&lt;/p&gt;

&lt;p&gt;每个节点并需包含两个重要的信息：一个是根据模拟结果估计的值和该节点已经被访问的次数。&lt;/p&gt;

&lt;p&gt;按照最为简单和最节约内存的实现，MCTS 将在每个迭代过程中增加一个子节点。不过，要注意其实根据不同的应用这里也可以在每个迭代过程中增加超过一个子节点。&lt;/p&gt;

&lt;h2 id=&quot;节点选择&quot;&gt;节点选择&lt;/h2&gt;

&lt;h3 id=&quot;bandits-和-ucb&quot;&gt;Bandits 和 UCB&lt;/h3&gt;

&lt;p&gt;在树向下遍历时的节点选择通过选择最大化某个量来实现，这其实类似于 Multiarmed bandit problem，其中的参与者必须选择一个 slot machine（bandit）来最大化每一轮的估计的收益。我们可以使用 Upper Confidence Bounds（UCB）公式常常被用来计算这个：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/MCTS2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中 v_i 是节点估计的值，n_i 是节点被访问的次数，而 N 则是其父节点已经被访问的总次数。C 是可调整参数。&lt;/p&gt;

&lt;p&gt;可能一开始看得时候有点不能理解，这个时候可以看下一个具体的例子，&lt;a href=&quot;https://zhuanlan.zhihu.com/p/25345778&quot;&gt;就是放在棋类中是怎么样运行的&lt;/a&gt;或者用老虎机作为解释来理解&lt;a href=&quot;http://blog.csdn.net/natsu1211/article/details/50986810&quot;&gt;MCTS中的UCB&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;exploitation-和-exploration&quot;&gt;Exploitation 和 Exploration&lt;/h3&gt;

&lt;p&gt;UCB 公式对已知收益的 exploitation 和鼓励接触那些相对未曾访问的节点的 exploration 进行平衡。收益估计基于随机模拟，所以节点必须被访问若干次来缺包估计变得更加可信；MCTS 估计会在搜索的开始不大可靠，而最终会在给定充分的时间后收敛到更加可靠的估计上，在无限时间下能够达到最优估计。&lt;/p&gt;

&lt;h3 id=&quot;mcts-和-uct&quot;&gt;MCTS 和 UCT&lt;/h3&gt;

&lt;p&gt;Kocsis 和 Szepervari 在 2006 年首先构建了一个完备的 MCTS 算法，通过扩展 UCB 到 树搜索，并将其命名为 Upper Confidence Bounds for Trees（UCT）方法。这其实是用在当前众多 MCTS 实现中的算法版本。&lt;/p&gt;

&lt;p&gt;UCT 可以被描述为 MCTS 的一个特例：UCT = MCTS + UCB。也即是说UCB在树方面的应用。&lt;/p&gt;

&lt;h2 id=&quot;优点&quot;&gt;优点&lt;/h2&gt;

&lt;h3 id=&quot;aheuristic&quot;&gt;Aheuristic&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;MCTS 不要求任何关于给定的领域策略或者具体实践知识来做出合理的决策。这个算法可以在没有任何关于博弈游戏除基本规则外的知识的情况下进行有效工作；&lt;/strong&gt;这意味着一个简单的 MCTS 实现可以重用在很多的博弈游戏中，只需要进行微小的调整，所以这也使得 MCTS 是对于一般的博弈游戏的很好的方法。&lt;/p&gt;

&lt;h3 id=&quot;asymmetric&quot;&gt;Asymmetric&lt;/h3&gt;

&lt;p&gt;MCTS 执行一种非对称的树的适应搜索空间拓扑结构的增长。这个算法会更频繁地访问更加有趣的节点，并聚焦其搜索时间在更加相关的树的部分。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/MCTS3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这使得 MCTS 更加适合那些有着更大的分支因子的博弈游戏，比如说 19X19 的围棋。这么大的组合空间会给标准的基于深度或者宽度的搜索方法带来问题，所以 MCTS 的适应性说明它（最终）可以找到那些更加优化的行动，并将搜索的工作聚焦在这些部分。&lt;/p&gt;

&lt;h2 id=&quot;缺点&quot;&gt;缺点&lt;/h2&gt;

&lt;p&gt;MCTS 有很少的缺点，不过这些缺点也可能是非常关键的影响因素。&lt;/p&gt;

&lt;h3 id=&quot;行为能力&quot;&gt;行为能力&lt;/h3&gt;

&lt;p&gt;MCTS 算法，根据其基本形式，在某些甚至不是很大的博弈游戏中在可承受的时间内也不能够找到最好的行动方式。这基本上是由于组合步的空间的全部大小所致，关键节点并不能够访问足够多的次数来给出合理的估计。&lt;/p&gt;

&lt;h3 id=&quot;速度&quot;&gt;速度&lt;/h3&gt;

&lt;p&gt;MCTS 搜索可能需要足够多的迭代才能收敛到一个很好的解上，这也是更加一般的难以优化的应用上的问题。例如，最佳的围棋程序可能需要百万次的交战和领域最佳和强化才能得到专家级的行动方案，而最有的 GGP 实现对更加复杂的博弈游戏可能也就只要每秒钟数十次（领域无关的）交战。对可承受的行动时间，这样的 GGP 可能很少有时间访问到每个合理的行动，所以这样的情形也不大可能出现表现非常好的搜索。&lt;/p&gt;

&lt;p&gt;幸运的是，算法的性能可以通过一些技术显著提升。&lt;/p&gt;

&lt;h2 id=&quot;提升&quot;&gt;提升&lt;/h2&gt;

&lt;p&gt;很多种 MCTS 强化的技术已经出现了。这些基本上可以归纳为领域知识或者领域独立两大类。&lt;/p&gt;

&lt;h3 id=&quot;领域知识&quot;&gt;领域知识&lt;/h3&gt;

&lt;p&gt;特定博弈游戏的领域知识可以用在树上来过滤掉不合理的行动或者在模拟过程中产生重要的对局（更接近人类对手的表现）。这意味着交战结果将会更加的现实而不是随机的模拟，所以节点只需要少量的迭代就能给出一个现实的收益值。&lt;/p&gt;

&lt;p&gt;领域知识可以产生巨大的性能提升，但在速度和一般性上也会有一定的损失。&lt;/p&gt;

&lt;h3 id=&quot;领域独立&quot;&gt;领域独立&lt;/h3&gt;

&lt;p&gt;领域独立强化能够应用到所有的问题领域中。这些一般用在树种（如 AMAF），还有一些用在模拟（如 在交战时倾向于胜利的行动）。领域独立强化并不和特定的领域绑定，具有一般性，这也是当前研究的重心所在。&lt;/p&gt;

</description>
        <pubDate>Fri, 28 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/28/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%A0%91%E6%90%9C%E7%B4%A2-MCTS.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/28/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%A0%91%E6%90%9C%E7%B4%A2-MCTS.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Actor Critic</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#actor-critic&quot; id=&quot;markdown-toc-actor-critic&quot;&gt;Actor Critic&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#为什么要有-actor-和-critic&quot; id=&quot;markdown-toc-为什么要有-actor-和-critic&quot;&gt;为什么要有 Actor 和 Critic&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#actor-critic综述&quot; id=&quot;markdown-toc-actor-critic综述&quot;&gt;Actor Critic综述&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#训练过程和组成&quot; id=&quot;markdown-toc-训练过程和组成&quot;&gt;训练过程和组成&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#deep-deterministic-policy-gradient-ddpg&quot; id=&quot;markdown-toc-deep-deterministic-policy-gradient-ddpg&quot;&gt;Deep Deterministic Policy Gradient (DDPG)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;actor-critic&quot;&gt;Actor Critic&lt;/h1&gt;

&lt;p&gt;强化学习中的一种结合体 Actor Critic (演员评判家), 它合并了 以值为基础 (比如 Q learning) 和 以动作概率为基础 (比如 Policy Gradients) 两类强化学习算法.&lt;/p&gt;

&lt;h2 id=&quot;为什么要有-actor-和-critic&quot;&gt;为什么要有 Actor 和 Critic&lt;/h2&gt;

&lt;p&gt;我们有了像 Q-learning 这么伟大的算法, 为什么还要瞎折腾出一个 Actor-Critic? &lt;strong&gt;原来 Actor-Critic 的 Actor 的前生是 Policy Gradients，或者说其实这也是一种Policy Gradients, 这能让它毫不费力地在连续动作中选取合适的动作, 而 Q-learning 做这件事会瘫痪.&lt;/strong&gt; 那为什么不直接用 Policy Gradients 呢? 原来 Actor Critic 中的 Critic 的前生是 Q-learning 或者其他的 以值为基础的学习法 , 能进行单步更新, 而传统的 Policy Gradients 则是回合更新, 这降低了学习效率.也就是说&lt;strong&gt;Actor Critic比单纯的Policy Gradients的效率要高。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;actor-critic综述&quot;&gt;Actor Critic综述&lt;/h2&gt;

&lt;p&gt;接着上次Policy Gradients，那里引入一个baseline。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/51policy_gradient2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里需要注意的就是其实在我的理解下：actor加上策略的Prediction就是actor-critic模型。而这个prediction在Q-learning那里就是少了greedy or e-greedy（这个在之前已知。只不过这里需要注意的就是on-learning和off-learning的区别）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/51policy_gradient3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;训练过程和组成&quot;&gt;训练过程和组成&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;训练actor常用的是policy gradient，训练critic可以用蒙特卡洛或者temporal difference（TD），训练一定要用experience replay。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;现在我们有两套不同的体系, Actor 和 Critic, 他们都能用不同的神经网络来代替 . 在 Policy Gradients 的影片中提到过, 现实中的奖惩会左右 Actor 的更新情况. Policy Gradients 也是靠着这个来获取适宜的更新. 那么何时会有奖惩这种信息能不能被学习呢? 这看起来不就是 以值为基础的强化学习方法做过的事吗. 那我们就拿一个 Critic 去学习这些奖惩机制, 学习完了以后. 由 Actor 来指手画脚, 由 Critic 来告诉 Actor 你的那些指手画脚哪些指得好, 哪些指得差, &lt;strong&gt;Critic 通过学习环境和奖励之间的关系, 能看到现在所处状态的潜在奖励, 所以用它来指点 Actor 便能使 Actor 每一步都在更新, 如果使用单纯的 Policy Gradients, Actor 只能等到回合结束才能开始更新，这也是效率低的原因.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;结合了 Policy Gradient (Actor) 和 Function Approximation (Critic) 的方法. Actor 基于概率选行为, Critic 基于 Actor 的行为评判行为的得分, Actor 根据 Critic 的评分修改选行为的概率.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;结合到具体的网络上就是：Actor和Critic各为一个网络，Actor输入是状态输出的是动作，loss就是&lt;code class=&quot;highlighter-rouge&quot;&gt;log_prob*td_error&lt;/code&gt;,(注意到这里的loss和Policy Gradient中的差不多，知识vt换成td_error，引导奖励值vt换了来源而已)，Critic输入的是状态输出的是V值（注意这里不是Q值），loss是&lt;code class=&quot;highlighter-rouge&quot;&gt;square((r+gamma*V_next) - V_eval)&lt;/code&gt;也就是&lt;code class=&quot;highlighter-rouge&quot;&gt;square(td_error)&lt;/code&gt;。他们两个网络交互更新是这样的：&lt;strong&gt;agent每次状态s1从actor中选择一个动作a1（也就是从actor网络的获得的动作）执行得到s2，和立即奖励r。然后把s1,s2,r喂给Critic网络更新参数并得到td_error，然后将a1，s1,td_error喂给actor网络更新参数，需要注意的是两个网络是同时更新的&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下面是基础Actor Critic的示意图，这个图比较好的说明了基础Actor Critic是如何运作的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Actor_Critic1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：这里首先讲的是最基础的Actor Critic，它由两个网络构成&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;基础Actor Critic涉及到了两个神经网络, 而且每次都是在连续状态中更新参数, 每次参数更新前后都存在相关性, 导致神经网络只能片面的看待问题, 甚至导致神经网络学不到东西. Google DeepMind 为了解决这个问题, 修改了 Actor Critic 的算法,&lt;/p&gt;

&lt;h2 id=&quot;deep-deterministic-policy-gradient-ddpg&quot;&gt;Deep Deterministic Policy Gradient (DDPG)&lt;/h2&gt;

&lt;p&gt;一句话概括 DDPG: &lt;strong&gt;Google DeepMind 提出的一种使用 Actor Critic 结构, 但是输出的不是行为的概率, 而是具体的行为, 用于连续动作 (continuous action) 的预测. DDPG 结合了之前获得成功的 DQN 结构, 提高了 Actor Critic 的稳定性和收敛性.&lt;/strong&gt;，DDPG 最大的优势就是能够在连续动作上更有效地学习，当然还有就是解决了之前基础Actor Critic难以收敛的问题。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/DDPG1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因为 DDPG 和 DQN 还有 Actor Critic 很相关, 所以最好这两者都了解下, 对于学习 DDPG 很有帮助, Actor critic 让 Policy gradient 单步更新的精华, 而且还吸收让计算机学会玩游戏的 DQN 的精华.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;网络有四个，其实大体上和基础 Actor Critic差不多，都是Actor给动作给Critic进行评估，Critic给反馈（基础中是td_error，而这里是dQ/da）给Actor进行更新参数。&lt;/p&gt;
&lt;/blockquote&gt;

</description>
        <pubDate>Thu, 27 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/27/Actor-Critic.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/27/Actor-Critic.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Policy Gradient</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#policy-gradient&quot; id=&quot;markdown-toc-policy-gradient&quot;&gt;Policy Gradient&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#什么是policy-gradient&quot; id=&quot;markdown-toc-什么是policy-gradient&quot;&gt;什么是Policy Gradient&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#更新网络&quot; id=&quot;markdown-toc-更新网络&quot;&gt;更新网络&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#从一般policy-gradient引申到actor-critic&quot; id=&quot;markdown-toc-从一般policy-gradient引申到actor-critic&quot;&gt;从一般Policy Gradient引申到Actor Critic&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;policy-gradient&quot;&gt;Policy Gradient&lt;/h1&gt;

&lt;h2 id=&quot;什么是policy-gradient&quot;&gt;什么是Policy Gradient&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://karpathy.github.io/2016/05/31/rl/?_utm_source=1-2-2&quot;&gt;Karpathy的blog&lt;/a&gt;中提到说更多的人更倾向于Policy Gradient.原因如下：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;基于值函数的方法（Q-learning, SARSA等等经典强化学习研究的大部分算法）存在策略退化问题，即值函数估计已经很准确了，但通过值函数得到的策略仍然不是最优。&lt;/strong&gt;这一现象类似于监督学习中通过后验概率来分类，后验概率估计的精度很高，但得到的分类仍然可能是错的。尤其是当强化学习使用值函数近似时，策略退化现象非常常见。可见 Tutorial on Reinforcement Learning  &lt;a href=&quot;http://lamda.nju.edu.cn/yuy/Default.aspx?Page=adl-rl&amp;amp;AspxAutoDetectCookieSupport=1&quot;&gt;slides&lt;/a&gt;中的例子。Policy Gradient不会出现策略退化现象，其目标表达更直接，求解方法更现代，还能够直接求解stochastic policy等等优点更加实用。&lt;/p&gt;

&lt;p&gt;我们已经知道DQN是一个基于价值value的方法。换句话说就是通过计算每一个状态动作的价值，然后选择价值最大的动作执行。这是一种间接的做法。那么，更直接的做法是什么？&lt;/p&gt;

&lt;p&gt;能不能直接更新策略网络Policy Network呢？&lt;/p&gt;

&lt;p&gt;什么是策略网络Policy Network？就是一个神经网络，&lt;strong&gt;输入是状态，输出直接就是估计动作（不是Q值）。这里的label就是真实动作,loss就是:&lt;code class=&quot;highlighter-rouge&quot;&gt;所选概率的-log值*（本reward + 衰减的未来reward）&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Network.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;要更新策略网络，或者说要使用梯度下降的方法来更新网络，我们需要有一个目标函数。对于策略网络，目标函数其实是比较容易给定的，就是很直接的，最后的结果！也就是&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Network1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;所有带衰减reward的累加期望&lt;/p&gt;

&lt;p&gt;那么问题就在于如何利用这个目标来更新参数\theta呢？咋一看这个损失函数和策略网络简直没有什么直接联系，reward是环境给出的，如何才能更新参数？换个说法就是如何能够计算出损失函数关于参数的梯度（也就是策略梯度）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Network2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Policy gradient 是 RL 中另外一个大家族, 他不像 Value-based 方法 (Q learning, Sarsa), 但他也要接受环境信息 (observation), 不同的是他要输出不是 action 的 value, 而是具体的那一个 action, 这样 policy gradient 就跳过了 value 这个阶段. 而且个人认为 Policy gradient 最大的一个优势是:&lt;strong&gt;输出的这个 action 可以是一个连续的值, 之前我们说到的 value-based 方法输出的都是不连续的值, 然后再选择值最大的 action,如果动作很多的话，这样贪婪策略来选择变得很不现实. 而 policy gradient 可以在一个连续分布上选取 action.这样对于动作众多或者连续动作的是很可行的&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;更新网络&quot;&gt;更新网络&lt;/h2&gt;

&lt;p&gt;改变动作的出现概率！
现在我们不考虑别的，就仅仅从概率的角度来思考问题。我们有一个策略网络，输入状态，输出动作的概率。然后执行完动作之后，我们可以得到reward，或者result。那么这个时候，我们有个非常简单的想法：&lt;/p&gt;

&lt;p&gt;如果某一个动作得到reward多，那么我们就使其出现的概率增大，如果某一个动作得到的reward少，那么我们就使其出现的概率减小。
当然，也显然的，用reward来评判动作的好坏是不准确的，甚至用result来评判也是不准确的。&lt;strong&gt;毕竟任何一个reward，result都依赖于大量的动作才导致的。&lt;/strong&gt;但是这并不妨碍我们做这样的思考：&lt;/p&gt;

&lt;p&gt;如果能够构造一个好的动作评判指标，来判断一个动作的好与坏，那么我们就可以通过改变动作的出现概率来优化策略！
假设这个评价指标是f(s,a),那么我们的Policy Network输出的是概率。一般情况下，更常使用log likelihood &lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Network3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;。原因的话看这里&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//math.stackexchange.com/questions/892832/why-we-consider-log-likelihood-instead-of-likelihood-in-gaussian-distribution&quot;&gt;Why we consider log likelihood instead of Likelihood in Gaussian Distribution&lt;/a&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;简单说明：其实要用log的主要原因就是我们之后要用到极大似然的方式来求，一个是比较好算，第二是这样才不会造成计算的溢出。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;因此，我们就可以构造一个损失函数如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Network4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;怎么理解呢？举个简单的AlphaGo的例子吧。对于AlphaGo而言，&lt;strong&gt;f(s,a)就是最后的结果。&lt;/strong&gt;也就是一盘棋中，如果这盘棋赢了，那么这盘棋下的每一步都是认为是好的，如果输了，那么都认为是不好的。好的f(s,a)就是1，不好的就-1。所以在这里，如果a被认为是好的，那么目标就是最大化这个好的动作的概率，反之亦然。&lt;/p&gt;

&lt;p&gt;这就是Policy Gradient最基本的思想。&lt;/p&gt;

&lt;p&gt;f(s,a)不仅仅可以作为动作的评价指标，还可以作为目标函数。就如同AlphaGo，评价指标就是赢或者输，而目标就是结果赢。这和之前分析的目标完全没有冲突。因此，我们可以利用评价指标f(s,a)来优化Policy，同时也是在优化的同时优化了f(s,a).那么问题就变成对f(s,a)求关于参数的梯度。下面的公式直接摘自Andrej Karpathy的blog，f(x)即是f(s,a)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Network5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从公式得到的结论可以看到正好和上一小结分析得到的目标函数一致。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;最后，来自&lt;a href=&quot;https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/5-1-policy-gradient-softmax1/&quot;&gt;莫烦python&lt;/a&gt;的一张图,那里的例子比较好懂，值得一看。下面也是基本的Policy Gradient的算法。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/policy_gradient_agr.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其实，这个也就是那个课程上的&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/04/21/Policy-Gradient.html&quot;&gt;Monte-Carlo Policy Gradient&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;从一般policy-gradient引申到actor-critic&quot;&gt;从一般Policy Gradient引申到Actor Critic&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Gradient_actor.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Wed, 26 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/26/Policy-Gradient.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/26/Policy-Gradient.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>DQN</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#dqn&quot; id=&quot;markdown-toc-dqn&quot;&gt;DQN&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#nature-dqn&quot; id=&quot;markdown-toc-nature-dqn&quot;&gt;Nature DQN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dqn有什么问题还可以如何改进&quot; id=&quot;markdown-toc-dqn有什么问题还可以如何改进&quot;&gt;DQN有什么问题？还可以如何改进？&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#double-dqnprioritised-replaydueling-network三大改进&quot; id=&quot;markdown-toc-double-dqnprioritised-replaydueling-network三大改进&quot;&gt;Double DQN，Prioritised Replay，Dueling Network三大改进&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;dqn&quot;&gt;DQN&lt;/h1&gt;

&lt;p&gt;大概的DQN算法，在之前的笔记中有提及，请查看&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/04/15/Value-Function-Approximation.html#dqn&quot;&gt;这篇文章&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;nature-dqn&quot;&gt;Nature DQN&lt;/h2&gt;

&lt;p&gt;NIPS DQN在基本的Deep Q-Learning算法的基础上使用了Experience Replay经验池。通过将训练得到的数据储存起来然后随机采样的方法降低了数据样本的相关性。提升了性能。接下来，Nature DQN做了一个改进，就是增加Target Q网络。也就是我们在计算目标Q值时使用专门的一个目标Q网络来计算，而不是直接使用预更新的Q网络。这样做的目的是为了减少目标计算与当前值的相关性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Nature_DQN.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上面的损失函数公式所示，&lt;strong&gt;计算目标Q值的网络使用的参数是w-，而不是w。就是说，原来NIPS版本的DQN目标Q网络是动态变化的，跟着Q网络的更新而变化，这样不利于计算目标Q值，导致目标Q值和当前的Q值相关性较大。因此提出单独使用一个目标Q网络。那么目标Q网络的参数如何来呢？还是从Q网络中来，只不过是延迟更新。也就是每次等训练了一段时间再将当前Q网络的参数值复制给目标Q网络。&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;神经网络的更新过程是这样的：两个网络,首先输入的都是状态，输出的都是Q值，然后选择k次动作（这里是贪婪或者是随机选择的，一般设为90%的选择最优，然后10%的随机选取。），在之后进行更新参数。loss就是计算目标（现实）Q值和估计Q值之间的差距，来更新Q估计网络。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;dqn有什么问题还可以如何改进&quot;&gt;DQN有什么问题？还可以如何改进？&lt;/h2&gt;

&lt;p&gt;在Nature DQN出来之后，肯定很多人在思考如何改进它。那么DQN有什么问题呢？&lt;/p&gt;

&lt;p&gt;下面列出一些坑：&lt;/p&gt;

&lt;p&gt;目标Q值的计算准确吗？全部通过max Q来计算有没有问题？&lt;/p&gt;

&lt;p&gt;随机采样的方法好吗？按道理不同样本的重要性是不一样的&lt;/p&gt;

&lt;p&gt;Q值代表状态，动作的价值，那么单独动作价值的评估会不会更准确？&lt;/p&gt;

&lt;p&gt;DQN中使用\epsilon-greedy的方法来探索状态空间，有没有更好的做法？&lt;/p&gt;

&lt;p&gt;使用卷积神经网络的结构是否有局限？加入RNN呢？&lt;/p&gt;

&lt;p&gt;DQN无法解决一些高难度的Atari游戏比如Montezuma’s Revenge，如何处理这些游戏？&lt;/p&gt;

&lt;p&gt;DQN训练时间太慢了，跑一个游戏要好几天，有没有办法更快？&lt;/p&gt;

&lt;p&gt;DQN训练是单独的，也就是一个游戏弄一个网络进行训练，有没有办法弄一个网络同时掌握多个游戏，或者训练某一个游戏后将知识迁移到新的游戏？&lt;/p&gt;

&lt;p&gt;DQN能否用在连续动作输出问题？&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;改进目标Q值计算：&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1509.06461&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Deep Reinforcement Learning with Double Q-learning&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;改进随机采样：&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1511.05952&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Prioritized Experience Replay&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;改进网络结构，评估单独动作价值：&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1511.06581&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Dueling Network Architectures for Deep Reinforcement Learning&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt; ( 本文为ICML最佳论文之一）&lt;/li&gt;&lt;li&gt;改进探索状态空间方式：（1）&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1602.04621&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Deep Exploration via Bootstrapped DQN&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;  （2）&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1507.00814&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;改变网络结构，增加RNN：&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1507.06527&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Deep Recurrent Q-Learning for Partially Observable MDPs&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;（非DeepMind出品，效果很一般，谈不上改进，本文也不考虑讲解）&lt;/li&gt;&lt;li&gt;实现DQN训练的迁移学习：（1）&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1511.06295&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Policy Distillation&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;  （2） &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1511.06342&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;解决高难度游戏Montezuma‘s Revenge：&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1606.01868&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Unifying Count-Based Exploration and Intrinsic Motivation&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;加快DQN训练速度：&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1602.01783&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Asynchronous Methods for Deep Reinforcement Learning&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt; （这篇文章还引出了可以替代DQN的A3C算法，效果4倍Nature DQN）&lt;/li&gt;&lt;li&gt;改变DQN使之能够应用在连续控制上面：&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1603.00748&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Continuous Deep Q-Learning with Model-based Acceleration&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;除了上面的问题，其他的就是将DQN应用到其他领域比如文字理解，目标定位等等，也就是DQN的拓展研究，这里就不罗列相关文章了。上面的这些成果基本出自DeepMind之手，只有一两篇出自其他大牛，比如&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//arxiv.org/find/cs/1/au%3A%2BAbbeel_P/0/1/0/all/0/1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Pieter Abbeel&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;，&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//arxiv.org/find/cs/1/au%3A%2BSalakhutdinov_R/0/1/0/all/0/1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Ruslan Salakhutdinov&lt;i class=&quot;icon-external&quot;&gt;&lt;/i&gt;&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;double-dqnprioritised-replaydueling-network三大改进&quot;&gt;Double DQN，Prioritised Replay，Dueling Network三大改进&lt;/h2&gt;

&lt;p&gt;大幅度提升DQN玩Atari性能的主要就是Double DQN，Prioritised Replay还有Dueling Network三大方法。&lt;/p&gt;

&lt;p&gt;David Silver在ICML 2016中的Tutorial上做了介绍：&lt;a href=&quot;http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf&quot;&gt;深度增强学习Tutorial &lt;/a&gt;下图引用其PPT：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Nature_DQN1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;简单说明一下：&lt;/p&gt;

&lt;p&gt;Double DQN：目的是减少因为max Q值计算带来的计算偏差，或者称为过度估计（over estimation）问题，用当前的Q网络来选择动作，用目标Q网络来计算目标Q。&lt;/p&gt;

&lt;p&gt;Prioritised replay：也就是优先经验的意思。优先级采用目标Q值与当前Q值的差值来表示。优先级高，那么采样的概率就高。&lt;/p&gt;

&lt;p&gt;Dueling Network：将Q网络分成两个通道，一个输出V，一个输出A，最后再合起来得到Q。如下图所示（引用自Dueling Network论文）。这个方法主要是idea很简单但是很难想到，然后效果一级棒，因此也成为了ICML的best paper。&lt;/p&gt;

</description>
        <pubDate>Wed, 26 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/26/DQN.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/26/DQN.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Exploration and Exploitation</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#exploration-and-exploitation&quot; id=&quot;markdown-toc-exploration-and-exploitation&quot;&gt;Exploration and Exploitation&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#ϵt-greedy&quot; id=&quot;markdown-toc-ϵt-greedy&quot;&gt;ϵ(t) greedy&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#upper-confidence-bounds-algorithm&quot; id=&quot;markdown-toc-upper-confidence-bounds-algorithm&quot;&gt;Upper Confidence Bounds Algorithm&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#information-state-search&quot; id=&quot;markdown-toc-information-state-search&quot;&gt;Information State Search&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;exploration-and-exploitation&quot;&gt;Exploration and Exploitation&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Exploration_and_Exploitation.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;ϵt-greedy&quot;&gt;ϵ(t) greedy&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Exploration_and_Exploitation1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;upper-confidence-bounds-algorithm&quot;&gt;Upper Confidence Bounds Algorithm&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Exploration_and_Exploitation2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;information-state-search&quot;&gt;Information State Search&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Exploration_and_Exploitation3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 25 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/25/Exploration-and-Exploitation.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/25/Exploration-and-Exploitation.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Integrating Learning and Planning</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#integrating-learning-and-planning&quot; id=&quot;markdown-toc-integrating-learning-and-planning&quot;&gt;Integrating Learning and Planning&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#model-based-reinforcement-learning&quot; id=&quot;markdown-toc-model-based-reinforcement-learning&quot;&gt;Model-Based Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#integrated-architectures&quot; id=&quot;markdown-toc-integrated-architectures&quot;&gt;Integrated Architectures&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#simulation-based-search&quot; id=&quot;markdown-toc-simulation-based-search&quot;&gt;Simulation-Based Search&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;integrating-learning-and-planning&quot;&gt;Integrating Learning and Planning&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Integrating_Learning.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;model-based-reinforcement-learning&quot;&gt;Model-Based Reinforcement Learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Integrating_Learning1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;integrated-architectures&quot;&gt;Integrated Architectures&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Integrating_Learning2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;simulation-based-search&quot;&gt;Simulation-Based Search&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Integrating_Learning3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 22 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/22/Integrating-Learning-and-Planning.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/22/Integrating-Learning-and-Planning.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Policy Gradient</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#policy-gradient&quot; id=&quot;markdown-toc-policy-gradient&quot;&gt;Policy Gradient&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#monte-carlo-policy-gradient&quot; id=&quot;markdown-toc-monte-carlo-policy-gradient&quot;&gt;Monte-Carlo Policy Gradient&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#actor-critic-policy-gradient&quot; id=&quot;markdown-toc-actor-critic-policy-gradient&quot;&gt;Actor-Critic Policy Gradient&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;policy-gradient&quot;&gt;Policy Gradient&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Gradient.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;monte-carlo-policy-gradient&quot;&gt;Monte-Carlo Policy Gradient&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Gradient1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;actor-critic-policy-gradient&quot;&gt;Actor-Critic Policy Gradient&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Policy_Gradient2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 21 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/21/Policy-Gradient.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/21/Policy-Gradient.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Wasserstein GAN</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#wasserstein-gan&quot; id=&quot;markdown-toc-wasserstein-gan&quot;&gt;Wasserstein GAN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#原始gan存在的主要问题&quot; id=&quot;markdown-toc-原始gan存在的主要问题&quot;&gt;原始GAN存在的主要问题：&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#解决不收敛non-convergence的问题&quot; id=&quot;markdown-toc-解决不收敛non-convergence的问题&quot;&gt;解决不收敛（non-convergence）的问题。&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#难以训练崩溃问题collapse-problem&quot; id=&quot;markdown-toc-难以训练崩溃问题collapse-problem&quot;&gt;难以训练：崩溃问题（collapse problem）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#无需预先建模模型过于自由不可控&quot; id=&quot;markdown-toc-无需预先建模模型过于自由不可控&quot;&gt;无需预先建模，模型过于自由不可控。&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#wesserstein-gan的改进之处&quot; id=&quot;markdown-toc-wesserstein-gan的改进之处&quot;&gt;Wesserstein GAN的改进之处&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#改进原始算法&quot; id=&quot;markdown-toc-改进原始算法&quot;&gt;改进原始算法&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#原始gan形式的问题&quot; id=&quot;markdown-toc-原始gan形式的问题&quot;&gt;原始GAN形式的问题&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#第一种原始gan形式的问题&quot; id=&quot;markdown-toc-第一种原始gan形式的问题&quot;&gt;第一种原始GAN形式的问题&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#第二种原始gan形式的问题&quot; id=&quot;markdown-toc-第二种原始gan形式的问题&quot;&gt;第二种原始GAN形式的问题&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#wgan之前的一个过渡解决方案加噪方案&quot; id=&quot;markdown-toc-wgan之前的一个过渡解决方案加噪方案&quot;&gt;WGAN之前的一个过渡解决方案——加噪方案&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#wasserstein距离&quot; id=&quot;markdown-toc-wasserstein距离&quot;&gt;Wasserstein距离&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#从wasserstein距离到wgan&quot; id=&quot;markdown-toc-从wasserstein距离到wgan&quot;&gt;从Wasserstein距离到WGAN&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;wasserstein-gan&quot;&gt;Wasserstein GAN&lt;/h1&gt;

&lt;h1 id=&quot;原始gan存在的主要问题&quot;&gt;原始GAN存在的主要问题：&lt;/h1&gt;

&lt;h2 id=&quot;解决不收敛non-convergence的问题&quot;&gt;解决不收敛（non-convergence）的问题。&lt;/h2&gt;

&lt;p&gt;目前面临的基本问题是：所有的理论都认为 GAN 应该在纳什均衡（Nash equilibrium）上有卓越的表现，但梯度下降只有在凸函数的情况下才能保证实现纳什均衡。当博弈双方都由神经网络表示时，在没有实际达到均衡的情况下，让它们永远保持对自己策略的调整是可能的【OpenAI Ian Goodfellow的Quora】。&lt;/p&gt;

&lt;h2 id=&quot;难以训练崩溃问题collapse-problem&quot;&gt;难以训练：崩溃问题（collapse problem）&lt;/h2&gt;

&lt;p&gt;GAN模型被定义为极小极大问题，没有损失函数，在训练过程中很难区分是否正在取得进展。GAN的学习过程可能发生崩溃问题（collapse problem），生成器开始退化，总是生成同样的样本点，无法继续学习。当生成模型崩溃时，判别模型也会对相似的样本点指向相似的方向，训练无法继续。【Improved Techniques for Training GANs】&lt;/p&gt;

&lt;h2 id=&quot;无需预先建模模型过于自由不可控&quot;&gt;无需预先建模，模型过于自由不可控。&lt;/h2&gt;

&lt;p&gt;与其他生成式模型相比，GAN这种竞争的方式不再要求一个假设的数据分布，即不需要formulate p(x)，而是使用一种分布直接进行采样sampling，从而真正达到理论上可以完全逼近真实数据，这也是GAN最大的优势。然而，这种不需要预先建模的方法缺点是太过自由了，对于较大的图片，较多的 pixel的情形，基于简单 GAN 的方式就不太可控了。在GAN[Goodfellow Ian, Pouget-Abadie J] 中，每次学习参数的更新过程，被设为D更新k回，G才更新1回，也是出于类似的考虑。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;生成器在生成数据和人脸时效果很好，但使用CIFAR-10数据集时，生成的图像就十分模糊。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;wesserstein-gan的改进之处&quot;&gt;Wesserstein GAN的改进之处&lt;/h2&gt;

&lt;p&gt;做到了以下爆炸性的几点：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度&lt;/li&gt;
  &lt;li&gt;基本解决了collapse mode的问题，确保了生成样本的多样性&lt;/li&gt;
  &lt;li&gt;训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高（如题图所示）&lt;/li&gt;
  &lt;li&gt;以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;改进原始算法&quot;&gt;改进原始算法&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;判别器最后一层去掉sigmoid&lt;/li&gt;
  &lt;li&gt;生成器和判别器的loss不取log&lt;/li&gt;
  &lt;li&gt;每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c&lt;/li&gt;
  &lt;li&gt;不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;原始gan形式的问题&quot;&gt;原始GAN形式的问题&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Wasserstein_GAN0.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;第一种原始gan形式的问题&quot;&gt;第一种原始GAN形式的问题&lt;/h2&gt;

&lt;p&gt;一句话概括：判别器越好，生成器梯度消失越严重&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Wasserstein_GAN.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Wasserstein_GAN1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;根据原始GAN定义的判别器loss，我们可以得到最优判别器的形式；而在&lt;strong&gt;最优判别器的下，我们可以把原始GAN定义的生成器loss等价变换为最小化真实分布P_r与生成分布P_g之间的JS散度。我们越训练判别器，它就越接近最优，最小化生成器的loss也就会越近似于最小化P_r和P_g之间的JS散度。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;问题就出在这个JS散度上。我们会希望如果两个分布之间越接近它们的JS散度越小，我们通过优化JS散度就能将P_g“拉向”P_r，最终以假乱真。这个希望在两个分布有所重叠的时候是成立的，但是如果两个分布完全没有重叠的部分，或者它们重叠的部分可忽略（下面解释什么叫可忽略），JS散度就固定是常数log 2，而这对于梯度下降方法意味着——梯度为0！&lt;/p&gt;

&lt;p&gt;而且：&lt;strong&gt;P_r与P_g不重叠或重叠部分可忽略的可能性非常大&lt;/strong&gt; 下面解释专业解释：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;当P_r与P_g的支撑集（support）是高维空间中的低维流形（manifold）时，P_r与P_g重叠部分测度（measure）为0的概率为1。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;不用被奇怪的术语吓得关掉页面，虽然论文给出的是严格的数学表述，但是直观上其实很容易理解。首先简单介绍一下这几个概念：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;支撑集（support）&lt;/strong&gt;其实就是&lt;strong&gt;函数的非零部分子集，&lt;/strong&gt;比如ReLU函数的支撑集就是(0, +oo)，一个概率分布的支撑集就是所有概率密度非零部分的集合。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;流形（manifold）:是高维空间中曲线、曲面概念的拓广&lt;/strong&gt;，我们可以在低维上直观理解这个概念，比如我们说三维空间中的一个曲面是一个二维流形，因为它的本质维度（intrinsic dimension）只有2，一个点在这个二维流形上移动只有两个方向的自由度。同理，三维空间或者二维空间中的一条曲线都是一个一维流形。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;测度（measure）&lt;/strong&gt;是高维空间中长度、面积、体积概念的拓广，可以理解为&lt;strong&gt;“超体积”。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;回过头来看第一句话，“当P_r与P_g的支撑集是高维空间中的低维流形时”，基本上是成立的。原因是GAN中的生成器一般是从某个低维（比如100维）的随机分布中采样出一个编码向量，再经过一个神经网络生成出一个高维样本（比如64x64的图片就有4096维）。当生成器的参数固定时，生成样本的概率分布虽然是定义在4096维的空间上，但它本身所有可能产生的变化已经被那个100维的随机分布限定了，其本质维度就是100，再考虑到神经网络带来的映射降维，最终可能比100还小，所以生成样本分布的支撑集就在4096维空间中构成一个最多100维的低维流形，“撑不满”整个高维空间。&lt;/p&gt;

&lt;p&gt;“撑不满”就会导致真实分布与生成分布难以“碰到面”，这很容易在二维空间中理解：一方面，二维平面中随机取两条曲线，它们之间刚好存在重叠线段的概率为0；另一方面，虽然它们很大可能会存在交叉点，但是相比于两条曲线而言，交叉点比曲线低一个维度，长度（测度）为0，可忽略。三维空间中也是类似的，随机取两个曲面，它们之间最多就是比较有可能存在交叉线，但是交叉线比曲面低一个维度，面积（测度）是0，可忽略。从低维空间拓展到高维空间，就有了如下逻辑：因为一开始生成器随机初始化，所以P_g几乎不可能与P_r有什么关联，所以它们的支撑集之间的重叠部分要么不存在，要么就比P_r和P_g的最小维度还要低至少一个维度，故而测度为0。所谓“重叠部分测度为0”，就是上文所言“不重叠或者重叠部分可忽略”的意思。&lt;/p&gt;

&lt;h2 id=&quot;第二种原始gan形式的问题&quot;&gt;第二种原始GAN形式的问题&lt;/h2&gt;

&lt;p&gt;最小化第二种生成器loss函数，会&lt;strong&gt;等价于最小化一个不合理的距离衡量，导致两个问题，一是梯度不稳定，二是collapse mode即多样性不足。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Wesserstein_gan2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;换言之，KL(P_g&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;P_r)对于上面两种错误的惩罚是不一样的，第一种错误对应的是“生成器没能生成真实的样本”，惩罚微小；第二种错误对应的是“生成器生成了不真实的样本” ，惩罚巨大。第一种错误对应的是缺乏多样性，第二种错误对应的是缺乏准确性。&lt;strong&gt;在这里，我们可以想象一下，gan是一个智能的，他在这一放一打之下，生成器宁可多生成一些重复但是很“安全”的样本，也不愿意去生成多样性的样本，因为那样一不小心就会产生第二种错误，得不偿失。这种现象就是大家常说的collapse mode。&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;wgan之前的一个过渡解决方案加噪方案&quot;&gt;WGAN之前的一个过渡解决方案——加噪方案&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;就是对生成样本和真实样本加噪声，直观上说，使得原本的两个低维流形“弥散”到整个高维空间，强行让它们产生不可忽略的重叠。而一旦存在重叠，JS散度就能真正发挥作用，此时如果两个分布越靠近，它们“弥散”出来的部分重叠得越多，JS散度也会越小而不会一直是一个常数，于是（在第一种原始GAN形式下）梯度消失的问题就解决了。&lt;/li&gt;
  &lt;li&gt;加噪方案是针对原始GAN问题的第二点根源提出的，解决了训练不稳定的问题，不需要小心平衡判别器训练的火候，可以放心地把判别器训练到接近最优，但是仍然没能够提供一个衡量训练进程的数值指标。但是WGAN本作就从第一点根源出发，用Wasserstein距离代替JS散度，同时完成了稳定训练和进程指标的问题！&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;wasserstein距离&quot;&gt;Wasserstein距离&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Wasserstein_GAN3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Wasserstein_GAN2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;从wasserstein距离到wgan&quot;&gt;从Wasserstein距离到WGAN&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Wasserstein_GAN4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Wasserstein_GAN5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Wesserstein GAN的算法如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Wesserstein_gan.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;前三点都是从理论分析中得到的，已经介绍完毕；第四点却是作者从实验中发现的，属于trick，相对比较“玄”。作者发现如果使用Adam，判别器的loss有时候会崩掉，当它崩掉时，Adam给出的更新方向与梯度方向夹角的cos值就变成负数，更新方向与梯度方向南辕北辙，这意味着判别器的loss梯度是不稳定的，所以不适合用Adam这类基于动量的优化算法。作者改用RMSProp之后，问题就解决了，因为RMSProp适合梯度不稳定的情况。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;最后，对于w-gan的最新进展，就是采用gradient penalty对Lipschitz限制，效果更好，更加稳定，在知乎上有比较好的&lt;a href=&quot;https://www.zhihu.com/question/52602529/answer/158727900&quot;&gt;中文讲解&lt;/a&gt;,非常值得一看。&lt;/p&gt;
&lt;/blockquote&gt;

</description>
        <pubDate>Thu, 20 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/20/Wasserstein-GAN.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/20/Wasserstein-GAN.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>model free-Control</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#model-free-control&quot; id=&quot;markdown-toc-model-free-control&quot;&gt;model free-Control&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#on-policy-monte-carlo&quot; id=&quot;markdown-toc-on-policy-monte-carlo&quot;&gt;On-Policy Monte-Carlo&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sarsa-algorithm&quot; id=&quot;markdown-toc-sarsa-algorithm&quot;&gt;Sarsa Algorithm&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#off-policy-learning&quot; id=&quot;markdown-toc-off-policy-learning&quot;&gt;Off-Policy Learning&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#off-policy-q-learning&quot; id=&quot;markdown-toc-off-policy-q-learning&quot;&gt;Off-Policy Q-Learning&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#q-learning和sarsa对比&quot; id=&quot;markdown-toc-q-learning和sarsa对比&quot;&gt;Q-Learning和Sarsa对比&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;model-free-control&quot;&gt;model free-Control&lt;/h1&gt;

&lt;p&gt;上次课谈到了在&lt;strong&gt;给定policy的情况下求解未知environment的MDP问题，称之为Model-Free Prediction问题。&lt;/strong&gt;本节则是解决&lt;strong&gt;未知policy情况下未知environment的MDP问题，也就是Model-Free Control问题&lt;/strong&gt;，这个问题实际上是最常见的强化学习问题。由于这种问题中未知policy，那么就有两种思路来获得policy，一种称为on-policy learning是基于某个policy做出一些action然后评估这个policy效果如何，一种称为off-policy learning是从一些已知的policy中学习policy，比如机器人在学习走路时，可以从人控制机器人走路的sample中来学习，但不是完全的跟sample走的action完全一样，在sample中尝试去走不同的一步看是否有更好reward。&lt;/p&gt;

&lt;h2 id=&quot;on-policy-monte-carlo&quot;&gt;On-Policy Monte-Carlo&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;On-Policy Monte-Carlo由policy evaluation + ϵ−Greedy Policy Improvement组成。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在第三课的动态规划解决planning问题(已知environment)中提出的Policy iteration和value iteration，其中policy iteration由policy evaluation和policy improvement组成。第四课中未知environment的policy evaluation是通过蒙特卡洛方法求解，结合起来到本课可以得到第一个解决&lt;strong&gt;Model-Free control方法即先通过贪婪算法来确定当前的policy，再通过蒙特卡洛policy evaluation来评估当前的policy好不好，再更新policy。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果在已知environment情况下policy improvement更新方式是&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/model_free_control.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;,可以看出它的解决方案是通过状态转移矩阵把所有可能转移到的状态得到的值函数都计算出来，从中来选择最大的，&lt;strong&gt;但未知environment则没有状态转移矩阵，因此只能通过最大化动作值函数来更新policy即&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/model_free_control1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;。&lt;/strong&gt;由于improvement的过程需要动作值函数，那么在policy evaluation的过程中针对给定的policy需要计算的V(s)也替换成Q(s,a)。&lt;/p&gt;

&lt;p&gt;但是greedy算法是存在一定的问题的，例如现在有两扇门，打开一扇门会有一定的奖励，经过一些开门试验后选择能够获得奖励最大的门。假设第一次打开左边的门获得的immdiate reward是0，那么左边门的return更新为V(left)=0V(left)=0，第二次打开右边获得的immdiate reward是+1，右边门return更新V(right)=1V(right)=1，此时如果根据greedy算法，那么下一次肯定会选择右边的门，第三次选择右边门获得reward是+3，return更新为V(right)=2V(right)=2(蒙特卡洛方法平均了一下)，根据greedy算法第四次也会选择右边门。因此按照贪婪算法就会一直选择右边门，但是其实我们并不清楚左边门到底是什么情况，我们只尝试了一次。从这个例子可以看出，需要对执行每个action的结果都做比较充分的了解，才能说自己的policy是正确的。&lt;/p&gt;

&lt;p&gt;因此提出改进算法在greedy基础上有一定概率选择一个随机action，即ϵ−Greedy Exploration，假设有m个action，那么有ϵϵ的概率随机选择一个action(包括greedy action)，从而可以得到更新的policy为(17:48开始证明了改进算法算出的新policy比之前的好，此处略过)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/model_free_control2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果每一个的episode都进行一次evaluation和improvement迭代，那么在第k次迭代时可以更新ϵ=1kϵ=1k。更新ϵϵ的算法称之为GLIE Monte-Carlo Control。&lt;/p&gt;

&lt;h2 id=&quot;sarsa-algorithm&quot;&gt;Sarsa Algorithm&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/model_free_control3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;off-policy-learning&quot;&gt;Off-Policy Learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/model_free_control4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;off-policy-q-learning&quot;&gt;Off-Policy Q-Learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/model_free_control5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Q-Learning 整体算法:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/27Q-Learning.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;q-learning和sarsa对比&quot;&gt;Q-Learning和Sarsa对比&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/27Sarsa.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从算法来看, 这就是他们两最大的不同之处了. 因为 Sarsa 是说到做到型, 所以我们也叫他 on-policy, 在线学习, 学着自己在做的事情. 而 Q learning 是说到但并不一定做到, 所以它也叫作 Off-policy, 离线学习. 而因为有了 maxQ, Q-learning 也是一个特别勇敢的算法.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;其实也就是在Q现实的选取上有所不同，Q-Learning的Q现实是借助别人的好的经验或者之前一段时间的经验（这样的经验是比较稳的）而Sarsa的Q现实是即时的选取，是一种比较激进的的做法。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/27Sarsa1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为什么说他勇敢呢, 因为 Q learning 机器人 永远都会选择最近的一条通往成功的道路, 不管这条路会有多危险. 而 Sarsa 则是相当保守, 他会选择离危险远远的, 拿到宝藏是次要的, 保住自己的小命才是王道. 这就是使用 Sarsa 方法的不同之处.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/DP and TD.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Sat, 15 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/15/model-free-Control.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/15/model-free-Control.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Value Function Approximation</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#value-function-approximation&quot; id=&quot;markdown-toc-value-function-approximation&quot;&gt;Value Function Approximation&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#incremental-methods&quot; id=&quot;markdown-toc-incremental-methods&quot;&gt;Incremental Methods&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dqn&quot; id=&quot;markdown-toc-dqn&quot;&gt;DQN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dqn应用&quot; id=&quot;markdown-toc-dqn应用&quot;&gt;DQN应用&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;value-function-approximation&quot;&gt;Value Function Approximation&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Function_Approximation.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;简单来说，&lt;strong&gt;function approximation的意义是&lt;/strong&gt;： &lt;strong&gt;large MDPs 的情况下，如果算出每种状态下的真实value function既没有足够的内存也没有足够的计算能力，此外比较接近的状态它们的值函数取值应该是很相似的，这是一种泛化能力。也就是说需要算法来求解近似的V(S)和Q(S,A)，并且针对未知的状态有比较强的泛化能力。这种近似算法称之为function approximation.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;incremental-methods&quot;&gt;Incremental Methods&lt;/h2&gt;

&lt;p&gt;假设近似值函数对w是可微的，最简单的就是用梯度下降，假设输入状态用特征向量&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Function_Approximation1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;，例如机器人的行走状态，第一个特征是距离横向基准位置多远，第二个特征是距离纵向基准位置多远等等。损失函数是&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Function_Approximation2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;。从而随机梯度下降求得权重改变量为&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Function_Approximation3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;。&lt;/p&gt;

&lt;p&gt;但是在强化学习中，vπ(S)是未知的，无法用来当做监督信息，因此要用别的东西来代替，从而可以根据Monte-Carlo Learning和Temporal Difference Learning两种方法来考虑。&lt;/p&gt;

&lt;p&gt;Monte-Carlo Learning中针对某个状态叠加每个episode中在这个状态上产生的return，因为每个episode是走到了终止状态的，所以可以向初始状态的方向将return传播回来。而实际上值函数就是return的期望，所以基于MC方法就是用GtGt代替vπ(S)
Temporal Difference Learning中针对某个状态估计下一个时刻可能获得的return，由immdiate reward和上一次更新的值函数构成，也称为TD target，从而更新当前时刻的值函数，因此用&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Function_Approximation4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;来替换vπ(S)vπ(S)。替换后发现括号内的这一项就是TD error。同样的TD(λ)也是替换成第四课的公式即可。&lt;/p&gt;

&lt;p&gt;也就是替换成下面的误差函数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Function_Approximation7.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而动作值函数也是差不多的，就是替换，这里就不提了，参考[1]。&lt;/p&gt;

&lt;p&gt;在强化学习中，有个比较经典的例子就是汽车爬山[2]，车会在凹的山谷中来回启动，不同的高度上汽车需要学会利用势能来到达对面的山顶，这个问题中的状态就是汽车所处的位置和当前的速度(个人觉得当前的速度应该是action，在不同的位置人控制不同的速度，但是David课中说action是选择加速还是不加速)，曲面的起伏代表了value function。通过图中多执行多个episode得到了值函数的表达形式。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Function_Approximation5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;dqn&quot;&gt;DQN&lt;/h2&gt;

&lt;p&gt;此处讲batch methods说”梯度下降的方法针对一个sample，只利用一次，更新一次梯度之后就不再使用了，并没有挖掘出这个sample所有信息，因此需要用batch methods来重复的利用sample并找到最佳拟合值函数，拟合所有看到过的sample” ，这个意思我觉得并不重要，如果用神经网络来学习参数必然会多次迭代sample，所以直接介绍DQN。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Function_Approximation6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后十分钟讲了一下如何结合最小二乘法与MC/TD，令导数等于0再推导，流程跟梯度下降一样，这里就不提了，经过这几课大致可以看出强化学习要求解的核心就是policy和值函数，这一课可以看出值函数的具体形式可以用神经网络表示出来，即把状态变换成一个特征向量当做输入，经过神经网络得到值函数输出。&lt;/p&gt;

&lt;h2 id=&quot;dqn应用&quot;&gt;DQN应用&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Function_Approximation8.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Function_Approximation9.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Sat, 15 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/15/Value-Function-Approximation.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/15/Value-Function-Approximation.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>model free-Prediction</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#unknown-mdp&quot; id=&quot;markdown-toc-unknown-mdp&quot;&gt;unknown MDP&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#episode&quot; id=&quot;markdown-toc-episode&quot;&gt;episode&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#探索的必要性&quot; id=&quot;markdown-toc-探索的必要性&quot;&gt;探索的必要性：&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#怎么理解prediction&quot; id=&quot;markdown-toc-怎么理解prediction&quot;&gt;怎么理解Prediction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#monte-carlo-reinforcement-learning&quot; id=&quot;markdown-toc-monte-carlo-reinforcement-learning&quot;&gt;Monte-Carlo Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#temporal-difference-learning&quot; id=&quot;markdown-toc-temporal-difference-learning&quot;&gt;Temporal-Difference Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#temporal-difference-learning-和-monte-carlo-reinforcement-learning&quot; id=&quot;markdown-toc-temporal-difference-learning-和-monte-carlo-reinforcement-learning&quot;&gt;Temporal-Difference Learning 和 Monte-Carlo Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#mp动态规划mctd的区别&quot; id=&quot;markdown-toc-mp动态规划mctd的区别&quot;&gt;mp（动态规划），mc，td的区别&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;unknown-mdp&quot;&gt;unknown MDP&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;environment是未知的，不清楚做出了某个action之后会变到哪一个state也不知道这个action好还是不好，&lt;/strong&gt;也就是说不清楚environment体现的model是什么，在这种情况下需要解决的prediction和control问题就是Model-free prediction和Model-free control。显然这种新的问题只能从与environment的交互得到的experience中获取信息。&lt;/p&gt;

&lt;h2 id=&quot;episode&quot;&gt;episode&lt;/h2&gt;

&lt;p&gt;将从某个起始状态开始执行到终止状态的一次遍历&lt;strong&gt;S1,A1,R2,…,Sk(状态，动作，回报)称为episode&lt;/strong&gt;。已知很多的episodes。&lt;/p&gt;

&lt;h2 id=&quot;探索的必要性&quot;&gt;探索的必要性：&lt;/h2&gt;

&lt;p&gt;由于不知道智能体与环境交互的模型，蒙特卡罗方法是利用经验平均来估计值函数。能否得到正确的值函数，取决于经验。&lt;strong&gt;如何获得充足的经验是无模型强化学习的核心所在。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在动态规划方法中，为了保证值函数的收敛性，算法会对状态空间中的状态进行逐个扫描。无模型的方法充分评估策略值函数的前提是每个状态都能被访问到。因此，在蒙特卡洛方法中必须采用一定的方法保证每个状态都能被访问到。其中一种方法是探索性初始化。&lt;/p&gt;

&lt;h2 id=&quot;怎么理解prediction&quot;&gt;怎么理解Prediction&lt;/h2&gt;

&lt;p&gt;在我的理解看来，Prediction就是对策略的评估，然后要进行迭代评估，原因是agent在执行一次一个策略得到一个episode来评估是不能有效代表这个策略的期望价值的，只有多次迭代才能找到价值期望。同时有证明TD和MC方法都是可以收敛的。&lt;/p&gt;

&lt;h2 id=&quot;monte-carlo-reinforcement-learning&quot;&gt;Monte-Carlo Reinforcement Learning&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;MC methods learn directly from episodes of experience(从episodes获得信息)&lt;/li&gt;
  &lt;li&gt;MC is model-free: no knowledge of MDP transitions / rewards（没有特定的转换函数和价值函数）&lt;/li&gt;
  &lt;li&gt;MC learns from complete episodes: no bootstrapping&lt;/li&gt;
  &lt;li&gt;MC uses the simplest possible idea: value = mean return（不是return的期望，而是均值）&lt;/li&gt;
  &lt;li&gt;Caveat: can only apply MC to episodic MDPs
 All episodes must terminate（一定要执行到终止状态）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Monte-Carlo1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;最后说明，Prediction是一种在某种确定的策略下求值的方式，在&lt;a href=&quot;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/MC-TD.pdf&quot;&gt;课件中的21点的例子中&lt;/a&gt;，多次迭代才能求出值的原因就是一次的episode并不能求出值，而是多次的episode才能找出在这种策略下，这些状态的值。或者说，在求值的过程中，其实我们是在寻找那个状态到价值的那个参数，但仅仅一次或几次的episode，不能找到那个合适的参数映射，只有数据量很大的时候才能，当然是存在收敛的时候的！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;temporal-difference-learning&quot;&gt;Temporal-Difference Learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Monte-Carlo2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;temporal-difference-learning-和-monte-carlo-reinforcement-learning&quot;&gt;Temporal-Difference Learning 和 Monte-Carlo Reinforcement Learning&lt;/h2&gt;

&lt;p&gt;我的理解是，&lt;strong&gt;一个是即时反馈，一个是完整的过程之后才反馈，&lt;/strong&gt;视频中有一个撞车的例子，讲如果在开着车太快而差点撞上（没有撞上）迎面来的车的话，Temporal-Difference Learning会负反馈，就像告诉你不要开太快避免撞车，而Monte-Carlo Reinforcement Learning是不会有负面反馈的，原因是在本质上整个过程中没有撞车！&lt;/p&gt;

&lt;p&gt;Temporal-Difference Learning可以找到正真的价值函数，Monte-Carlo Reinforcement Learning得到也是正真的价值函数，&lt;strong&gt;根据大数定律&lt;/strong&gt;！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Temporal_ca1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Temporal_ca2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;mp动态规划mctd的区别&quot;&gt;mp（动态规划），mc，td的区别&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/mp_mc_td.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Sat, 15 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/15/Monte-Carlo-Reinforcement-Learning.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/15/Monte-Carlo-Reinforcement-Learning.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>cs231n-线性分类器（多分类svm和Softmax）</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cs231n-线性分类器多分类svm和softmax&quot; id=&quot;markdown-toc-cs231n-线性分类器多分类svm和softmax&quot;&gt;cs231n-线性分类器（多分类svm和Softmax）&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#理解线性分类器&quot; id=&quot;markdown-toc-理解线性分类器&quot;&gt;理解线性分类器&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#偏差和权重的合并技巧&quot; id=&quot;markdown-toc-偏差和权重的合并技巧&quot;&gt;偏差和权重的合并技巧&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#多类支持向量机损失-multiclass-support-vector-machine-loss&quot; id=&quot;markdown-toc-多类支持向量机损失-multiclass-support-vector-machine-loss&quot;&gt;多类支持向量机损失 Multiclass Support Vector Machine Loss&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#正则化&quot; id=&quot;markdown-toc-正则化&quot;&gt;正则化&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#多分类svm其他要注意的地方&quot; id=&quot;markdown-toc-多分类svm其他要注意的地方&quot;&gt;多分类svm其他要注意的地方&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#softmax分类器&quot; id=&quot;markdown-toc-softmax分类器&quot;&gt;Softmax分类器&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#softmax分类器-和多分类svm比较&quot; id=&quot;markdown-toc-softmax分类器-和多分类svm比较&quot;&gt;Softmax分类器 和多分类svm比较&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;cs231n-线性分类器多分类svm和softmax&quot;&gt;cs231n-线性分类器（多分类svm和Softmax）&lt;/h1&gt;

&lt;p&gt;我们将要实现一种更强大的方法来解决图像分类问题，该方法可以自然地延伸到神经网络和卷积神经网络上。这种方法主要有两部分组成：&lt;strong&gt;一个是评分函数（score function），它是原始图像数据到类别分值的映射。另一个是损失函数（loss function），它是用来量化预测分类标签的得分与真实标签之间一致性的。&lt;/strong&gt;该方法可转化为一个最优化问题，在最优化过程中，将通过更新评分函数的参数来最小化损失函数值。&lt;/p&gt;

&lt;h2 id=&quot;理解线性分类器&quot;&gt;理解线性分类器&lt;/h2&gt;

&lt;p&gt;线性分类器计算图像中3个颜色通道中所有像素的值与权重的矩阵乘，从而得到分类分值。根据我们对权重设置的值，对于图像中的某些位置的某些颜色，函数表现出喜好或者厌恶（根据每个权重的符号而定）。举个例子，可以想象“船”分类就是被大量的蓝色所包围（对应的就是水）。那么“船”分类器在蓝色通道上的权重就有很多的正权重（它们的出现提高了“船”分类的分值），而在绿色和红色通道上的权重为负的就比较多（它们的出现降低了“船”分类的分值）。&lt;/p&gt;

&lt;p&gt;————————————————————————————————————————&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs231nleaner1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一个将图像映射到分类分值的例子。为了便于可视化，假设图像只有4个像素（都是黑白像素，这里不考虑RGB通道），有3个分类（红色代表猫，绿色代表狗，蓝色代表船，注意，这里的红、绿和蓝3种颜色仅代表分类，和RGB通道没有关系）。首先将图像像素拉伸为一个列向量，与W进行矩阵乘，然后得到各个分类的分值。需要注意的是，这个W一点也不好：猫分类的分值非常低。从上图来看，算法倒是觉得这个图像是一只狗。&lt;/p&gt;

&lt;p&gt;将图像看做高维度的点：既然图像被伸展成为了一个高维度的列向量，那么我们可以把图像看做这个高维度空间中的一个点（即每张图像是3072维空间中的一个点）。整个数据集就是一个点的集合，每个点都带有1个分类标签。&lt;/p&gt;

&lt;h2 id=&quot;偏差和权重的合并技巧&quot;&gt;偏差和权重的合并技巧&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs231nleaner2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;多类支持向量机损失-multiclass-support-vector-machine-loss&quot;&gt;多类支持向量机损失 Multiclass Support Vector Machine Loss&lt;/h2&gt;

&lt;p&gt;损失函数的具体形式多种多样。首先，介绍常用的多类支持向量机（SVM）损失函数。SVM的损失函数想要SVM在正确分类上的得分始终比不正确分类上的得分高出一个边界值\Delta。我们可以把损失函数想象成一个人，这位SVM先生（或者女士）对于结果有自己的品位，如果某个结果能使得损失值更低，那么SVM就更加喜欢它。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs231nleaner3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;正则化&quot;&gt;正则化&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs231nleaner4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs231nleaner5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;需要注意的是，和权重不同，&lt;strong&gt;偏差没有这样的效果，因为它们并不控制输入维度上的影响强度。因此通常只对权重W正则化，而不正则化偏差b。&lt;/strong&gt;在实际操作中，可发现这一操作的影响可忽略不计。最后，因为正则化惩罚的存在，不可能在所有的例子中得到0的损失值，这是因为只有当W=0的特殊情况下，才能得到损失值为0。&lt;/p&gt;

&lt;h2 id=&quot;多分类svm其他要注意的地方&quot;&gt;多分类svm其他要注意的地方&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs231nleaner6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;softmax分类器&quot;&gt;Softmax分类器&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs231nleaner7.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs231nleaner8.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;softmax分类器-和多分类svm比较&quot;&gt;Softmax分类器 和多分类svm比较&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs231nleaner9.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;针对一个数据点，SVM和Softmax分类器的不同处理方式的例子。两个分类器都计算了同样的分值向量f（本节中是通过矩阵乘来实现）。不同之处在于对f中分值的解释：SVM分类器将它们看做是分类评分，它的损失函数鼓励正确的分类（本例中是蓝色的类别2）的分值比其他分类的分值高出至少一个边界值。Softmax分类器将这些数值看做是每个分类没有归一化的对数概率，鼓励正确分类的归一化的对数概率变高，其余的变低。SVM的最终的损失值是1.58，Softmax的最终的损失值是0.452，但要注意这两个数值没有可比性。只在给定同样数据，在同样的分类器的损失值计算中，它们才有意义。&lt;/p&gt;

&lt;p&gt;————————————————————————————————————————&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Softmax分类器为每个分类提供了“可能性”&lt;/strong&gt;：SVM的计算是无标定的，而且难以针对所有分类的评分值给出直观解释。Softmax分类器则不同，它允许我们计算出对于所有分类标签的可能性。举个例子，针对给出的图像，SVM分类器可能给你的是一个[12.5, 0.6, -23.0]对应分类“猫”，“狗”，“船”。而softmax分类器可以计算出这三个标签的”可能性“是[0.9, 0.09, 0.01]，这就让你能看出对于不同分类准确性的把握。为什么我们要在”可能性“上面打引号呢？这是因为可能性分布的集中或离散程度是由正则化参数λ直接决定的，λ是你能直接控制的一个输入参数。举个例子，假设3个分类的原始分数是[1, -2, 0]，那么softmax函数就会计算：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs231nleaner10.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在看起来，概率的分布就更加分散了。还有，随着正则化参数λ不断增强，权重数值会越来越小，最后输出的概率会接近于均匀分布。这就是说，softmax分类器算出来的概率最好是看成一种对于分类正确性的自信。和SVM一样，数字间相互比较得出的大小顺序是可以解释的，但其绝对值则难以直观解释。&lt;/p&gt;

&lt;p&gt;在实际使用中，SVM和Softmax经常是相似的：通常说来，两种分类器的表现差别很小，不同的人对于哪个分类器更好有不同的看法。相对于Softmax分类器，&lt;strong&gt;SVM更加“局部目标化（local objective）”，这既可以看做是一个特性，也可以看做是一个劣势。&lt;/strong&gt;考虑一个评分是[10, -2, 3]的数据，其中第一个分类是正确的。那么一个SVM（\Delta =1）会看到正确分类相较于不正确分类，已经得到了比边界值还要高的分数，它就会认为损失值是0。SVM对于数字个体的细节是不关心的：如果分数是[10, -100, -100]或者[10, 9, 9]，对于SVM来说没设么不同，只要满足超过边界值等于1，那么损失值就等于0。&lt;/p&gt;

&lt;p&gt;对于softmax分类器，情况则不同。对于[10, 9, 9]来说，计算出的损失值就远远高于[10, -100, -100]的。换句话来说，softmax分类器对于分数是永远不会满意的：正确分类总能得到更高的可能性，错误分类总能得到更低的可能性，损失值总是能够更小。但是，SVM只要边界值被满足了就满意了，不会超过限制去细微地操作具体分数。这可以被看做是SVM的一种特性。举例说来，一个汽车的分类器应该把他的大量精力放在如何分辨小轿车和大卡车上，而不应该纠结于如何与青蛙进行区分，因为区分青蛙得到的评分已经足够低了。&lt;/p&gt;

</description>
        <pubDate>Sat, 15 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/15/cs231n-%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8-%E5%A4%9A%E5%88%86%E7%B1%BBsvm%E5%92%8CSoftmax.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/15/cs231n-%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8-%E5%A4%9A%E5%88%86%E7%B1%BBsvm%E5%92%8CSoftmax.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Planning by dynamic programming</title>
        <description>
</description>
        <pubDate>Thu, 13 Apr 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/04/13/Planning-by-Dynamic-Programming.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/04/13/Planning-by-Dynamic-Programming.html</guid>
        
        
      </item>
    
      <item>
        <title>reinforcement learning</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reinforcement-learning&quot; id=&quot;markdown-toc-reinforcement-learning&quot;&gt;reinforcement learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#强化学习是什么&quot; id=&quot;markdown-toc-强化学习是什么&quot;&gt;强化学习是什么&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#what-makes-reinforcement-learning-different-from-other-machine-learning-paradigms&quot; id=&quot;markdown-toc-what-makes-reinforcement-learning-different-from-other-machine-learning-paradigms&quot;&gt;What makes reinforcement learning different from other machine learning paradigms?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#examples-of-reinforcement-learning&quot; id=&quot;markdown-toc-examples-of-reinforcement-learning&quot;&gt;Examples of Reinforcement Learning&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#强化学习组成&quot; id=&quot;markdown-toc-强化学习组成&quot;&gt;强化学习组成&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sequential-decision-making&quot; id=&quot;markdown-toc-sequential-decision-making&quot;&gt;Sequential Decision Making&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#agent的组成&quot; id=&quot;markdown-toc-agent的组成&quot;&gt;Agent的组成&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#探索和利用&quot; id=&quot;markdown-toc-探索和利用&quot;&gt;探索和利用&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#强化学习的分类&quot; id=&quot;markdown-toc-强化学习的分类&quot;&gt;强化学习的分类&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reinforcement-learning&quot;&gt;reinforcement learning&lt;/h2&gt;

&lt;h2 id=&quot;强化学习是什么&quot;&gt;强化学习是什么&lt;/h2&gt;

&lt;p&gt;强化学习是多学科多领域交叉的一个产物，它的&lt;strong&gt;本质就是解决“decision making”问题，即学会自动进行决策&lt;/strong&gt;。在computer science领域体现为机器学习算法。在Engineering领域体现在决定the sequence of actions来得到最好的结果。在Neuroscience领域体现在理解人类大脑如何做出决策，主要的研究是reward system。在Psychology领域，研究动物如何做出决策，动物的行为是由什么导致的。在Economics领域体现在博弈论的研究。这&lt;strong&gt;所有的问题最终都归结为一个问题，人为什么能够并且如何做出最优决策。是怎么样找到最优决策的&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;what-makes-reinforcement-learning-different-from-other-machine-learning-paradigms&quot;&gt;What makes reinforcement learning different from other machine learning paradigms?&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;There is no supervisor, only a reward signal(用&lt;strong&gt;奖励来提升模型能力,而不是label&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;Feedback is delayed, not instantaneous（&lt;strong&gt;做出一系列行为后最终反馈回来的reward signal&lt;/strong&gt;）&lt;/li&gt;
  &lt;li&gt;Time really matters (sequential, non i.i.d data)（时间是主要原因）&lt;/li&gt;
  &lt;li&gt;Agent’s actions affect the subsequent data it receives&lt;/li&gt;
  &lt;li&gt;强化学习面对的&lt;strong&gt;输入(状态)总是在变化且不独立，输入不像监督学习是独立同分布的&lt;/strong&gt;。而每当算法做出一个行为，它影响了下一次决策的输入。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;examples-of-reinforcement-learning&quot;&gt;Examples of Reinforcement Learning&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Fly stunt manoeuvres in a helicopter（直升机特技表演）s表示某个特定状态&lt;/li&gt;
  &lt;li&gt;Defeat the world champion at Backgammon（棋类等智力比赛）&lt;/li&gt;
  &lt;li&gt;Manage an investment portfolio（管理金融证卷）&lt;/li&gt;
  &lt;li&gt;Control a power station（控制电力站）&lt;/li&gt;
  &lt;li&gt;Make a humanoid robot walk（机器人行走）&lt;/li&gt;
  &lt;li&gt;Play many different Atari games better than humans（玩智力游戏）&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;强化学习组成&quot;&gt;强化学习组成&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/rl_baseknow1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/rl_baseknow2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;sequential-decision-making&quot;&gt;Sequential Decision Making&lt;/h2&gt;

&lt;p&gt;Goal: select actions to maximise total future reward&lt;/p&gt;

&lt;p&gt;Actions may have long term consequences and reward that it may be better to sacrifice immediate  to gain more
long-term reward may be delayed&lt;/p&gt;

&lt;p&gt;Examples:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;A financial investment (may take months to mature)
Refuelling a helicopter (might prevent a crash in several hours)
Blocking opponent moves (might help winning chances many
moves from now)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;在强化学习中，可以比作我们人和周围环境的交互，人在观察之后做出动作就会得到环境的相对应的反馈。而在强化学习中，我们就充当那个环境，我们给他一些数据给他观察，然后它做出动作，然后我们在制定一些反馈，随着时间的进行，模型就会越来越趋向于我们所想要的那样！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;agent的组成&quot;&gt;Agent的组成&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/rl_baseknow2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;探索和利用&quot;&gt;探索和利用&lt;/h2&gt;

&lt;p&gt;强化学习是一种试错(trial-and-error)的学习方式，一开始不清楚environment的工作方式，不清楚执行什么样的行为是对的，什么样是错的。因而agent需要从不断尝试的经验中发现一个好的policy，从而在这个过程中获取更多的reward。&lt;/p&gt;

&lt;p&gt;在这样的学习过程中，就会有一个在Exploration和Exploitation之间的权衡，&lt;strong&gt;前者是说会放弃一些已知的reward信息，而去尝试一些新的选择，&lt;/strong&gt;即在某种状态下，算法也许已经学习到选择什么action让reward比较大，但是并不能每次都做出同样的选择，也许另外一个没有尝试过的选择会让reward更大，即Exploration希望能够探索更多关于environment的信息。&lt;strong&gt;而后者是指根据已知的信息最大化reward。&lt;/strong&gt;例如，在选择一个餐馆时，Exploitation会选择你最喜欢的餐馆，而Exploration会尝试选择一个新的餐馆。&lt;/p&gt;

&lt;h2 id=&quot;强化学习的分类&quot;&gt;强化学习的分类&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/RL_ppt2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;强化学习算法根据以策略为中心还是以值函数最优可以分为两大类，策略优化方法和动态规划方法。其中策略优化方法又分为进化算法和策略梯度方法；动态规划方法分为策略迭代算法和值迭代算法。策略迭代算法和值迭代算法可以利用广义策略迭代方法进行统一描述。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/ppt.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;根据转移概率是否已知和某个动作是否好不好可以分为基于模型的强化学习算法和无模型的强化学习算法，如上图。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;需要注意的是在一开始学的时候指迭代和策略迭代是base model的，也就是基于model的，而后面学习的蒙特卡洛树搜索或者其他base model是两个不一样的base model的，前者是实实在在的了解环境，在对环境有所了解的基础上（体现在知道p等）建模。而后者是用“想象力对环境进行建模”，也就是多出了一个虚拟环境。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/RL_fen_PPT.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面一图算是一个总结，也就是说根据model是否free分和以值函数和策略优化分是两回事，他们是有交叉的!&lt;/p&gt;

&lt;p&gt;强化学习算法根据策略是否是随机的，分为确定性策略强化学习和随机性策略强化学习。另外，强化学习算法中的回报函数十分关键，根据回报函数是否已知，可以分为强化学习和逆向强化学习。逆向强化学习是根据专家实例将回报函数学出来&lt;/p&gt;

</description>
        <pubDate>Sun, 02 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/02/reinforcement-learning.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/02/reinforcement-learning.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Markov decision processes</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#基础概念&quot; id=&quot;markdown-toc-基础概念&quot;&gt;基础概念&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#state-transition-distribution状态转换分布&quot; id=&quot;markdown-toc-state-transition-distribution状态转换分布&quot;&gt;state transition distribution(状态转换分布)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#markov-process&quot; id=&quot;markdown-toc-markov-process&quot;&gt;Markov Process&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#马尔可夫链过程markov-chainprocess&quot; id=&quot;markdown-toc-马尔可夫链过程markov-chainprocess&quot;&gt;马尔可夫链/过程(Markov Chain/Process)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#马尔可夫奖赏过程markov-reward-process&quot; id=&quot;markdown-toc-马尔可夫奖赏过程markov-reward-process&quot;&gt;马尔可夫奖赏过程(Markov Reward Process)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#马尔可夫决策过程markov-decision-process&quot; id=&quot;markdown-toc-马尔可夫决策过程markov-decision-process&quot;&gt;马尔可夫决策过程(Markov Decision Process)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;基础概念&quot;&gt;基础概念&lt;/h1&gt;

&lt;p&gt;状态集合S: &lt;strong&gt;有限状态state集合，s表示某个特定状态&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;动作集合A: &lt;strong&gt;有限动作action集合，a表示某个特定动作&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;state-transition-distribution状态转换分布&quot;&gt;state transition distribution(状态转换分布)&lt;/h3&gt;

&lt;p&gt;状态转换分布（state transition distribution）。对于每个属于集合S的状态s和每个属于集合A的动作a，如果我们在状态s中采取了动作s，那么我们就会转换到一个新的状态中，而状态转换分布就给出了我们会随机转换到哪个状态的概率分布。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/zhuangtaizhuanhuan.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
分布（state transition distribution）。对于每个属于集合S的状态s和每个属于集合A的动作a，如果我们在状态s中采取了动作s，那么我们就会转换到一个新的状态中，而状态转换分布就给出了我们会随机转换到哪个状态的概率分布。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;也就是在某个状态采取某个动作之后的一些转换概率&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Markov_decision_processes.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;markov-process&quot;&gt;Markov Process&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;从MP开始到MRP再到MDP，了解值函数的具体概念与reward有什么联系&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MDP描述了强化学习的environment，且是fully Observable的&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;马尔可夫链过程markov-chainprocess&quot;&gt;马尔可夫链/过程(Markov Chain/Process)&lt;/h2&gt;

&lt;p&gt;先说说马尔可夫性质：&lt;code class=&quot;highlighter-rouge&quot;&gt;“The future is independent of the past given the present”&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Markov Property.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The state captures all relevant information from the history，Once the state is known, the history may be thrown away。i.e. The state is a sufficient statistic of the future&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Markov_decision_processes1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;课件原文：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For a Markov state s and successor state s‘, the state transition probability is defined by&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/successor state s.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;State transition matrix P defines transition probabilities from all
states s to all successor states s’：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/successor states s1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;where each row of the matrix sums to 1&lt;/p&gt;

&lt;p&gt;A Markov process is a memoryless random process, i.e. a sequence of random states S1, S2, … with the Markov property&lt;/p&gt;

&lt;p&gt;A Markov Process (or Markov Chain) is a tuple &amp;lt;S,P&amp;gt; where S is a (finite) set of states and P is a state transition probability matrix,
P（ss’） = P [S（t+1) = s’| S（t）= s]&lt;/p&gt;

&lt;h2 id=&quot;马尔可夫奖赏过程markov-reward-process&quot;&gt;马尔可夫奖赏过程(Markov Reward Process)&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Markov_decision_processes2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Markov_decision_processes3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Markov_decision_processes4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Markov_decision_processes5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Markov_decision_processes6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;马尔可夫决策过程markov-decision-process&quot;&gt;马尔可夫决策过程(Markov Decision Process)&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Markov_decision_processes7.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/26Markov_decision_processes8.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Sun, 02 Apr 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/02/Markov-decision-processes.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/04/02/Markov-decision-processes.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Paper about Very Deep Convolutional Networks for Text Classification</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#paper-about-very-deep-convolutional-networks-for-text-classification&quot; id=&quot;markdown-toc-paper-about-very-deep-convolutional-networks-for-text-classification&quot;&gt;Paper about Very Deep Convolutional Networks for Text Classification&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#vdcnn-architecture&quot; id=&quot;markdown-toc-vdcnn-architecture&quot;&gt;VDCNN Architecture&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#convolutional-block&quot; id=&quot;markdown-toc-convolutional-block&quot;&gt;Convolutional Block&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;paper-about-very-deep-convolutional-networks-for-text-classification&quot;&gt;Paper about Very Deep Convolutional Networks for Text Classification&lt;/h1&gt;

&lt;p&gt;To the best of our knowledge, this is the first time that very deep convolutional nets have been applied to text processing.&lt;/p&gt;

&lt;h2 id=&quot;vdcnn-architecture&quot;&gt;VDCNN Architecture&lt;/h2&gt;

&lt;p&gt;The overall architecture of our network is shown in Figure 1. &lt;strong&gt;Our model begins with a look-up table that generates a 2D tensor of size (f 0 , s) that contain the embeddings of the s characters. s is fixed to 1024, and f 0 can be seen as the ”RGB” dimension of the input text.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/VDCNN.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In Figure 1, temporal convolutions with kernel size 3 and X feature maps are denoted ”3, Temp Conv, X”, fully connected layers which are linear projections (matrix of size I × O) are denoted ”fc(I, O)” and ”3-max pooling, stride 2” means temporal max pooling with kernel size 3 and stride 2.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;investigated &lt;strong&gt;the same kind of “ResNet shortcut” connections&lt;/strong&gt; as in (Heet al., 2016a), namely identity and 1 × 1 convolutions (see Figure 1)&lt;/p&gt;

&lt;p&gt;Inspired by the philosophy of VGG and ResNets we apply these two design rules: (i) for the same output temporal resolution, the layers have the same number of feature maps, (ii) when the temporal resolution is halved, the number of feature maps is doubled. This helps reduce the memory footprint of the network.&lt;/p&gt;

&lt;h2 id=&quot;convolutional-block&quot;&gt;Convolutional Block&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Convolutional block.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Each convolutional block (see Figure 2) is a sequence of two convolutional layers, each one followed by a temporal BatchNorm (Ioffe and Szegedy, 2015) layer and an ReLU activation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Convolutional block.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Different depths of the overall architecture are obtained by varying the number of convolutional blocks in between the pooling layers (see table 2)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In this work, we have explored four depths for our networks: 9, 17, 29 and 49, which we define as being the number of convolutional layers. The depth of a network is obtained by summing the number of blocks with 64, 128, 256 and 512 filters, with each block containing two convolutional layers. In Figure 1, the network has 2 blocks of each type, resulting in a depth of 2 × (2 + 2 + 2 + 2) = 16. Adding the very first convolutional layer, this sums to a depth of 17 convolutional layers. The depth can thus be increased or decreased by adding or removing convolutional blocks with a certain number of filters. The best configurations we observed for depths 9, 17, 29 and 49 are described in Table 2. We also give the number of parameters of all convolutional layers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;We explore three types of down-sampling between blocks K i and K i+1 (Figure 1) :&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(i) The first convolutional layer of K i+1 has stride 2 (ResNet-like).&lt;/p&gt;

&lt;p&gt;(ii) K i is followed by a k-max pooling layer where k is such that the resolution is halved (Kalchbrenner et al., 2014).&lt;/p&gt;

&lt;p&gt;(iii) K i is followed by max-pooling with kernel size 3 and stride 2 (VGG-like).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;All these types of pooling reduce the temporal resolution by a factor 2. At the final convolutional layer, the resolution is thus s d .&lt;/p&gt;
&lt;/blockquote&gt;

</description>
        <pubDate>Fri, 31 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/31/paper-about-Very-Deep-Convolutional-Networks.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/31/paper-about-Very-Deep-Convolutional-Networks.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>paper about Sequence to Sequence Learning with Neural Networks</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#paper-about-sequence-to-sequence-learning-with-neural-networks&quot; id=&quot;markdown-toc-paper-about-sequence-to-sequence-learning-with-neural-networks&quot;&gt;paper about Sequence to Sequence Learning with Neural Networks&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#shortage-of-traditional-dnn&quot; id=&quot;markdown-toc-shortage-of-traditional-dnn&quot;&gt;shortage of traditional DNN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-model&quot; id=&quot;markdown-toc-the-model&quot;&gt;the model&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;paper-about-sequence-to-sequence-learning-with-neural-networks&quot;&gt;paper about Sequence to Sequence Learning with Neural Networks&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Long Short-Term Memory (LSTM) architecture [16] can solve general sequence to sequence problems.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;shortage-of-traditional-dnn&quot;&gt;shortage of traditional DNN&lt;/h2&gt;

&lt;p&gt;Despite their flexibility and power, &lt;strong&gt;DNNs can only be applied to problems whose inputs and targets can be sensibly encoded with vectors of fixed dimensionality.&lt;/strong&gt; It is a significant limitation, since many important problems are best expressed with sequences whose lengths are not known a-priori. For example, speech recognition and machine translation are sequential problems. Likewise, question answering can also be seen as mapping a sequence of words representing the question to a sequence of words representing the answer. It is therefore clear that &lt;strong&gt;a domain-independent method that learns to map sequences to sequences would be useful&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-model&quot;&gt;the model&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Sequence to Sequence.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;a trick:&lt;/strong&gt;the LSTM did not suffer on very long sentences,The simple trick of reversing the words in the source sentence is one of the key technical contributions of this work&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Sequence to Sequence Learning.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 29 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/29/Sequence-to-Sequence-Learning.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/29/Sequence-to-Sequence-Learning.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>paper about batch normalization and dropout</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#paper-about-batch-normalization-and-dropout&quot; id=&quot;markdown-toc-paper-about-batch-normalization-and-dropout&quot;&gt;paper about batch normalization and dropout&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#batch-normalization&quot; id=&quot;markdown-toc-batch-normalization&quot;&gt;Batch Normalization&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#batch-normalization-via-mini-batch-statistics&quot; id=&quot;markdown-toc-batch-normalization-via-mini-batch-statistics&quot;&gt;Batch Normalization via mini-batch statistics&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#training-and-inference-with-batch-normalized-networks&quot; id=&quot;markdown-toc-training-and-inference-with-batch-normalized-networks&quot;&gt;Training and Inference with Batch Normalized Networks&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#batch-normalization-enables-higher-learning-rate&quot; id=&quot;markdown-toc-batch-normalization-enables-higher-learning-rate&quot;&gt;Batch Normalization enables higher learning rate&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#dropout&quot; id=&quot;markdown-toc-dropout&quot;&gt;dropout&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#阻止overfitting&quot; id=&quot;markdown-toc-阻止overfitting&quot;&gt;阻止Overfitting&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-motivation-of-dropout&quot; id=&quot;markdown-toc-the-motivation-of-dropout&quot;&gt;the Motivation of dropout&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;paper-about-batch-normalization-and-dropout&quot;&gt;paper about batch normalization and dropout&lt;/h1&gt;

&lt;h1 id=&quot;batch-normalization&quot;&gt;Batch Normalization&lt;/h1&gt;

&lt;h2 id=&quot;batch-normalization-via-mini-batch-statistics&quot;&gt;Batch Normalization via mini-batch statistics&lt;/h2&gt;

&lt;p&gt;In the batch setting where each training step is based on the entire training set, we would use the whole set to nor malize activations. However, this is impractical when using stochastic optimization. Therefore, we make the sec-
ond simplification: since we use mini-batches in stochastic gradient training, each mini-batch produces estimates
of the mean and variance of each activation. This way, &lt;strong&gt;the statistics used for normalization can fully participate in the gradient backpropagation. Note that the use of mini batches is enabled by computation of per-dimension vari- ances rather than joint covariances; in the joint case, regularization would be required since the mini-batch size is likely to be smaller than the number of activations being whitened, resulting in singular covariance matrices.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Batch Normalizing1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;training-and-inference-with-batch-normalized-networks&quot;&gt;Training and Inference with Batch Normalized Networks&lt;/h2&gt;

&lt;p&gt;Using moving averages instead, we can track the accuracy of a model as it trains. Since the means and variances are fixed during inference, the normalization is simply a linear transform applied to each activation. It may further be composed with the scaling by γ and shift by β, to yield a single linear transform that replaces BN(x). Algorithm 2 summarizes the procedure for training batch-normalized networks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Batch Normalizing2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;batch-normalization-enables-higher-learning-rate&quot;&gt;Batch Normalization enables higher learning rate&lt;/h2&gt;
&lt;p&gt;Batch Normalization helps address these issues. &lt;strong&gt;By normalizing activations throughout the network, it prevents small changes to the parameters from amplifying into larger and suboptimal changes in activations in gradients&lt;/strong&gt;; for instance, it prevents the training from getting stuck in the saturated regimes of nonlinearities.&lt;/p&gt;

&lt;h1 id=&quot;dropout&quot;&gt;dropout&lt;/h1&gt;

&lt;h2 id=&quot;阻止overfitting&quot;&gt;阻止Overfitting&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;(NO.1)Overfitting can be reduced by using “dropout” to prevent complex co-adaptations on the training data&lt;/strong&gt;. On each presentation of each training case, each hidden unit is randomly omitted from the network with a probability of 0.5, so a hidden unit cannot rely on other hidden units being present. &lt;strong&gt;(NO.2)Another way to view the dropout procedure is as a very efficient way of perform-ing model averaging with neural networks. A good way to reduce the error on the test set is to average the predictions produced by a very large number of different networks.&lt;/strong&gt; The standard 1way to do this is to train many separate networks and then to apply each of these networks to the test data, but this is computationally expensive during both training and testing. Random dropout makes it possible to train a huge number of different networks in a reasonable time. There is almost certainly a different network for each presentation of each training case but all of these networks share the same weights for the hidden units that are present.&lt;/p&gt;

&lt;h2 id=&quot;the-motivation-of-dropout&quot;&gt;the Motivation of dropout&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;(NO.1)A motivation for dropout comes from a theory of the role of sex in evolution,&lt;/strong&gt;Sexual reproduction involves taking half the genes of one parent and half of the other, adding a very small amount of random mutation, and combining them to produce an offspring. The asexual alternative is to create an offspring with a slightly mutated copy of the parent’s genes. It seems plausible that asexual reproduction should be a better way to optimize individual fitness because a good set of genes that have come to work well together can be passed on directly to the offspring. On the other hand, sexual reproduction is likely to break up these co-adapted sets of genes, especially if these sets are large and, intuitively, this should decrease the fitness of organisms that have already evolved complicated co- adaptations. However, sexual reproduction is the way most advanced organisms evolved.&lt;/p&gt;

&lt;p&gt;One possible explanation for the superiority of sexual reproduction is that, over the long term, the criterion for natural selection may not be individual fitness but rather mix-ability of genes. The ability of a set of genes to be able to work well with another random set of genes makes them more robust. Since a gene cannot rely on a large set of partners to be present at all times, it must learn to do something useful on its own or in collaboration with a small number of other genes. According to this theory, the role of sexual reproduction is not just to allow useful new genes to spread throughout the population, but also to facilitate this process by reducing complex co-adaptations that would reduce the chance of a new gene improving the fitness of an individual. Similarly, each hidden unit in a neural network trained with dropout must learn to work with a randomly chosen sample of other units. This should make each hidden unit more robust and drive it towards creating useful features on its own without relying on other hidden units to correct its mistakes. However, the hidden units within a layer will still learn to do different things from each other. One might imagine that the net would become robust against dropout by making many copies of each hidden unit, but this is a poor solution for exactly the same reason as replica codes
are a poor way to deal with a noisy channel&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(NO.2)A closely related, but slightly different motivation for dropout comes from thinking about successful conspiracies&lt;/strong&gt;. Ten conspiracies each involving five people is probably a better way to create havoc than one big conspiracy that requires fifty people to all play their parts correctly. If conditions do not change and there is plenty of time for rehearsal, a big conspiracy can work well, but with non-stationary conditions, the smaller the conspiracy the greater its chance of still working. Complex co-adaptations can be trained to work well on a training set, but on novel test data they are far more likely to fail than multiple simpler co-adaptations that achieve the same thing.&lt;/p&gt;
</description>
        <pubDate>Wed, 29 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/29/Batch-Normalization-and-dropout.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/29/Batch-Normalization-and-dropout.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>《Deep Learning》-representation learning</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#representation-learning&quot; id=&quot;markdown-toc-representation-learning&quot;&gt;representation learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#representation-learning-1&quot; id=&quot;markdown-toc-representation-learning-1&quot;&gt;representation learning&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#why-humans-can-learning-well-by-small-set-of-labeled-examples&quot; id=&quot;markdown-toc-why-humans-can-learning-well-by-small-set-of-labeled-examples&quot;&gt;why humans can learning well by small set of labeled examples&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#greedy-layer-wise-unsupervised-pretraining&quot; id=&quot;markdown-toc-greedy-layer-wise-unsupervised-pretraining&quot;&gt;Greedy Layer-Wise Unsupervised Pretraining&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#what&quot; id=&quot;markdown-toc-what&quot;&gt;what:&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-advantage-of--unsupervised-pretraining&quot; id=&quot;markdown-toc-the-advantage-of--unsupervised-pretraining&quot;&gt;the advantage of  Unsupervised Pretraining&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-disadvantage-of-unsupervised-pretraining&quot; id=&quot;markdown-toc-the-disadvantage-of-unsupervised-pretraining&quot;&gt;the disadvantage of unsupervised Pretraining&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#todaydeep-learning-and-unsupervised-pretraining&quot; id=&quot;markdown-toc-todaydeep-learning-and-unsupervised-pretraining&quot;&gt;today,deep learning and unsupervised pretraining&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;representation-learning&quot;&gt;representation learning&lt;/h2&gt;

&lt;h2 id=&quot;representation-learning-1&quot;&gt;representation learning&lt;/h2&gt;

&lt;p&gt;We can think of feedforward networks trained by supervised learning as performing a kind of representation learning. Specifically, the last layer of the network is typically a linear classifier, such as a softmax regression classifier. The rest  of the network learns to provide a representation to this classifier. Training with a supervised criterion naturally leads to the representation at every hidden layer (but more so near the top hidden layer) taking on properties that make the classification task easier. For example, classes that were not linearly separable in the input features may become linearly separable in the last hidden layer. In principle, the last layer could be another kind of model, such as a nearest neighbor classifier (Salakhutdinov and Hinton , 2007a ). The features in the penultimate layer should learn different properties depending on the type of the last layer.&lt;/p&gt;

&lt;h3 id=&quot;why-humans-can-learning-well-by-small-set-of-labeled-examples&quot;&gt;why humans can learning well by small set of labeled examples&lt;/h3&gt;
&lt;p&gt;Humans and animals are able to learn from very few labeled examples. We do not yet know how this is possible. Many factors could explain improved human performance—for example, the brain may use very large ensembles of classifiers or Bayesian inference techniques. One popular hypothesis is that the brain is able  to leverage unsupervised or semi-supervised learning. There are many ways to leverage unlabeled data. In this chapter, we focus on the hypothesis that the  unlabeled data can be used to learn a good representation.&lt;/p&gt;

&lt;h2 id=&quot;greedy-layer-wise-unsupervised-pretraining&quot;&gt;Greedy Layer-Wise Unsupervised Pretraining&lt;/h2&gt;

&lt;h3 id=&quot;what&quot;&gt;what:&lt;/h3&gt;
&lt;p&gt;Unsupervised learning played a key historical role in the revival of deep neural networks, allowing for the first time to train a deep supervised network without requiring architectural specializations like convolution or recurrence. We call this procedure unsupervised pretraining, or more precisely, greedy layer-wise unsupervised pretraining.&lt;/p&gt;

&lt;h3 id=&quot;the-advantage-of--unsupervised-pretraining&quot;&gt;the advantage of  Unsupervised Pretraining&lt;/h3&gt;

&lt;p&gt;Unsupervised pretraining combines two different ideas. First, it makes use of the idea that the choice of initial parameters for a deep neural network can have a significant &lt;strong&gt;regularizing effect on the model (and, to a lesser extent, that it can improve optimization)&lt;/strong&gt;. Second, it makes use of the more general idea that learning about the input distribution can &lt;strong&gt;help to learn about the mapping from inputs to outputs.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-disadvantage-of-unsupervised-pretraining&quot;&gt;the disadvantage of unsupervised Pretraining&lt;/h3&gt;
&lt;p&gt;Compared to other ways of incorporating this belief by using unsupervised learning, unsupervised pretraining has the disadvantage that it &lt;strong&gt;operates with two separate training phases.&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;One reason that these two training phases are disadvantageous is that there is not a single hyperparameter that predictably reduces or increases the strength of the regularization arising from the unsupervised pretraining.&lt;/li&gt;
  &lt;li&gt;Another disadvantage of having two separate training phases is that each phase has its own hyperparameters. The performance of the second phase usually cannot be predicted during the first phase, so there is a long delay between proposing hyperparameters for the first phase and being able to update them using feedback from the second phase&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;todaydeep-learning-and-unsupervised-pretraining&quot;&gt;today,deep learning and unsupervised pretraining&lt;/h3&gt;

&lt;p&gt;Today, unsupervised pretraining has been largely abandoned, except in the
field of natural language processing.we can regard  word2vec which use widely in netural language processing as the method of unsupervised pretraining
&lt;strong&gt;for the reason as follow:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;These same techniques  outperform unsupervised pretraining on mediumsized datasets such as CIFAR-10 and MNIST, which have roughly 5,000 labeled examples per class. On extremely small datasets, such as the alternative splicing dataset, Bayesian methods outperform methods based on unsupervised pretraining (Srivastava , 2013 ). For these reasons, the popularity of unsupervised pretraining has declined.&lt;/p&gt;
</description>
        <pubDate>Sun, 26 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/26/Representation-Learning.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/26/Representation-Learning.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>支持向量机（SVM）</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#支持向量机svm&quot; id=&quot;markdown-toc-支持向量机svm&quot;&gt;支持向量机（SVM）&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#基本概念&quot; id=&quot;markdown-toc-基本概念&quot;&gt;基本概念&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#和logistic回归的区别&quot; id=&quot;markdown-toc-和logistic回归的区别&quot;&gt;和Logistic回归的区别&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#间隔&quot; id=&quot;markdown-toc-间隔&quot;&gt;间隔&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#函数间隔&quot; id=&quot;markdown-toc-函数间隔&quot;&gt;函数间隔&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#几何间隔&quot; id=&quot;markdown-toc-几何间隔&quot;&gt;几何间隔&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#函数间隔和几何间隔的关系&quot; id=&quot;markdown-toc-函数间隔和几何间隔的关系&quot;&gt;函数间隔和几何间隔的关系&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#有关凸优化&quot; id=&quot;markdown-toc-有关凸优化&quot;&gt;有关凸优化&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#svm分类&quot; id=&quot;markdown-toc-svm分类&quot;&gt;svm分类&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#线性可分支持向量机&quot; id=&quot;markdown-toc-线性可分支持向量机&quot;&gt;线性可分支持向量机&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#线性支持向量机&quot; id=&quot;markdown-toc-线性支持向量机&quot;&gt;线性支持向量机&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#非线性支持向量机&quot; id=&quot;markdown-toc-非线性支持向量机&quot;&gt;非线性支持向量机&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#核方法&quot; id=&quot;markdown-toc-核方法&quot;&gt;核方法&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mercer-定理&quot; id=&quot;markdown-toc-mercer-定理&quot;&gt;Mercer 定理：&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#低维转高维要解决的问题&quot; id=&quot;markdown-toc-低维转高维要解决的问题&quot;&gt;低维转高维要解决的问题&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#核方法和分类或者回归的问题&quot; id=&quot;markdown-toc-核方法和分类或者回归的问题&quot;&gt;核方法和分类（或者回归）的问题&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#核方法的直观理解&quot; id=&quot;markdown-toc-核方法的直观理解&quot;&gt;核方法的直观理解&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#how-to-select-svm-kernels&quot; id=&quot;markdown-toc-how-to-select-svm-kernels&quot;&gt;How to select SVM kernels?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#坐标法求最优解&quot; id=&quot;markdown-toc-坐标法求最优解&quot;&gt;坐标法求最优解&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#二元偏导数的几何意义&quot; id=&quot;markdown-toc-二元偏导数的几何意义&quot;&gt;二元偏导数的几何意义&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#梯度下降和坐标下降的区别&quot; id=&quot;markdown-toc-梯度下降和坐标下降的区别&quot;&gt;梯度下降和坐标下降的区别&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#序列最小优化算法smo-sequential-minimal-optimization&quot; id=&quot;markdown-toc-序列最小优化算法smo-sequential-minimal-optimization&quot;&gt;序列最小优化算法（SMO: sequential minimal optimization）&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;支持向量机svm&quot;&gt;支持向量机（SVM）&lt;/h1&gt;

&lt;p&gt;今天讲下支持向量机！这个模型很强大，但理解起来可能有点麻烦，它的理论支持已经比较完善了（相对于深度神经网络而言），涉及的数学比较多，我理解的也相当的有限，希望能够讲好点，下面开始吧！&lt;/p&gt;

&lt;h2 id=&quot;基本概念&quot;&gt;基本概念&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;支持向量机，因其英文名为support vector machine，故一般简称SVM，通俗来讲，它是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。&lt;/li&gt;
  &lt;li&gt;按照惯例，先上一个最通俗的例子来直观的理解SVM，我从知乎上找到了一篇回答，他很形象的描述了SVM，传送门：&lt;a href=&quot;https://www.zhihu.com/question/21094489&quot;&gt;通俗理解svm&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;最大间隔分类器（maximum margin classifier，可以被看做是支持向量机的前身）实际上就选择特定的w,b使&lt;strong&gt;几何间隔&lt;/strong&gt;最大化。&lt;/li&gt;
  &lt;li&gt;它通常被认为是最好的现成监督学习算法之一（很多人认为它是最好的）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;和logistic回归的区别&quot;&gt;和Logistic回归的区别&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;就是在Z=w^T&lt;em&gt;x+θ0=&amp;gt;Z=w^T&lt;/em&gt;x+b,和b这个截距。是的y的值在-1和1之间&lt;/li&gt;
  &lt;li&gt;为了更加简洁的介绍支持向量机，我们需要先引入一种新的标记。考虑使用线性分类器解决“特征为x目标为y”的二元分类问题。这次，我们使用y∈{−1,1}来标记两个分类（而不是之前的y∈{0,1}），再使用参数向量w,b代替之前的参数向量θ和θ0（就是截距），于是我们现在将分类器写为：hw,b(x)=g(wTx+b)，w是参数向量，b是一个实数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;问：&lt;/strong&gt;为什么直接用正负一而不是0，1呢？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;答：&lt;/strong&gt;因为在表示几何间隔和函数间隔的时候，+1表示的是1类的间隔，而-1表示的是另一类的间隔，可以通过统一的公式来表示点到超平面的间隔&lt;/p&gt;

&lt;h2 id=&quot;间隔&quot;&gt;间隔&lt;/h2&gt;

&lt;p&gt;在讲函数间隔之前，我们先来看下一个直观的理解：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://nbviewer.jupyter.org/github/zlotus/notes-LSJU-machine-learning/blob/master/resource/chapter06_image01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;如果求关于点A的预测，我们会非常确定其值为y=1。相反，点C距离判别边界很近，虽然它在判别边界y=1一侧，但是如果判别边界稍有变动，它就有可能被放在y=0一侧。因此，我们对点A预测的“信心”强于点C。而点B则在两者之间，通常来说，如果点距离判别边界越远，模型做出预测的“信心”就越强。也就是说，如果对于给定训练集，可以找到一条能够准确并可信（即样本距离边界很远）的预测所有训练样本的判别边界，则称这个拟合是良好的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;故现在我们从间隔的角度，或者说是信心，因为这反映出该拟合对分类结果的“信心”很足。所以，“信心”是一个很好的指标，后面我们将使用函数间隔形式化这个指标。考虑其空间意义，就是两类被模型描述相差越远（注意不是实际两类差别，因为两类差别是客观不变的，这里的差别指两类离这分界模型距离），那么模型就是最好的。在svm，用到的就是间隔（或者说是信心）。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;函数间隔&quot;&gt;函数间隔&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;先给出定义，给定一个样本，它的函数间隔是：&lt;img src=&quot;http://img.blog.csdn.net/20150724151103540&quot; alt=&quot;&quot; /&gt;因此可知，如果要得到一个值尽可能大的函数间隔，当y为-1时，这时要求&lt;img src=&quot;http://img.blog.csdn.net/20150724151135069&quot; alt=&quot;&quot; /&gt;要尽可能的小于零，相反，如果y为1时，这时要求&lt;img src=&quot;http://img.blog.csdn.net/20150724151135069&quot; alt=&quot;&quot; /&gt;要尽可能的大于零。同时，在这里，我们也可以理解下面一个问题：&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;我们发现，最终最大间隔分类用的不是函数间隔，而是几何间隔，为什么呢？因为有一个性质导致其函数间隔不能有效的反映预测的可信度，就是在函数间隔成倍增加的时候，分类超平面并没有改变，也就不能用函数间隔的大小来衡量超平面是否合理。但也许，你也有如下问题:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;问：&lt;/strong&gt;为什么要成倍增加来看函数间隔?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;答：&lt;/strong&gt;因为这里是证明函数间隔不能用来作为依据，那么只要证明存在一种情况使得函数间隔变化结果却不变就可以了（注意用简单的二维的例子）。几何间隔就是点到直线的距离，高维就是上面的几何间隔，而函数间隔就是未标准化的几何间隔。&lt;/p&gt;

&lt;h2 id=&quot;几何间隔&quot;&gt;几何间隔&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20150724151517346&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;回到一开始讲间隔的时候，给出几何间隔的定义公式,定义A点的几何间隔为：&lt;img src=&quot;http://img.blog.csdn.net/20150724151725371&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;函数间隔和几何间隔的关系&quot;&gt;函数间隔和几何间隔的关系&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;函数间隔/&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;w&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;=几何间隔，函数间隔会随着w和b的缩放而缩放，但是对于算法的参数选取没有意义。几何间隔不会随着w和b的缩放而缩放。&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;高维就是上面的几何间隔，而函数间隔就是未标准化的几何间隔。&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;**问：&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;w&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;存在的意义是什么？**&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;将(w,b)变为(2w,2b)相当于给函数间隔乘了系数2，于是我们发现，如果通过改变w,b的取值，我们可以让函数间隔变得很大，然而分类超平面并没有改变，所以单纯的通过这种方式改变函数间隔的大小没有什么实质意义，应该引入一种标准化条件，比如令∥w∥=1（此时是垂直于超平面的单位向量）。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;我的理解，纯碎w，b改变，函数间隔改变了，但当纯碎w，b改变时，对于这里的g(z)来说，效果没有变化，故纯粹改变w，b时，不能用来作为确定更好参数的前提。函数间隔倍数增加无效，几何间隔加减变化有效，指倍数不能对正负改变但加减可以。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;table&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;看了几遍之后，终于理解，**这里的&lt;/td&gt;
        &lt;td&gt; &lt;/td&gt;
        &lt;td&gt;w&lt;/td&gt;
        &lt;td&gt; &lt;/td&gt;
        &lt;td&gt;要联想低维的点到直线的距离就好**，没有那么复杂，就是二维点到直线距离的除数而已&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;为什么在求解最优化的时候，函数间隔可以设为1？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;答：按比例缩放参数(w,b)对假设结果没有任何影响，我们现在可以利用这一点。我们现在来引入限制条件：对于给定的训练集，以(w,b)为参数的函数间隔必须为1，在这里，数值是什么关系的，这只是一种约束，通过数值等比例缩放得到。&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;也就是说函数间隔和最优解无关，因为函数间隔可以任意变化，但问题还是原来的问题&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;有关凸优化&quot;&gt;有关凸优化&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;因为下面会用到比较多凸优化，所以在这里先说下它的简单定义。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;简单的说，优化问题中，目标函数为凸函数，约束变量取值于一个凸集中的优化问题称为凸优化，举个简单例子，设S为凸集，f(x)为S上凸函数，则问题min f(x) s.t. x属于S。为一个凸优化。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;设S为n维空间中的一个点集，X1、X2为S中的任两点。若对于任给的t，0&amp;lt;=t&amp;lt;=1，点X=tX1+(1-t)X2也属于S，则称S为n维空间中的一个凸集。组合tX1+(1-t)X2称为X1和X2的凸组合。简单的说，若两点在一个点集中，那么连接这两点的线段上所有点也在这个点集中，这样的点集就称为凸集。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;svm分类&quot;&gt;svm分类&lt;/h2&gt;

&lt;p&gt;SVM包括：线性可分支持向量机、线性支持向量机、非线性支持向量机。其区分如下。&lt;/p&gt;

&lt;p&gt;线性可分支持向量机 ：要求硬间隔最大化，也叫硬间隔支持向量机。&lt;/p&gt;

&lt;p&gt;线性支持向量机 ：要求软间隔最大化，也叫软间隔支持向量机。&lt;/p&gt;

&lt;p&gt;非线性支持向量机    ：包含核函数的SVM。&lt;/p&gt;

&lt;p&gt;注：“线性支持向量机”中线性指的是最终的分割超平面是线性的，而不是指数据是线性可分的，于是这三种SVM也可以这样描述：&lt;/p&gt;

&lt;p&gt;线性可分支持向量机 ：数据线性可分，分割面为线性。&lt;/p&gt;

&lt;p&gt;线性支持向量机 ：数据线性不可分，分割面为线性。&lt;/p&gt;

&lt;p&gt;非线性支持向量机    ：数据无所谓，分割面不为线性。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;下面，我们就按照这样的顺序来讲解svm的有关内容。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;线性可分支持向量机&quot;&gt;线性可分支持向量机&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20160719115921950&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;也就是这样的情形，下面我们通过间隔最大化得到SVM的分隔超平面，然后进行分类&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/svm_a1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/svm_a2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/lagelangrei1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/svm_qiu1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/svm_qiu2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;线性支持向量机&quot;&gt;线性支持向量机&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20160719143206126&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;也就是这样的情形，下面我们对目标函数着损失函数进行稍加的修改。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/svm_b1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/svm_b2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;非线性支持向量机&quot;&gt;非线性支持向量机&lt;/h2&gt;

&lt;h2 id=&quot;核方法&quot;&gt;核方法&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;核方法的主要思想是基于这样一个假设：&lt;strong&gt;“在低维空间中不能线性分割的点集，通过转化为高维空间中的点集时，很有可能变为线性可分的”&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/kernel1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;mercer-定理&quot;&gt;Mercer 定理：&lt;/h2&gt;
&lt;p&gt;任何半正定的函数都可以作为核函数。所谓半正定的函数f(xi,xj)，是指拥有训练数据集合（x1,x2,…xn)，我们定义一个矩阵的元素aij = f(xi,xj)，这个矩阵式n*n的，如果这个矩阵是半正定的，那么f(xi,xj)就称为半正定的函数。（这个mercer定理不是核函数必要条件，只是一个充分条件，即还有不满足mercer定理的函数也可以是核函数。）–这个有待确定。常见的核函数有高斯核，多项式核等等，在这些常见核的基础上，通过核函数的性质（如对称性等）可以进一步构造出新的核函数。&lt;/p&gt;

&lt;h2 id=&quot;低维转高维要解决的问题&quot;&gt;低维转高维要解决的问题&lt;/h2&gt;
&lt;p&gt;一是由于是在高维度空间中计算，导致curse of dimension问题；二是非常的麻烦，每一个点都必须先转换到高维度空间，然后求取分割平面的参数等等，还有就是转化成高维通常是用一个函数映射，而映射之后的求解会变得艰难，不过在svm中内积的形式就给我们方便，也就是可以用内积的方式，用简单的计算，得到和高纬一样结果&lt;/p&gt;

&lt;h2 id=&quot;核方法和分类或者回归的问题&quot;&gt;核方法和分类（或者回归）的问题&lt;/h2&gt;
&lt;p&gt;“为什么我们要关心向量的内积？”，一般地，我们可以把分类（或者回归）的问题分为两类：参数学习的形式和基于实例的学习形式。参数学习的形式就是通过一堆训练数据，把相应模型的参数给学习出来，然后训练数据就没有用了，对于新的数据，用学习出来的参数即可以得到相应的结论；而基于实例的学习（又叫基于内存的学习）则是在预测的时候也会使用训练数据，如KNN算法。而&lt;strong&gt;基于实例的学习一般就需要判定两个点之间的相似程度&lt;/strong&gt;，一般就通过向量的内积来表达。从这里可以看出，核方法不是万能的，它一般只针对基于实例的学习。&lt;/p&gt;

&lt;h2 id=&quot;核方法的直观理解&quot;&gt;核方法的直观理解&lt;/h2&gt;
&lt;p&gt;能够直观（这种直观印象并非严格成立）的看出，如果向量ϕ(x)与ϕ(z)方向靠的比较近，那么根据K(x,z)=ϕ(x)Tϕ(z)可知这个值会比较大；反正，如果两个向量近乎正交（方向离的比较远），则K(x,z)=ϕ(x)Tϕ(z)将会很小。如此，我们就可以用K(x,z)度量ϕ(x)与ϕ(z)的相似度，或者x与z的相似度。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/kernel2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-to-select-svm-kernels&quot;&gt;How to select SVM kernels?&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;the linear kernel works fine if your dataset if linearly separable&lt;/li&gt;
  &lt;li&gt;the rule of thumb is: use linear SVMs (or logistic regression) for linear problems, and nonlinear kernels such as the Radial Basis Function kernel for non-linear problems.&lt;/li&gt;
  &lt;li&gt;it looks like both linear and RBF kernel SVM would work equally well on this dataset(linearly separable).but ，we should choose linear kernels.for the reason that Not only is it more expensive to train a RBF kernel SVM, but you also have to keep the kernel matrix around, and the projection into this “infinite” higher dimensional space were the data becomes linearly separable is more expensive as well during prediction&lt;/li&gt;
  &lt;li&gt;the polynomial kernel. In practice, it is less useful for efficiency (computational as well as predictive) performance reasons.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后，给出在非线性的情况下的svm解法！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/nonliner1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;坐标法求最优解&quot;&gt;坐标法求最优解&lt;/h2&gt;

&lt;p&gt;考虑解决无约束最优问题：
&lt;img src=&quot;http://images2015.cnblogs.com/blog/929166/201611/929166-20161114110147451-1360754235.png&quot; alt=&quot;&quot; /&gt;svm
现在，我们只将W看做关于αi的函数，与支持向量机无关。到目前为止我们已经了解了两种优化算法：梯度下降/上升法，牛顿法，这里我们再来介绍一种新的优化算法——坐标下降/上升法（coordinate descent/ascent algorithm）：
&lt;img src=&quot;http://images2015.cnblogs.com/blog/929166/201611/929166-20161114110331592-1707362330.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在算法里面一层循环中，我们会固定除αiαi以外的参数，然后重新优化这个关于αi的函数W。对上面的这个例子，里面的循环会按照α1,α2,⋯,αm,α1,α2,⋯的顺序进行优化。（对一些复杂的问题可能会使用别的顺序，比如，我们可以看哪个参数会带来W(α)最大幅度的增长，就选择哪个参数作为下一个优化的对象。）&lt;/p&gt;

&lt;p&gt;而当函数W恰好符合里面一层循环可以高效运行的状态时（事实上有很多优化问题很容易固定其他参数只对一个参数求最优值，在这种情况下本算法的内层循环将会执行的非常快。而支持向量机通常也属于这种情况），坐标下降/上升法确实是一个效率很高的算法，如图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://nbviewer.jupyter.org/github/zlotus/notes-LSJU-machine-learning/blob/master/resource/chapter08_image03.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;很多小伙伴看到这里其实还是有点疑惑的，感觉这样的方法一定能够求得最优解吗？我当时也有这样的疑惑，没关系，那再来看下下面的数学图像讲解：&lt;/p&gt;

&lt;h2 id=&quot;二元偏导数的几何意义&quot;&gt;二元偏导数的几何意义&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://h.hiphotos.baidu.com/zhidao/wh%3D600%2C800/sign=b1b9945ab8389b5038aae854b505c9e5/0df3d7ca7bcb0a467577057d6a63f6246b60af19.jpg&quot; alt=&quot;&quot; /&gt;
比如一个椭球面,它有无数个点,有其中一点（a,b,c） 函数对x的偏导数 就是 阴影椭圆形的线框（平行于x0z面）,再建立坐标x‘0z’,仅考虑该坐标的话  有函数z=f（x）  f’（x）是z=f（x）的导数（也是斜率）同时也等于球面函数在（a,b,c）点对于x的偏导&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;问：&lt;/strong&gt;所以到底怎么理解坐标下降/上升法？
&lt;strong&gt;答：&lt;/strong&gt;我们可以看上图，一开始我们确定(a,b,c然后对x求偏导数，这个时候y是固定的，然后再对y求偏导数，这个时候x是固定的)，稍微想象一下就会发现最后我们是会到达局部最大/小点的！&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/google19890102/article/details/51065297&quot;&gt;坐标上升&lt;/a&gt;，这个博客唯一可能会误导的是，首先要确定初始的点，而博客中没有&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;梯度下降和坐标下降的区别&quot;&gt;梯度下降和坐标下降的区别&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;梯度下降法又称为最速下降法，他也是下降法，不过和坐标下降法的主要区别就是多了一个下降方向的选取，在坐标下降中下降方向是沿着每一维的坐标轴方向进行的，也就是方向是类似于（0,0,1,0,0）、（0,0,0,1,0）（假设是5维）这种形式的，而梯度下降法中，下降方向变换为函数在当前点的梯度方向，当维度很高时，梯度下降的优势就要比坐标下降明显很多。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;序列最小优化算法smo-sequential-minimal-optimization&quot;&gt;序列最小优化算法（SMO: sequential minimal optimization）&lt;/h2&gt;

&lt;p&gt;讲完上面一般的坐标法求解之后，下面我们来讲解在SVM的坐标法求解！&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SMO（sequential minimal optimization）算法起源于SVM, John Platt起初了一个高效解决对偶问题的方法.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/mysom2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后，它的具体算法步骤如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/my_som.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;最后推荐博文时间：&lt;a href=&quot;http://blog.csdn.net/v_july_v/article/details/7624837&quot;&gt;SVM较好的博文&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!-- 多说评论框 start --&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;2017032501&quot; data-title=&quot; svm&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Sat, 25 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>《Deep Learning》-cnn and rnn</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#deep-learning-cnn-and-rnn&quot; id=&quot;markdown-toc-deep-learning-cnn-and-rnn&quot;&gt;《Deep Learning》-cnn and rnn&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#motivation-of-cnn&quot; id=&quot;markdown-toc-motivation-of-cnn&quot;&gt;Motivation of CNN&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#advantage-of-sparse-interactions&quot; id=&quot;markdown-toc-advantage-of-sparse-interactions&quot;&gt;advantage of sparse interactions:&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#what-is-the-equivariant-representations&quot; id=&quot;markdown-toc-what-is-the-equivariant-representations&quot;&gt;what is the equivariant representations&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;deep-learning-cnn-and-rnn&quot;&gt;《Deep Learning》-cnn and rnn&lt;/h1&gt;

&lt;h2 id=&quot;motivation-of-cnn&quot;&gt;Motivation of CNN&lt;/h2&gt;
&lt;p&gt;Convolution leverages three important ideas that can help improve a machinelearning system: &lt;strong&gt;sparse interactions , parameter sharing and equivariant representations.&lt;/strong&gt; Moreover, convolution provides a means for working with inputs of variable size&lt;/p&gt;

&lt;h4 id=&quot;advantage-of-sparse-interactions&quot;&gt;advantage of sparse interactions:&lt;/h4&gt;

&lt;p&gt;This means that we need to store fewer parameters, which both reduces the memory requirements of the model and improves its statistical efficiency. It also means that computing the output requires fewer operations. These improvements in efficiency are usually quite large.&lt;/p&gt;

&lt;p&gt;For example, when processing images, it is useful to detect edges in the first layer of a convolutional network. The same edges appear more or less everywhere in the image, so it is practical to share parameters across the entire image.&lt;/p&gt;

&lt;h3 id=&quot;what-is-the-equivariant-representations&quot;&gt;what is the equivariant representations&lt;/h3&gt;

&lt;p&gt;In the case of convolution, the particular form of parameter sharing causes the layer to have a property called &lt;strong&gt;equivariance to translation.&lt;/strong&gt; To say a function is equivariant means that if the input changes, the output changes in the same way. Specifically, &lt;strong&gt;a function f(x) is equivariant to a function g if f (g(x)) = g(f(x))&lt;/strong&gt;.In the case of convolution, if we let g be any function that translates the input, i.e., shifts it, then the convolution function is equivariant to g. For example, let I be a function giving image brightness at integer coordinates. Let g be a function mapping one image function to another image function,** such that I’= g(I) is the image function with I’ (x, y) = I( x − 1, y). This shifts every pixel of I one unit to the right. If we apply this transformation to I , then apply convolution, the result will be the same as if we applied convolution to I’ , then applied the transformation g to the output&lt;strong&gt;. When processing time series data, this means that convolution produces a sort of timeline that shows when different features appear in the input. If we move an event later in time in the input, the exact same representation of it will appear in the output, just later in time. **Similarly with images, convolution creates a 2-D map of where certain features appear in the input. If we move the object in the input, its representation will move the same amount in the output.&lt;/strong&gt; This is useful for when we know that some function of a small number of neighboring pixels is useful when applied to multiple input locations. For example, when processing images, it is useful to detect edges in the first layer of a convolutional network. &lt;strong&gt;The same edges appear more or less everywhere in the image, so it is practical to share parameters across the entire image.&lt;/strong&gt; In some cases, we may not wish to share parameters across the entire image. For example, if we are processing images that are cropped to be centered on an individual’s face, we probably want to extract different features at different locations—the part of the network processing the top of the face needs to look for eyebrows, while the part of the network processing the bottom of the face needs to look for a chin.&lt;/p&gt;

&lt;p&gt;Convolution is not naturally equivariant to some other transformations, such as changes in the scale or rotation of an image. Other mechanisms are necessary for handling these kinds of transformations.&lt;/p&gt;

&lt;p&gt;Finally, some kinds of data cannot be processed by neural networks defined by matrix multiplication with a fixed-shape matrix. Convolution enables processing of some of these kinds of data&lt;/p&gt;
</description>
        <pubDate>Fri, 24 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/24/Deep-Learning-cnn-and-rnn.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/24/Deep-Learning-cnn-and-rnn.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>《Deep Learning》-Deep Feedforward Networks</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#deep-learning-deep-feedforward-networks&quot; id=&quot;markdown-toc-deep-learning-deep-feedforward-networks&quot;&gt;《Deep Learning》-Deep Feedforward Networks&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#feedforward-neural-networks&quot; id=&quot;markdown-toc-feedforward-neural-networks&quot;&gt;Feedforward neural networks&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#linear-models-and-nonlinear-functions&quot; id=&quot;markdown-toc-linear-models-and-nonlinear-functions&quot;&gt;linear models and nonlinear functions&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#how-to-choose-the-mapping-φkernel&quot; id=&quot;markdown-toc-how-to-choose-the-mapping-φkernel&quot;&gt;how to choose the mapping φ(kernel)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#activation-function&quot; id=&quot;markdown-toc-activation-function&quot;&gt;activation function&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cost-functions&quot; id=&quot;markdown-toc-cost-functions&quot;&gt;Cost Functions&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#regularization&quot; id=&quot;markdown-toc-regularization&quot;&gt;Regularization&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#why-we-do-not-need-to-leaves-the-biases-regularized&quot; id=&quot;markdown-toc-why-we-do-not-need-to-leaves-the-biases-regularized&quot;&gt;why we do not need to leaves the biases regularized&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#the-sigmoid-function-use-as-output-units&quot; id=&quot;markdown-toc-the-sigmoid-function-use-as-output-units&quot;&gt;the sigmoid function use as output units&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#architecture-design&quot; id=&quot;markdown-toc-architecture-design&quot;&gt;Architecture Design&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#multi-task-learning&quot; id=&quot;markdown-toc-multi-task-learning&quot;&gt;Multi-Task Learning&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#linear-model&quot; id=&quot;markdown-toc-linear-model&quot;&gt;linear model&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#deeper-is-better&quot; id=&quot;markdown-toc-deeper-is-better&quot;&gt;deeper is better&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;deep-learning-deep-feedforward-networks&quot;&gt;《Deep Learning》-Deep Feedforward Networks&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;from now on,I will write my blog of the book(deep learning)  in English,I am sorry that my English is so poor,but ,i will try my best&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;feedforward-neural-networks&quot;&gt;Feedforward neural networks&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Feedforward neural networks are called networks because they are typically represented by composing together many different functions.&lt;/li&gt;
  &lt;li&gt;these networks are called neural because they are loosely inspired by neuroscience.&lt;/li&gt;
  &lt;li&gt;There are no feedback connections in which outputs of the model are fed back into itself. When feedforward neural networks are extended to include feedback connections, they are called recurrent neural networks&lt;/li&gt;
  &lt;li&gt;It is best to think of feedforward networks as function approximation machines that are designed to achieve statistical generalization, occasionally drawing some insights from what we know about the brain, rather than as models of brain function&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;linear-models-and-nonlinear-functions&quot;&gt;linear models and nonlinear functions&lt;/h2&gt;

&lt;p&gt;To extend linear models to represent nonlinear functions of x, we can apply the linear model not to x itself but to a transformed input φ(x), where φ is a nonlinear transformation. Equivalently, we can apply the kernel trick described in Sec. 5.7.2 , to obtain a nonlinear learning algorithm based on implicitly applying the φ mapping. We can think of φ as providing a set of features describing x, or as providing a new representation for x .&lt;/p&gt;

&lt;h2 id=&quot;how-to-choose-the-mapping-φkernel&quot;&gt;how to choose the mapping φ(kernel)&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;One option is to use a very generic φ, such as the infinite-dimensional φ that is implicitly used by kernel machines based on the RBF kernel. If φ(x) is of high enough dimension, we can always have &lt;strong&gt;enough capacity to fit the training set(advantage)&lt;/strong&gt;, but &lt;strong&gt;generalization to the test set often remains poor(disadvange,by overfitting)&lt;/strong&gt;. Very generic feature mappings are usually based only on the principle of local smoothness and do not encode enough prior information to solve advanced problems.&lt;/li&gt;
  &lt;li&gt;Another option is to manually engineer φ . Until the advent of deep learning, this was the dominant approach. This approach requires decades of human effort for each separate task, with practitioners specializing in different domains such as speech recognition or computer vision, and with little transfer between domains.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/nonlinear.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;activation-function&quot;&gt;activation function&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;q：Why we need activation function？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;a:
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/activation function.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;q:Why ReLU is the default activation function recommended for use with most feedforward neural networks.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;a：
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/ReLU1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;cost-functions&quot;&gt;Cost Functions&lt;/h2&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;mean squared error and mean absolute error often lead to poor results when used with gradient-based optimization. Some output units that saturate produce very small gradients when combined with these cost functions. This is one reason that the cross-entropy cost function is more popular than mean squared error or mean absolute error, even when it is not necessary to estimate an entire distribution p( y&lt;/td&gt;
      &lt;td&gt;x ) .&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;regularization&quot;&gt;Regularization&lt;/h2&gt;

&lt;p&gt;Regularization of an estimator works by trading increased bias for reduced variance.&lt;/p&gt;

&lt;h3 id=&quot;why-we-do-not-need-to-leaves-the-biases-regularized&quot;&gt;why we do not need to leaves the biases regularized&lt;/h3&gt;

&lt;p&gt;Before delving into the regularization behavior of different norms, we note that for neural networks, we typically choose to use a parameter norm penalty Ω that penalizes only the weights of the affine transformation at each layer and leaves the biases unregularized. The biases typically require less data to fit accurately than the weights. &lt;strong&gt;Each weight specifies how two variables interact. Fitting the weight well requires observing both variables in a variety of conditions. Each bias controls only a single variable. This means that we do not induce too much variance by leaving the biases unregularized. Also, regularizing the bias parameters can introduce a significant amount of underfitting.&lt;/strong&gt; We therefore use the vector &lt;strong&gt;w&lt;/strong&gt; to indicate all of the weights that should be affected by a norm penalty, while the vector &lt;strong&gt;θ&lt;/strong&gt; denotes all of the parameters, including both w and the unregularized parameters.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;也就是说，拟合权值w，是两个变量的交互，需要适应各种情况，而偏置不直接和输入数据相乘,它并不&lt;strong&gt;直接影响某一维度的数据&lt;/strong&gt;,因此常常不用对偏置正则化&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-sigmoid-function-use-as-output-units&quot;&gt;the sigmoid function use as output units&lt;/h2&gt;

&lt;p&gt;Their use as output units is compatible with the use of gradient-based learning when an appropriate cost function can undo the saturation of the sigmoid in the output layer.&lt;/p&gt;

&lt;h2 id=&quot;architecture-design&quot;&gt;Architecture Design&lt;/h2&gt;

&lt;p&gt;In these chain-based architectures, the main architectural considerations are to choose the depth of the network and the width of each layer. As we will see,a network with even one hidden layer is sufficient to fit the training set. Deeper networks often are able to use far fewer units per layer and far fewer parameters and often generalize to the test set, but are also often harder to optimize. The ideal network architecture for a task must be found via experimentation guided by monitoring the validation set error.&lt;/p&gt;

&lt;h3 id=&quot;multi-task-learning&quot;&gt;Multi-Task Learning&lt;/h3&gt;

&lt;p&gt;Multi-task learning ( Caruana , 1993 ) is a way to improve generalization by pooling the examples (which can be seen as soft constraints imposed on the parameters) arising out of several tasks. In the same way that additional training examples put more pressure on the parameters of the model towards values that generaliz well, when part of a model is shared across tasks, that part of the model is more constrained towards good values (assuming the sharing is justified), often yielding better generalization.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/mutitask.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;linear-model&quot;&gt;linear model&lt;/h3&gt;

&lt;p&gt;A linear model, mapping from features to outputs via matrix multiplication, canby definition represent only linear functions. It has the advantage of being easy to train because many loss functions result in convex optimization problems when applied to linear models. Unfortunately, we often want to learn nonlinear functions.&lt;/p&gt;

&lt;h2 id=&quot;deeper-is-better&quot;&gt;deeper is better&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/webwxgetmsgimg.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;a feedforward network with a single layer is sufficient to represent any function, but the layer may be infeasibly large and may fail to learn and generalize correctly. In many circumstances, using deeper models can reduce the number of units required to represent the desired function and can reduce the amount of generalization error&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;2017032401&quot; data-title=&quot; 《Deep Learning》-Deep Feedforward Networks&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Fri, 24 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/24/Deep-Learning-Deep-Feedforward-Networks.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/24/Deep-Learning-Deep-Feedforward-Networks.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>《Deep Learning》-Machine Learning Basics</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#deep-learning-machine-learning-basics&quot; id=&quot;markdown-toc-deep-learning-machine-learning-basics&quot;&gt;《Deep Learning》-Machine Learning Basics&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#kinds-of-machine-learning&quot; id=&quot;markdown-toc-kinds-of-machine-learning&quot;&gt;kinds of machine Learning&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bais&quot; id=&quot;markdown-toc-bais&quot;&gt;bais&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#manifold-learning&quot; id=&quot;markdown-toc-manifold-learning&quot;&gt;Manifold Learning&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#流形学习的基本概念&quot; id=&quot;markdown-toc-流形学习的基本概念&quot;&gt;流形学习的基本概念&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;deep-learning-machine-learning-basics&quot;&gt;《Deep Learning》-Machine Learning Basics&lt;/h1&gt;

&lt;h2 id=&quot;kinds-of-machine-learning&quot;&gt;kinds of machine Learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/deep-learning1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/deep-learning2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;bais&quot;&gt;bais&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Bias.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;manifold-learning&quot;&gt;Manifold Learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Manifold1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Manifold2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Manifold3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Manifold4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;　　假设数据是均匀采样于一个高维欧氏空间中的低维流形，流形学习就是从高维采样数据中恢复低维流形结构，即找到高维空间中的低维流形，并求出相应的嵌入映射，以实现维数约简或者数据可视化。它是从观测到的现象中去寻找事物的本质，找到产生数据的内在规律。流形学习方法是模式识别中的基本方法，分为线性流形学习算法和非线性流形学习算法，线性方法就是传统的方法如主成分分析（PCA）和线性判别分析（LDA），非线行流形学习算法包括等距映射（Isomap），拉普拉斯特征映射（LE）等&lt;/p&gt;

&lt;p&gt;流形学习是个很广泛的概念。这里我主要谈的是自从2000年以后形成的流形学习概念和其主要代表方法。自从2000年以后，流形学习被认为属于非线性降维的一个分支。众所周知，引导这一领域迅速发展的是2000年Science杂志上的两篇文章: Isomap and LLE (Locally Linear Embedding)。&lt;/p&gt;

&lt;h3 id=&quot;流形学习的基本概念&quot;&gt;流形学习的基本概念&lt;/h3&gt;

&lt;p&gt;那流形学习是什莫呢？为了好懂，我尽可能应用少的数学概念来解释这个东西。所谓流形（manifold）就是一般的几何对象的总称。比如人，有中国人、美国人等等；流形就包括各种维数的曲线曲面等。和一般的降维分析一样，流形学习把一组在高维空间中的数据在低维空间中重新表示。和以往方法不同的是，在流形学习中有一个假设，就是所处理的数据采样于一个潜在的流形上，或是说对于这组数据存在一个潜在的流形。对于不同的方法，对于流形性质的要求各不相同，这也就产生了在流形假设下的各种不同性质的假设，比如在Laplacian Eigenmaps中要假设这个流形是紧致黎曼流形等。对于描述流形上的点，我们要用坐标，而流形上本身是没有坐标的，所以为了表示流形上的点，必须把流形放入外围空间（ambient space）中，那末流形上的点就可以用外围空间的坐标来表示。比如R^3中的球面是个2维的曲面，因为球面上只有两个自由度，但是球面上的点一般是用外围R^3空间中的坐标表示的，所以我们看到的R^3中球面上的点有3个数来表示的。当然球面还有柱坐标球坐标等表示。对于R^3中的球面来说，那末流形学习可以粗略的概括为给出R^3中的表示，在保持球面上点某些几何性质的条件下，找出找到一组对应的内蕴坐标（intrinsic coordinate）表示，显然这个表示应该是两维的，因为球面的维数是两维的。这个过程也叫参数化（parameterization）。直观上来说，就是把这个球面尽量好的展开在通过原点的平面上。在PAMI中，这样的低维表示也叫内蕴特征（intrinsic feature）。一般外围空间的维数也叫观察维数，其表示也叫自然坐标（外围空间是欧式空间）表示,在统计中一般叫observation。&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;2017032301&quot; data-title=&quot; 《Deep Learning》-Machine Learning Basics&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Thu, 23 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/23/Deep-Learning-Machine-Learning-Basics.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/23/Deep-Learning-Machine-Learning-Basics.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Cs224d_state of the art</title>
        <description>&lt;h1 id=&quot;cs224d-cnnstate-of-the-art&quot;&gt;cs224d-cnn,state of the art&lt;/h1&gt;

&lt;h2 id=&quot;cnn&quot;&gt;cnn&lt;/h2&gt;

&lt;p&gt;在这个convolution 横流的年代，cv领域大放异彩，在nlp这里也不例外，下面记下cnn的自己和主要slides！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Gradient_Checks1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 19 Mar 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/03/19/cs224d_state-of-the-art.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/03/19/cs224d_state-of-the-art.html</guid>
        
        
      </item>
    
      <item>
        <title>convolution neural network</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#convolution-neural-network&quot; id=&quot;markdown-toc-convolution-neural-network&quot;&gt;convolution neural network&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#四类解决方案解决图片的不变性from-prml&quot; id=&quot;markdown-toc-四类解决方案解决图片的不变性from-prml&quot;&gt;四类解决方案解决图片的不变性（from PRML）&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#background-for-cnn&quot; id=&quot;markdown-toc-background-for-cnn&quot;&gt;BackGround for cnn&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#简介&quot; id=&quot;markdown-toc-简介&quot;&gt;简介&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#卷积层&quot; id=&quot;markdown-toc-卷积层&quot;&gt;卷积层&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#卷积计算&quot; id=&quot;markdown-toc-卷积计算&quot;&gt;卷积计算&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#局部链接&quot; id=&quot;markdown-toc-局部链接&quot;&gt;局部链接&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#参数共享&quot; id=&quot;markdown-toc-参数共享&quot;&gt;参数共享&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#多卷积核&quot; id=&quot;markdown-toc-多卷积核&quot;&gt;多卷积核&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#一些卷积层的tricktip&quot; id=&quot;markdown-toc-一些卷积层的tricktip&quot;&gt;一些卷积层的trick&amp;amp;tip&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1-我们倾向于选择多层小size的卷积层而不是一个大size的卷积层&quot; id=&quot;markdown-toc-1-我们倾向于选择多层小size的卷积层而不是一个大size的卷积层&quot;&gt;1. 我们倾向于选择多层小size的卷积层，而不是一个大size的卷积层。&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#11的卷积大概有两个方面的作用&quot; id=&quot;markdown-toc-11的卷积大概有两个方面的作用&quot;&gt;1×1的卷积大概有两个方面的作用&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#汇聚层&quot; id=&quot;markdown-toc-汇聚层&quot;&gt;汇聚层&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#max-pooling&quot; id=&quot;markdown-toc-max-pooling&quot;&gt;Max Pooling&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#average-pooling&quot; id=&quot;markdown-toc-average-pooling&quot;&gt;Average Pooling&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#归一化层&quot; id=&quot;markdown-toc-归一化层&quot;&gt;归一化层&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#output&quot; id=&quot;markdown-toc-output&quot;&gt;OutPut&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#inception&quot; id=&quot;markdown-toc-inception&quot;&gt;Inception&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#ＣＮＮ-的结构&quot; id=&quot;markdown-toc-ＣＮＮ-的结构&quot;&gt;ＣＮＮ 的结构&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#参考链接&quot; id=&quot;markdown-toc-参考链接&quot;&gt;参考链接&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;convolution-neural-network&quot;&gt;convolution neural network&lt;/h2&gt;

&lt;p&gt;深度学习可以说从2006年的泛起火花，在2012点开始爆发，而原因就是在ImageNet这个比赛上cnn的异常突出，在之后的好几年，冠军或者说前三基本上都是在cnn上做文章，有关cnn在ImageNet的论文很值得一读，我也大体看了下，并写了&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/02/24/paper-ImageNet.html&quot;&gt;一篇笔记&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;卷积神经网络和上一章讲的常规神经网络非常相似：它们都是由神经元组成，神经元中有具有学习能力的权重和偏差。每个神经元都得到一些输入数据，进行内积运算后再进行激活函数运算。&lt;/p&gt;

&lt;h2 id=&quot;四类解决方案解决图片的不变性from-prml&quot;&gt;四类解决方案解决图片的不变性（from PRML）&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;我们知道，在很多图片中，比如都存在一只猫，但那只猫的姿态或者形态是非常不同的，在我们人类看来这没什么，很容易知道它都是一只猫，但是，在计算机看来，就没有那么简单了，关于这种图片内容的不变性，我们可以有如下的方法来解决！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Data Augmentation：用神经网络生成多种变化&lt;/p&gt;

&lt;p&gt;Tangent Propagation：用正则项的方式，用一个函数&lt;/p&gt;

&lt;p&gt;Invariant feature：用一些特征用来做不变性&lt;/p&gt;

&lt;p&gt;Neural Network structure with invariant properties (e.g. CNN)：用一些特征结构，比如cnn
开头&lt;/p&gt;

&lt;h3 id=&quot;background-for-cnn&quot;&gt;BackGround for cnn&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;人眼在识别图像时，往往从局部到全局&lt;/li&gt;
  &lt;li&gt;局部与局部之间联系往往不太紧密&lt;/li&gt;
  &lt;li&gt;我们不需要神经网络中的每个结点都掌握全局的知识，因此可以从这里减少需要学习的参数数量&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;卷积神经网络主要由三种类型的层构成：&lt;strong&gt;卷积层，汇聚（Pooling）层和全连接层（全连接层和常规神经网络中的一样）&lt;/strong&gt;。通过将这些层叠加起来，就可以构建一个完整的卷积神经网络。&lt;/li&gt;
  &lt;li&gt;有的层有参数，有的没有（卷积层和全连接层有，ReLU层和汇聚层没有）。&lt;/li&gt;
  &lt;li&gt;有的层有额外的超参数，有的没有（卷积层、全连接层和汇聚层有，ReLU层没有）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面是一个cnn神经网络结构的例子：
&lt;img src=&quot;https://pic3.zhimg.com/d9259be829b1cdb3d98a399ebc56defa_b.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面以层到层的顺序来讲解cnn：&lt;/p&gt;

&lt;h2 id=&quot;卷积层&quot;&gt;卷积层&lt;/h2&gt;

&lt;p&gt;注意，一下讨论的前提是你熟悉了传统ANN的网络结构和一般知识，不明白的可以先看下我前面的博文，&lt;a href=&quot;https://yzhihao.github.io/2017/03/13/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html&quot;&gt;神经网络（基本概念）&lt;/a&gt;，还有开头这篇&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/03/12/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-BP%E5%92%8C%E5%AF%BB%E6%89%BE%E6%9C%80%E4%BC%98%E5%8C%96.html&quot;&gt;神经网络-BP，更新参数策略&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;卷积计算&quot;&gt;卷积计算&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;其实，深度神经网络就是隐含层的数量较多，导致参数增多多，而我们可以理解卷积层存在的重要意义&lt;strong&gt;就是减少参数的数量。&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;首先讨论的是，在没有大脑和生物意义上的神经元之类的比喻下，卷积层到底在计算什么。卷积层的参数是有一些可学习的滤波器集合构成的。每个滤波器(fiter)在空间上（宽度和高度）都比较小，但是&lt;strong&gt;深度和输入数据一致&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在深度一致的时候，&lt;code class=&quot;highlighter-rouge&quot;&gt;n*n&lt;/code&gt;的fiter对&lt;code class=&quot;highlighter-rouge&quot;&gt;m*m&lt;/code&gt;的图片做卷积运算的话，就会产生&lt;code class=&quot;highlighter-rouge&quot;&gt;（m-n）/1+1&lt;/code&gt;（注意那个除以1是步长，在这里步长是1，当然也可以设置成其他的值，除不尽的情况是在外围加上几层，使得可以整除）的新的生成层，所以最重要的就是能整除&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;举个例子：
 假设输入数据体尺寸为[32x32x3]（比如CIFAR-10的RGB图像），如果感受野（或滤波器尺寸）是5x5，那么卷积层中的每个神经元会有输入数据体中[5x5x3]区域的权重，共5x5x3=75个权重（还要加一个偏差参数）。注意这个连接在深度维度上的大小必须为3，和输入数据体的深度一致。但这样有什么用呢？请看下面：&lt;/p&gt;

&lt;h3 id=&quot;局部链接&quot;&gt;局部链接&lt;/h3&gt;

&lt;p&gt;左图为全连接，右图为局部连接：
&lt;img src=&quot;https://raw.githubusercontent.com/stdcoutzyx/Paper_Read/master/blogs/imgs/5.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在上右图中，假如每个神经元只和10×10个像素值相连，那么权值数据为1000000×100个参数，减少为原来的万分之一。而那10×10个像素值对应的10×10个参数，其实就相当于卷积操作。所以，这样做的目的就是大大的减少了参数的数量。&lt;/p&gt;

&lt;h3 id=&quot;参数共享&quot;&gt;参数共享&lt;/h3&gt;

&lt;p&gt;参数共享的原因:&lt;/p&gt;

&lt;p&gt;如果在&lt;strong&gt;图像某些地方探测到一个水平的边界是很重要的，那么在其他一些地方也会同样是有用的，这是因为图像结构具有平移不变性。&lt;/strong&gt;所以在卷积层的输出数据体的55x55个不同位置中，就没有必要重新学习去探测一个水平边界了。也就是说如果说一个卷积核在图片的一小块儿区域可以得到很好的特征，那么在其他的地方，也可以得到很好的特征。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;理解图像的平移不变性，就是我们可以反过来看，把fiter的平移提取，看成是图片的相对平移，而用fiter去提取突出的特征。但需要注意的是，&lt;strong&gt;一个fiter就提取一种特征，所以会有下面的多卷积核&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;真实案例：Krizhevsky构架赢得了2012年的ImageNet挑战，其输入图像的尺寸是[227x227x3]。在第一个卷积层，神经元使用的感受野尺寸，步长，不使用零填充。因为(227-11)/4+1=55，卷积层的深度，则卷积层的输出数据体尺寸为[55x55x96]。55x55x96个神经元中，每个都和输入数据体中一个尺寸为[11x11x3]的区域全连接。在深度列上的96个神经元都是与输入数据体中同一个[11x11x3]区域连接，但是权重不同。有一个有趣的细节，在原论文中，说的输入图像尺寸是224x224，这是肯定错误的，因为(224-11)/4+1的结果不是整数。这件事在卷积神经网络的历史上让很多人迷惑，而这个错误到底是怎么发生的没人知道。我的猜测是Alex忘记在论文中指出自己使用了尺寸为3的额外的零填充。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在卷积层中使用参数共享是用来控制参数的数量。就用上面的例子，在第一个卷积层就有55x55x96=290,400个神经元，每个有11x11x3=364个参数和1个偏差。将这些合起来就是290400x364=105,705,600个参数。单单第一层就有这么多参数，显然这个数目是非常大的。&lt;/li&gt;
  &lt;li&gt;在一个深度切片中，每个滤波器都被55x55个神经元共享。注意参数共享的假设是有道理的：如果在图像某些地方探测到一个水平的边界是很重要的，那么在其他一些地方也会同样是有用的，这是因为图像结构具有平移不变性。共有96x11x11x3=34,848个不同的权重，或34,944个参数（+96个偏差）&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;相对全连接传统神经网络，&lt;strong&gt;ｃｎｎ的参数较少的原理就是参数共享和局部连接&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;注意:&lt;/strong&gt;如果在一个深度切片中的所有权重都使用同一个权重向量，那么卷积层的前向传播在每个深度切片中可以看做是在计算神经元权重和输入数据体的卷积（这就是“卷积层”名字由来）。这也是为什么总是将这些权重集合称为滤波器（filter）（或卷积核（kernel）），因为它们和输入进行了卷积！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;多卷积核&quot;&gt;多卷积核&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;可以认为多个卷积和就是在提取不同的方面的特征！&lt;/li&gt;
  &lt;li&gt;上面所述只有100个参数时，表明只有1个10*10的卷积核，显然，特征提取是不充分的，我们可以添加多个卷积核，比如32个卷积核，可以学习32种特征。在有多个卷积核时，如下图所示：
&lt;img src=&quot;https://raw.githubusercontent.com/stdcoutzyx/Paper_Read/master/blogs/imgs/7.jpg&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/conv2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;注意，这里是只有两个filter，也就是说和深度无关，一个filter提取一种特征&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;关于卷积层的讲解，当然其他也讲的很好，大家可以看下cs231n课程中的笔记，特别是那个gif图片，讲两个卷积核详细的卷积运算过程，&lt;a href=&quot;https://cs231n.github.io/convolutional-networks/#conv&quot;&gt;英文版&lt;/a&gt;;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit&quot;&gt;中文翻译&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;一些卷积层的tricktip&quot;&gt;一些卷积层的trick&amp;amp;tip&lt;/h2&gt;

&lt;p&gt;如下：&lt;/p&gt;

&lt;h3 id=&quot;1-我们倾向于选择多层小size的卷积层而不是一个大size的卷积层&quot;&gt;1. 我们倾向于选择多层小size的卷积层，而不是一个大size的卷积层。&lt;/h3&gt;
&lt;p&gt;现在，我们以3个3x3的卷积层和1个7x7的卷积层为例，加以对比说明。从下图可以看出，这两种方法最终得到的activation map大小是一致的，但3个3x3的卷积层明显更好：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1)、3层的非线性组合要比1层线性组合提取出的特征具备更高的表达能力；
2)、3层小size的卷积层的参数数量要少，3x3x3&amp;lt;7x7；
3)、同样的，为了便于反向传播时的梯度计算，我们需要保留很多中间梯度，3层小size的卷积层需要保留的中间梯度更少。 ![](http://upload-images.jianshu.io/upload_images/2301760-f4dac7749cd64ada.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;11的卷积大概有两个方面的作用&quot;&gt;1×1的卷积大概有两个方面的作用&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;实现跨通道的交互和信息整合(NIN)&lt;/li&gt;
  &lt;li&gt;进行卷积核通道数的降维和升维(Residual network,google net)&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;这个详见&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/02/24/paper-ImageNet.html&quot;&gt;ImageNet Evolution&lt;/a&gt;中的为什么可以是1×1卷积&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;汇聚层&quot;&gt;汇聚层&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;在连续的卷积层之间会周期性地插入一个汇聚层。它的作用是逐渐降低数据体的空间尺寸，这样的话就能减少网络中参数的数量，&lt;strong&gt;使得计算资源耗费变少，也能有效控制过拟合，提取重要特征，符合不变性&lt;/strong&gt;。汇聚层使用MAX操作，对输入数据体的每一个深度切片独立进行操作，改变它的空间尺寸。最常见的形式是汇聚层使用尺寸2x2的滤波器，以步长为2来对每个深度切片进行降采样，将其中75%的激活信息都丢掉。每个MAX操作是从4个数字中取最大值（也就是在深度切片中某个2x2的区域）。深度保持不变。&lt;/li&gt;
  &lt;li&gt;一般是&lt;code class=&quot;highlighter-rouge&quot;&gt;2*2&lt;/code&gt;或者&lt;code class=&quot;highlighter-rouge&quot;&gt;3*3&lt;/code&gt;，计算公式和卷积层的差不多&lt;/li&gt;
  &lt;li&gt;在池化单元内部能够具有平移的不变性，它的平移范围也是有一定范围的，因为每个池化单元都是连续的，所以能够保证图像整体上发生了平移一样能提取特征进行匹配。一般来说，都是用max或者是average，而max还是average都是在提取区域特征，均相当于一种抽象，抽象就是过滤掉了不必要的信息（当然也会损失信息细节），所以在抽象层次上可以进行更好的识别。至于max与average效果是否一样，还是要看需要识别的图像细节特征情况，这个不一定的，不过据说差异不会超过2%。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;max-pooling&quot;&gt;Max Pooling&lt;/h3&gt;

&lt;p&gt;在一个卷积层的输出层上取一个切片，取其中最大值代表这个切片&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;优点
    &lt;ul&gt;
      &lt;li&gt;不增加需要调整的参数&lt;/li&gt;
      &lt;li&gt;通常比其他方法准确&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;缺点：更多Hyper Parameter，包括要取最值的切片大小，以及去切片的步长&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;average-pooling&quot;&gt;Average Pooling&lt;/h3&gt;
&lt;p&gt;在卷积层输出中，取切片，取平均值代表这个切片&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;有些人认为池化层并不是必要的，此外，有人发现&lt;strong&gt;去除池化层对于生成式模型（generative models）很重要，&lt;/strong&gt;例如variational autoencoders(VAEs)，generative adversarial networks(GANs)。可能在以后的模型结构中，池化层会逐渐减少或者消失。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/CCCPceng.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;归一化层&quot;&gt;归一化层&lt;/h2&gt;

&lt;p&gt;在卷积神经网络的结构中，提出了很多不同类型的归一化层，有时候是为了&lt;strong&gt;实现在生物大脑中观测到的抑制机制。&lt;/strong&gt;比如在AlexNet 中的&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/02/24/paper-ImageNet.html&quot;&gt;Local Response Nomalization&lt;/a&gt; ，但是这些层渐渐都不再流行，因为实践证明它们的效果即使存在，也是极其有限的。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;当然，cnn中有很多都用到了batch normalization和dropout，关于这个trick的讲解，可以看下&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/03/29/Batch-Normalization-and-dropout.html&quot;&gt;这篇博文&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;output&quot;&gt;OutPut&lt;/h2&gt;

&lt;p&gt;将一个deep and narrow的feature层作为输入，传给一个Regular神经网络&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/yzhihao/GDLnotes/raw/master/res/conv_output.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;inception&quot;&gt;Inception&lt;/h3&gt;
&lt;p&gt;对同一个卷积层输出，执行各种二次计算，将各种结果堆叠到新输出的depth方向上&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/yzhihao/GDLnotes/raw/master/res/inception.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个在GoogLeNet中教具代表性，可以查看下&lt;/p&gt;

&lt;h2 id=&quot;ＣＮＮ-的结构&quot;&gt;ＣＮＮ 的结构&lt;/h2&gt;

&lt;p&gt;最简单的CNNs结构的diagram（input+1conv+1pool+2fc）:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/2301760-029d98a6f80dda80.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里我们列举几种常见类型的卷积神经网络结构：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;· INPUT --&amp;gt; FC/OUT      这其实就是个线性分类器
· INPUT --&amp;gt; CONV --&amp;gt; RELU --&amp;gt; FC/OUT
· INPUT --&amp;gt; [CONV --&amp;gt; RELU --&amp;gt; POOL]*2 --&amp;gt; FC --&amp;gt; RELU --&amp;gt; FC/OUT
· INPUT --&amp;gt; [CONV --&amp;gt; RELU --&amp;gt; CONV --&amp;gt; RELU --&amp;gt; POOL]*3 --&amp;gt; [FC --&amp;gt; RELU]*2 --&amp;gt; FC/OUT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;最后，回到开头，强烈建议，关于几个重要的cnn的变形，大家可以看下那几篇在ImageNet的paper！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;参考链接&quot;&gt;参考链接&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;张雨石 &lt;a href=&quot;http://blog.csdn.net/stdcoutzyx/article/details/41596663&quot;&gt;Conv神经网络&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Bill Xia &lt;a href=&quot;https://ibillxia.github.io/blog/2013/04/06/Convolutional-Neural-Networks/&quot;&gt;卷积神经网络（CNN）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- 多说评论框 start --&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;2017031802&quot; data-title=&quot;convolution neural network&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Sat, 18 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/18/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/18/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>cs224d-cnn in nlp</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cs224d-cnn-in-nlp&quot; id=&quot;markdown-toc-cs224d-cnn-in-nlp&quot;&gt;cs224d-cnn in nlp&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#from-rnn-to-cnn&quot; id=&quot;markdown-toc-from-rnn-to-cnn&quot;&gt;from rnn to cnn&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cnnsingle-layer&quot; id=&quot;markdown-toc-cnnsingle-layer&quot;&gt;cnn—single layer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#pooling&quot; id=&quot;markdown-toc-pooling&quot;&gt;pooling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#structure&quot; id=&quot;markdown-toc-structure&quot;&gt;structure&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cs224d-cnn-in-nlp&quot;&gt;cs224d-cnn in nlp&lt;/h2&gt;

&lt;p&gt;在之前我们可以看到从convolution在图像处理方面的大放异彩，在nlp领域，其实cnn也从示弱，下面记下cnn在nlp中的一些模型原理与recurrent neural network和recursive neural network的一些区别和比较。&lt;/p&gt;

&lt;h2 id=&quot;from-rnn-to-cnn&quot;&gt;from rnn to cnn&lt;/h2&gt;

&lt;p&gt;首先来看下rnn到cnn，因为recursive network需要parser tree，然后recurrent network就比较依赖前面的词。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/RNN_disad1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;cnnsingle-layer&quot;&gt;cnn—single layer&lt;/h2&gt;

&lt;p&gt;cnn的主要论文或者原理在前面有比较多的笔记或者博文了，可以看下这篇&lt;a href=&quot;&quot;&gt;cnn&lt;/a&gt;，在这里就不讲，现在主要讲解的是cnn在应用在nlp时的结构：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/single_layer_cnn.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/single_layer_cnn1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/single_layer_cnn2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/single_layer_cnn3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;pooling&quot;&gt;pooling&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Pooling1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Pooling2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;structure&quot;&gt;structure&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/structure1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/structure2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;!-- 多说评论框 start --&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;2017031801&quot; data-title=&quot;cs224d-cnn in nlp&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Sat, 18 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/18/cnn-in-nlp.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/18/cnn-in-nlp.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>cs224d-Recursive Neural Networks</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cs224d-recursive-neural-networks&quot; id=&quot;markdown-toc-cs224d-recursive-neural-networks&quot;&gt;cs224d-Recursive Neural Networks&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#简要&quot; id=&quot;markdown-toc-简要&quot;&gt;简要&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#a-simple-single-layer-rnn&quot; id=&quot;markdown-toc-a-simple-single-layer-rnn&quot;&gt;A simple single layer RNN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#后向传播&quot; id=&quot;markdown-toc-后向传播&quot;&gt;后向传播&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#syntactically-untied-su-rnn&quot; id=&quot;markdown-toc-syntactically-untied-su-rnn&quot;&gt;Syntactically Untied SU-RNN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mv-rnns-matrix-vector-recursive-neural-networks&quot; id=&quot;markdown-toc-mv-rnns-matrix-vector-recursive-neural-networks&quot;&gt;MV-RNN’s (Matrix-Vector Recursive Neural Networks)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#rntns-recursive-neural-tensor-network&quot; id=&quot;markdown-toc-rntns-recursive-neural-tensor-network&quot;&gt;RNTNs (Recursive Neural Tensor Network)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;cs224d-recursive-neural-networks&quot;&gt;cs224d-Recursive Neural Networks&lt;/h1&gt;

&lt;h2 id=&quot;简要&quot;&gt;简要&lt;/h2&gt;

&lt;p&gt;Recursive Neural Networks is indeed a superset of the previously discussed Recurrent Neural Network&lt;/p&gt;

&lt;p&gt;The syntactic rules of language are highly recursive. So we take advantage of that recursive structure with a model that respects it!&lt;/p&gt;

&lt;p&gt;递归神经网络通过在一个结构上递归地应用同一组参数来预测任意输入的结构， 或者通过遍历输入的拓扑结构产生一个标量输出来创建网络。 上篇文章介绍的循环神经网络可以看成时间上的递归， 可以看成是结构递归的一种简化版递归神经网络。&lt;/p&gt;

&lt;p&gt;RNN适用于有嵌套层次和内在递归结构的任务。目前RNN在NLP领域的应用主要有句法分析和 句子表示。假设一个句子的含义是由句子中词的含义和词的组合方式决定的 ，word2vec已经一定程度上说明可以用向量来表示词的含义，词的组合规则从句法的角度 来看可以理解成句法树，我们可以通过遍历句法树来构建RNN（递归的时候使用同一组参数 ）来生成句子的表示。这样生成句子、短语的表示考虑了词的顺序、词的组合和词的含义。 其实我们可以利用RNN来同时学习句子的句法结构和句子的向量表示。&lt;/p&gt;

&lt;p&gt;RNN用于结构预测的时候需要用到一个&lt;code class=&quot;highlighter-rouge&quot;&gt;max-margin&lt;/code&gt;标函数，暂时没有看懂这个目标函数。 所以本文仅介绍在有一个句法树的前提下来生成句子表示的过程，同时结合一个简单的情感 分析任务来解释RNN的前向传播和反向传播过程。&lt;/p&gt;

&lt;p&gt;要解决下面的问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;There are literally an infinite amount of possible combinations of words. Storing and training an infinite amount of vectors would just be absurd.&lt;/li&gt;
  &lt;li&gt;Some combinations of words while they might be completely reasonable to hear in language, may never be represented in our training/dev corpus. So we would never learn them.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;就是词的组合无限，我们是学不来全部词组的，现在我们要一种方式用有限的词向量来解决接近无限的自然语言处理问题，不过实践证明，Recursive Neural Networks是可以做到这一点的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;a-simple-single-layer-rnn&quot;&gt;A simple single layer RNN&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Recursive_Neural_Networks1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Recursive Neural Networks2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;最简单的一个Recursive Neural Networks模型，需要注意的是，这的w是共享的，也就是说相同类别的一段文字，所用的w是一样的。但这很容易造成模型的capacity不强，文中有如下一段话：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;using the same W to bring together a Noun Phrase and Verb Phrase and to bring together a Prepositional Phrase and another word vector seems intuitively wrong. And maybe we are bluntly merging all of these functionalities into too weak of a model.&lt;/p&gt;

&lt;h2 id=&quot;后向传播&quot;&gt;后向传播&lt;/h2&gt;

&lt;p&gt;需要注意的是在RNN中我们在每个节点用的参数都是一样的，求导的时候和普通神经网络的区别 在于我们只需要把每个节点的参数的梯度累加起来就可以了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Recusive_cs224d.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;整个后向传播过程也是一个深度优先遍历，步骤如下：&lt;/p&gt;

&lt;p&gt;1.计算根节点的误差&lt;/p&gt;

&lt;p&gt;2.计算左孩子的误差&lt;/p&gt;

&lt;p&gt;3.计算右孩子的误差&lt;/p&gt;

&lt;p&gt;下面以上节提到的情感分析的例子来描述一下整个后向传播过程。前文可知，RNN中每个节点 都进行了一次softmax分类，每个节点输出的情感分类的损失可以用交叉熵度量：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Recusive_cs224d1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Recusive_cs224d2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;syntactically-untied-su-rnn&quot;&gt;Syntactically Untied SU-RNN&lt;/h2&gt;

&lt;p&gt;What we can do to remedy this shortcoming is to ”syntactically untie” the weights of these different tasks. By this we mean, there is no reason to expect the optimal W for one category of inputs to be at all related to the optimal W for another category of inputs. So we let these W’s be different and relax this constraint. While this for sure increases our weight matrices to learn, the performance boost we gain is non-trivial.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;这个模型相对与上面一个模型在实际上有了很大的改进，就是不同的语法类别就用不同的w权重的规定，然后再boot他们的权重，这样肯定会学到更多，但也还是capacity不足。如下：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/recursive_neural10.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;mv-rnns-matrix-vector-recursive-neural-networks&quot;&gt;MV-RNN’s (Matrix-Vector Recursive Neural Networks)&lt;/h2&gt;

&lt;p&gt;但需要说明的是，这个模型在在分类文本的时候还是有些时候不能有很好的capacity，具体如下：&lt;/p&gt;

&lt;p&gt;By observing the errors the model makes, we see even the MV-RNN still can not express certain relations. We observe three major classes of mistakes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Syntactically Untied SU-RNN4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;rntns-recursive-neural-tensor-network&quot;&gt;RNTNs (Recursive Neural Tensor Network)&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Syntactically Untied SU-RNN6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Syntactically Untied SU-RNN5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;!-- 多说评论框 start --&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;2017031701&quot; data-title=&quot;cs224d-Recursive Neural Networks&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Fri, 17 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/17/Recursive-Neural-Networks.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/17/Recursive-Neural-Networks.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>cs224d-rnn,gru,lstm</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cs224d-rnngrulstm&quot; id=&quot;markdown-toc-cs224d-rnngrulstm&quot;&gt;cs224d-rnn,gru,lstm&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#rnn&quot; id=&quot;markdown-toc-rnn&quot;&gt;RNN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#rnn训练&quot; id=&quot;markdown-toc-rnn训练&quot;&gt;RNN训练&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#lstm&quot; id=&quot;markdown-toc-lstm&quot;&gt;Lstm&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#gru&quot; id=&quot;markdown-toc-gru&quot;&gt;GRU&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#grus-and-lstm&quot; id=&quot;markdown-toc-grus-and-lstm&quot;&gt;GRUS and Lstm&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;cs224d-rnngrulstm&quot;&gt;cs224d-rnn,gru,lstm&lt;/h1&gt;

&lt;p&gt;因为rnn和lstm的讲解在这篇博文已经讲过比较多了，这里就不详细讲解rnn和lstm了，下面主要是rnn的训练和一种变种！&lt;/p&gt;

&lt;h2 id=&quot;rnn&quot;&gt;RNN&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs224d_rnn1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;RNN语言模型中非常关键的一点是&lt;strong&gt;每个时刻采用的W矩阵都是一个，所以参数规模不会随着依赖上下文的长度增加而指数增长。&lt;/strong&gt; 通常来说采用交叉熵作为损失函数，那么在t时刻的损失为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs224d_rnn2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;用来&lt;strong&gt;衡量语言模型的一个常用指标是困惑度（perplexity），困惑度越低表示预测下个词的置信度越高&lt;/strong&gt;，困惑度和交叉熵的关系如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs224d_rnn3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;rnn训练&quot;&gt;RNN训练&lt;/h2&gt;

&lt;p&gt;其实RNN本质上还是一个普通的多层神经网络，只是&lt;strong&gt;层与层之间使用的是同一个权重矩阵&lt;/strong&gt;而已， 同样可以利用后向误差传播的原理来进行后向误差传播， 只需要把t时刻的误差一直传播到t=0时刻，但是在实际实现的时候一般只需要向后传播τ≈3−5个时间单位。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs224d_rnn4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs224d_rnn5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;lstm&quot;&gt;Lstm&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;笔记原文:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/lstm.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/lstm2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;gru&quot;&gt;GRU&lt;/h2&gt;

&lt;p&gt;GRU可以看成是LSTM的变种，GRU把&lt;strong&gt;LSTM中的&lt;code class=&quot;highlighter-rouge&quot;&gt;forget gate&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;input gate&lt;/code&gt;用&lt;code class=&quot;highlighter-rouge&quot;&gt;update gate&lt;/code&gt;来替代。&lt;/strong&gt; 把&lt;code class=&quot;highlighter-rouge&quot;&gt;cell state&lt;/code&gt;和隐状态h(t)进行合并，在计算当前时刻新信息的方法和LSTM有所不同。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;笔记原文:&lt;/strong&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/gru1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/gru2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/gru3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;下图是GRU更新h(t)的过程：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/gru_cs224d1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/gru_cs224d.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;grus-and-lstm&quot;&gt;GRUS and Lstm&lt;/h2&gt;

&lt;p&gt;GRU有两个门，LSTM有三个门;GRU没有不同于隐状态的内部记忆c_{t}，没有LSTM中的输出门;GRU输入门和遗忘门通过更新门z进行耦合，重置门r被直接应用于之前的隐状态。因此，&lt;strong&gt;LSTM中的重置门的责任实质上被分割到了r和z中。GRU在计算输出时，没有使用第二个非线性单元。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;现在你已经看到了两个能够解决消失梯度问题的模型，你可能会疑惑：使用哪一个？GRU非常新，它们之间的权衡没有得到完全的研究。根据&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1412.3555&quot;&gt;Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling&lt;/a&gt;和 &lt;a href=&quot;http://link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v37/jozefowicz15.pdf&quot;&gt;An Empirical Exploration of Recurrent Network Architectures&lt;/a&gt;的实验结果，两者之前没有很大差别。在许多任务中，两种结构产生了差不多的性能，调整像层大小这样的参数可能比选择合适的架构更重要。&lt;strong&gt;GRU的参数更少，因而训练稍快或需要更少的数据来泛化。另一方面，如果你有足够的数据，LSTM的强大表达能力可能会产生更好的结果。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;2017031701&quot; data-title=&quot;cs224d-rnn,gru,lstm&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;p&gt;两宴书长，一与家天斜。出寒看阶帆，竺却参雴飞。&lt;/p&gt;

</description>
        <pubDate>Fri, 17 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/17/cs224d_RNN,GRU,LSTM.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/17/cs224d_RNN,GRU,LSTM.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>cs224d-neuro network</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cs224d-neuro-network&quot; id=&quot;markdown-toc-cs224d-neuro-network&quot;&gt;cs224d-neuro network&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#训练神经网络&quot; id=&quot;markdown-toc-训练神经网络&quot;&gt;训练神经网络&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#rnn&quot; id=&quot;markdown-toc-rnn&quot;&gt;rnn&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#交叉熵&quot; id=&quot;markdown-toc-交叉熵&quot;&gt;交叉熵&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;cs224d-neuro-network&quot;&gt;cs224d-neuro network&lt;/h1&gt;

&lt;p&gt;因为神经网络基础已经讲过了，在这里就不重复细讲，在这里主要讲的是结合nlp中的一些trick和tip，顺带讲下对&lt;strong&gt;交叉熵&lt;/strong&gt;的进一步理解&lt;/p&gt;

&lt;h2 id=&quot;训练神经网络&quot;&gt;训练神经网络&lt;/h2&gt;

&lt;p&gt;下面讲述的是怎么才能训练出比较好的神经网络，一些&lt;strong&gt;tip&amp;amp;trick&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/neuro_network.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;选择适当的网络结构
    &lt;ol&gt;
      &lt;li&gt;结构：单个词，固定窗口，词袋，递归 vs 循环，CNN，基于句子 vs 基于文档&lt;/li&gt;
      &lt;li&gt;非线性函数选择&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;用梯度检查来校验是否有实现bug&lt;/li&gt;
  &lt;li&gt;参数初始化&lt;/li&gt;
  &lt;li&gt;优化技巧&lt;/li&gt;
  &lt;li&gt;检查模型是否能够在数据集上过拟合
    &lt;ol&gt;
      &lt;li&gt;如果不能，那么需要改变模型结果或者让模型参数规模更大（例如增加隐藏层）&lt;/li&gt;
      &lt;li&gt;如果可以，那么增加正则化项&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;还有就是在检查神经网络的时候的梯度检查：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Gradient_Checks1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Gradient_Checks2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Gradient Check.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;rnn&quot;&gt;rnn&lt;/h2&gt;
&lt;p&gt;文中简单介绍了一下rnn和他为什么难以训练，下面给出课件：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Recurrent_neural_network1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Recurrent_neural_network2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Recurrent_neural_network3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;文中也给出，因为我们知道训练rnn很容易梯度消失或者梯度爆炸，下面是一种切割梯度的方式，来阻止梯度爆炸：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/clipping_gradients1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/gradients2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;需要注意的是，在后面讲到的lstm中，它是可以防止梯度消失，但不能防止梯度爆炸，具体原因请查看&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/03/12/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html#lstm-如何来避免梯度弥撒和梯度爆炸&quot;&gt;这篇博文&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;交叉熵&quot;&gt;交叉熵&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Cross_entropy1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Cross_entropy2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里很明白的说明了&lt;strong&gt;最小化交叉熵就是在最小化kl散度&lt;/strong&gt;，好的，一开始并不知道它是什么，下面摘自网上，对于kl散度和交叉熵的解释：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/kl_sandu.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比如TD-IDF算法就可以理解为相对熵的应用：词频在整个语料库的分布与词频在具体文档中分布之间的差异性。交叉熵可在神经网络(机器学习)中作为损失函数，&lt;strong&gt;p表示真实标记的分布，q则为训练后的模型的预测标记分布，交叉熵损失函数可以衡量p与q的相似性。&lt;/strong&gt;交叉熵作为损失函数还有一个好处是使用sigmoid函数在梯度下降时能避免均方误差损失函数学习速率降低的问题，因为学习速率可以被输出的误差所控制。&lt;/p&gt;

&lt;p&gt;PS：&lt;/p&gt;

&lt;p&gt;通常“相对熵”也可称为“交叉熵”，因为真实分布p是固定的，&lt;code class=&quot;highlighter-rouge&quot;&gt;D(p||q)&lt;/code&gt;由&lt;code class=&quot;highlighter-rouge&quot;&gt;H(p,q)&lt;/code&gt;决定。当然也有特殊情况，彼时2者须区别对待。&lt;/p&gt;

&lt;p&gt;尽管&lt;strong&gt;KL散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，&lt;/strong&gt;即&lt;code class=&quot;highlighter-rouge&quot;&gt;D(p||q)！=D(q||p)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Cross_entropy&quot;&gt;维基百科-Cross_entropy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;2017031502&quot; data-title=&quot;cs224d-neuro network&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Thu, 16 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/16/cs224d_neuro-network.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/16/cs224d_neuro-network.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>cs224d-word Vectors</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cs224d-word-vectors&quot; id=&quot;markdown-toc-cs224d-word-vectors&quot;&gt;cs224d-word Vectors&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#word2vec-and-glove&quot; id=&quot;markdown-toc-word2vec-and-glove&quot;&gt;word2vec and Glove&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#word2vec&quot; id=&quot;markdown-toc-word2vec&quot;&gt;word2vec&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#cbow&quot; id=&quot;markdown-toc-cbow&quot;&gt;CBOW&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#cs224d_skip-gram&quot; id=&quot;markdown-toc-cs224d_skip-gram&quot;&gt;cs224d_Skip-Gram&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#词向量的再训练&quot; id=&quot;markdown-toc-词向量的再训练&quot;&gt;词向量的再训练&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;cs224d-word-vectors&quot;&gt;cs224d-word Vectors&lt;/h1&gt;

&lt;h2 id=&quot;word2vec-and-glove&quot;&gt;word2vec and Glove&lt;/h2&gt;

&lt;p&gt;下面是有关GloVe模型的描述：
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/GloVe.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面是关于word2vec和Glove两个模型的区别，文章摘自&lt;a href=&quot;https://www.quora.com/How-is-GloVe-different-from-word2vec&quot;&gt;quora&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/word2vec_glove.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;简单说明，在我看在word2vec就是一个&lt;strong&gt;预测模型，&lt;/strong&gt;然后是可能根据上下文来预测中心词或者反过来，而Glove是说明一个词袋的词的关系，是一个&lt;strong&gt;Count-based models&lt;/strong&gt;一开始是高维的，然后提取其中的主要因子，然后用低维来表示高维中绝大部分的信息。
还有就是 The additional benefits of GloVe over word2vec is that it is easier to parallelize the implementation which means it’s easier to train over more data, which, with these models, is always A Good Thing.，这段话说明了在大量数据的时候，GloVe比较好的并行实现！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;最后，贴一张ppt，讲述Count based模型和direct predicDon模型的区别。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Count_based_and predicDon.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;word2vec&quot;&gt;word2vec&lt;/h2&gt;

&lt;p&gt;因为在word2vec中，我们知道是有&lt;strong&gt;两个向量来表示一个词的，分别是中心词和”旁边“词，但在最后我们只需要一个词向量来代表一个词，&lt;/strong&gt;下面就说明了怎么来合并这两个词！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/word_vectors1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cbow&quot;&gt;CBOW&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs224d_CBOW.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cs224d_skip-gram&quot;&gt;cs224d_Skip-Gram&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs224d_Skip-Gram.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面是介绍词向量的评估，分为两种，一个是内部一个是外部评估：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/evaluate_word.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;词向量内部评测方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;词向量内部评测方法主要有词向量类比、词向量相关度，这两种方法有相应的数据集。&lt;/p&gt;

&lt;p&gt;词向量类比的基本思想如下:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cs224d_votors_e.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;目前评测的数据集主要是word2vec项目提供的&lt;a href=&quot;https://code.google.com/p/word2vec/source/browse/trunk/questions-words.txt&quot;&gt;数据集&lt;/a&gt;包含了语义类比和语法类比两种。语义类比的数据有州名包含城市名、首都和国家， 语法类比的数据是比较级类比和时态类比。&lt;/p&gt;

&lt;p&gt;词向量相关度的数据集例如&lt;a href=&quot;http://www.cs.technion.ac.il/~gabr/resources/data/wordsim353/&quot;&gt;WordSim353&lt;/a&gt;， 该数据集是人为地给两个词的相关度打分（从0-10），然后通过计算词向量的Cosine相似度与 这个相关度进行对比。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;词向量外部评测方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;简单来说就是把词向量应用于具体的任务中来评测不同的词向量对于任务整体性能的影响。 这里需要注意的问题是，应用于具体任务的时候是否还需要调整词向量， 一般来说调整词向量会降低向量的范化能力。所以一般具体任务的训练集足够大时才考虑调整词向量。&lt;/p&gt;

&lt;h3 id=&quot;词向量的再训练&quot;&gt;词向量的再训练&lt;/h3&gt;

&lt;p&gt;下面课程用一个很简单的额例子说明了在数据量较小的情况下，去训练词向量会使得分类失去泛华能力，这是不可取的！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Losing_generalization_smell_vec1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Losing_generalization_smell_vec2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Losing_generalization_smell_vec3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;2017031501&quot; data-title=&quot;cs224d-word Vectors&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Wed, 15 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/15/cs224d.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/15/cs224d.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Gengerative Adversarial Networks</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#生成对抗网络&quot; id=&quot;markdown-toc-生成对抗网络&quot;&gt;生成对抗网络&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#概述&quot; id=&quot;markdown-toc-概述&quot;&gt;概述&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#训练&quot; id=&quot;markdown-toc-训练&quot;&gt;训练&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#如何训练gan&quot; id=&quot;markdown-toc-如何训练gan&quot;&gt;如何训练GAN&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#gan模型优化&quot; id=&quot;markdown-toc-gan模型优化&quot;&gt;GAN模型优化：&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dcgan&quot; id=&quot;markdown-toc-dcgan&quot;&gt;DCGAN&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;生成对抗网络&quot;&gt;生成对抗网络&lt;/h1&gt;

&lt;h2 id=&quot;概述&quot;&gt;概述&lt;/h2&gt;

&lt;p&gt;这些网络的要点是：有两个模型，一个是生成模型（generative model），一个是判别模型(discriminative model)。判别模型的任务是判断给定的图像看起来是自然的还是人为伪造的（图像来源于数据集）。生成模型的任务是生成看起来自然真实的、和原始数据相似的图像。这可以看做一种零和或两个玩家的纸牌游戏。本文采用的类比是生成模型像“一个造假团伙，试图生产和使用假币”，而判别模型像“检测假币的警察”。生成器（generator）试图欺骗判别器（discriminator），判别器则努力不被生成器欺骗。模型经过交替优化训练，两种模型都能得到提升，直到到达一个“假冒产品和真实产品无法区分”的点。&lt;/p&gt;

&lt;h2 id=&quot;训练&quot;&gt;训练&lt;/h2&gt;

&lt;p&gt;在训练的过程中&lt;strong&gt;固定一方，更新另一方的网络权重，交替迭代，在这个过程中，双方都极力优化自己的网络，从而形成竞争对抗，直到双方达到一个动态的平衡（纳什均衡）&lt;/strong&gt;，此时生成模型 G 恢复了训练数据的分布（造出了和真实数据一模一样的样本），判别模型再也判别不出来结果，准确率为 50%，约等于乱猜。&lt;strong&gt;这是双方网路都得到利益最大化，也就是不再更新自己的权重&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;网络示意：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/28GAN_1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;注：这里的G网络的输入是一个符合简单分布如高斯分布或者均匀分布的随机噪声。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;算法流程：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20160915122301396&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;如何训练gan&quot;&gt;如何训练GAN&lt;/h2&gt;

&lt;p&gt;给出下面的伪代码：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;while equilibrium_not_reached:

# train the discriminator to classify a batch of images from our
# dataset as real and a batch of images generated by our current
# generator as fake

1.)
discriminator.train_on_batch(image_batch=real_image_batch,
							 labels=real)
2.)
discriminator.train_on_batch(image_batch=generated_image_batch,
							 labels=fake)
# train the generator to trick the discriminator into
# classifying a batch of generated images as real. The key here
# is that the discriminator is frozen (not trainable) in this
# step, but it's loss functions gradients are back-propagated
# through the combined network to the generator
# the generator updates its weights in the most ideal way
# possible based on these gradients

3.)
combined.train_on_batch(input=batch_of_noise, labels=real)
# where combined is a model that consists of the generator and
# discriminator joined together such that: input =&amp;gt; generator =&amp;gt;
# generator_output =&amp;gt; discriminator =&amp;gt; classification
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面的过程简要如下：对于辨别器，如果得到的是生成图片辨别器应该输出 0，如果是真实的图片应该输出 1，得到误差梯度反向传播来更新参数。对于生成器，首先由生成器生成一张图片，然后输入给判别器判别并的到相应的误差梯度，然后反向传播这些图片梯度成为组成生成器的权重。直观上来说就是：&lt;strong&gt;辨别器不得不告诉生成器如何调整从而使它生成的图片变得更加真实。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;gan模型优化&quot;&gt;GAN模型优化：&lt;/h2&gt;

&lt;p&gt;理解了上面的之后，下面就是直接上数学式子了：&lt;/p&gt;

&lt;p&gt;GAN模型没有损失函数，优化过程是一个“二元极小极大博弈（minimax two-player game）”问题:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/gan_loss.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是关于判别网络D和生成网络G的&lt;strong&gt;价值函数（Value Function），训练网络D使得最大概率地分对训练样本的标签（最大化log D(x)），训练网络G最小化log(1 – D(G(z)))，即最大化D的损失。&lt;/strong&gt;训练过程中固定一方，更新另一个网络的参数，交替迭代，使得对方的错误最大化，最终，G 能估测出样本数据的分布。生成模型G隐式地定义了一个概率分布Pg，我们希望Pg 收敛到数据真实分布Pdata。论文证明了这个极小化极大博弈当且仅当Pg = Pdata时存在最优解，即达到纳什均衡，此时生成模型G恢复了训练数据的分布，判别模型D的准确率等于50%。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意这里在介绍原始基本的gan，其实现在，这个价值函数已经发生很大的变化，如果从原理来说的话，就是用Wasserstein距离来量度真实分布和生成分布之间的差距，具体看&lt;a href=&quot;&quot;&gt;这篇博文&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;dcgan&quot;&gt;DCGAN&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.06434.pdf&quot;&gt;论文地址：[1511.06434] Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;DCGAN把上述的G和D用了两个卷积神经网络（CNN）。但不是直接换就可以了，DCGAN对卷积神经网络的结构做了一些改变，以提高样本的质量和收敛的速度，这些改变有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;取消所有pooling层。G网络中使用转置卷积（transposed convolutional layer）进行上采样，D网络中用加入stride的卷积代替pooling。&lt;/li&gt;
  &lt;li&gt;在D和G中均使用batch normalization&lt;/li&gt;
  &lt;li&gt;去掉FC层，使网络变为全卷积网络&lt;/li&gt;
  &lt;li&gt;G网络中使用ReLU作为激活函数，最后一层使用tanh&lt;/li&gt;
  &lt;li&gt;D网络中使用LeakyReLU作为激活函数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DCGAN中的G网络示意：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/gan_model_dc.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出输入的是高斯分布的数据，最终生成图片，相等于卷积网络的逆过程。&lt;/p&gt;

&lt;p&gt;最后说下GAN的优缺点-（翻译摘自知乎，&lt;a href=&quot;https://www.quora.com/What-are-the-pros-and-cons-of-using-generative-adversarial-networks-a-type-of-neural-network&quot;&gt;Ian Goodfellow的原回答&lt;/a&gt;）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/adv_disadv_gan.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;更多有关基础GAN的知识，详细查看&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/02/24/paper-GAN.html&quot;&gt;paper-GAN&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

</description>
        <pubDate>Tue, 14 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/14/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/14/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>神经网络（基本概念）</title>
        <description>&lt;h1 id=&quot;神经网络基本概念&quot;&gt;神经网络（基本概念）&lt;/h1&gt;

&lt;p&gt;现在，我们一起来了解下最近都大火的神经网络（neural network），它看起来，听起来很高大上，但是，事实上，理解起来也就这样啦，下面来一起看下吧！&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;以下大多笔记来自cs231n，一个非常不错的deep learning课，值得一看，奉上&lt;a href=&quot;http://cs231n.stanford.edu/&quot;&gt;链接&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;作为线性分类器的单个神经元&quot;&gt;作为线性分类器的单个神经元&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;只要在神经元的输出端有一个合适的损失函数，就能让单个神经元变成一个线性分类器。因此说，那些&amp;amp;&lt;strong&gt;线性的分类器本身就是一个单层神经网络&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;但注意，对于非线性的模型：&lt;/strong&gt;SVM和神经网络走了两条不同的道路：神经网络通过&lt;strong&gt;多个隐层的方法来实现非线性的函数，有一些理论支持（比如说带隐层的神经网络可以模拟任何函数），但是目前而言还不是非常完备；SVM则采用了kernel trick的方法，这个在理论上面比较完备（RKHS，简单地说就是一个泛函的线性空间）。&lt;/strong&gt;两者各有好坏，神经网络最近的好处是网络设计可以很灵活，但是老被人说跳大神；SVM的理论的确漂亮，但是kernel设计不是那么容易，所以最近没有那么热了。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意：说神经网络多少层数的时候一般不包括输入层。
在神经网络中的激活主要讲的是梯度的更新的激活&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;why-deep-neural-network-not-fat-neural-network&quot;&gt;why deep neural network not fat neural network??&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/why_deep_neural_network.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/why_deep_neural_network1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A shallow network has less number of hidden layers. &lt;strong&gt;While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.&lt;/p&gt;

&lt;h2 id=&quot;表达能力capacity&quot;&gt;表达能力（capacity）&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;表达能力：就是指对某个神经网络的判别能力（泛化误差，训练误差之类的来衡量）&lt;/li&gt;
  &lt;li&gt;可以认为它们定义了一个由一系列函数组成的函数族，网络的权重就是每个函数的参数。&lt;/li&gt;
  &lt;li&gt;神经网络可以近似任何&lt;strong&gt;连续函数&lt;/strong&gt;。至于为什么，可以简单的理解为当隐层数量越高，它就能把样本空间分为更多部分，这样对于分类来说就可以更加的准确，但要注意的是防止过拟合，具体看一看下这篇:&lt;a href=&quot;https://zhuanlan.zhihu.com/p/25590725&quot;&gt;神经网络为什么能够无限逼近任意连续函数？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;更大网络总是更好的这一事实。然而更大容量的模型一定要和更强的正则化（比如更高的权重衰减）配合，否则它们就会过拟合。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;机器学习的模型中为什么加入bias&quot;&gt;机器学习的模型中为什么加入bias?&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/bais1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/bais2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;正则化-regularization&quot;&gt;正则化 Regularization:&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/regulazation1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意：&lt;strong&gt;L1正则化会让权重向量在最优化的过程中变得稀疏（即非常接近0）;L2正则化可以直观理解为它对于大数值的权重向量进行严厉惩罚，倾向于更加分散的权重向量。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;l1,l2正则化的图像化：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/27regulaztion.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;随机失活（Dropout）：&lt;strong&gt;Dropout可以看作是Bagging的极限形式，每个模型都在当一情况中训练，同时模型的每个参数都经过与其他模型共享参数，从而高度正则化。&lt;/strong&gt;在训练过程中，随机失活也可以被认为是对完整的神经网络抽样出一些子集，每次基于输入数据只更新子网络的参数（然而，数量巨大的子网络们并不是相互独立的，因为它们都共享参数）。在&lt;strong&gt;测试过程中不使用随机失活，可以理解为是对数量巨大的子网络们做了模型集成（model ensemble），以此来计算出一个平均的预测。&lt;/strong&gt;关于这个，可以看下&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/03/29/Batch-Normalization-and-dropout.html&quot;&gt;Batch-Normalization and dropout&lt;/a&gt;中的dropout部分&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;需要注意的是，&lt;strong&gt;在正则化的时候，bais是不需要正则化的，不然可能会导致欠拟合！&lt;/strong&gt;具体看&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/03/24/Deep-Learning-Deep-Feedforward-Networks.html#regularization&quot;&gt;这篇博文&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;数据预处理&quot;&gt;数据预处理&lt;/h2&gt;

&lt;h3 id=&quot;为什么要预处理&quot;&gt;为什么要预处理：&lt;/h3&gt;

&lt;p&gt;简单的从二维来理解，首先，图像数据是高度相关的，假设其分布如下图a所示(简化为2维)。由于初始化的时候，我们的参数一般都是0均值的，因此开始的拟合y=Wx+b，基本过原点附近(因为b接近于零)，如图b红色虚线。因此，网络需要经过多次学习才能逐步达到如紫色实线的拟合，即收敛的比较慢。如果我们对输入数据先作减均值操作，如图c，显然可以加快学习。更进一步的，我们对数据再进行去相关操作，使得数据更加容易区分，这样又会加快训练，如图d。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/neural_network_base1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;基础预处理方法&quot;&gt;基础预处理方法&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;归一化处理
    &lt;ol&gt;
      &lt;li&gt;均值减法（Mean subtraction）:它对数据中&lt;strong&gt;每个独立特征减去平均值，&lt;/strong&gt;从几何上可以理解为在每个维度上都将数据云的中心都迁移到原点。（就是每个特征数据减去其相应特征的平均值）&lt;/li&gt;
      &lt;li&gt;归一化（Normalization）;先对数据做零中心化（zero-centered）处理，然后每个维度都除以其标准差，实现代码为&lt;code class=&quot;highlighter-rouge&quot;&gt;X /= np.std(X, axis=0)。&lt;/code&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_neural_network_s1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;左边：&lt;/strong&gt;原始的2维输入数据。&lt;strong&gt;中间：&lt;/strong&gt;在每个维度上都减去平均值后得到零中心化数据，现在数据云是以原点为中心的。&lt;strong&gt;右边：&lt;/strong&gt;每个维度都除以其标准差来调整其数值范围。红色的线指出了数据各维度的数值范围，在中间的零中心化数据的数值范围不同，但在右边归一化数据中数值范围相同。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;PCA和白化（Whitening）是另一种预处理形式&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;白化（Whitening）:白化操作的输入是特征基准上的数据，然后对&lt;strong&gt;每个维度除以其特征值来对数值范围进行归一化&lt;/strong&gt;。该变换的几何解释是：如果数据服从多变量的高斯分布，那么经过白化后，数据的分布将会是一个&lt;strong&gt;均值为零，且协方差相等&lt;/strong&gt;的矩阵&lt;/li&gt;
      &lt;li&gt;特征向量是按照特征值的大小排列的。我们可以利用这个性质来对数据降维，只要使用前面的小部分特征向量，丢弃掉那些包含的数据没有方差的维度。 这个操作也被称为&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/02/11/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7-%E4%BA%8C.html#pca&quot;&gt;主成分分析（ Principal Component Analysis）&lt;/a&gt; 简称PCA）降维&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_neural_network_s2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(中间是pca，右边是白化),&lt;/p&gt;

&lt;h3 id=&quot;需要注意的是&quot;&gt;需要注意的是:&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;对比与上面的中心化，pca有点类似，但是不同的是，pca把数据变换到了数据协方差矩阵的基准轴上（协方差矩阵变成对角阵），也就是说他是轴对称个的，但简单的零中心化，它不是轴对称个的；还有PCA是一种降维的预处理，而零中心化并不是。&lt;/li&gt;
  &lt;li&gt;在上面的pca然后白化可以数据零均值（pca）和单位方差，弱相关性。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;常见错误:&lt;/strong&gt;进行预处理很重要的一点是：任何预处理策略（比如数据均值）都只能在训练集数据上进行计算，算法训练完毕后再应用到验证集或者测试集上。例如，如果先计算整个数据集图像的平均值然后每张图片都减去平均值，最后将整个数据集分成训练/验证/测试集，那么这个做法是错误的。应该怎么做呢？应该先分成训练/验证/测试集，&lt;strong&gt;只是从训练集中求图片平均值，然后各个集（训练/验证/测试集）中的图像再减去这个平均值。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;batch-normalization&quot;&gt;Batch Normalization&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Batch Normalization就是在每一层的wx+b和f(wx+b)之间加一个归一化（将wx+b归一化成：均值为0，方差为1；&lt;/strong&gt;但在原论文中，作者为了计算的稳定性，加了两个参数将数据又还原回去了，这两个参数也是需要训练的。）层，说白了，就是对每一层的数据都预处理一次。方便直观感受，上张图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/neural_network_base2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个方法可以进一步加速收敛，因此学习率可以适当增大，加快训练速度；过拟合现象可以得倒一定程度的缓解，所以可以不用Dropout或用较低的Dropout，而且可以减小L2正则化系数，训练速度又再一次得到了提升。即Batch Normalization可以降低我们对正则化的依赖程度。&lt;/p&gt;

&lt;p&gt;现在的深度神经网络基本都会用到Batch Normalization：其做法是让激活数据在训练开始前通过一个网络，网络处理数据使其服从标准高斯分布。在全连接之后做的操作&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一句话总结：批量归一化可以理解为在网络的每一层之前都做预处理，只是这种操作以另一种方式与网络集成在了一起。搞定！&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;还有要注意的是，Batch Normalization和pca加白化有点类似，结果都是可以零均值加上单位方差，可以使得数据弱相关，但是在深度神经网络中，&lt;strong&gt;我们一般不要pca加白化，原因就是白化需要计算整个训练集的协方差矩阵、求逆等操作，计算量很大，此外，反向传播时，白化操作不一定可导。&lt;/strong&gt;
最后，可以看下&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/03/29/Batch-Normalization-and-dropout.html#batch-normalization&quot;&gt;Batch-Normalization and dropout&lt;/a&gt;中的Batch-Normalization部分&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;权重初始化&quot;&gt;权重初始化&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;全零初始化是禁止的。因为：&lt;strong&gt;如果网络中的每个神经元都计算出同样的输出，然后它们就会在反向传播中计算出同样的梯度，从而进行同样的参数更新。换句话说，如果权重被初始化为同样的值导致在隐层的敏感值和梯度权值都相等，神经元之间就失去了不对称性的源头。(会导致：所有的隐单元都是相同的. 学习失败)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面是两个网上资料，关于为什么不能全零初始化：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/dengdan890730/p/5865558.html&quot;&gt;全零初始化-解释1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/36068411/answer/95670563?from=profile_answer_card&quot;&gt;讨论全零初始化-解释2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;小随机数初始化： 产生的数字为&lt;strong&gt;以零为平均值，单位标准差的高斯分布。&lt;/strong&gt;使用这种方式，每个神经元的权重矩阵都从多维度高斯分布中随机初始化。所以神经元在输入空间内指向不同的方向。代码为&lt;code class=&quot;highlighter-rouge&quot;&gt;w = np.random.randn(n) 	* sqrt(2.0/n)&lt;/code&gt;。&lt;strong&gt;这个形式是神经网络算法使用ReLU神经元时的当前最佳推荐。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;稀疏初始化（Sparse initialization）:每个神经元都同下一层固定数目的神经元随机连接（其权重数值由一个小的高斯分布生成）&lt;/p&gt;

&lt;p&gt;偏置（biases）的初始化。&lt;strong&gt;通常将偏置初始化为0，这是因为随机小数值权重矩阵已经打破了对称性。&lt;/strong&gt;对于ReLU非线性激活函数，有研究人员喜欢使用如0.01这样的小数值常量作为所有偏置的初始值，这是因为他们认为这样做能让所有的ReLU单元一开始就激活，这样就能保存并传播一些梯度。然而，这样做是不是总是能提高算法性能并不清楚（有时候实验结果反而显示性能更差），所以通常还是使用0来初始化偏置参数。&lt;/p&gt;

&lt;h2 id=&quot;理解激励函数&quot;&gt;理解激励函数&lt;/h2&gt;

&lt;h3 id=&quot;sigmoid非线性函数&quot;&gt;sigmoid非线性函数&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;优点：
    &lt;ol&gt;
      &lt;li&gt;比较好的解释性&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;缺点：
    &lt;ol&gt;
      &lt;li&gt;Sigmoid函数饱和使梯度消失。sigmoid神经元有一个不好的特性，就是当神经元的激活&lt;strong&gt;在接近0或1处时会饱和&lt;/strong&gt;：在这些区域，梯度几乎为0。（信号可以理解为信号）&lt;/li&gt;
      &lt;li&gt;输出不是零中心的，这一情况将影响梯度下降的运作，因为如果输入神经元的数据总是正数，那么关于w的梯度在反向传播的过程中，将会要么全部是正数，要么全部是负数，这样梯度下降权重更新时出现z字型的下降。这样收敛会变得异常的慢。（&lt;strong&gt;这也是为什么要一直保持为数据的0中心化&lt;/strong&gt;）—–&lt;strong&gt;但这个问题比较小&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;exp（）&lt;/code&gt;在深度神经网络时候相比就比较慢&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/neural_network_base3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;tanh非线性函数&quot;&gt;Tanh非线性函数&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;优点
    &lt;ol&gt;
      &lt;li&gt;它的输出是零中心的。因此，在实际操作中，tanh非线性函数比sigmoid非线性函数更受欢迎。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;缺点
    &lt;ol&gt;
      &lt;li&gt;和Sigmoid函数一样，饱和使梯度消失。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/neural_network_base4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;relu&quot;&gt;ReLU&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;优点
    &lt;ol&gt;
      &lt;li&gt;ReLU对于随机梯度下降的收敛有巨大的加速作用（ Krizhevsky 等的论文指出有6倍之多）。据称这是&lt;strong&gt;由它的线性，非饱和的公式&lt;/strong&gt;导致的&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;现在大部分的DNN用的激活函数，至于为什么，可以看下这个&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/02/24/paper-ImageNet.html&quot;&gt;paper-ImageNet&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;缺点
    &lt;ol&gt;
      &lt;li&gt;当x是小于0的时候，那么从此所以流过这个神经元的梯度将都变成0。&lt;/li&gt;
      &lt;li&gt;这个ReLU单元在训练中将不可逆转的死亡，因为这导致了数据多样化的丢失。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/neural_network_base5.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;leaky-relu&quot;&gt;Leaky ReLU&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;优点
    &lt;ol&gt;
      &lt;li&gt;非饱和的公式&lt;/li&gt;
      &lt;li&gt;Leaky ReLU是为解决“ReLU死亡”问题的尝试&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;缺点
    &lt;ol&gt;
      &lt;li&gt;有些研究者的论文指出这个激活函数表现很不错，但是其效果并不是很稳定&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Kaiming He等人在2015年发布的论文Delving Deep into Rectifiers中介绍了一种新方法PReLU，把负区间上的斜率当做每个神经元中的一个参数。然而该激活函数在在不同任务中均有益处的一致性并没有特别清晰。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/neural_network_base6.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;elu&quot;&gt;ELU&lt;/h3&gt;
&lt;p&gt;指数线性单元（Exponential Linear Units, ELU）
ELU的公式为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/neural_network_base7.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ELU.png
函数曲线如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/neural_network_base8.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;maxout&quot;&gt;Maxout&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Maxout是对ReLU和leaky ReLU的一般化归纳&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;优点
    &lt;ol&gt;
      &lt;li&gt;拥有ReLU单元的所有优点（线性操作和不饱和），而没有它的缺点（死亡的ReLU单元）&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;缺点
  1.每个神经元的参数数量增加了一倍，这就导致整体参数的数量激增。难训练,容易过拟合&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;怎么用激活函数&quot;&gt;怎么用激活函数&lt;/h3&gt;

&lt;p&gt;“那么该用那种呢？”&lt;strong&gt;用ReLU非线性函数。注意设置好学习率，&lt;/strong&gt;(如果学习率设置得太高，可能会发现网络中40%的神经元都会死掉（在整个训练集中这些神经元都不会被激活）。通过合理设置学习率，这种情况的发生概率会降低。),&lt;em&gt;解决方案：&lt;/em&gt;或许可以监控你的网络中死亡的神经元占的比例。如果单元死亡问题困扰你，就试试Leaky ReLU或者Maxout，不要再用sigmoid了。也可以试试tanh，但是其效果应该不如ReLU或者Maxout。&lt;/p&gt;

&lt;h2 id=&quot;交叉熵&quot;&gt;交叉熵&lt;/h2&gt;
&lt;p&gt;一个非常常见的，非常漂亮的成本函数是“交叉熵”（cross-entropy）。交叉熵产生于信息论里面的信息压缩编码技术，但是它后来演变成为从博弈论到机器学习等其他领域里的重要技术手段。它的定义如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/neural_network_base9.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;y 是我们预测的概率分布, y’ 是实际的分布（我们输入的one-hot vector)&lt;/p&gt;

&lt;p&gt;交叉熵是正的，并且当所有输入x的输出都能接近期望输出y的话，交叉熵的值将会接近 0。这两个特征在直觉上我们都会觉得它适合做代价函数。事实上，我们的均方代价函数也同时满足这两个特征。这对于交叉熵来说是一个好消息。而且交叉熵有另一个均方代价函数不具备的特征，它能够避免学习速率降低的情况。&lt;/p&gt;

&lt;p&gt;因为MSE（均方误差）不会出太大问题、同时也基本不能很好地解决问题,而折叶损失函数不能很好的描述概率和局部目标化（local objective）的问题，故一般都用这个交叉熵作为损失函数。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在现在的深度神经网络中，大多数情况下，我们使用的就是交叉熵这个代价函数
&lt;a href=&quot;https://hit-scir.gitbooks.io/neural-networks-and-deep-learning-zh_cn/content/chap3/c3s1.html&quot;&gt;详细了解交叉熵&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;参数维数&quot;&gt;参数维数&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;对于全链接网络，参数的数量：If network has sj units in layer j and sj+1 units in layer j+1, then Θ(j) will be of dimension sj+1×(sj+1).&lt;/li&gt;
  &lt;li&gt;对于卷积神经网络和循环神经网络，参数是在空间上和时间上共享的，这个下面再说！&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Mon, 13 Mar 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/03/13/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/03/13/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html</guid>
        
        
      </item>
    
      <item>
        <title>神经网络-BP，更新参数策略</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#神经网络-bp更新参数策略&quot; id=&quot;markdown-toc-神经网络-bp更新参数策略&quot;&gt;神经网络-BP，更新参数策略&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#反向传播&quot; id=&quot;markdown-toc-反向传播&quot;&gt;反向传播&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#链式法则&quot; id=&quot;markdown-toc-链式法则&quot;&gt;链式法则&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#梯度的回传流中的模式&quot; id=&quot;markdown-toc-梯度的回传流中的模式&quot;&gt;梯度的回传流中的模式&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#gradient-checking&quot; id=&quot;markdown-toc-gradient-checking&quot;&gt;Gradient Checking&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#随机梯度下降及各种更新方法&quot; id=&quot;markdown-toc-随机梯度下降及各种更新方法&quot;&gt;随机梯度下降及各种更新方法&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#普通更新&quot; id=&quot;markdown-toc-普通更新&quot;&gt;普通更新,&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#动量momentum更新&quot; id=&quot;markdown-toc-动量momentum更新&quot;&gt;动量（Momentum）更新&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#nesterov动量更新&quot; id=&quot;markdown-toc-nesterov动量更新&quot;&gt;Nesterov动量更新&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#学习率退火&quot; id=&quot;markdown-toc-学习率退火&quot;&gt;学习率退火&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#逐参数适应学习率方法&quot; id=&quot;markdown-toc-逐参数适应学习率方法&quot;&gt;逐参数适应学习率方法&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#总结&quot; id=&quot;markdown-toc-总结&quot;&gt;总结：&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#简单神经网络训练&quot; id=&quot;markdown-toc-简单神经网络训练&quot;&gt;简单神经网络训练&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#训练一个较好的神经网络需要&quot; id=&quot;markdown-toc-训练一个较好的神经网络需要&quot;&gt;训练一个较好的神经网络需要：&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;神经网络-bp更新参数策略&quot;&gt;神经网络-BP，更新参数策略&lt;/h1&gt;

&lt;h2 id=&quot;反向传播&quot;&gt;反向传播&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;其实它就是很简单的求导链式法则&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;目标：本节将帮助读者对反向传播形成直观而专业的理解。反向传播是利用链式法则递归计算表达式的梯度的方法。理解反向传播过程及其精妙之处，对于理解、实现、设计和调试神经网络非常关键。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;链式法则&quot;&gt;链式法则&lt;/h2&gt;

&lt;p&gt;有小伙伴可能不是很清楚什么是链式法则，下面进行解释：&lt;/p&gt;

&lt;p&gt;先举一个例子：
我们以求e=(a+b)*(b+1)的偏导[3]为例。&lt;/p&gt;

&lt;p&gt;它的复合关系画出图可以表示如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/bp_neural_network1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在图中，引入了中间变量c,d。在图中，引入了中间变量c,d。为了求出a=2, b=1时，e的梯度，我们可以先利用偏导数的定义求出不同层之间相邻节点的偏导关系，如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/bp_neural_network2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;利用链式法则我们知道：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/bp_neural_network3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以及&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/bp_neural_network4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;链式法则在上图中的意义是什么呢？其实不难发现，
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/bp_neural_network5.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
的值等于从a到e的路径上的偏导值的乘积，而&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+e%7D%7B%5Cpartial+b%7D&quot; alt=&quot;&quot; /&gt;的值等于从b到e的路径1(b-c-e)上的偏导值的乘积加上路径2(b-d-e)上的偏导值的乘积。也就是说，对于上层节点p和下层节点q，要求得&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+p%7D%7B%5Cpartial+q%7D&quot; alt=&quot;&quot; /&gt;，需要找到从q节点到p节点的所有路径，并且对每条路径，求得该路径上的所有偏导数之乘积，然后将所有路径的 “乘积” 累加起来才能得到&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+p%7D%7B%5Cpartial+q%7D&quot; alt=&quot;&quot; /&gt;的值。&lt;/p&gt;

&lt;p&gt;大家也许已经注意到，这样做是十分冗余的，因为很多&lt;strong&gt;路径被重复访问&lt;/strong&gt;了。比如上图中，a-c-e和b-c-e就都走了路径c-e。对于权值动则数万的深度模型中的神经网络，这样的冗余所导致的计算量是相当大的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;同样是利用链式法则，BP算法则机智地避开了这种冗余，它对于每一个路径只访问一次就能求顶点对所有下层节点的偏导值。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;正如反向传播(BP)算法的名字说的那样，BP算法是反向(自上往下)来寻找路径的。从最上层的节点e开始，初始值为1，以层为单位进行处理。对于e的下一层的所有子节点，将1乘以e到某个节点路径上的偏导值，并将结果“堆放”在该子节点中。等e所在的层按照这样传播完毕后，第二层的每一个节点都“堆放”些值，然后我们针对每个节点，把它里面所有“堆放”的值求和，就得到了顶点e对该节点的偏导。然后将这些第二层的节点各自作为起始顶点，初始值设为顶点e对它们的偏导值，以”层”为单位重复上述传播过程，即可求出顶点e对每一层节点的偏导数。&lt;/p&gt;

&lt;p&gt;以上图为例，节点c接受e发送的1&lt;em&gt;2并堆放起来，节点d接受e发送的1&lt;/em&gt;3并堆放起来，至此第二层完毕，求出各节点总堆放量并继续向下一层发送。节点c向a发送2&lt;em&gt;1并对堆放起来，节点c向b发送2&lt;/em&gt;1并堆放起来，节点d向b发送3&lt;em&gt;1并堆放起来，至此第三层完毕，节点a堆放起来的量为2，节点b堆放起来的量为2&lt;/em&gt;1+3*1=5, 即顶点e对b的偏导数为5.&lt;/p&gt;

&lt;p&gt;举个不太恰当的例子，如果把上图中的箭头表示欠钱的关系，即c→e表示e欠c的钱。以a, b为例，直接计算e对它们俩的偏导相当于a, b各自去讨薪。a向c讨薪，c说e欠我钱，你向他要。于是a又跨过c去找e。b先向c讨薪，同样又转向e，b又向d讨薪，再次转向e。可以看到，追款之路，充满艰辛，而且还有重复，即a, b 都从c转向e。&lt;/p&gt;

&lt;p&gt;而BP算法就是主动还款。e把所欠之钱还给c，d。c，d收到钱，乐呵地把钱转发给了a，b，皆大欢喜。&lt;/p&gt;

&lt;h2 id=&quot;梯度的回传流中的模式&quot;&gt;梯度的回传流中的模式&lt;/h2&gt;

&lt;p&gt;一个有趣的现象是在多数情况下，反向传播中的梯度可以被很直观地解释。例如神经网络中最常用的加法、乘法和取最大值这三个门单元，它们在反向传播过程中的行为都有非常简单的解释。先看下面这个例子：&lt;/p&gt;

&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/bp_neural_network6.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一个展示反向传播的例子。加法操作将梯度相等地分发给它的输入。取最大操作将梯度路由给更大的输入。乘法门拿取输入激活数据，对它们进行交换，然后乘以梯度。&lt;/p&gt;

&lt;p&gt;——————————————————————————————————————————&lt;/p&gt;

&lt;p&gt;从上例可知：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;加法门单元把输出的梯度相等地分发给它所有的输入，这一行为与输入值在前向传播时的值无关。这是因为加法操作的局部梯度都是简单的+1，所以所有输入的梯度实际上就等于输出的梯度，因为乘以1.0保持不变。上例中，加法门把梯度2.00不变且相等地路由给了两个输入。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;取最大值门单元对梯度做路由。和加法门不同，取最大值门将梯度转给其中一个输入，这个输入是在前向传播中值最大的那个输入。这是因为在取最大值门中，最高值的局部梯度是1.0，其余的是0。上例中，取最大值门将梯度2.00转给了z变量，因为z的值比w高，于是w的梯度保持为0。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;乘法门单元相对不容易解释。它的局部梯度就是输入值，但是是相互交换之后的，然后根据链式法则乘以输出值的梯度。上例中，x的梯度是-4.00x2.00=-8.00。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;非直观影响及其结果。注意一种比较特殊的情况，如果乘法门单元的其中一个输入非常小，而另一个输入非常大，那么乘法门的操作将会不是那么直观：它将会把大的梯度分配给小的输入，把小的梯度分配给大的输入。在线性分类器中，权重和输入是进行点积，这说明输入数据的大小对于权重梯度的大小有影响。例如，在计算过程中对所有输入数据样本乘以1000，那么权重的梯度将会增大1000倍，这样就必须降低学习率来弥补。这就是为什么数据预处理关系重大，它即使只是有微小变化，也会产生巨大影响。对于梯度在计算线路中是如何流动的有一个直观的理解，可以帮助读者调试网络。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;附上一个&lt;a href=&quot;http://ufldl.stanford.edu/wiki/index.php/%E5%8F%8D%E5%90%91%E4%BC%A0%E5%AF%BC%E7%AE%97%E6%B3%95&quot;&gt;维基专业解释&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;gradient-checking&quot;&gt;Gradient Checking&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Once you have verified once that your backpropagation algorithm is correct, you don’t need to compute gradApprox again. The code to compute gradApprox can be very slow.&lt;/li&gt;
  &lt;li&gt;that why we shoulf use Backpropagation Algorithm but not forward propagation  to compute partial derivatives&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;随机梯度下降及各种更新方法&quot;&gt;随机梯度下降及各种更新方法&lt;/h2&gt;

&lt;h3 id=&quot;普通更新&quot;&gt;普通更新,&lt;/h3&gt;

&lt;p&gt;就是在回归那里一样的普通更新方法&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/02/16/%E5%9B%9E%E5%BD%92-%E7%AE%80%E5%8D%95%E5%88%86%E7%B1%BB.html#梯度下降算法&quot;&gt;梯度下降算法&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;主要注意的是，在深度学习中比较常用的是mini-batch 梯度下降&lt;/p&gt;

&lt;h2 id=&quot;动量momentum更新&quot;&gt;动量（Momentum）更新&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 动量更新
v = mu * v - learning_rate * dx # 与速度融合（1）
x += v # 与位置融合
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在这里引入了一个初始化为0的变量v和一个超参数mu,物理观点建议&lt;strong&gt;梯度只是影响速度，然后速度再影响位置&lt;/strong&gt;。从公式可以看出，我们通过重复地增加梯度项来构造速度，那么随着迭代次数的增加，速度会越来越快，这样就能够确保momentum技术比标准的梯度下降运行得更快；同时μ的引入，一个典型的设置是刚开始将动量设为0.5而在后面的多个周期（epoch）中慢慢提升到0.99。，&lt;strong&gt;保证了在接近谷底时速度会慢慢下降，最终停在谷底，而不是在谷底来回震荡。&lt;/strong&gt; 所以，由于在公式（1）中，两项都会发生变化，所以导致的后果就是V先增大，后减小。&lt;/p&gt;

&lt;h2 id=&quot;nesterov动量更新&quot;&gt;Nesterov动量更新&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x_ahead = x + mu * v
# 计算dx_ahead(在x_ahead处的梯度，而不是在x处的梯度)
v = mu * v - learning_rate * dx_ahead
x += v
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;等价与：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;v_prev = v # 存储备份
v = mu * v - learning_rate * dx # 速度更新保持不变
x += -mu * v_prev + (1 + mu) * v # 位置更新变了形式
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;和上面的动量（Momentum）更新差不多，但是，不同的在于，当参数向量位于某个位置x时，观察上面的动量更新公式可以发现，动量部分（忽视带梯度的第二个部分）会通过&lt;code class=&quot;highlighter-rouge&quot;&gt;mu * v&lt;/code&gt;稍微改变参数向量。因此，如果要计算梯度，那么&lt;strong&gt;可以将未来的近似位置&lt;code class=&quot;highlighter-rouge&quot;&gt;x + mu * v&lt;/code&gt;看做是“向前看”，这个点在我们一会儿要停止的位置附近。因此，计算&lt;code class=&quot;highlighter-rouge&quot;&gt;x + mu * v&lt;/code&gt;的梯度而不是“旧”位置x的梯度就有意义了。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/bp_neural_network7.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Nesterov动量。既然我们知道动量将会把我们带到绿色箭头指向的点，我们就不要在原点（红色点）那里计算梯度了。使用Nesterov动量，我们就在这个“向前看”的地方计算梯度。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/bp_neural_network8.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;学习率退火&quot;&gt;学习率退火&lt;/h2&gt;

&lt;p&gt;如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在实际应用中，我们通常选择步长衰减，因为它包含的超参数少，计算代价低。&lt;/p&gt;

&lt;h2 id=&quot;逐参数适应学习率方法&quot;&gt;逐参数适应学习率方法&lt;/h2&gt;

&lt;p&gt;前面讨论的所有方法都是对学习率进行全局地操作，并且对所有的参数都是一样的。学习率调参是很耗费计算资源的过程，所以很多工作投入到发明能够适应性地对学习率调参的方法，甚至是逐个参数适应学习率调参。很多这些方法依然需要其他的超参数设置，但是其观点是这些方法对于更广范围的超参数比原始的学习率方法有更良好的表现。在本小节我们会介绍一些在实践中可能会遇到的常用适应算法：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Adagrad&lt;/strong&gt;是一个由Duchi等提出的适应性学习率算法&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 假设有梯度和参数向量x
cache += dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;注意，变量cache的尺寸和梯度矩阵的尺寸是一样的，还跟踪了每个参数的梯度的平方和。这个一会儿将用来归一化参数更新步长，归一化是逐元素进行的。注意，接收到高梯度值的权重更新的效果被减弱，而接收到低梯度值的权重的更新效果将会增强。有趣的是平方根的操作非常重要，如果去掉，算法的表现将会糟糕很多。用于平滑的式子eps（一般设为1e-4到1e-8之间）是防止出现除以0的情况。Adagrad的一个缺点是，在深度学习中单调的学习率被证明通常过于激进且过早停止学习。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RMSprop&lt;/strong&gt;。是一个非常高效，但没有公开发表的适应性学习率方法。有趣的是，每个使用这个方法的人在他们的论文中都引用自Geoff Hinton的Coursera课程的&lt;a href=&quot;http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf&quot;&gt;第六课的第29页PPT&lt;/a&gt;。这个方法用一种很简单的方式修改了Adagrad方法，让它不那么激进，单调地降低了学习率。具体说来，就是它使用了一个梯度平方的滑动平均：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cache =  decay_rate * cache + (1 - decay_rate) * dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在上面的代码中，decay_rate是一个超参数，常用的值是[0.9,0.99,0.999]。其中x+=和Adagrad中是一样的，但是cache变量是不同的。因此，RMSProp仍然是基于梯度的大小来对每个权重的学习率进行修改，这同样效果不错。但是和Adagrad不同，其更新不会让学习率单调变小。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Adam&lt;/strong&gt;。有点像RMSProp+momentum，效果比RMSProp稍好,简化的代码是下面这样：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;m = beta1*m + (1-beta1)*dx
v = beta2*v + (1-beta2)*(dx**2)
x += - learning_rate * m / (np.sqrt(v) + eps)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;注意这个更新方法看起来真的和RMSProp很像，除了使用的是平滑版的梯度m，而不是用的原始梯度向量dx。论文中推荐的参数值eps=1e-8, beta1=0.9, beta2=0.999。在实际操作中，我们推荐Adam作为默认的算法，一般而言跑起来比RMSProp要好一点。但是也可以试试SGD+Nesterov动量。完整的Adam更新算法也包含了一个偏置（bias）矫正机制，因为m,v两个矩阵初始为0，在没有完全热身之前存在偏差，需要采取一些补偿措施。建议读者可以阅读论文查看细节，或者课程的PPT。&lt;/p&gt;

&lt;h1 id=&quot;总结&quot;&gt;总结：&lt;/h1&gt;

&lt;h2 id=&quot;简单神经网络训练&quot;&gt;简单神经网络训练&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Randomly initialize the weights&lt;/li&gt;
  &lt;li&gt;Implement forward propagation to get hΘ(x(i)) for any x(i)&lt;/li&gt;
  &lt;li&gt;Implement the cost function&lt;/li&gt;
  &lt;li&gt;Implement backpropagation to compute partial derivatives&lt;/li&gt;
  &lt;li&gt;Use gradient checking to confirm that your backpropagation works. Then disable gradient checking.&lt;/li&gt;
  &lt;li&gt;Use gradient descent or a built-in optimization function to minimize the cost function with the weights in theta.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;训练一个较好的神经网络需要&quot;&gt;训练一个较好的神经网络需要：&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;利用小批量数据对实现进行梯度检查，还要注意各种错误。&lt;/li&gt;
  &lt;li&gt;进行合理性检查，确认初始损失值是合理的，在小数据集上能得到100%的准确率。&lt;/li&gt;
  &lt;li&gt;在训练时，跟踪损失函数值，训练集和验证集准确率，如果愿意，还可以跟踪更新的参数量相对于总参数量的比例（一般在1e-3左右），然后如果是对于卷积神经网络，可以将第一层的权重可视化。&lt;/li&gt;
  &lt;li&gt;推荐的两个更新方法是SGD+Nesterov动量方法，或者Adam方法。&lt;/li&gt;
  &lt;li&gt;随着训练进行学习率衰减。比如，在固定多少个周期后让学习率减半，或者当验证集准确率下降的时候。&lt;/li&gt;
  &lt;li&gt;使用随机搜索（不要用网格搜索）来搜索最优的超参数。分阶段从粗（比较宽的超参数范围训练1-5个周期）到细（窄范围训练很多个周期）地来搜索。&lt;/li&gt;
  &lt;li&gt;进行模型集成来获得额外的性能提高。&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Sun, 12 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/12/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-BP%E5%92%8C%E5%AF%BB%E6%89%BE%E6%9C%80%E4%BC%98%E5%8C%96.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/12/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-BP%E5%92%8C%E5%AF%BB%E6%89%BE%E6%9C%80%E4%BC%98%E5%8C%96.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>循环神经网络</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#循环神经网络recurrent-neural-network&quot; id=&quot;markdown-toc-循环神经网络recurrent-neural-network&quot;&gt;循环神经网络（recurrent neural network）&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#引出循环神经网络&quot; id=&quot;markdown-toc-引出循环神经网络&quot;&gt;引出循环神经网络&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#rnn讲解&quot; id=&quot;markdown-toc-rnn讲解&quot;&gt;RNN讲解&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#为什么可以参数共享的简单理解&quot; id=&quot;markdown-toc-为什么可以参数共享的简单理解&quot;&gt;为什么可以参数共享的简单理解:&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cnn-and-rnn&quot; id=&quot;markdown-toc-cnn-and-rnn&quot;&gt;CNN and RNN&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#long-term依赖问题&quot; id=&quot;markdown-toc-long-term依赖问题&quot;&gt;Long-Term依赖问题&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lstmlong-short-term-memory&quot; id=&quot;markdown-toc-lstmlong-short-term-memory&quot;&gt;LSTM（Long Short-Term Memory）&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lstm背后的核心思想&quot; id=&quot;markdown-toc-lstm背后的核心思想&quot;&gt;LSTM背后的核心思想&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#深入浅出lstm&quot; id=&quot;markdown-toc-深入浅出lstm&quot;&gt;深入浅出LSTM&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#lstm-如何来避免梯度弥撒和梯度爆炸&quot; id=&quot;markdown-toc-lstm-如何来避免梯度弥撒和梯度爆炸&quot;&gt;LSTM 如何来避免梯度弥撒和梯度爆炸？&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#beam-search&quot; id=&quot;markdown-toc-beam-search&quot;&gt;Beam Search&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#翻译与识图&quot; id=&quot;markdown-toc-翻译与识图&quot;&gt;翻译与识图&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;循环神经网络recurrent-neural-network&quot;&gt;循环神经网络（recurrent neural network）&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意，需要明白&lt;strong&gt;recurrent neural network和recursive neural network&lt;/strong&gt;之间的区别！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;引出循环神经网络&quot;&gt;引出循环神经网络&lt;/h2&gt;

&lt;p&gt;在传统的神经网络模型中，是从输入层到隐含层再到输出层，层与层之间是全连接的，每层之间的节点是无连接的。但是这种普通的神经网络对于很多问题却无能无力。例如，你要预测句子的下一个单词是什么，一般需要用到前面的单词，因为一个句子中前后单词并不是独立的。这个时候，我们怎么办呢？下面有两种解决方案&lt;/p&gt;

&lt;p&gt;在每轮训练中，需要判断至今为之发生了什么，过去输入的所有数据都对当下的分类造成影响&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;一种思路是记忆之前的分类器的状态，在这个基础上训练新的分类器，从而结合历史影响，但是这样需要大量历史分类器&lt;/li&gt;
  &lt;li&gt;重用分类器，只用一个分类器总结状态，其他分类器接受对应时间的训练，然后传递状态,这样就避免了需要大量历史分类器，而且还比较有效的解决了这个问题。而这样一种东西是什么呢？没错，就是RNN(循环神经网络),它的做法就如下图&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/recurrent_neural_network_s1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;rnn讲解&quot;&gt;RNN讲解&lt;/h2&gt;
&lt;p&gt;RNNs的目的使用来处理序列数据。RNNs之所以称为循环神经网路，即一个序列当前的输出与前面的输出也有关。具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。理论上，RNNs能够对任何长度的序列数据进行处理。但是在实践中，为了降低复杂性往往假设当前的状态只与前面的几个状态相关，下图便是一个典型的RNNs：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/recurrent_neural_network1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/recurrent_neural_network2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt; RNNs包含输入单元(Input units)，输入集标记为{x0,x1,…,xt,xt+1,…}，而输出单元(Output units)的输出集则被标记为{y0,y1,…,yt,yt+1.,..}。RNNs还包含隐藏单元(Hidden units)，我们将其输出集标记为{s0,s1,…,st,st+1,…}，这些隐藏单元完成了最为主要的工作。你会发现，在图中：有一条单向流动的信息流是从输入单元到达隐藏单元的，与此同时另一条单向流动的信息流从隐藏单元到达输出单元。在某些情况下，RNNs会打破后者的限制，引导信息从输出单元返回隐藏单元，这些被称为“Back Projections”，并且隐藏层的输入还包括上一隐藏层的状态，即隐藏层内的节点可以自连也可以互连。&lt;/p&gt;

&lt;p&gt;  上图将循环神经网络进行展开成一个全神经网络。例如，对一个包含5个单词的语句，那么展开的网络便是一个五层的神经网络，每一层代表一个单词。对于该网络的计算过程如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;xt表示第t,t=1,2,3…步(step)的输入。比如，x1为第二个词的one-hot向量(根据上图，x0为第一个词)；
  PS：使用计算机对自然语言进行处理，便需要将自然语言处理成为机器能够识别的符号，加上在机器学习过程中，需要将其进行数值化。而词是自然语言理解与处理的基础，因此需要对词进行数值化，词向量(Word Representation，Word embeding)[1]便是一种可行又有效的方法。何为词向量，即使用一个指定长度的实数向量v来表示一个词。有一种种最简单的表示方法，就是使用One-hot vector表示单词，即根据单词的数量|V|生成一个|V| * 1的向量，当某一位为一的时候其他位都为零，然后这个向量就代表一个单词。缺点也很明显：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;由于向量长度是根据单词个数来的，如果有新词出现，这个向量还得增加，麻烦！(Impossible to keep up to date);&lt;/li&gt;
      &lt;li&gt;主观性太强(subjective)&lt;/li&gt;
      &lt;li&gt;这么多单词，还得人工打labor并且adapt，想想就恐&lt;/li&gt;
      &lt;li&gt;最不能忍受的一点便是很难计算单词之间的相似性。 现在有一种更加有效的词向量模式，该模式是通过神经网或者深度学习对词进行训练，输出一个指定维度的向量，该向量便是输入词的表达。如word2vec（可参照&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/03/12/Word2Vec.html&quot;&gt;上一篇博文&lt;/a&gt;）&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;st为隐藏层的第t步的状态，它是网络的记忆单元。 st根据当前输入层的输出与上一步隐藏层的状态进行计算。st=f(Uxt+Wst−1)，其中f一般是非线性的激活函数，如tanh或ReLU，在计算s0时，即第一个单词的隐藏层状态，需要用到s−1，但是其并不存在，在实现中一般置为0向量；&lt;/p&gt;

&lt;p&gt;ot是第t步的输出，如下个单词的向量表示，ot=softmax(Vst).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;需要注意的是：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;你可以认为隐藏层状态st是网络的记忆单元. st包含了前面所有步的隐藏层状态。而输出层的输出ot只与当前步的st有关，在实践中，为了降低网络的复杂度，往往st只包含前面若干步而不是所有步的隐藏层状态；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在传统神经网络中，每一班个网络层的参数是不共享的。而&lt;strong&gt;在RNNs中，每输入一步，每一层各自都共享参数U,V,W。其反映着RNNs中的每一步都在做相同的事，只是输入不同，因此大大地降低了网络中需要学习的参数&lt;/strong&gt;；这里并没有说清楚，解释一下，传统神经网络的参数是不共享的，并不是表示对于每个输入有不同的参数，而是将RNN是进行展开，这样变成了多层的网络，如果这是一个多层的传统神经网络，那么xt到st之间的U矩阵与xt+1到st+1之间的U是不同的，而RNNs中的却是一样的，同理对于s与s层之间的W、s层与o层之间的V也是一样的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;上图中每一步都会有输出，但是每一步都要有输出并不是必须的。比如，我们需要预测一条语句所表达的情绪，我们仅仅需要关系最后一个单词输入后的输出，而不需要知道每个单词输入后的输出。同理，每步都需要输入也不是必须的。&lt;strong&gt;RNNs的关键之处在于隐藏层，隐藏层能够捕捉序列的信息。&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;为什么可以参数共享的简单理解&quot;&gt;为什么可以参数共享的简单理解:&lt;/h3&gt;

&lt;p&gt;用通俗的例子解释：&lt;/p&gt;

&lt;p&gt;演奏音乐时，乐器将力转成相应的震动产生声音，而整个演奏拥有一个主旋律贯穿全曲。其中乐器的物理特性就相当于参数，同一乐器在各个时刻物理特性在各个时刻都是共享的。其内在也有一个隐藏的主旋律基准（主题），旋律信息（上一个状态乘与主题）与音乐信息（输入称与参数）共同决定下一时刻的实际声音。&lt;/p&gt;

&lt;p&gt;或者是：捏陶瓷：不同角度相当于不同的时刻&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/recurrent_neural_network_s2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;若用前馈网络：网络训练过程相当于不用转盘，而是徒手将各个角度捏成想要的形状。不仅工作量大，效果也难以保证。&lt;/p&gt;

&lt;p&gt;若用递归网络：网络训练过程相当于在不断旋转的转盘上，以一种手势捏造所有角度。工作量降低，效果也可保证。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;而对于RNN，我的理解就是对于一个句子或者文本，那个&lt;strong&gt;参数可以看成是语法结构或者一般规律，而下一个单词的预测必须是上一个单词和一般规律或者语法结构向结合的。我们知道，语法结构和一般规律在语言当中是共享的，所以，参数自然就是共享的！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;rnn的训练&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对于RNN是的训练和对传统的ANN训练一样。同样使用BP误差反向传播算法，不过有一点区别。如果将RNNs进行网络展开，那么参数W,U,V是共享的，而传统神经网络却不是的。并且在使用梯度下降算法中，每一步的输出不仅依赖当前步的网络，并且还以来前面若干步网络的状态。比如，在t=4时，我们还需要向后传递三步，以及后面的三步都需要加上各种的梯度。该学习算法称为&lt;strong&gt;Backpropagation Through Time (BPTT)&lt;/strong&gt;。后面会对BPTT进行详细的介绍。需要意识到的是，在vanilla RNNs训练中，BPTT无法解决长时依赖问题(即当前的输出与前面很长的一段序列有关，一般超过十步就无能为力了)，因为BPTT会带来所谓的梯度消失或梯度爆炸问题(the vanishing/exploding gradient problem)。当然，有很多方法去解决这个问题，如LSTMs便是专门应对这种问题的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意在语言模型（RNNLM）中，若输入的序列的是A，B，C，D那么训练的label序列就是B，C，D，D，然后在此基础上进行反向传播&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;或者简单的理解：&lt;/p&gt;

&lt;p&gt;在上面的图中，一大块神经网络，A，观察一些输入xt，输出一个值ht。循环允许信息从网络的一步传到下一步。&lt;/p&gt;

&lt;p&gt;这些循环使得循环神经网络似乎有点神秘。然而，如果你想多一点，其实它们跟一个正常的神经网络没有神秘区别。一个循环神经网络可以被认为是同一个网络的多重副本，每个部分会向继任者传递一个信息。想一想，如果我们展开了循环会发生什么：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/recurrent_neural_network_s3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个链式本质揭示了，循环神经网络跟序列和列表是紧密相关的。它们是神经网络为这类数据而生的自然架构&lt;/p&gt;

&lt;h3 id=&quot;cnn-and-rnn&quot;&gt;CNN and RNN&lt;/h3&gt;

&lt;p&gt;我们需要记住的是，深度是怎么减少参数的，很大原因就是参数共享，而&lt;strong&gt;CNN是 在空间上共享参数，RNN是在时间上（顺序上）共享参数：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/recurrent_neural_network_s4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;long-term依赖问题&quot;&gt;Long-Term依赖问题&lt;/h4&gt;

&lt;p&gt;有时候，我们只需要查看最近的信息来执行现在的任务，例如，考虑一个语言模型试图基于先前的词预测下一个词。如果我们要预测“the clouds are in the sky”，我们不需要其他更遥远的上下文 —— 非常明显，下一个词就应该是sky。在这样的例子中，相关信息和目的地之间的距离是很小的。RNN可以学着区使用过去的信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/recurrent_neural_network_s5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但也有一些情况是我们需要更多上下文的。考虑预测这个句子中最后一个词：“I grew up in France… I speak fluent French.” 最近的信息表明下一个词可能是一种语言的名字，但如果我们想要找出是哪种语言，我们需要从更久远的地方获取France的上下文。相关信息和目标之间的距离完全可能是非常巨大的。&lt;/p&gt;

&lt;p&gt;不幸的是，随着距离的增大，RNN变得不能够连接信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/recurrent_neural_network_s6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;长期依赖导致的神经网络困境&lt;/p&gt;

&lt;p&gt;理论上，RNN是绝对能够处理这样的“长期依赖的”。人类可以仔细地从这些词中找到参数然后解决这种形式的一些雏形问题。然而，实践中，RNN似乎不能够学习到这些。 Hochreiter (1991) [German] 和 Bengio, et al. 1994年曾探索过这个问题，他们发现了一些非常根本的导致RNN难以生效的原因。&lt;/p&gt;

&lt;p&gt;万幸的是，LSTM没有这个问题！也就是说不会产生由于太多层导致的梯度爆炸或者梯度消亡的问题！&lt;/p&gt;

&lt;h2 id=&quot;lstmlong-short-term-memory&quot;&gt;LSTM（Long Short-Term Memory）&lt;/h2&gt;

&lt;h2 id=&quot;lstm背后的核心思想&quot;&gt;LSTM背后的核心思想&lt;/h2&gt;

&lt;p&gt;LSTM的关键在于cell的状态，也就是图中贯穿顶部的那条水平线。&lt;/p&gt;

&lt;p&gt;cell的状态像是一条传送带，它&lt;strong&gt;贯穿整条链，其中只发生一些小的线性作用。信息流过这条线而不改变是非常容易&lt;/strong&gt;的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/lstm_mylearn1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;LSTM确实有能力&lt;strong&gt;移除或增加信息&lt;/strong&gt;到cell状态中，由被称为门的结构精细控制。&lt;/p&gt;

&lt;p&gt;门是一种让信息可选地通过的方法。它们&lt;strong&gt;由一个sigmoid神经网络层和一个点乘操作组成。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/lstm_mylearn2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;sigmod层输出[0, 1]区间内的数，描述了每个部分中应该通过的比例。输出0意味着“什么都不能通过”，而输出1意味着“让所有东西通过！”。&lt;/p&gt;

&lt;p&gt;一个LSTM有四个这样的门，以保护和控制cell的状态。&lt;/p&gt;

&lt;h2 id=&quot;深入浅出lstm&quot;&gt;深入浅出LSTM&lt;/h2&gt;

&lt;p&gt;我们的LSTM的&lt;strong&gt;第一步是决定我们需要从cell状态中扔掉什么样的信息。这个决策由一个称为“遗忘门”的sigmoid层做出&lt;/strong&gt;。它观察h(t-1)和x(t)，位cell状态Ct-1中每个number输出一个0和1之间的数。1代表“完全保留这个值”，而0代表“完全扔掉这个值”。&lt;/p&gt;

&lt;p&gt;让我们回到我们那个基于上文预测最后一个&lt;strong&gt;词的语言模型。在这样一个问题中，cell的状态可能包含当前主题的种类，这样才能使用正确的名词。当我们看到一个新的主题的时候，我们会想要遗忘旧的主题的种类。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/lstm_mylearn3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第二步是决定我们需要在cell state里存储什么样的信息&lt;/strong&gt;。这个问题有两个部分。第一，一个sigmoid层调用“输入门”以决定哪些数据是需要更新的。然后，一个tanh层为新的候选值创建一个向量C~t，这些值能够加入state中。下一步，我们要将这两个部分合并以创建对state的更新。&lt;/p&gt;

&lt;p&gt;在我们的语言模型的例子中，我们想要把&lt;strong&gt;主题的种类加入到cell state中，以替代我们要遗忘的旧的种类。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/lstm_mylearn4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在是时候更新旧的cell stateCt-1到新的cell stateCt。前一步已经决定了我们需要做的事情，我们只需要实现它。&lt;/p&gt;

&lt;p&gt;我们把&lt;strong&gt;旧的state与ft相乘，遗忘我们先前决定遗忘的东西，然后我们加上it * C`(t)。这是新的候选值，受我们对每个状态值的更新度约束而缩放。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在语言模型的例子中，这&lt;strong&gt;就是我们真正扔掉旧主题种类，并增加新的信息的地方，&lt;/strong&gt;正如我们之前所决定的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/lstm_mylearn5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后，我们需要&lt;strong&gt;决定要输出的东西。这个输出基于我们的cell state，&lt;/strong&gt;但会是一个过滤版本。首先，我们运行一个sigmoid层，以决定cell state中的那个部分是我们将要输出的。然后我们把cell state放进tanh（将数值压到-1和1之间），最后将它与sigmoid门的输出相乘，这样我们就只输出了我们想要的部分了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/lstm_mylearn6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;语言模型的例子中，由于它仅关注一个主题，它可能会输出与一个动词相关的信息，以防后面还有其他的词。比如，它可能输出这个主题是单数还是复数，让我们知道如果后面还有东西，动词才会对应出现。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/lstm_mylearn7.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;到目前为止，我们所讲述的只是很普通的lstm，其实它有非常非常多的变种，详情了解可以看下这篇&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/03/17/cs224d_RNN,GRU,LSTM.html&quot;&gt;cs224d的学习笔记&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;关于lstm有这样一篇博客讲的很好：&lt;a href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot;&gt;地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;对应的中文版&lt;a href=&quot;https://github.com/yzhihao/GDLnotes/blob/master/note/lesson-4/unstand_lstm.md&quot;&gt;中文版&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;lstm-如何来避免梯度弥撒和梯度爆炸&quot;&gt;LSTM 如何来避免梯度弥撒和梯度爆炸？&lt;/h3&gt;

&lt;p&gt;LSTM只能避免RNN的梯度消失（gradient vanishing）;梯度膨胀(gradient explosion)不是个严重的问题，一般靠裁剪后的优化算法即可解决，比如gradient clipping（如果梯度的范数大于某个给定值，将梯度同比收缩），下面简单说说LSTM如何避免梯度消失&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/vanish gradient.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;beam-search&quot;&gt;Beam Search&lt;/h3&gt;
&lt;p&gt;有了上面的模型之后，我们可以根据上文来推测下文，甚至创造下文，预测，筛选最大概率的词，喂回，继续预测……&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/recurrent_neural_network_s11.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;我们可以每次只预测一个字母，but this is greedy，每次都挑最好的那个&lt;/li&gt;
  &lt;li&gt;也可以每次多预测几步，然后挑整体概率较高的那个，以减少偶然因素的影响&lt;/li&gt;
  &lt;li&gt;但这样需要生成的sequence会指数增长&lt;/li&gt;
  &lt;li&gt;因此我们在多预测几步的时候，只为概率比较高的几个候选项做预测，that’s beam search.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;翻译与识图&quot;&gt;翻译与识图&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;RNN将variable length sequence问题变成了fixed length vector问题，同时因为实际上我们能利用vector进行预测，我们也可以将vector变成sequence&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;我们可以利用这一点，输入一个序列，到一个RNN里，将输出输入到另一个逆RNN序列，形成另一种序列，比如，语言翻译&lt;/li&gt;
  &lt;li&gt;如果我们将CNN的输出接到一个RNN，就可以做一种识图系统&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 12 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/12/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/12/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>理解word2woc</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#理解word2woc&quot; id=&quot;markdown-toc-理解word2woc&quot;&gt;理解word2woc&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#embeddings&quot; id=&quot;markdown-toc-embeddings&quot;&gt;Embeddings&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#什么是word-embedding&quot; id=&quot;markdown-toc-什么是word-embedding&quot;&gt;什么是word embedding&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#向量空间模型&quot; id=&quot;markdown-toc-向量空间模型&quot;&gt;向量空间模型&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#word2vec&quot; id=&quot;markdown-toc-word2vec&quot;&gt;Word2Vec&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cbowcontinuous-bag-of-words&quot; id=&quot;markdown-toc-cbowcontinuous-bag-of-words&quot;&gt;CBOW(Continuous Bag-of-Words)&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#word2vec向量到底在哪儿&quot; id=&quot;markdown-toc-word2vec向量到底在哪儿&quot;&gt;word2vec向量到底在哪儿?&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#cbow--skip-gram模型的加速策略一hierarchical-softmax&quot; id=&quot;markdown-toc-cbow--skip-gram模型的加速策略一hierarchical-softmax&quot;&gt;CBOW / Skip-gram模型的加速策略（一）：Hierarchical Softmax&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#cbow--skip-gram模型的加速策略二negative-sampling&quot; id=&quot;markdown-toc-cbow--skip-gram模型的加速策略二negative-sampling&quot;&gt;CBOW / Skip-gram模型的加速策略（二）：Negative Sampling&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#t-sne&quot; id=&quot;markdown-toc-t-sne&quot;&gt;t-SNE&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#类比&quot; id=&quot;markdown-toc-类比&quot;&gt;类比&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;理解word2woc&quot;&gt;理解word2woc&lt;/h1&gt;

&lt;h2 id=&quot;embeddings&quot;&gt;Embeddings&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;为什么要用词向量：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;自然语言处理系统通常将词汇作为离散的单一符号，例如 “cat” 一词或可表示为 Id537 ，而 “dog” 一词或可表示为 Id143。这些符号编码毫无规律，无法提供不同词汇之间可能存在的关联信息。换句话说，在处理关于 “dogs” 一词的信息时，模型将无法利用已知的关于 “cats” 的信息（例如，它们都是动物，有四条腿，可作为宠物等等）。可见，将词汇表达为上述的独立离散符号将进一步导致数据稀疏，使我们在训练统计模型时不得不寻求更多的数据。而词汇的向量表示将克服上述的难题。&lt;/p&gt;

&lt;h2 id=&quot;什么是word-embedding&quot;&gt;什么是word embedding&lt;/h2&gt;

&lt;p&gt;word embedding的意思是：给出一个文档，文档就是一个单词序列比如 “A B A C B F G”, 希望对文档中每个不同的单词都得到一个对应的向量(往往是低维向量)表示。比如，对于这样的“A B A C B F G”的一个序列，也许我们最后能得到：A对应的向量为[0.1 0.6 -0.5]，B对应的向量为[-0.2 0.9 0.7]  （此处的数值只用于示意）&lt;/p&gt;

&lt;p&gt;之所以希望把每个单词变成一个向量，目的还是为了方便计算，比如“求单词A的同义词”，就可以通过“求与单词A在cos距离下最相似的向量”来做到。&lt;/p&gt;

&lt;p&gt;需要注意的是和下面要讲的word2vec的联系和区别，&lt;strong&gt;word embedding 是一个将词向量化的概念，为区别one-hot的词向量，可翻译成词嵌入。而word2vec是谷歌提出一种word embedding 的工具或者算法集合&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;向量空间模型&quot;&gt;向量空间模型&lt;/h3&gt;

&lt;p&gt;向量空间模型 (VSMs)将词汇表达（嵌套）于一个连续的向量空间中，语义近似的词汇被映射为相邻的数据点。向量空间模型在自然语言处理领域中有着漫长且丰富的历史，不过几乎所有利用这一模型的方法都依赖于 分布式假设，其核心思想为出现于上下文情景中的词汇都有相类似的语义。采用这一假设的研究方法大致分为以下两类：&lt;strong&gt;基于计数的方法 (e.g. 潜在语义分析， Glove)， 和 预测方法 (e.g. 神经概率化语言模型，word2vec).&lt;/strong&gt;关于这个可以看下一篇&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/03/15/cs224d.html&quot;&gt;关于word vectors的cs224d笔记&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;简而言之：&lt;strong&gt;基于计数的方法计算某词汇与其邻近词汇在一个大型语料库中共同出现的频率及其他统计量，然后将这些统计量映射到一个小型且稠密的向量中。预测方法则试图直接从某词汇的邻近词汇对其进行预测，在此过程中利用已经学习到的小型且稠密的嵌套向量。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在这里，我们主要讨论的是&lt;strong&gt;神经概率化语言模型&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;word2vec&quot;&gt;Word2Vec&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://nooverfit.com/wp/wp-content/uploads/2016/09/screen-shot-2015-04-10-at-4-16-00-pm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;最简单的理解，其实&lt;strong&gt;word2vec是只有一个隐层的全连接神经网络&lt;/strong&gt;, 用来预测给定单词的关联度大的单词.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/yzhihao/GDLnotes/raw/master/res/predictword.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面看图说下整体步骤是怎么样的：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;在输入层，一个词被转化为词向量！&lt;/li&gt;
  &lt;li&gt;然后在第一个隐层，输入的是一个WV+b（v就是输入的词向量，w，b是参数），&lt;strong&gt;做一个线性模型,注意已这里只是简单的映射，并没有非线性激活函数,当然一个神经元可以是线性的，这时就相当于一个线性回归函数。&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;第三层可以简单看成一个分类器吧，最后输出的是那是词的概率&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;好了，到了举例子时间：&lt;/p&gt;

&lt;p&gt;如果我们的语料仅仅有这3句话: “the dog saw a cat”, “the dog chased the cat”, “the cat climbed a tree”. 那么单词字典只有8个单词: “the”, “dog”, “saw”, “a”, “cat”, “chased”, “climbed”, “tree”.&lt;/p&gt;

&lt;p&gt;那么V=8, 输入层的初始就可以是:&lt;/p&gt;

&lt;p&gt;[1, 1, 1, 1, 1, 1, 1, 1] 代表: [“the”, “dog”, “saw”, “a”, “cat”, “chased”, “climbed”, “tree”]&lt;/p&gt;

&lt;p&gt;输入[“”, “dog“, “”,  “”,  “”,  “”,  “”,  “”] 可以表示为: [0, 1, 0, 0, 0, 0, 0, 0]&lt;/p&gt;

&lt;p&gt;输入[“”, “”,  “saw“,  “” ,  “”,  “”,  “”,  “”] 可以表示为: [0, 0, 1, 0, 0, 0, 0,0]&lt;/p&gt;

&lt;p&gt;如果是在字典中有的, 就用1表示&lt;/p&gt;

&lt;p&gt;W0 的大小是NxV, 于是, 通过训练完毕的W&lt;sub&gt;I&lt;/sub&gt; 和W&lt;sub&gt;0&lt;/sub&gt; , 只要输入单词, 就能预测出最符合这个上下文的下一个单词. 当然这个单词一定是字典中有的, 就是说在大小V中的字典中, 选出概率最大的那个单词.&lt;/p&gt;

&lt;p&gt;但需要注意的是：Word2vec是一种可以进行高效率词嵌套学习的预测模型。其有两种变体是现在比较常用的，分别为：连续词袋模型（CBOW）及Skip-Gram模型。从算法角度看，这两种方法非常相似，其区别为&lt;strong&gt;CBOW根据源词上下文词汇（’the cat sits on the’）来预测目标词汇（例如，‘mat’），而Skip-Gram模型做法相反，它通过目标词汇来预测源词汇。Skip-Gram模型采取CBOW的逆过程的动机在于：CBOW算法对于很多分布式信息进行了平滑处理（例如将一整段上下文信息视为一个单一观察量）。很多情况下，对于小型的数据集，这一处理是有帮助的。相形之下，Skip-Gram模型将每个“上下文-目标词汇”的组合视为一个新观察量，这种做法在大型数据集中会更为有效。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;词表中每个词的词向量都存在一个矩阵中。由于存在两套词向量，因此就有两个矩阵：输入词矩阵n&lt;em&gt;V的矩阵，&lt;strong&gt;其每一列都是一个词作为周围词时的词向量；&lt;/strong&gt;输出词是一个v&lt;/em&gt;n的矩阵，&lt;strong&gt;其每一行都是一个词作为中心词时的词向量。&lt;/strong&gt;比如说若想取出词作为周围词时的词向量，只要知道词在词表中的编号即可，取出的操作相当于用输入词矩阵乘以词的one-hot representation。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;也就是说，每个词有两个向量，在最后在平均或其他操作组合成一个向量&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;讲完这些，下面来讲讲Word2vec的两个变体模型，先讲不加速的，然后再讲其加速改进！&lt;/p&gt;

&lt;h2 id=&quot;cbowcontinuous-bag-of-words&quot;&gt;CBOW(Continuous Bag-of-Words)&lt;/h2&gt;
&lt;p&gt;不带加速的CBOW模型是一个两层结构，通过上下文来预测中心词——&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;输入层：n 个节点，上下文共 2m 个词的词向量的平均值,其中，这里的n表示词向量的维数，&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;表示词典的基数&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;输入层到输出层的连接边：输出词矩阵 U&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;×n ；&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;输出层：&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;个节点。第 i 个节点代表中心词是词 wi_ 的概率。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;如果要“看做”三层结构的话，可以认为——&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;输入层：2m×&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;个节点，上下文共 2m 个词的one-hot representation&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;输入层到投影层到连接边：输入词矩阵 Vn×&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;；&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;投影层：n 个节点，上下文共 2m 个词的词向量的平均值；&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;投影层到输出层的连接边：输出词矩阵 U&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;×n ；&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;输出层：&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;个节点。第 i 个节点代表中心词是词 wi_ 的概率。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;这样表述相对清楚，将one-hot到word embedding那一步描述了出来。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://images2015.cnblogs.com/blog/1008922/201608/1008922-20160830124440402-325932526.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;word2vec向量到底在哪儿&quot;&gt;word2vec向量到底在哪儿?&lt;/h2&gt;

&lt;p&gt;其实这些词向量就是神经网络里的参数，生成词向量的过程就是一个参数更新的过程。那么究竟是什么参数呢？就是这个网络的第一层和第二层：将one-hot向量转换成低维词向量的这一层（虽然大家都不称之为一层，但在我看来就是一层），因为word2vec的输入是one-hot。one-hot可看成是&lt;code class=&quot;highlighter-rouge&quot;&gt;1*N&lt;/code&gt;（N是词总数）的矩阵，与这个系数矩阵（&lt;code class=&quot;highlighter-rouge&quot;&gt;N*M&lt;/code&gt;, M是word2vec词向量维数）相乘之后就可以得到1*M的向量，这个向量就是这个词对应的词向量了。那么对于那个&lt;code class=&quot;highlighter-rouge&quot;&gt;N*M&lt;/code&gt;的矩阵，每一行就对应了每个单词的词向量。接下来就是进入神经网络，然后通过训练不断更新这个矩阵。&lt;strong&gt;注意这里得到两个词向量，之后还要把两个词向量变成一个&lt;/strong&gt;。关于这个还可以查看&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/03/15/cs224d.html&quot;&gt;这篇博文&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;cbow--skip-gram模型的加速策略一hierarchical-softmax&quot;&gt;CBOW / Skip-gram模型的加速策略（一）：Hierarchical Softmax&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/word2woc154.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/word2woc155.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以词表中的全部词作为叶子节点，词频作为节点的权，构建Huffman树，作为输出。Huffman树是二叉树，在叶子节点及叶子节点的权给定的情况下，该树的带权路径长度最短（一个节点的带权路径长度指根节点到该节点的路径长度乘以该节点的权，树的带权路径长度指全部叶子节点的带权路径长度之和）。&lt;strong&gt;直观上可以看出，叶子节点的权越大，则该叶子节点就应该离根节点越近。因此对于模型来说就是，词频越高的词，距离根节点就越近。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;关于Hierarchical Softmax详细可以查看&lt;a href=&quot;http://blog.csdn.net/itplus/article/details/37969979&quot;&gt;这篇博文&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;cbow--skip-gram模型的加速策略二negative-sampling&quot;&gt;CBOW / Skip-gram模型的加速策略（二）：Negative Sampling&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;现在用到比较多的是这种策略&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;第二种加速策略是Negative Sampling（NEG，负采样），这是Noise-Contrastive Estimation（NCE，噪声对比估计）的简化版本：&lt;strong&gt;把语料中的一个词串的中心词替换为别的词，构造语料 𝔻D 中不存在的词串作为负样本。因此在这种策略下，优化目标变为了：最大化正样本的概率，同时最小化负样本的概率。&lt;/strong&gt;对于一个词串 (w,c)(w,c) （ cc 表示 ww 的上下文），用二项Logistic回归模型对其是正样本的概率建模：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/word2woc1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/word2woc2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面就第二种加速举个例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/word2woc3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/word2woc4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;t-sne&quot;&gt;t-SNE&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;查看某个词在embedding里的最近邻居可以看到单词间的语义接近关系&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;将vector构成的空间降维，可以更高效地查找最近单词，但降维过程中要保持邻居关系（原来接近的降维后还要接近） t-SNE就是这样一种有效的方法&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;类比&quot;&gt;类比&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;实际上我们能得到的不仅是单词的邻接关系，由于将单词向量化，可以对单词进行计算&lt;/li&gt;
  &lt;li&gt;可以通过计算进行语义加减，语法加减&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/yzhihao/GDLnotes/raw/master/res/analogies.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://github.com/yzhihao/GDLnotes/raw/master/res/vecanalogy.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《深度学习》-Bengio&lt;br /&gt;
《统计学习方法》-李航&lt;br /&gt;
《机器学习》-周志华&lt;br /&gt;
《机器学习实战》-Peter Harrington&lt;br /&gt;
斯坦福大学公开课-机器学习&lt;br /&gt;
网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;2017031201&quot; data-title=&quot; word2woc&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Sun, 12 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/12/Word2Vec.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/12/Word2Vec.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>生成模型，判别模型，贝叶斯算法</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#生成模型判别模型贝叶斯算法&quot; id=&quot;markdown-toc-生成模型判别模型贝叶斯算法&quot;&gt;生成模型，判别模型，贝叶斯算法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#贝叶斯&quot; id=&quot;markdown-toc-贝叶斯&quot;&gt;贝叶斯&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#朴素贝叶斯假设&quot; id=&quot;markdown-toc-朴素贝叶斯假设&quot;&gt;朴素贝叶斯假设&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#拉普拉斯平滑laplace-smoothing&quot; id=&quot;markdown-toc-拉普拉斯平滑laplace-smoothing&quot;&gt;拉普拉斯平滑（Laplace smoothing）&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;生成模型判别模型贝叶斯算法&quot;&gt;生成模型，判别模型，贝叶斯算法&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;生成方法的特点：上面说到，**生成方法学习联合概率密度分布P(X,Y)，所以就可以从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度。但它不关心到底划分各类的那个分类边界在哪。生成方法可以还原出联合概率分布P(Y&lt;/td&gt;
          &lt;td&gt;X)，而判别方法不能。生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快的收敛于真实模型，当存在隐变量时，仍可以用生成方法学习。此时判别方法就不能用。**&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;判别方法的特点：判别方法直接学习的是决策函数Y=f(X)或者条件概率分布P(Y&lt;/td&gt;
          &lt;td&gt;X)。不能反映训练数据本身的特性。但&lt;strong&gt;它寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。直接面对预测，往往学习的准确率更高。&lt;/strong&gt;由于直接学习P(Y&lt;/td&gt;
          &lt;td&gt;X)或P(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;需要注意的是，在分类算法中，&lt;strong&gt;大部分都是判别模型。因为如果使用生成模型，那么，我们就需要去对p(x)建模，但这增加了我们的工作量&lt;/strong&gt;，这让我们很不爽（除了上面说的那个估计得到P(X)可能不太准确外）。实际上，&lt;strong&gt;因为数据的稀疏性，导致我们都是被强迫地使用弱独立性假设去对p(x)建模的，所以就产生了局限性&lt;/strong&gt;。所以我们更趋向于直观的使用判别模型去分类。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;举个例子，贝叶斯就是一种生成模型算法，生成学习算法：GLA首先确定p(x|y)和p(y)，由贝叶斯准则得到后验分布&lt;img src=&quot;http://images.cnitblog.com/blog/405927/201412/050156335615212.png&quot; alt=&quot;&quot; /&gt;,通过最大后验准则进行预测，&lt;img src=&quot;http://images.cnitblog.com/blog/405927/201412/050156342172611.png&quot; alt=&quot;&quot; /&gt;
对y进行分类，建立多个模型，并求其概率。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/8195017&quot;&gt;这篇博文&lt;/a&gt;详细讲述了生成模型和判别模型的一些联系和区别，值得一看。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;贝叶斯&quot;&gt;贝叶斯&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;贝叶斯定理是一种“根据数据集内容的变化而更新假设概率”的方法。&lt;/li&gt;
  &lt;li&gt;ps：上面引号中的内容用另一种方式表达就是：假设的概率随看到的数据而变化。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;于是对于事件A和B，贝叶斯定理的表达式可写成：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/byesi.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;P(A|B) = P(A)P(B|A) / P(B)在这种解释里，每项的意义如下：
    1. P(A)：先验概率。即：在的得到新数据前某一假设的概率。
    2. P(A|B)：后验概率。即：在看到新数据后，要计算的该假设的概率。
    3. P(B|A）：似然度。即：在该假设下，得到这一数据的概率。
    4. P(B)：标准化常亮。即：在任何假设下得到这一数据的概率。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;先验概率P(A)：取出饼干的碗是碗1的概率。结果是1/2。
后验概率P(A|B)：得到的是香草饼干，且该饼干从碗1中拿到。待求。
似然度P(B|A：在碗1中得到香草饼干的概率。结果是3/4。
标准化常量P(B)：饼干是香草饼干的概率。结果是5/8。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;在概率论中，我们就学过，其实贝叶斯就是结果推向过程的一种方法，它的本质还是条件概率&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;问：为什么可以去掉贝叶斯的分母？&lt;/strong&gt;
&lt;strong&gt;答：因为那个表示的总概率，而标准化常量P（B）都是相同的，它是一个标准化常量，可以忽略&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;朴素贝叶斯假设&quot;&gt;朴素贝叶斯假设&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;设x(i)对于给定的条件y是独立的，这个假设叫做朴素贝叶斯假设，即一个词是在邮件中出现的事件和其他词是在邮件中出现事件是独立的。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;显然为假，所以称朴素贝叶斯&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;xi….x3,x4,⋅xn，不同的邮件n是相同的，指的是字典单词的总个数。&lt;/p&gt;

&lt;h3 id=&quot;拉普拉斯平滑laplace-smoothing&quot;&gt;拉普拉斯平滑（Laplace smoothing）&lt;/h3&gt;
&lt;p&gt;目的：&lt;strong&gt;改进朴素贝叶斯算法的不足:避免分子出现为0的情况&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;下面出现的符号还是以上面垃圾邮件的例子为准。
p(x1| c1)是指的:在垃圾邮件c1 这个类别中，单词x1出现的概率。（x1 是待考察的邮件中的某个单词）
定义符号：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;n1 ：在所有垃圾邮件中单词x1 出现的次数。如果x1 没有出现过，则n1 = 0。&lt;/li&gt;
  &lt;li&gt;n：属于c1 类的所有文档的出现过的单词总数目。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;得到公式
   	&lt;code class=&quot;highlighter-rouge&quot;&gt;p(x1|c1)= n1 / n&lt;/code&gt;
而拉普拉斯平滑就是将上式修改为：
  ` p(x1|c1)= (n1 + 1) / (n + N)&lt;code class=&quot;highlighter-rouge&quot;&gt;
   &lt;/code&gt;p(x2|c1)= (n2 + 1) / (n + N)&lt;code class=&quot;highlighter-rouge&quot;&gt;
   &lt;/code&gt;……`&lt;/p&gt;

&lt;p&gt;其中，N是所有单词的数目。修正分母是为了保证概率和为1。&lt;/p&gt;

&lt;p&gt;举个例子：中国男足vs韩国男足的前5场的比分是0:5，那预测第六场中国队胜出的概率是多少时难道给0/5，这绝壁不行。所以分子分母都加1，变成1/6。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;由于朴素贝叶斯网络用的不多，现在还不打打算讲它。以后有机会在讲吧！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《深度学习》-Bengio&lt;br /&gt;
《统计学习方法》-李航&lt;br /&gt;
《机器学习》-周志华&lt;br /&gt;
《机器学习实战》-Peter Harrington&lt;br /&gt;
斯坦福大学公开课-机器学习&lt;br /&gt;
网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201701181&quot; data-title=&quot;feature engineering&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Sun, 12 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/12/%E7%94%9F%E6%88%90-%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/12/%E7%94%9F%E6%88%90-%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>paper-Optimization</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#optimization&quot; id=&quot;markdown-toc-optimization&quot;&gt;Optimization&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#momentum-and-nesterovs-accelerated-gradient&quot; id=&quot;markdown-toc-momentum-and-nesterovs-accelerated-gradient&quot;&gt;Momentum and Nesterov’s Accelerated Gradient&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#adam&quot; id=&quot;markdown-toc-adam&quot;&gt;adam&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;optimization&quot;&gt;Optimization&lt;/h1&gt;

&lt;h2 id=&quot;momentum-and-nesterovs-accelerated-gradient&quot;&gt;Momentum and Nesterov’s Accelerated Gradient&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;论文原文：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/momentum1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/momentum2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/momentum3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/momentum4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面截取了一大段，看起来有些突兀，但我觉的这些都是非常重要的。这里说明了普通动量更新和Nesterov动量更新的主要思想。&lt;/p&gt;

&lt;h2 id=&quot;adam&quot;&gt;adam&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/adam1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;算法的整体流程如上图，它看起来像是RMSProp的动量版。简化的代码是下面这样。而关于RMSProp，请看这篇博文。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/adam2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;以上就是这个算法的详细解释，主要在讲的就是怎么自适应学习率的变化&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下面就是这个算法的详细的证明过程：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/adam3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/adam4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 11 Mar 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/11/paper-Optimization.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/03/11/paper-Optimization.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>简单聚类</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#简单聚类&quot; id=&quot;markdown-toc-简单聚类&quot;&gt;简单聚类&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#k-means算法&quot; id=&quot;markdown-toc-k-means算法&quot;&gt;k-means算法&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#算法步骤&quot; id=&quot;markdown-toc-算法步骤&quot;&gt;算法步骤&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#k-means算法是否一定收敛&quot; id=&quot;markdown-toc-k-means算法是否一定收敛&quot;&gt;k-means算法是否一定收敛&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#k-means算法的凸性质&quot; id=&quot;markdown-toc-k-means算法的凸性质&quot;&gt;k-means算法的凸性质&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#k如何选择&quot; id=&quot;markdown-toc-k如何选择&quot;&gt;K如何选择&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#聚类中心如何初始化&quot; id=&quot;markdown-toc-聚类中心如何初始化&quot;&gt;聚类中心如何初始化&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#k-means的公式化解释&quot; id=&quot;markdown-toc-k-means的公式化解释&quot;&gt;K-means的公式化解释&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#k-means聚类方法总结&quot; id=&quot;markdown-toc-k-means聚类方法总结&quot;&gt;K-means聚类方法总结&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#k-means的一个小改进k中值聚类&quot; id=&quot;markdown-toc-k-means的一个小改进k中值聚类&quot;&gt;K-means的一个小改进（K中值聚类）&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#混合高斯模型&quot; id=&quot;markdown-toc-混合高斯模型&quot;&gt;混合高斯模型&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#gmm的em算法的推导&quot; id=&quot;markdown-toc-gmm的em算法的推导&quot;&gt;GMM的EM算法的推导&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#gmm的初始化&quot; id=&quot;markdown-toc-gmm的初始化&quot;&gt;GMM的初始化&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#高斯混合模型与k-means异同点&quot; id=&quot;markdown-toc-高斯混合模型与k-means异同点&quot;&gt;高斯混合模型与K-means异同点&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;简单聚类&quot;&gt;简单聚类&lt;/h1&gt;

&lt;h2 id=&quot;k-means算法&quot;&gt;k-means算法&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;来，今天讲下应该是最简单的一个聚类算法，K-means算法,很好上手，很好实现，&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;算法步骤&quot;&gt;算法步骤&lt;/h3&gt;
&lt;p&gt;输入：样本S = X1, X2,…, Xm。
步骤：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;选择初始的K个类别中心μ1，μ2，…，μk，k &amp;lt; m&lt;/li&gt;
  &lt;li&gt;对每个样本Xi，找到与其最近的那个聚类中心后将其标记为距离类别中心最近的类别，即：
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; PS：上式的读法是：样本xi的类别距离xi最近的聚类中心μj的那个类别。    3. 经过上面一步，有些聚类(聚类集合也称为簇)中的元素就更新了，于是就需要调整聚类中心，所以将每个类别中心更新为隶属该类别的所有样本的均值： &amp;lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot;/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;重复最后两步，直到类别中心的变化小于某阈值。
终止条件：迭代次数/簇中心变化率/最小平方误差MSE(MinimumSquared Error)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;好了，算法步骤写完了，那我们下面继续讨论几个问题。&lt;/p&gt;

&lt;h3 id=&quot;k-means算法是否一定收敛&quot;&gt;k-means算法是否一定收敛&lt;/h3&gt;
&lt;p&gt;*　k -means算法一定收敛吗？在特定的场景下，答案是肯定的。
*　可以证明k-means正是在J上的坐标下降过程（参考第八讲）。尤其是k-means算法的内循环实际上是在重复：保持μ不变最小化J关于c的函数，然后再保持c不变最小化J关于μ的函数。因此，J是单调递减的，它的函数值一定收敛&lt;/p&gt;

&lt;h3 id=&quot;k-means算法的凸性质&quot;&gt;k-means算法的凸性质&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;失真函数J是一个非凸函数，所以对于J的坐标下降并不能保证其收敛于全局最小值，即kk-means会被局部最小值影响。尽管如此，kk-means算法通常都都能很好的完成聚类任务。
    &lt;blockquote&gt;
      &lt;p&gt;也就是说初始值对结果的影响较大
在聚类的时候要多选几次随机初始化，然后选择最小&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;k如何选择&quot;&gt;K如何选择&lt;/h3&gt;

&lt;p&gt;步骤知道了，那选择几个类别呢？
 这个还真没有好办法，只能使用先验知识选定、拍脑门选一个或者用交叉验证的方式去验证….
 当然有些地方说K=(n/2)1/2，这个知道就好。&lt;/p&gt;

&lt;h3 id=&quot;聚类中心如何初始化&quot;&gt;聚类中心如何初始化&lt;/h3&gt;
&lt;p&gt;话说K-means是初值敏感的,K-means算法会产生局部最优值的。即：如果聚类中心选择的不太好的话，可能到一个不太好的地方后就停了。那如何选择聚类中心呢？有这么个方法:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;随便选一个聚类中心A，然后统计所有的样本点到A的距离，并让距离A远的样本点选中的概率大一些（如：距离A越远的样本点权值越大）。&lt;/li&gt;
  &lt;li&gt;在上面的基础上选出第二个点B作为聚类中心，然后计算所有样本点到这两个聚类中心的距离（如：所有样本点到最近的那个聚类中心的距离作为其权值），距离远的选中概率大。&lt;/li&gt;
  &lt;li&gt;重复上面的步骤，选出K个聚类中心。
   PS：选中聚类中心时可以给个阈值，如果距离小于阈值就PASS，如果大与阈值就作为候选聚类中心，而这个阈值的选择方法可以是：建立个最小生成树，然后对边的权值取均值/最大值/最小值作为阈值。当然，实际运用中经常不这么麻烦，假设是二维的，于是上面的图可以放到一个x,y 坐标轴上，于是就求出最左边样本点到最右边样本点的长度X，和最上边样本点与最下边样本点的长度Y，然后用X/N和Y/N作为阈值的参考值。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;k-means的公式化解释&quot;&gt;K-means的公式化解释&lt;/h3&gt;
&lt;p&gt;记K个簇中心为μ1，μ2，…，μk，每个簇的样本数目为N1,N2, …, Nk
 使用平方误差作为目标函数：
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注：上式中等号右边的意思是：求属于第j个簇的所有样本到第j个簇的聚类中心μj的距离的平方和，然后求所有簇的上述值的和。&lt;/p&gt;

&lt;p&gt;我们的目的是对该目标函数取最小，哪一个聚类中心，或者说哪一个簇能使该目标函数取最小，我们就说哪个是最好的。
 于是对μ求偏导：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是在说：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;聚类中心即在该聚类中的所有样本的和求均值。&lt;/li&gt;
  &lt;li&gt;样本距离聚类中心是服从高斯分布的。&lt;/li&gt;
  &lt;li&gt;K-means最终的结果一定是像个圆形的。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;k-means聚类方法总结&quot;&gt;K-means聚类方法总结&lt;/h3&gt;
&lt;p&gt;优点：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;是解决聚类问题的一种经典算法，简单、快速&lt;/li&gt;
  &lt;li&gt;对处理大数据集，该算法保持可伸缩性和高效率&lt;/li&gt;
  &lt;li&gt;当簇近似为高斯分布时，它的效果较好
缺点：&lt;/li&gt;
  &lt;li&gt;在簇的平均值可被定义的情况下才能使用，可能不适用于某些应用&lt;/li&gt;
  &lt;li&gt;必须事先给出k(要生成的簇的数目)，而且对初值敏感，对于不同的初始值，可能会导致不同结果。&lt;/li&gt;
  &lt;li&gt;不适合于发现非凸形状的簇或者大小差别很大的簇&lt;/li&gt;
  &lt;li&gt;对躁声和孤立点数据敏感&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;k-means的一个小改进k中值聚类&quot;&gt;K-means的一个小改进（K中值聚类）&lt;/h3&gt;
&lt;p&gt;比如数组1、2、3、4、100的均值为22，显然距离“大多数”数据1、2、3、4比较远。
于是改成求数组的中位数3，在该实例中更为稳妥。
这就是K-Mediods聚类（K中值聚类），它的目标函数一定意义上可以认为是把K-means的目标函数中的平方换成绝对值。
这个算法在一定程度上可以对抗异常值。&lt;/p&gt;

&lt;h2 id=&quot;混合高斯模型&quot;&gt;混合高斯模型&lt;/h2&gt;

&lt;p&gt;从几何上讲，单高斯分布模型在二维空间应该近似于椭圆，在三维空间上近似于椭球。遗憾的是在很多分类问题中，属于同一类别的样本点并不满足“椭圆”分布的特性。这就引入了高斯混合模型。而且因为高斯函数具有良好的计算性能，所以GMM被广泛地应用。&lt;/p&gt;

&lt;p&gt;GMM简单的说就是从几个GSM(高斯分布)中生成出来的。即，如果GSM（高斯分布）的概率密度函数用&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster5.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
 ，θ = (μ,σ2)
 表示的话，那GMM就是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster6.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，ak是系数，ak &amp;gt;=0，
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster7.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster8.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;称为第k个分模型，其中θk= (μk,σk2)。a1+a2+…+aK = 1。&lt;/p&gt;

&lt;h3 id=&quot;gmm的em算法的推导&quot;&gt;GMM的EM算法的推导&lt;/h3&gt;
&lt;p&gt;假设观测数据y1, y2,…, yN由GMM生成&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster9.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，θ = (a1,a2, …, ak; θ1, θ2, …, θk)。
我们的目标是用EM算法估计GMM的参数θ。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1,明确隐变量，写出完全数据的对数似然函数&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;可以设想观测数据yj，j = 1, 2,…, N，是这样产生的：首先依概率ak选择第k个高斯分布分模型φ(y&lt;/td&gt;
      &lt;td&gt;θk)；然后依第k个分模型的概率分布φ(y&lt;/td&gt;
      &lt;td&gt;θk)生成观测数据yj。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;这时观测数据yj是已知的，观测数据yj来自的第k个分模型是未知的(k =1, 2, .., K)，于是这个就是隐变量，我们用rjk表示，其定义如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster10.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;PS：隐变量rjk是0-1随机变量。
有了观测数据yj及未观测数据rjk，那么完全数据是
 (yj,rj1, rj2, …, rjk), j = 1, 2, …, N
于是，可以写出完全数据的似然函数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster11.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;式中&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster12.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
（a式）&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;tip：
第一个等号：在满足θ的高斯分布中，第j样本点出现的概率是P(yj, rj1, rj2, …, rjK | θ)，于是代表“所有的样本点出现的概率”的P(y,r | θ)就推出了第一个等号。
第二个等号：由9.27式可得，若第j个观测来自第k个分模型时，rjk=1，即，akφ(yj|θk)]^rjk = akφ(yj|θk)]，反之，akφ(yj|θk)]^rjk = 0。
于是将K个akφ(yj|θk)]^rjk连乘，就表示了第j个样本集合属于第k个分模型，即P(yj, rj1, rj2, …, rjK | θ)的展开
后面两个等号是基本的数学知识，就不再解释了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;那么，完全数据的对数似然函数就是&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster13.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2，EM算法的E步：确定Q函数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster14.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;tip：
上面的第三个等号的推导，就是把（a式）中的nk带进去，然后把E放到里面。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster15.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster16.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
是在当前模型参数下第j个观测数据来自第k个分模型的概率，称为分模型k对观测数据yi的响应度。&lt;/p&gt;

&lt;p&gt;最后将&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster17.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;代入9.28式，即得&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster18.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3，确定EM算法的M步&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这一步就简单了，Q函数已经知道，即9.29式，那对Q函数中的θ对应的各参数求偏导，并令其为0就可以了，其结果如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/base_cluster19.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4，重复以上计算，知道对数似然函数不再有明显的变化为止。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;gmm的初始化&quot;&gt;GMM的初始化&lt;/h3&gt;

&lt;p&gt;方案1：协方差矩阵设为单位矩阵，每个模型比例的先验概率设为相等；均值u设为随机数。&lt;/p&gt;

&lt;p&gt;方案 2：由k均值（k-means）聚类算法对样本进行聚类，利用各类的均值作为u，初始的协方差矩阵源自于原始数据的协方差矩阵，且每个簇的初始协方差矩阵相同，取各类样本占样本总数的比例。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;我们发现，通常用方案二会取得更好的结果&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;高斯混合模型与k-means异同点&quot;&gt;高斯混合模型与K-means异同点&lt;/h3&gt;

&lt;p&gt;相同点：
（1）需要指定K值
（2）需要指定初始值，例如K-means的中心点，GMM的各个参数
（3）都是含有EM算法思想&lt;/p&gt;

&lt;p&gt;不同点：
（1）优化目标函数不同，K-means:最短距离，GMM：最大化log似然估计
 (2）E步的指标不同，K-means:点到中心的距离（硬指标），GMM：求解每个观测数据的每个component的概率（软指标）&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《统计学习方法》-李航&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;《机器学习》-周志华&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;《机器学习实战》-Peter Harrington&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;斯坦福大学公开课-机器学习&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;

&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201702255&quot; data-title=&quot;cluster&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;

&lt;!-- 多说评论框 end --&gt;

&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;

&lt;script type=&quot;text/javascript&quot;&gt;

var duoshuoQuery = {short_name:&quot;yzhhome&quot;};

  (function() {

    var ds = document.createElement('script');

    ds.type = 'text/javascript';ds.async = true;

    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';

    ds.charset = 'UTF-8';

    (document.getElementsByTagName('head')[0] 

     || document.getElementsByTagName('body')[0]).appendChild(ds);

  })();

  &lt;/script&gt;

</description>
        <pubDate>Sat, 25 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/25/%E7%AE%80%E5%8D%95%E8%81%9A%E7%B1%BB.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/25/%E7%AE%80%E5%8D%95%E8%81%9A%E7%B1%BB.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>论文笔记-GAN</title>
        <description>&lt;h1 id=&quot;gan&quot;&gt;GAN&lt;/h1&gt;

&lt;p&gt;这里的论文主要&lt;/p&gt;

&lt;h2 id=&quot;为什么要有gan&quot;&gt;为什么要有GAN&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;论文原文：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Deep generative models have had less of an impact, due to the difficulty of approximating many intractable probabilistic computations that arise in maximum likelihood estimation and related strategies, and due to difficulty of leveraging the benefits of piecewise linear units in the generative context. We propose a new generative model estimation procedure that sidesteps these difficulties.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;讲述了&lt;strong&gt;（1）用出现在最大似然估计和相关策略很难很好的完成许多棘手的概率近似计算，（2）同时也很难扩充分段的网络结构的优势去生成那些相应内容&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;gan的算法流程和整体概念图&quot;&gt;GAN的算法流程和整体概念图&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;论文原文：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/P-GAN1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/P-GAN2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;gan散度&quot;&gt;GAN散度&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;论文原文：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/P-GAN3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/P-GAN4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意上面的式子,也就变成了下面这个
&lt;img src=&quot;http://zhihu.com/equation?tex=2JS%28P_r+%7C%7C+P_g%29+-+2%5Clog+2&quot; alt=&quot;&quot; /&gt;
GAN定义的判别器loss，我们可以得到最优判别器的形式；而在最优判别器的下，我们可以把原始GAN定义的生成器loss等价变换为最小化真实分布P_r与生成分布P_g之间的JS散度。我们越训练判别器，它就越接近最优，最小化生成器的loss也就会越近似于最小化P_r和P_g之间的JS散度。
但其实在散度的表示存在很多问题,详细见:&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/04/20/Wasserstein-GAN.html&quot;&gt;Wasserstein-GAN&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;gan收敛&quot;&gt;GAN收敛&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;论文原文：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/P-GAN5.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在这里注意的是可以理解为&lt;strong&gt;在优化最佳判别器的时候同时在给生成器最佳的梯度&lt;/strong&gt;，简单理解就是在判别器在判别的时候，它在同时告诉生成器，应该要怎么生成一张图片或其他来让判别器认为生成的图片更加的真实。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;原始gan优缺点&quot;&gt;原始GAN优缺点&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/gan_advanddisadv.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;缺点：必须同时把握好训练强度，避免生成样本过度接近真实样本从而减少其多样性。也就是&lt;strong&gt;too many values of z to the same value of x to have enough diversity to model p data&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;优点：（1）不需要马尔可夫链，反馈有反向梯度的形式，（2）对抗最大的好处是判别器的梯度之间传向生成器（3）生成对抗网络甚至可以拟合degenerate的分布。&lt;/p&gt;

&lt;blockquote&gt;

&lt;/blockquote&gt;

&lt;h1 id=&quot;dcgans&quot;&gt;DCGANs&lt;/h1&gt;

&lt;p&gt;GANs provide an attractive alternative to maximum likelihood techniques. One can additionally argue that their learning process and the lack of a heuristic cost function (such as pixel-wise independent mean-square error) are attractive to representation learning. GANs have been known to be unstable to train, often resulting in generators that produce nonsensical outputs. There has been very limited published research in trying to understand and visualize what GANs learn, and the intermediate representations of multi-layer GANs.&lt;/p&gt;

&lt;h2 id=&quot;dcgan结构特点&quot;&gt;DCGAN结构特点&lt;/h2&gt;

&lt;p&gt;首先来看下它的结构：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/dcgan_stru.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We propose and evaluate a set of constraints on the architectural topology of Convolutional
GANs that make them stable to train in most settings. We name this class of architectures
Deep Convolutional GANs (DCGAN)
• We use the trained discriminators for image classification tasks, showing competitive performance with other unsupervised algorithms.
• We visualize the filters learnt by GANs and empirically show that specific filters have
learned to draw specific objects.&lt;/p&gt;

&lt;p&gt;• We show that the generators have interesting vector arithmetic properties allowing for easy
manipulation of many semantic qualities of generated samples.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/dc_gan1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;在dcgan中三个改进cnn方式&quot;&gt;在DCGAN中三个改进cnn方式&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/dc-gan-impro.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;也就是取消pooling，取消全链接，加上BN。&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;

&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;2017031001&quot; data-title=&quot;gan&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;

&lt;!-- 多说评论框 end --&gt;

&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;

&lt;script type=&quot;text/javascript&quot;&gt;

var duoshuoQuery = {short_name:&quot;yzhhome&quot;};

  (function() {

    var ds = document.createElement('script');

    ds.type = 'text/javascript';ds.async = true;

    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';

    ds.charset = 'UTF-8';

    (document.getElementsByTagName('head')[0] 

     || document.getElementsByTagName('body')[0]).appendChild(ds);

  })();

  &lt;/script&gt;

</description>
        <pubDate>Fri, 24 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/24/paper-GAN.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/24/paper-GAN.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>ImageNet Evolution(论文笔记)</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#imagenet-evolution论文笔记&quot; id=&quot;markdown-toc-imagenet-evolution论文笔记&quot;&gt;ImageNet Evolution(论文笔记)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#alexnet&quot; id=&quot;markdown-toc-alexnet&quot;&gt;AlexNet&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#数据准备&quot; id=&quot;markdown-toc-数据准备&quot;&gt;数据准备&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#选择relu-nonlinearity的原因&quot; id=&quot;markdown-toc-选择relu-nonlinearity的原因&quot;&gt;选择ReLU Nonlinearity的原因&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#local-response-nomalization&quot; id=&quot;markdown-toc-local-response-nomalization&quot;&gt;Local Response Nomalization&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#alexnet的结构和训练&quot; id=&quot;markdown-toc-alexnet的结构和训练&quot;&gt;AlexNet的结构和训练&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#vggnet&quot; id=&quot;markdown-toc-vggnet&quot;&gt;VGGNet&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#vggnet的结构特点&quot; id=&quot;markdown-toc-vggnet的结构特点&quot;&gt;VGGNet的结构特点&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#network-in-network&quot; id=&quot;markdown-toc-network-in-network&quot;&gt;Network in Network&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#卷积层的改进&quot; id=&quot;markdown-toc-卷积层的改进&quot;&gt;卷积层的改进&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#论11卷积的作用&quot; id=&quot;markdown-toc-论11卷积的作用&quot;&gt;论1×1卷积的作用&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#使用全局均值池化&quot; id=&quot;markdown-toc-使用全局均值池化&quot;&gt;使用全局均值池化&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#googlenet&quot; id=&quot;markdown-toc-googlenet&quot;&gt;GoogLeNet&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#googlenet的结构特点&quot; id=&quot;markdown-toc-googlenet的结构特点&quot;&gt;GoogLeNet的结构特点&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#残差网络&quot; id=&quot;markdown-toc-残差网络&quot;&gt;残差网络&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#再论11卷积的作用&quot; id=&quot;markdown-toc-再论11卷积的作用&quot;&gt;再论1*1卷积的作用&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;imagenet-evolution论文笔记&quot;&gt;ImageNet Evolution(论文笔记)&lt;/h2&gt;

&lt;p&gt;下面来来开始说下这些年最火的ImageNet图像识别模型，当然这里我是在记论文笔记，他们都是卷积神经网络，如果还不知道什么是卷积神经网络的话，请移步到&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/03/18/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html&quot;&gt;这篇博文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;关于深度，其实在ImageNet这个比赛来说，可以说是一年更比一年深，到了2015残差网络，作者在论文中甚至说他试过用1000多层，只是它的效果和100多层的效果差不多，所以也就用可100多层的网络作为最后选择。&lt;/p&gt;

&lt;p&gt;下面就是从AlexNet到ResNet的深度变化的直观过程，他们的结构各有特点，下面将一一说明。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/paper_ImageNet1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;alexnet&quot;&gt;AlexNet&lt;/h2&gt;

&lt;h3 id=&quot;数据准备&quot;&gt;数据准备&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;论文原文(来源AlexNet)：&lt;/strong&gt;We did not pre-process the images in any other way, except for subtracting the mean activity over the training set from each pixel.So we trained our network on the (centered) raw RGB values of the pixels.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;很简单，我们在做图像处理的时候，&lt;strong&gt;只需要数据零中心话即可，&lt;/strong&gt;其实也是深度学习端到端的要义-直接输入原始数据，仅仅需要一个模型，不用很多的预处理，其他模块，然后就可以输出结果，而不是像传统系统，要几个模块的设计（比如：机器翻译 要设计翻译模型 语言模型 调序模型）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;选择relu-nonlinearity的原因&quot;&gt;选择ReLU Nonlinearity的原因&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;论文原文(来源AlexNet)：&lt;/strong&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/paper_ImageNet2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;相对与选择那些会饱和的激活函数，例如tanh或者，用&lt;strong&gt;ReLU线性激活函数&lt;/strong&gt;是最快的，从那个图中我们也可以看的出来，而在这个特性在这种深层大型的神经网络中是非常重要的！同时需要注意的是&lt;strong&gt;现在大部分的深度神经网络都选择这个为激活函数&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;local-response-nomalization&quot;&gt;Local Response Nomalization&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;论文原文(来源AlexNet)：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/paper_ImageNet3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;使用ReLU f(x)=max(0,x)后，你会发现&lt;strong&gt;激活函数之后的值没有了tanh、sigmoid函数那样有一个值域区间，所以一般在ReLU之后会做一个normalization&lt;/strong&gt;，LRU就是稳重提出（这里不确定，应该是提出？）一种方法，在神经科学中有个概念叫“Lateral inhibition”，讲的是活跃的神经元对它周边神经元的影响，这个灵感来源于人体中的神经网络！&lt;/p&gt;

&lt;h3 id=&quot;alexnet的结构和训练&quot;&gt;AlexNet的结构和训练&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;论文原文(来源AlexNet)：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/paper_ImageNet4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;需要注意的是，作者用了两个GPU来进行训练，然后卷积只在某一层进行交叉链接！这样可以加快训练，但效果也不会被影响&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;vggnet&quot;&gt;VGGNet&lt;/h2&gt;

&lt;h3 id=&quot;vggnet的结构特点&quot;&gt;VGGNet的结构特点&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;论文原文(来源AlexNet)：&lt;/strong&gt;
Our ConvNet configurations are quite different from the ones used in the top-performing entries of the ILSVRC-2012 (Krizhevsky et al., 2012) and ILSVRC-2013 competitions (Zeiler &amp;amp; Fergus,2013; Sermanet et al., 2014). Rather than using relatively large receptive fields in the first conv. layers (e.g. 11 × 11 with stride 4 in (Krizhevsky et al., 2012), or 7 × 7 with stride 2 in (Zeiler &amp;amp; Fergus,2013; Sermanet et al., 2014)), we use very small 3 × 3 receptive fields throughout the whole net,which are convolved with the input at every pixel (with stride 1). It is easy to see that a stack of two 3 × 3 conv. layers (without spatial pooling in between) has an effective receptive field of 5 × 5; three&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/paper_ImageNet5.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;VGGnet其实和一开始的AlexNet在结构上没有什么太大的差别，不同的就是，在第一个卷基层层使用更小的filter尺寸和间隔(kernel size=3, stride=1), AlexNet(kernel size=11, stride=4)。然后更加的深了！这样可以减少参数（文中有举例），并且可以得到更多的特征，经过三层非线性激活函数增加了非线性的特性！&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这里说明了1X1卷积核到底有什么作用？在这里说了就是&lt;strong&gt;可以在保持feature map 尺寸不变（即不损失分辨率）的前提下大幅增加非线性特性，把网络做得很deep。&lt;/strong&gt;但对于1X1卷积核，下面下面要将的GoogLeNet和ResNet同样使用了，但那个是用来降维和升维的，具体的下面在讲！&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;network-in-network&quot;&gt;Network in Network&lt;/h2&gt;

&lt;h3 id=&quot;卷积层的改进&quot;&gt;卷积层的改进&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/networw-in.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;卷积层的改进：MLPconv，在每个local部分进行比传统卷积层复杂的计算，如上图右，&lt;strong&gt;提高每一层卷积层对于复杂特征的识别能力，这里举个不恰当的例子，传统的CNN网络，每一层的卷积层相当于一个只会做单一任务，你必须要增加海量的filters来达到完成特定量类型的任务，而MLPconv的每层conv有更加大的能力，每一层能够做多种不同类型的任务，在选择filters时只需要很少量的部分&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;论11卷积的作用&quot;&gt;论1×1卷积的作用&lt;/h3&gt;

&lt;p&gt;1×1的卷积层（可能）引起人们的重视是在NIN的结构中，论文中林敏师兄的想法是利用MLP代替传统的线性卷积核，从而提高网络的表达能力。文中同时利用了跨通道pooling的角度解释，认为文中提出的&lt;strong&gt;MLP其实等价于在传统卷积核后面接cccp层，从而实现多个feature map的线性组合，实现跨通道的信息整合。而cccp层是等价于1×1卷积的，因此细看NIN的caffe实现，就是在每个传统卷积层后面接了两个cccp层（其实就是接了两个1×1的卷积层）。这就实现跨通道的交互和信息整合&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;使用全局均值池化&quot;&gt;使用全局均值池化&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;论文原文(来源Network in Network)：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/paper_ImageNet6.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;采用全局均值池化来解决传统CNN网络中最后全连接层参数过于复杂的特点，而且全连接会造成网络的泛化能力差，Alexnet中有提高使用dropout来提高网络的泛化能力。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;global average pooling 与average pooling的区别:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如最后一个卷积层输出10个feature map，average pooling 是对每个feature map分别求平均，输出10个feature map。
global average pooling是对每个feature map内部取平均，每个feature map变成一个值（因为kernel的大小设置成和feature map的相同），10个feature map就变成一个10维的向量，然后直接输入到softmax中。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;其实简单理解就是在原始的CNN中10个feature map的话经过average pooling输出的不一定是一个值，而global average pooling输出的就一定是一个值&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下图是直观理解：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/cnn_pooling_nin.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;googlenet&quot;&gt;GoogLeNet&lt;/h2&gt;

&lt;h2 id=&quot;googlenet的结构特点&quot;&gt;GoogLeNet的结构特点&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/gogle1net.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;再论1×1卷积的作用&lt;/strong&gt;以GoogLeNet的3a模块为例，输入的feature map是28×28×192，3a模块中1×1卷积通道为64，3×3卷积通道为128,5×5卷积通道为32，如果是左图结构，那么卷积核参数为1×1×192×64+3×3×192×128+5×5×192×32，而右图对3×3和5×5卷积层前分别加入了通道数为96和16的1×1卷积层，这样卷积核参数就变成了1×1×192×64+（1×1×192×96+3×3×96×128）+（1×1×192×16+5×5×16×32），参数大约减少到原来的三分之一。&lt;/p&gt;

&lt;h2 id=&quot;残差网络&quot;&gt;残差网络&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/resnet_jie.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过求偏导我们就能看到,F(X)就是拟合残差，x就是之前的函数结果，两个相加就可以得到更加好的结果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/paper_ImageNet8.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我们发现，其实残差网络和dropout有类似的功能，其实也可以用上面的图，一条路径就代表这一个网络的话，那么就是和dropout类似的，这样集成正则化的方式，也是能有效采用这样的加深网络的方式来提升模型性能。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;再论11卷积的作用&quot;&gt;再论1*1卷积的作用&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/paper_ImageNet7.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ResNet同样也利用了1×1卷积，并且是在3×3卷积层的前后都使用了，不仅进行了降维，还进行了升维，使得卷积层的输入和输出的通道数都减小，参数数量进一步减少.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;

&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;2017030901&quot; data-title=&quot;imagenet&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;

&lt;!-- 多说评论框 end --&gt;

&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;

&lt;script type=&quot;text/javascript&quot;&gt;

var duoshuoQuery = {short_name:&quot;yzhhome&quot;};

  (function() {

    var ds = document.createElement('script');

    ds.type = 'text/javascript';ds.async = true;

    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';

    ds.charset = 'UTF-8';

    (document.getElementsByTagName('head')[0] 

     || document.getElementsByTagName('body')[0]).appendChild(ds);

  })();

  &lt;/script&gt;

</description>
        <pubDate>Fri, 24 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/24/paper-ImageNet.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/24/paper-ImageNet.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>关联分析(二)_FP-growth算法</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#关联分析二fp-growth算法&quot; id=&quot;markdown-toc-关联分析二fp-growth算法&quot;&gt;关联分析(二)–FP-growth算法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#构建fp树&quot; id=&quot;markdown-toc-构建fp树&quot;&gt;构建FP树&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#从一颗fp树中挖掘频繁项集&quot; id=&quot;markdown-toc-从一颗fp树中挖掘频繁项集&quot;&gt;从一颗FP树中挖掘频繁项集&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#抽取条件模式基&quot; id=&quot;markdown-toc-抽取条件模式基&quot;&gt;抽取条件模式基&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;关联分析二fp-growth算法&quot;&gt;关联分析(二)–FP-growth算法&lt;/h2&gt;

&lt;p&gt;FP-growth算法将数据存储在一种称为FP树的紧凑数据结构中。FP（Frequent Pattern）通过链接来连接相似元素，被连起来的元素项可以看成一个链表。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/FP-growth1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;同搜索树不同的是，一个元素项可以在一棵FP树中出现多次。FP树会存储项集的出现频率，而每个项集会以路径的方式存储在树中。存在相似元素的集合会共享树的一部分。只有当集合之间完全不同时，树才会分叉。树节点上给出集合中的单个元素及其在序列中的出现次数，路径会给出该序列的出现次数。相似项之间的链接即节点链接，用于快速发现相似项的位置。
FP-growth算法首先构建FP树，然后利用它来挖掘频繁项集。为构建FP树，需要对原始数据集扫描两遍。第一遍对所有元素项的出现次数进行计数。第二遍扫描只考虑那些频繁元素。&lt;/p&gt;

&lt;h2 id=&quot;构建fp树&quot;&gt;构建FP树&lt;/h2&gt;
&lt;p&gt;除了FP树的类，还需要头指针表来指向给定类型的第一个实例。通过头指针表可以快速访问FP树中一个给定类型的所有元素。可用字典保存，并且其value存放FP树中每类元素的总数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/FP-growth2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第一遍遍历数据集得到每个元素项的出现频率。去掉不满足最小支持度的元素项。再构建FP树。构建时，读入每个项集并将其添加到一条已经存在的路径中。如果该路径不存在，则创建一条新路径。每个事务就是一个无序集合。假设集合{z,x,y}和{y,z,r}，那么在FP树中，相同项只会表示一次。为此在将集合添加到树之前，先对每个集合进行排序，排序基于元素项出现的频率。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/FP-growth3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在对事务记录过滤和排序之后，就可以构建FP树了。从空集，向其中不断添加频繁项集。过滤、排序后的事务依次添加到树中，如果树中巳存在现有元素，则增加现有元素的值;如果现有元素不存在，则向树添加一个分枝。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/FP-growth4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;从一颗fp树中挖掘频繁项集&quot;&gt;从一颗FP树中挖掘频繁项集&lt;/h2&gt;
&lt;p&gt;有了FP树之后，就可以抽取频繁项集了，首先从单元素项集开始，然后在此基础上逐步构建更大的集合。&lt;/p&gt;

&lt;p&gt;步骤：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;从FP树中获得条件模式基;&lt;/li&gt;
  &lt;li&gt;利用条件模式基，构建一个条件FP树;&lt;/li&gt;
  &lt;li&gt;迭代重复步骤1,2，直到树包含&lt;strong&gt;一个元素&lt;/strong&gt;项为止。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;抽取条件模式基&quot;&gt;抽取条件模式基&lt;/h3&gt;

&lt;p&gt;条件模式基是以所查找元素项为结尾的路径集合。每一条路径其实都是一条前缀路径。图12-2中，符号r的前缀路径有{x,s},{z,x,y}和{z}。根据头指针表通过上溯树直到根节点抽取出条件模式基。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/FP-growth5.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;由前缀再创建条件FP树&lt;/strong&gt;
对于每一个频繁项，都要创建一颗条件FP树。通过递归可发现频繁项、条件模式基以及另外的条件树。假设以频繁项t创建一个条件FP树，然后对{t,y}、{t,x}、…等重复该过程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/FP-growth6.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;恩，也不是特别的难是吧，下面再补充一个详细例子，主要注意的就是在用频繁项递归构建FP树那里要注意一下就好了！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;算法原始数据如下：
&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;1、I5的条件模式基是(I2 I1:1), (I2 I1 I3:1)，I5构造得到的条件FP-树如下。然后递归调用FP-growth，模式后缀为I5。这个条件FP-树是单路径的，在FP_growth中直接列举{I2:2，I1:2，I3:1}的所有组合，之后和模式后缀I5取并集得到支持度&amp;gt;2的所有模式：{ I2 I5:2, I1 I5:2, I2 I1 I5:2}。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/FP-growth7.gif&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2、I5的情况是比较简单的，因为I5对应的条件FP-树是单路径的，我们再来看一下稍微复杂一点的情况I3。I3的条件模式基是(I2 I1:2), (I2:2), (I1:2)，生成的条件FP-树如左下图，然后递归调用FP-growth，模式前缀为I3。I3的条件FP-树仍然是一个多路径树，首先把模式后缀I3和条件FP-树中的项头表中的每一项取并集，得到一组模式{I2 I3:4, I1 I3:4}，但是这一组模式不是后缀为I3的所有模式。还需要递归调用FP-growth，模式后缀为{I1，I3}，{I1，I3}的条件模式基为{I2：2}，其生成的条件FP-树如右下图所示。这是一个单路径的条件FP-树，在FP_growth中把I2和模式后缀{I1，I3}取并得到模式{I1 I2 I3：2}。理论上还应该计算一下模式后缀为{I2，I3}的模式集，但是{I2，I3}的条件模式基为空，递归调用结束。最终模式后缀I3的支持度&amp;gt;2的所有模式为：{ I2 I3:4, I1 I3:4, I1 I2 I3:2}&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/FP-growth8.gif&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/FP-growth9.gif&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;根据FP-growth算法，最终得到的支持度&amp;gt;2频繁模式如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;FP-growth算法比Apriori算法快一个数量级，在空间复杂度方面也比Apriori也有数量级级别的优化。但是对于海量数据，FP-growth的时空复杂度仍然很高，可以采用的改进方法包括数据库划分，数据采样等等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《统计学习方法》-李航&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;《机器学习》-周志华&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;《机器学习实战》-Peter Harrington&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;斯坦福大学公开课-机器学习&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;

&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201702245&quot; data-title=&quot;FP-growth&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;

&lt;!-- 多说评论框 end --&gt;

&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;

&lt;script type=&quot;text/javascript&quot;&gt;

var duoshuoQuery = {short_name:&quot;yzhhome&quot;};

  (function() {

    var ds = document.createElement('script');

    ds.type = 'text/javascript';ds.async = true;

    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';

    ds.charset = 'UTF-8';

    (document.getElementsByTagName('head')[0] 

     || document.getElementsByTagName('body')[0]).appendChild(ds);

  })();

  &lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/lmm2003/article/details/6882737&quot;&gt;FP树的例子&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 24 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/24/%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90-FP-growth%E7%AE%97%E6%B3%95.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/24/%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90-FP-growth%E7%AE%97%E6%B3%95.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>关联分析（一）_Apriori</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#关联分析一apriori&quot; id=&quot;markdown-toc-关联分析一apriori&quot;&gt;关联分析（一）–Apriori&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#关联分析的基本概念&quot; id=&quot;markdown-toc-关联分析的基本概念&quot;&gt;关联分析的基本概念&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#apriori&quot; id=&quot;markdown-toc-apriori&quot;&gt;Apriori&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#总结和改进&quot; id=&quot;markdown-toc-总结和改进&quot;&gt;总结和改进&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;关联分析一apriori&quot;&gt;关联分析（一）–Apriori&lt;/h2&gt;

&lt;p&gt;先讲一个著名的“啤酒与尿布”的故事，它就是来自对购物单的关联分析！&lt;/p&gt;

&lt;p&gt;“啤酒与尿布”的故事产生于20世纪90年代的美国沃尔玛超市中，沃尔玛的超市管理人员分析销售数据时发现了一个令人难于理解的现象：在某些特定的情况下，“啤酒”与“尿布”两件看上去毫无关系的商品会经常出现在同一个购物篮中，这种独特的销售现象引起了管理人员的注意，经过后续调查发现，这种现象出现在年轻的父亲身上。&lt;/p&gt;

&lt;p&gt;关联分析有两种形式：频繁项集、关联规则。频繁项集（frequent item sets）是经常出现在一块的物品的集合，关联规则（association rules）暗示两种物品之间可能存在很强的关系。使用频繁项集和关联规则，商家可以更好地理解他们的顾客。&lt;/p&gt;

&lt;h3 id=&quot;关联分析的基本概念&quot;&gt;关联分析的基本概念&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;支持度:
关联规则A-&amp;gt;B的支持度support=P(AB)，指的是事件A和事件B同时发生的概率。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;置信度:
置信度confidence=P(B|A)=P(AB)/P(A),指的是发生事件A的基础上发生事件B的概率。比如说在规则Computer =&amp;gt; antivirus_software , 其中 support=2%, confidence=60%中，就表示的意思是所有的商品交易中有2%的顾客同时买了电脑和杀毒软件，并且购买电脑的顾客中有60%也购买了杀毒软件。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;k项集:
如果事件A中包含k个元素，那么称这个事件A为k项集，并且事件A满足最小支持度阈值的事件称为频繁k项集。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;由频繁项集产生强关联规则
1）K维数据项集LK是频繁项集的必要条件是它所有K-1维子项集也为频繁项集，记为LK-1　
2）如果K维数据项集LK的任意一个K-1维子集Lk-1，不是频繁项集，则K维数据项集LK本身也不是最大数据项集。
3）Lk是K维频繁项集，如果所有K-1维频繁项集合Lk-1中包含LK的K-1维子项集的个数小于K，则Lk不可能是K维最大频繁数据项集。
4）同时满足最小支持度阀值和最小置信度阀值的规则称为强规则。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;例如：用一个简单的例子说明。表1是顾客购买记录的数据库D，包含6个事务。项集I={网球拍,网球,运动鞋,羽毛球}。考虑关联规则：网球拍 =&amp;gt; 网球，事务1,2,3,4,6包含网球拍，事务1,2,6同时包含网球拍和网球，支持度support= 3/6 = 0.5，置信度confident= 3/5 = 0.6。若给定最小支持度 a =0.5，最小置信度 \beta =0.6，关联规则网球拍 =&amp;gt; 网球是有趣的，认为购买网球拍和购买网球之间存在强关联。&lt;/p&gt;

&lt;h2 id=&quot;apriori&quot;&gt;Apriori&lt;/h2&gt;

&lt;p&gt;Apriori 算法是一种最有影响力的挖掘布尔关联规则的频繁项集的 算法，它是由Rakesh Agrawal 和RamakrishnanSkrikant 提出的。它使用一种称作逐层搜索的迭代方法，k- 项集用于探索（k+1）- 项集。首先，找出频繁 1- 项集的集合。该集合记作L1。L1 用于找频繁2- 项集的集合 L2，而L2 用于找L2，如此下去，直到不能找到 k- 项集。每找一个 Lk 需要一次数据库扫描。然而，这样遍历就太慢了，所以为提高频繁项集逐层产生的效率，一种称作Apriori 性质的重 要性质 用于压缩搜索空间。其运行定理在于一是频繁项集的所有非空子集都必须也是频繁的，二是非频繁项集的所有父集都是非频繁的。&lt;/p&gt;

&lt;p&gt;Apriori算法过程分为两个步骤：&lt;/p&gt;

&lt;p&gt;第一步通过迭代，检索出事务数据库中的所有频繁项集，即支持度不低于用户设定的阈值的项集；&lt;/p&gt;

&lt;p&gt;第二步利用频繁项集构造出满足用户最小信任度的规则。&lt;/p&gt;

&lt;p&gt;具体做法就是：&lt;/p&gt;

&lt;p&gt;首先找出频繁1-项集，记为L1；然后利用L1来产生候选项集C2，对C2中的项进行判定挖掘出L2，即频繁2-项集；不断如此循环下去直到无法发现更多的频繁k-项集为止。每挖掘一层Lk就需要扫描整个数据库一遍。算法利用了一个性质：&lt;/p&gt;

&lt;p&gt;Apriori 性质：任一频繁项集的所有非空子集也必须是频繁的。意思就是说，生成一个k-itemset的候选项时，如果这个候选项有子集不在(k-1)-itemset(已经确定是frequent的)中时，那么这个候选项就不用拿去和支持度判断了，直接删除。具体而言：&lt;/p&gt;

&lt;p&gt;1） 连接步&lt;/p&gt;

&lt;p&gt;为找出Lk（所有的频繁k项集的集合），通过将Lk-1（所有的频繁k-1项集的集合）与自身连接产生候选k项集的集合。候选集合记作Ck。设l1和l2是Lk-1中的成员。记li[j]表示li中的第j项。&lt;code class=&quot;highlighter-rouge&quot;&gt;假设Apriori算法对事务或项集中的项按字典次序排序，即对于（k-1）项集li，li[1]&amp;lt;li[2]&amp;lt;……….&amp;lt;li[k-1]。将Lk-1与自身连接，如果(l1[1]=l2[1])&amp;amp;&amp;amp;( l1[2]=l2[2])&amp;amp;&amp;amp;……..&amp;amp;&amp;amp; (l1[k-2]=l2[k-2])&amp;amp;&amp;amp;(l1[k-1]&amp;lt;l2[k-1])，那认为l1和l2是可连接。连接l1和l2 产生的结果是{l1[1],l1[2],……,l1[k-1],l2[k-1]}。&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;2） 剪枝步&lt;/p&gt;

&lt;p&gt;CK是LK的超集，也就是说，CK的成员可能是也可能不是频繁的。通过扫描所有的事务（交易），确定CK中每个候选的计数，判断是否小于最小支持度计数，如果不是，则认为该候选是频繁的。为了压缩Ck,可以利用Apriori性质：任一频繁项集的所有非空子集也必须是频繁的，反之，如果某个候选的非空子集不是频繁的，那么该候选肯定不是频繁的，从而可以将其从CK中删除。&lt;/p&gt;

&lt;p&gt;不懂，用图说话！：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/apriori1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图显示了4种商品所有可能的组合。对给定的集合项集{0,3}，需要遍历每条记录并检查是否同时包含0和3,扫描完后除以记录总数即可得支持度。对于包含N种物品的数据集共有2的N次方-1种项集组合，即使100种，也会有1.26×10的30次方种可能的项集组成。
为降低计算时间，可用Apriori原理：如果某个项集是频繁的，那么它的所有子集也是频繁的。逆反：如果一个项集是非频繁集，那么它的所有超集也是非频繁的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/apriori2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/apriori3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;恩，应该比较好理解了，其实这个算法也不算难的了，挺简单的！但为了写机器学习博文的宗旨——&lt;strong&gt;用最简单的方式去理解一切！&lt;/strong&gt;下面再来一个更简单直观的例子吧!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下面以图例的方式说明该算法的运行过程： 假设有一个数据库D，其中有4个事务记录，分别表示为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/apriori4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里预定最小支持度minSupport=2,下面用图例说明算法运行的过程：&lt;/p&gt;

&lt;p&gt;1、扫描D，对每个候选项进行支持度计数得到表C1:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/apriori5.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2、比较候选项支持度计数与最小支持度minSupport，产生1维最大项目集L1：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/apriori6.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3、由L1产生候选项集C2：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/apriori7.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;4、扫描D，对每个候选项集进行支持度计数:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/apriori8.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;5、比较候选项支持度计数与最小支持度minSupport，产生2维最大项目集L2：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/apriori9.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;6、由L2产生候选项集C3：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/apriori10.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;7、比较候选项支持度计数与最小支持度minSupport，产生3维最大项目集L3：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/apriori11.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;算法终止。&lt;/p&gt;

&lt;h2 id=&quot;总结和改进&quot;&gt;总结和改进&lt;/h2&gt;
&lt;p&gt;从算法的运行过程，我们可以看出该Apriori算法的优点：简单、易理解、数据要求低，然而我们也可以看到Apriori算法的缺点：&lt;/p&gt;

&lt;p&gt;(1)在每一步产生侯选项目集时循环产生的组合过多，没有排除不应该参与组合的元素;&lt;/p&gt;

&lt;p&gt;(2)每次计算项集的支持度时，都对数据库D中的全部记录进行了一遍扫描比较，如果是一个大型的数据库的话，这种扫描比较会大大增加计算机系统的I/O开销。而这种代价是随着数据库的记录的增加呈现出几何级数的增加。因此人们开始寻求更好性能的算法。&lt;/p&gt;

&lt;p&gt;(3)针对Apriori算法的性能瓶颈问题-需要产生大量候选项集和需要重复地扫描数据库，2000年Jiawei Han等人提出了基于FP树生成频繁项集的FP-growth算法。该算法只进行2次数据库扫描且它不使用侯选集，直接压缩数据库成一个频繁模式树，最后通过这棵树生成关联规则。研究表明它比Apriori算法大约快一个数量级。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;我自己用《机器学习实战》上面的数据做过实战，实践证明，只用来查找频繁集项的话，那FP-growth算法真的不是比Apriori算法快那么一点，而是真的快很多！！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;改进：怎么说呢，如果非要用Apriori的话，那就用来查找关联规则把，如果只要查找频繁集，虽然网上有一大推的改进方式，但我认识最简便的方式就是直接换模型啦，换模型之前，看下看一篇&lt;a href=&quot;&quot;&gt;FP-growth算法&lt;/a&gt;（滑稽）&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《统计学习方法》-李航&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;《机器学习》-周志华&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;《机器学习实战》-Peter Harrington&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;斯坦福大学公开课-机器学习&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;

&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201702235&quot; data-title=&quot;Apriori&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;

&lt;!-- 多说评论框 end --&gt;

&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;

&lt;script type=&quot;text/javascript&quot;&gt;

var duoshuoQuery = {short_name:&quot;yzhhome&quot;};

  (function() {

    var ds = document.createElement('script');

    ds.type = 'text/javascript';ds.async = true;

    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';

    ds.charset = 'UTF-8';

    (document.getElementsByTagName('head')[0] 

     || document.getElementsByTagName('body')[0]).appendChild(ds);

  })();

  &lt;/script&gt;

</description>
        <pubDate>Thu, 23 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/23/%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90apriori.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/23/%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90apriori.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>ListNet</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#listnet&quot; id=&quot;markdown-toc-listnet&quot;&gt;ListNet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;listnet&quot;&gt;ListNet&lt;/h2&gt;

&lt;p&gt;因为在项目中涉及到异常学生检测中这个需求，然后在正好在datacastle中有个比赛正好是这个学生成绩排名的，就直接拿来练手了！&lt;/p&gt;

&lt;p&gt;排序一直是信息检索的核心问题之一，Learning to Rank(简称LTR)用机器学习的思想来解决排序问题。LTR有三种主要的方法：PointWise，PairWise，ListWise。ListNet算法就是ListWise方法的一种，由刘铁岩，李航等人在ICML2007的论文Learning to Rank:From Pairwise approach to Listwise Approach中提出。&lt;/p&gt;

&lt;p&gt;Pairwise方法的实际上是把排序问题转换成分类问题，以最小化文档对的分类错误为目标。但是评估排序结果的好坏通常采用MAP或NDCG等考虑文档排序的方法，所以Pairwise方法的损失函数并不是非常合适。 ListNet算法定义了一种Listwise的损失函数，该损失函数表示由我们的模型计算得来的文档排序和真正的文档排序之间的差异，ListNet最小化该损失函数以达到排序的目的。&lt;/p&gt;

&lt;p&gt;ListNet首先把文档的排序列表转换成概率分布，然后选取交叉熵来衡量由模型训练出的文档排序和真正的文档排序之间的差异，最小化这个差异值来完成排序。下面我们从如何把文档列表转换成概率，如何计算概率分布之间的差异值，如何优化差异值三个部分来介绍ListNet算法。&lt;/p&gt;

&lt;p&gt;(1) 组合概率.&lt;/p&gt;

&lt;p&gt;假设我们需要对n篇文档进行排序，我们用π=&amp;lt;π(1),π(2),…,π(n)&amp;gt;表示一种排列组合，其中π(i)表示排列在第i个位置的文档。设Φ(.)是一个递增和恒大于0的函数，Φ(x)可以是线性函数Φ(x)=αx或者指数函数Φ(x)=exp(x),则排列组合π的概率为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/ListNet1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面公式有一些有用的性质（下面性质论文中均有描述）：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;所有排列的概率之和为1&lt;/li&gt;
  &lt;li&gt;概率最大排列是按照得分逆序，最小的是升序&lt;/li&gt;
  &lt;li&gt;交换排列中两个的位置，得分高的前移会使得概率增加&lt;/li&gt;
  &lt;li&gt;如果 ϕ(x)=αxϕ(x)=αx 是一个线性函数，可以保证 Ps(π)Ps(π) 缩放不变性&lt;/li&gt;
  &lt;li&gt;如果 ϕ(x)=exp(x)ϕ(x)=exp(x) 是一个指数函数，可以保证 Ps(π)Ps(π) 平移不变性&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其中Sπ(j)表示排列在第j个位置的文档的得分。组合概率的计算复杂度为O(n!)，当文档的数量较多时，计算量太大，所以ListNet选用了另外一种概率:Top-K概率。&lt;/p&gt;

&lt;p&gt;(2) Top-K概率.&lt;/p&gt;

&lt;p&gt;序列(j1,j2,…,jk)的Top-K概率表示这些文档排在n个文档中前K个的概率。在定义Top-K概率之前，需要首先定义前K个文档为(j1,j2,…,jk)的文档排序的Top-K Subgroup：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/ListNet2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而Gk代表所有的Top-K Subgroup集合：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/ListNet3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Gk中总共有N!/(N-k)!种不同的组合，大大低于组合概率的N!种组合。&lt;/p&gt;

&lt;p&gt;n个文档中(j1,j2,…,jk)排在前k个的概率，亦即(j1,j2,…,jk)的Top-K概率为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/ListNet4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(j1,j2,…,jk)的Top-K概率的计算方法为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/ListNet5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;计算概率分布的差异值&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在得到利用模型训练出的文档排序和真正的文档排序的概率分布之后，我们可以使用多种方法来计算两个概率分布之间的差异值作为损失函数，ListNet采用交叉熵来计算两个概率分布之间的差异。&lt;/p&gt;

&lt;p&gt;两个概率分布p和q之间的交叉熵定义为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/ListNet6.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在ListNet中，假设Py(i)(g)表示实际的文档排序g的概率，而Pz(i)(g)表示模型计算得来的文档排序g的概率，则两个文档排序概率分布之间的交叉熵为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/ListNet7.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;优化损失函数&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ListNet使用神经网络来计算文档的得分值，选取Φ(x)=exp(x)，然后使用梯度下降(Gradient Descent)的方法来不断更新神经网络的参数ω, 最小化损失函数, ω的迭代公式如下:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/ListNet8.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ListNet中选择的模型依然是神经网络，排列中的变换函数 ϕ 选择指数函数时。具体如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/ListNet9.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优化流程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/ListNet10.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;最后说下，这个模型在排序方面还是非常不错的，在datacastle的&lt;a href=&quot;http://www.pkbigdata.com/common/cmpt/%E5%AD%A6%E7%94%9F%E6%88%90%E7%BB%A9%E6%8E%92%E5%90%8D%E9%A2%84%E6%B5%8B_%E6%8E%92%E8%A1%8C%E6%A6%9C.html&quot;&gt;学生成绩排名预测 &lt;/a&gt;中，凭借这这个模型，得到第11名的名次&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;

&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201702225&quot; data-title=&quot;ListNet&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;

&lt;!-- 多说评论框 end --&gt;

&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;

&lt;script type=&quot;text/javascript&quot;&gt;

var duoshuoQuery = {short_name:&quot;yzhhome&quot;};

  (function() {

    var ds = document.createElement('script');

    ds.type = 'text/javascript';ds.async = true;

    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';

    ds.charset = 'UTF-8';

    (document.getElementsByTagName('head')[0] 

     || document.getElementsByTagName('body')[0]).appendChild(ds);

  })();

  &lt;/script&gt;

</description>
        <pubDate>Wed, 22 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/22/ListNet%E5%8E%9F%E7%90%86.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/22/ListNet%E5%8E%9F%E7%90%86.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>EM算法</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#em算法&quot; id=&quot;markdown-toc-em算法&quot;&gt;EM算法&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#jensen不等式jensens-inequality&quot; id=&quot;markdown-toc-jensen不等式jensens-inequality&quot;&gt;Jensen不等式（Jensen’s inequality）&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#极大似然估计&quot; id=&quot;markdown-toc-极大似然估计&quot;&gt;极大似然估计&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#em算法-1&quot; id=&quot;markdown-toc-em算法-1&quot;&gt;EM算法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#em算法的求解思想&quot; id=&quot;markdown-toc-em算法的求解思想&quot;&gt;EM算法的求解思想&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#em算法推导&quot; id=&quot;markdown-toc-em算法推导&quot;&gt;EM算法推导&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#q函数&quot; id=&quot;markdown-toc-q函数&quot;&gt;Q函数：&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#em算法另一种理解&quot; id=&quot;markdown-toc-em算法另一种理解&quot;&gt;EM算法另一种理解&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;em算法&quot;&gt;EM算法&lt;/h2&gt;

&lt;p&gt;今天我们讲下一个算法，注意，它不是一个模型，而只是一个一般方法，是求解最优值的一个方法！然后，好想吐槽的是，因为em算法比较概率论的问题，但很巧的是，我的概率论下学期才开始学，高中又很多忘记了，所以一开始接触em算法的时候，简直想死。。。感觉它很难理解，非常难以理解，还好，冒着向死而生的思想，我就不行时间的投入，精力的投入，还搞不定它，最后是感谢网上的博文，一点一点的理解，现在应该是有些明白了，但是可能任然有许多比较懵懂，下面我敢但写下这篇博文。。。希望不会被打！&lt;/p&gt;

&lt;h3 id=&quot;jensen不等式jensens-inequality&quot;&gt;Jensen不等式（Jensen’s inequality）&lt;/h3&gt;
&lt;p&gt;我们常见到的Jensen不等式的版本是：
    当φ是凸函数时(φ’’&amp;gt;0)：φ( E(x) )&amp;lt;= E(φ(x) )
    不过这里用到的是下面这个版本：
    当φ是凸函数时&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不太好理解，那我们就拿下面简单的例子来说明：
设有限集合中只有x1和x2，我们很容易发现，当是凸函数的时候（&lt;strong&gt;注意：这里的凸函数是外国的概念引入，和我们国内学的凸函数是相反的，下面的我们学的时候是凹函数&lt;/strong&gt;）φ( E(x) )&amp;lt;= E(φ(x)是一直成立的，当x1=x2的时候，取等号！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;好了，在低维的理解了之后，我们就可以很自然的引申到高维的来理解，其实是一样的！&lt;/p&gt;

&lt;h2 id=&quot;极大似然估计&quot;&gt;极大似然估计&lt;/h2&gt;
&lt;p&gt;讲EM算法之前，我们先来看下极大似然估计，这个在&lt;a href=&quot;&quot;&gt;与机器学习有关的数学基础——概率论部分&lt;/a&gt;这片博文有讲解，而EM算法是为了解决“最大似然估计”中更复杂的情形而存在的。
 这里“极大似然估计中更复杂的情形”是什么情形呢？
 我们知道极大似然估计是求解实现结果的最佳参数θ，但极大似然估计需要面临的概率分布只有一个或者知道结果是通过哪个概率分布实现的，只不过你不知道这个概率分布的参数。而如果概率分布有多个呢或者你不知道结果是通过哪个概率分布实现的？于是别说去确定“这些概率分布”的最佳参数了，我们连最终结果是根据哪个概率分布得出来的都不知道，这就是EM算法要面临的情况了。&lt;/p&gt;

&lt;h2 id=&quot;em算法-1&quot;&gt;EM算法&lt;/h2&gt;

&lt;p&gt;最大似然估计和EM算法都是根据实现结果求解概率分布的最佳参数θ，但最大似然估计中知道每个结果对应哪个概率分布（我知道哪个概率分布实现了这个结果），而EM算法面临的问题是：我不知道哪个概率分布实现了该结果。怎么在不知道其概率分布的情况下还能求解其问题？且看EM算法：&lt;/p&gt;

&lt;h2 id=&quot;em算法的求解思想&quot;&gt;EM算法的求解思想&lt;/h2&gt;
&lt;p&gt;在说明EM算法的求解思想前，我们先总结下上面的内容。&lt;/p&gt;

&lt;p&gt;一般的用Y表示观测到的随机变量的数据，Z表示隐随机变量的数据(因为我们观测不到结果是从哪个概率分布中得出的，所以将这个叫做隐变量)。于是Y和Z连在一起被称为完全数据，仅Y一个被称为不完全数据。&lt;/p&gt;

&lt;p&gt;这时有没有发现EM算法面临的问题主要就是：有个隐变量数据Z。而如果Z已知的话，那问题就可用极大似然估计求解了。
 于是乎，怎么把Z变成已知的？&lt;/p&gt;

&lt;p&gt;我先举个日常生活的例子。&lt;/p&gt;

&lt;p&gt;结果：大厨把锅里的菜平均分配到两个碟子里&lt;/p&gt;

&lt;p&gt;难题：如果只有一个碟子乘菜那就什么都不用说了，但问题是有2个碟子，而因为根本无法估计一个碟子里应该乘多少菜，所以无法一次性把菜完全平均分配。&lt;/p&gt;

&lt;p&gt;解法：大厨先把锅里的菜一股脑倒进两个碟子里，然后看看哪个碟子里的菜多，就把这个碟子中的菜往另一个碟子中匀匀，之后重复多次匀匀的过程，直到两个碟子中菜的量大致一样。
 上面的例子中，平均分配这个结果是“观测数据”，为实现平均分配而给每个盘子分配多少菜是“待求参数θ”，分配菜的手感就是“概率分布”。于是若只有一个盘子，那概率分布就确定了（“把锅里的菜全部倒到一个盘子”这样的手感是个人都有吧），而因为有两个盘子，所以“给一个盘子到多少菜才好”的手感就有些模糊不定，不过我们可以采用上面的解法来实现最终目标。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;理解EM算法最好的方式我觉得就是结合这些类比去理解，然后看下那些数学公式是怎么来的，这样就可以事半功倍了！请看下面：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;EM算法的思想就是：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;给θ自主规定个初值（既然我不知道想实现“两个碟子平均分配锅里的菜”的话每个碟子需要有多少菜，那我就先估计个值）；&lt;/li&gt;
  &lt;li&gt;根据给定观测数据和当前的参数θ，求未观测数据z的条件概率分布的期望（在上一步中，已经根据手感将菜倒进了两个碟子，然后这一步根据“两个碟子里都有菜”和“当前两个碟子都有多少菜”来判断自己倒菜的手感）；&lt;/li&gt;
  &lt;li&gt;上一步中z已经求出来了，于是根据极大似然估计求最优的θ’（手感已经有了，那就根据手感判断下盘子里应该有多少菜，然后把菜匀匀）；&lt;/li&gt;
  &lt;li&gt;因为第二步和第三步的结果可能不是最优的，所以重复第二步和第三步，直到收敛（重复多次匀匀的过程，直到两个碟子中菜的量大致一样）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;而上面的第二步被称作E步（求期望），第三步被称作M步（求极大化），于是EM算法就在不停的EM、EM、EM….，所以被叫做EM算法，你看，多形象（摊手）。&lt;/p&gt;

&lt;p&gt;下面，我们把上面的做法对应到EM算法。从直观上理解，很好明白把！&lt;/p&gt;

&lt;h2 id=&quot;em算法推导&quot;&gt;EM算法推导&lt;/h2&gt;
&lt;p&gt;该来的总会来的，最终我们还是要用数学语言来描述EM算法，那么下面我们看看EM算法的推导过程。&lt;/p&gt;

&lt;p&gt;在此先将问题抽象：
   已知模型为p(Y|θ)，Y=(y1, y2,…, yn)，求θ。
  为了满足EM算法的情形，我们引入隐含变量Z=(z1, z2, …, zn)。
解：
   1，虽然我们面对的概率模型里含有隐变量，但我们的目标是不会变的，即，极大化观测数据（不完全数据）Y关于参数θ的对数似然函数，即，极大化：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        PS：上面式子的第二个等号利用了[边缘概率与联合概率]()方面的知识；第三个等号利用了条件概率公式，于是P(y,z) = P(y|z) P(z)，最后把参数θ加上去，即，所有式子都添加θ，就成了9.12式。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;2，我们开始对L(θ)进行迭代，使得新的估计值θ能使L(θ)增加，假设现在已经迭代了i次，于是就是使当前的L(θ)大于L(θ(i))，即L(θ) &amp;gt;L(θ(i))，就这样使L(θ)逐步达到最大值。
            PS：这就是EM算法中的M步。
   为此，我们考虑两者的差：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;利用Jensen不等式得到其下界：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF5.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了便于之后的书写，令&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF6.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;则L(θ)&amp;gt;= B(θ, θ(i))
即函数B(θ, θ(i))是L(θ)的一个下界。PS：L(θ(i))= B(θ(i), θ(i))
因此，任何可以使B(θ, θ(i))增大的θ也可以使L(θ)增大。
于是，为了使L(θ)有尽可能大的增长，选择θ(i+1)使B(θ, θ(i))达到极大，即：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF7.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在求θ(i+1)的表达式&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF8.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3，为了计算上面的式子，我们就要计算（所以在算法中，这一步在上一步之前）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF9.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;而这个就是完全观测数据的对数似然函数logP(Y,Z&lt;/td&gt;
      &lt;td&gt;θ)关于在给定观测数据Y和当前参数θ(i)下对未观测数据Z的条件概率分布P(Z&lt;/td&gt;
      &lt;td&gt;Y, θ(i))的期望，这个被称为Q函数，即：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF10.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;也就是说，要计算期望。
   而这，就是EM算法中的E步。&lt;/p&gt;

&lt;p&gt;4，不断迭代上面两步，直到收敛。
用图形解释EM算法的推导过程的话就是下面这样：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF11.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上图所示，图中上方曲线为L(θ)，下方曲线为B(θ, θ(i))。在推导过程中已经知道B(θ,θ(i))是对数似然函数L(θ)的下界，且两个函数在点θ = θ(i)处相等。之后EM算法找到下一个点θ(i+1)使函数B(θ, θ(i))极大化，也使函数Q(θ, θ(i))极大化。这时L(θ) &amp;gt;= B(θ, θ(i))，函数B(θ, θ(i))的增加保证对数似然函数L(θ)在每次迭代中也是增加的。EM算法再点θ(i+1)重新计算Q函数值，进行下次迭代。在这个过程中，对数似然函数L(θ)不断增大。&lt;/p&gt;

&lt;p&gt;不过，从图中可以推断出EM算法可能因为陷入局部最优值而找不到全局最优解,并且对初始值是比较敏感的，这点需要注意。&lt;/p&gt;

&lt;h2 id=&quot;q函数&quot;&gt;Q函数：&lt;/h2&gt;

&lt;p&gt;Q函数就是EM算法第二步的Q(θ, θ(i))，我将Q函数单独放在一章是因为Q函数是EM算法的核心。
如果你已经深刻理解了上面的内容，那么会明白，整个EM算法最难的部分就是构建Q函数。为什么？因为EM算法的两步E步和M步在实际应用中就是“构建Q函数”和“通过偏导求极大值”，而后者我想大家都会，于是如何构造前者就是我们需要掌握的技能了。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;PS：当然，对于最常用的“高斯混合模型”已经有现成的公式可以套用了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;首先先看下Q函数的定义：&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;完全观测数据的对数似然函数logP(Y,Z&lt;/td&gt;
      &lt;td&gt;θ)关于在给定观测数据Y和当前参数θ(i)下对未观测数据Z的条件概率分布P(Z&lt;/td&gt;
      &lt;td&gt;Y, θ(i))的期望称为Q函数，即：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF12.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;于是你看懂了吗？
反正我一开始没看懂，虽然根据定义知道是求期望，但为了弄懂第二个等号真的用了我一番功夫。&lt;/p&gt;

&lt;p&gt;下面我解释下。
首先Q函数是求期望，这个不用多说。
然后，是求什么的期望？为了方面说明，我们把上面的式子的条件给去掉，即Q(θ, θ(i)) = E[logP(Y, Z)]。这下一目了然了，是求函数logP(Y,Z)的期望，而既然是求函数的期望，那就需要用到下面的知识了：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF13.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里使用第一个。
首先对于logP(Y,Z)，因为Y是观测变量数据，Z是隐变量数据，因此Z是未知量。所以，对应到上面第一个求法就是：x(变量)=Z，g(x) = g(z) = logP(Y, Z)，又因为Q函数的定义中已经告知P(Z| Y, θ(i))是条件概率分布，所以P(Z | Y, θ(i))就对应上面的分布律，不过为了方面说明，这里还是先将条件给去掉，即分布律为P(Z)。
这样一来，套用上面的公式，就有了：&lt;/p&gt;

&lt;p&gt;Ez[logP(Y,Z)] = logP(Y,Z)P(Z)&lt;/p&gt;

&lt;p&gt;上面为了方面理解而把表示条件的参数都给去掉了，下面按照Q函数的定义把条件给还原回来，于是就有了Q函数定义中的式子。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;PS：如果上面还原参数的这步你还有点晕，那就这样想：
            联合概率P(Y, Z)是在参数为θ的某分布中，所以为了用公式表述完整，我们将其写成P(Y,Z | θ)，分布律P(Z)是在观测变量Y和在EM算法中一步步迭代时当前步骤中已知的“以θ(i)为参数的某分布”下的分布律，所以为了用公式表述完整，我们将其写成P(Z | Y, θ(i))&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;至于Q函数为什么写成Q(θ, θ(i))，这是因为它想表达：在当前迭代中我要找出一个新θ，使得“以新θ为参数的某分布”优于“用上一次迭代中已找出的θ(i)为参数的某分布”。&lt;/p&gt;

&lt;h2 id=&quot;em算法另一种理解&quot;&gt;EM算法另一种理解&lt;/h2&gt;
&lt;p&gt;坐标上升法（Coordinate ascent）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/EMSF14.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图中的直线式迭代优化的路径，可以看到每一步都会向最优值前进一步，而且前进路线是平行于坐标轴的，因为每一步只优化一个变量。&lt;/p&gt;

&lt;p&gt;这犹如在x-y坐标系中找一个曲线的极值，然而曲线函数不能直接求导，因此什么梯度下降方法就不适用了。但固定一个变量后，另外一个可以通过求导得到，因此可以使用坐标上升法，一次固定一个变量，对另外的求极值，最后逐步逼近极值。对应到EM上，E步：固定θ，优化Q；M步：固定Q，优化θ；交替将极值推向最大。&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《统计学习方法》-李航&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;《机器学习》-周志华&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;《机器学习实战》-Peter Harrington&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;斯坦福大学公开课-机器学习&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;

&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201702215&quot; data-title=&quot;EM&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;

&lt;!-- 多说评论框 end --&gt;

&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;

&lt;script type=&quot;text/javascript&quot;&gt;

var duoshuoQuery = {short_name:&quot;yzhhome&quot;};

  (function() {

    var ds = document.createElement('script');

    ds.type = 'text/javascript';ds.async = true;

    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';

    ds.charset = 'UTF-8';

    (document.getElementsByTagName('head')[0] 

     || document.getElementsByTagName('body')[0]).appendChild(ds);

  })();

  &lt;/script&gt;

</description>
        <pubDate>Tue, 21 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/21/EM%E7%AE%97%E6%B3%95.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/21/EM%E7%AE%97%E6%B3%95.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>一般线性模型</title>
        <description>
</description>
        <pubDate>Sun, 19 Feb 2017 00:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//2017/02/19/%E4%B8%80%E8%88%AC%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//2017/02/19/%E4%B8%80%E8%88%AC%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html</guid>
        
        
      </item>
    
      <item>
        <title>决策树</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#决策树&quot; id=&quot;markdown-toc-决策树&quot;&gt;决策树&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#构建决策树&quot; id=&quot;markdown-toc-构建决策树&quot;&gt;构建决策树&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#信息增益&quot; id=&quot;markdown-toc-信息增益&quot;&gt;信息增益&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#id3算法&quot; id=&quot;markdown-toc-id3算法&quot;&gt;ID3算法&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#信息增益比&quot; id=&quot;markdown-toc-信息增益比&quot;&gt;信息增益比&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#c45算法&quot; id=&quot;markdown-toc-c45算法&quot;&gt;C4.5算法&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#id3和c45算法的特点&quot; id=&quot;markdown-toc-id3和c45算法的特点&quot;&gt;ID3和C4.5算法的特点&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#基尼指数和基尼指数gini&quot; id=&quot;markdown-toc-基尼指数和基尼指数gini&quot;&gt;基尼指数和基尼指数(Gini)&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#cart生成算法二叉分类树&quot; id=&quot;markdown-toc-cart生成算法二叉分类树&quot;&gt;CART生成算法（二叉分类树）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#二叉回归树&quot; id=&quot;markdown-toc-二叉回归树&quot;&gt;二叉回归树&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#决策树的剪枝&quot; id=&quot;markdown-toc-决策树的剪枝&quot;&gt;决策树的剪枝&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#先预剪枝&quot; id=&quot;markdown-toc-先预剪枝&quot;&gt;先（预）剪枝&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#后剪枝&quot; id=&quot;markdown-toc-后剪枝&quot;&gt;后剪枝&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#决策树的剪枝针对id3c45生成的决策树&quot; id=&quot;markdown-toc-决策树的剪枝针对id3c45生成的决策树&quot;&gt;决策树的剪枝（针对ID3/C4.5生成的决策树）&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#cart剪枝&quot; id=&quot;markdown-toc-cart剪枝&quot;&gt;CART剪枝&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#剪枝总结&quot; id=&quot;markdown-toc-剪枝总结&quot;&gt;剪枝总结：&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;决策树&quot;&gt;决策树&lt;/h1&gt;

&lt;p&gt;决策树应该是一个比较简单的算法了，对比后面svm，神经网络，PF树那些。所以应该讲起来应该会比较轻松，特别是学过数据结构的小伙伴来说，就更加的简单了。&lt;/p&gt;

&lt;p&gt;下面开始吧！开头必须要上一个通俗的例子是吧！去网上找到一个比较有意思的例子，如下:
      通俗来说，决策树分类的思想类似于找对象。现想象一个女孩的母亲要给这个女孩介绍男朋友，于是有了下面的对话：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  女儿：多大年纪了？

  母亲：26。

  女儿：长的帅不帅？

  母亲：挺帅的。

  女儿：收入高不？

  母亲：不算很高，中等情况。

  女儿：是公务员不？

  母亲：是，在税务局上班呢。

  女儿：那好，我去见见。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个女孩的决策过程就是典型的分类树决策。相当于通过年龄、长相、收入和是否公务员对将男人分为两个类别：见和不见。假设这个女孩对男人的要求是：30岁以下、长相中等以上并且是高收入者或中等以上收入的公务员，那么这个可以用下图表示女孩的决策逻辑（声明：此决策树纯属为了写文章而YY的产物，没有任何根据，也不代表任何女孩的择偶倾向）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图完整表达了这个女孩决定是否见一个约会对象的策略，其中绿色节点表示判断条件，橙色节点表示决策结果，箭头表示在一个判断条件在不同情况下的决策路径，图中红色箭头表示了上面例子中女孩的决策过程。&lt;/p&gt;

&lt;p&gt;这幅图基本可以算是一颗决策树，说它“基本可以算”是因为图中的判定条件没有量化，如收入高中低等等，还不能算是严格意义上的决策树，如果将所有条件量化，则就变成真正的决策树了。&lt;/p&gt;

&lt;p&gt;有了上面直观的认识，我们可以正式定义决策树了：&lt;/p&gt;

&lt;p&gt;决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。使用决策树进行决策的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果。&lt;/p&gt;

&lt;p&gt;可以看到，决策树的决策过程非常直观，容易被人理解。目前决策树已经成功运用于医学、制造产业、天文学、分支生物学以及商业等诸多领域。知道了决策树的定义以及其应用方法，下面就详细的介绍下决策树吧！&lt;/p&gt;

&lt;h2 id=&quot;构建决策树&quot;&gt;构建决策树&lt;/h2&gt;

&lt;p&gt;首先是特征选择，特征选择在构造决策树是关键，主要有通过信息增益，信息增益比，基尼系数，对率回归来划分并进而构建决策树的方式！下面就一个一个的介绍吧！&lt;/p&gt;

&lt;h3 id=&quot;信息增益&quot;&gt;信息增益&lt;/h3&gt;

&lt;p&gt;信息增益在这里我不打算讲了，详细请看&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/01/18/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7-%E4%B8%80.html#section-8&quot;&gt;这篇博文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;下面给出一些计算公式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree_n1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;id3算法&quot;&gt;ID3算法&lt;/h2&gt;

&lt;p&gt;ID3算法的核心思想就是以信息增益度量属性选择，选择分裂后信息增益最大的属性进行分裂。下面来看看详细的算法过程&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;输入： 训练数据集D，特征集A，阈值ε；&lt;/li&gt;
  &lt;li&gt;输出：决策树T；&lt;/li&gt;
  &lt;li&gt;过程：
    &lt;ol&gt;
      &lt;li&gt;若当前可用的D中的所有实例仅有一个类C，则将类C作为当前T的当前结点，返回T；&lt;/li&gt;
      &lt;li&gt;若A=Ф(即：没有可用特征。如：一开始就没有特征给你用或经过一定次数的分类后，特征已用过一遍)，则将D中实例数最大的那个类作为T的当前结点，返回T；&lt;/li&gt;
      &lt;li&gt;若A≠Ф，则计算各特征的信息增益，选择信息增益最大的特征Ag；&lt;/li&gt;
      &lt;li&gt;若Ag的信息增益小于阈值ε，则用当前D中实例数最大的类作为该节点的类标记，返回T；&lt;/li&gt;
      &lt;li&gt;否则，根据Ag中每一个值ai将当前的D分割成若干个非空子集Di，将Di中实例数最大的类作为标记，构建子结点，由节点集子结点构成T，返回T；&lt;/li&gt;
      &lt;li&gt;对第i个子结点，以Di为训练集，以ai为特征集，递归的调用1~5步，得到子树Ti，返回Ti；&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意：&lt;strong&gt;停止构建树的临界点有如下:
1.提取特征后，剩下只有一个类。
2.Ag的信息增益小于阈值ε
3.没有特征可取。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;例子：下面的例子来自《统计学习方法》(图片来自csnd):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ID3算法只有树的生成，所以该算法生成的树容易产生过拟合,针对这个问题，下面有专门的枝剪算法来防止过拟合。&lt;/p&gt;

&lt;p&gt;信息增益比的生成决策树的算法和ID3的算法类似，所以下面讲不再专门用信息增益比（C4.5算法）来举例。&lt;/p&gt;

&lt;h3 id=&quot;信息增益比&quot;&gt;信息增益比&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;若 g(X,Y)表示信息增益，H(X)表示信息熵，则信息增益比为：gR(X,Y) = g(X, Y) / H(X)。相信看懂信息增益的小伙伴看着这个信息增益比也是很好理解的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;c45算法&quot;&gt;C4.5算法&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;ID3算法存在一个问题，就是偏向于多值属性，例如，如果存在唯一标识属性ID，则ID3会选择它作为分裂属性，这样虽然使得划分充分纯净，但这种划分对分类几乎毫无用处。ID3的后继算法C4.5使用增益率（gain ratio）的信息增益扩充，试图克服这个偏倚。&lt;/li&gt;
  &lt;li&gt;C4.5算法就是将ID3第三步的信息增益换成信息增益比，其他不变。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;id3和c45算法的特点&quot;&gt;ID3和C4.5算法的特点&lt;/h2&gt;

&lt;p&gt;上面我们说了ID3和C4.5算法，下面我们就来总结下他们的特点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ID3对于多值特征
对于取值多的属性，尤其一些连续型数值，比如两条地理数据的距离属性，这个单独的属性就可以划分所有的样本，使得所有分支下的样本集合都是“纯的”也就是说这时候按照信息增益切分各部分都是纯的熵最小是0 ，但是这种切分没有意义（最极端的情况是每个叶子节点只有一个样本）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一个属性的信息增益越大，表明属性对样本的熵减少的能力更强，这个属性使得数据由不确定性变成确定性的能力越强。
所以如果是取值更多的属性，更容易使得数据更“纯”（尤其是连续型数值），其信息增益更大，决策树会首先挑选这个属性作为树的顶点。结果训练出来的形状是一棵庞大且深度很浅的树，这样的划分是极为不合理的。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;C4.5，增益率准则对可取值数目较少的属性有所偏好，因此实际中，我们先从候选划分属性中找出信息增益高于平均水平的属性，再从中选出增益率最高的。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;基尼指数和基尼指数gini&quot;&gt;基尼指数和基尼指数(Gini)&lt;/h3&gt;
&lt;p&gt;从节点的训练数据集D计算现有特征对该数据集的基尼指数(Gini)。此时，对每一个特征A，对其可能取得每一个值a，根据“样本A = a的结果是‘是’或‘否’”将D分割成D1，D2两部分，利用式①计算A = a 时的Gini。&lt;/p&gt;

&lt;p&gt;PS：基尼指数(Gini)代表了某一集合的不确定性，Gini越大，样本集合的不确定性就越大，这点和熵相似。其实，我们可以将信息增益和基尼系数进行对比，他们的关系可以见下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;cart生成算法二叉分类树&quot;&gt;CART生成算法（二叉分类树）&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;输入：训练数据D，停止计算的条件&lt;/li&gt;
  &lt;li&gt;输出：CART决策树(二叉树)&lt;/li&gt;
  &lt;li&gt;过程：
    &lt;ol&gt;
      &lt;li&gt;从节点的训练数据集D计算现有特征对该数据集的基尼指数(Gini)。此时，对每一个特征A，对其可能取得每一个值a，根据“样本A = a的结果是‘是’或‘否’”将D分割成D1，D2两部分，利用式①计算A = a 时的Gini。&lt;/li&gt;
      &lt;li&gt;在所有可能的特征A以及它们所有可能的切分点a中选择Gini最小的特征及其对应的切分点作为最优特征和最优切分点，然后依据最优特征与最优切分点从现节点生成两个子结点，最后将训练数据集依据特征分配到两个子结点中去。&lt;/li&gt;
      &lt;li&gt;对两个子结点递归的调用上面两步直至满足停止条件。&lt;/li&gt;
      &lt;li&gt;生成CART决策树。&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;PS：&lt;strong&gt;算法的停止条件是“节点的样本个数 &amp;lt; 预定阈值”或“样本集合的Gini &amp;lt; 预定阈值（样本基本属于同一类）”或“无更多特征”。&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;例子：
下面来看一个具体的例子。我们使用下图所示的数据集来作为示例，为了便于后面的叙述，我们将其再列出如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree6.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先对数据集非类标号属性{是否有房，婚姻状况，年收入}分别计算它们的Gini系数增益，取Gini系数增益值最大的属性作为决策树的根节点属性。根节点的Gini系数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/CART1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当根据是否有房来进行划分时，Gini系数增益计算过程为&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree7.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/CART2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;若按婚姻状况属性来划分，属性婚姻状况有三个可能的取值{married，single，divorced}，分别计算划分后的&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;{married}&lt;/td&gt;
          &lt;td&gt;{single,divorced}&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;{single}&lt;/td&gt;
          &lt;td&gt;{married,divorced}&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;{divorced}&lt;/td&gt;
          &lt;td&gt;{single,married}&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;的Gini系数增益。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/CART3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;对比计算结果，根据婚姻状况属性来划分根节点时取Gini系数增益最大的分组作为划分结果，也就是{married}&lt;/td&gt;
      &lt;td&gt;{single,divorced}。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;最后考虑年收入属性，我们发现它是一个连续的数值类型。我们在前面的文章里已经专门介绍过如何应对这种类型的数据划分了。对此还不是很清楚的朋友可以参考之前的文章，这里不再赘述。&lt;/p&gt;

&lt;p&gt;对于年收入属性为数值型属性，首先需要对数据按升序排序，然后从小到大依次用相邻值的中间值作为分隔将样本划分为两组。例如当面对年收入为60和70这两个值时，我们算得其中间值为65。倘若以中间值65作为分割点。Sl作为年收入小于65的样本，Sr表示年收入大于等于65的样本，于是则得Gini系数增益为&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/CART4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其他值的计算同理可得，我们不再逐一给出计算过程，仅列出结果如下（最终我们取其中使得增益最大化的那个二分准则来作为构建二叉树的准则）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree8.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最大化增益等价于最小化子女结点的不纯性度量（Gini系数）的加权平均值，之前的表里我们列出的是Gini系数的加权平均值，现在的表里给出的是Gini系数增益。现在我们希望最大化Gini系数的增益。根据计算知道，三个属性划分根节点的增益最大的有两个：年收入属性和婚姻状况，他们的增益都为0.12。此时，选取首先出现的属性作为第一次划分。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/CART5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于年收入属性则有：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree9.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后我们构建的CART如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree10.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;最后我们总结一下，CART和C4.5/ID3的主要区别：
C4.5/ID3采用信息增益/信息增益率来作为分支特征的选择标准，而CART则采用Gini系数；
C4.5/ID3不一定是二叉树，但CART一定是二叉树。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;二叉回归树&quot;&gt;二叉回归树&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;对回归树：用平方误差最小化准则，进行特征选择，生成二叉树,在这篇博文不讲了。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;决策树的剪枝&quot;&gt;决策树的剪枝&lt;/h2&gt;

&lt;p&gt;因为决策树的生成算法容易构建过于复杂的决策树，产生过拟合。而剪枝从已生成的树上裁掉一些子树或叶结点，并将其根结点或父结点作为新的叶结点，从而简化分类树模型，在这里我们可以联想其实剪枝就是一直正则化手段，简化模型，防止过拟合！下面我们进行详细介绍：&lt;/p&gt;

&lt;h3 id=&quot;先预剪枝&quot;&gt;先（预）剪枝&lt;/h3&gt;

&lt;p&gt;预剪枝是指在决策树生成过程中，对每个结点事先估计，若不能提升泛化性能，则停止划分当前结点。预剪枝降低了过拟合的风险，也减少了决策树的训练时间，但是它是一种“贪心算法”很有可能会造成欠拟合。&lt;/p&gt;

&lt;h3 id=&quot;后剪枝&quot;&gt;后剪枝&lt;/h3&gt;

&lt;h4 id=&quot;决策树的剪枝针对id3c45生成的决策树&quot;&gt;决策树的剪枝（针对ID3/C4.5生成的决策树）&lt;/h4&gt;

&lt;p&gt;在决策树学习中将已生成的树进行简化的过程称为剪枝(pruning)。具体地，剪枝从已生成的树上裁掉一些子树或叶结点，并将其根结点或父结点作为新的叶结点，从而简化分类树模型.
&lt;strong&gt;决策树的剪枝往往通过极小化决策树整体的损失函数(loss fimction)或代价函数( cost function)来实现。&lt;/strong&gt;
设树T的叶结点个数为|T|, t是树T的叶结点，该叶结点有Nt个样本点，其中k类的样本点有Ntk个，k=1,2,…,K，Ht(T)为叶结点t上的经验嫡，a&amp;gt;=0为参数，则决策树学习的损失函数可以定义为&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree11.png &quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree12.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因前面的一项可以表示为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree13.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;则最终公式为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree14.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;C(T)表示模型对训练数据的预测误差，即模型与训练数据的拟合程度，|T|表示平莫型复杂度，参数a&amp;gt;=0控制两者之间的影响。剪枝，就是当a确定时，选择损失函数最小的模型，即损失函数最小的子树。&lt;strong&gt;损失函数正好表示了对模型的复杂度和训练数据的拟合两者的平衡。
决策树生成只考虑了通过提高信息增益(或信息增益比)对训练数据进行更好的拟合，学习局部的模型；
决策树剪枝通过优化损失函数还考虑了减小模型复杂度，学习整体的模型。&lt;/strong&gt;
利用损失函数最小原则进行剪枝就是用正则化的极大似然估计进行模型选择。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree15.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree16.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;cart剪枝&quot;&gt;CART剪枝&lt;/h4&gt;

&lt;p&gt;其实CART剪枝有挺多方式的，但在这里我只讲一种简单的常用的（也就是该博文中的：CCP—代价复杂度剪枝），其他方式可以看看&lt;a href=&quot;http://www.cnblogs.com/yonghao/p/5064996.html&quot;&gt;这篇博文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;来看下原文&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/jianzhi1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/jianzhi2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/decision_tree17.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;剪枝总结&quot;&gt;剪枝总结：&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;我们可以说：决策树生成只考虑了通过提高信息增益(或信息增益比)对训练数据进行更好的拟合，学习局部的模型；决策树剪枝通过优化损失函数还考虑了减小模型复杂度，学习整体的模型。&lt;/li&gt;
  &lt;li&gt;后剪枝决策树比起预剪枝决策树保留了更多的分支。在一般情形下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但同时其训练时间花销也比较大。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《统计学习方法》-李航&lt;br /&gt;
《机器学习》-周志华&lt;br /&gt;
《机器学习实战》-Peter Harrington&lt;br /&gt;
斯坦福大学公开课-机器学习&lt;br /&gt;
网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201702181&quot; data-title=&quot;desicion tree&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Sat, 18 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/18/%E5%86%B3%E7%AD%96%E6%A0%91.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/18/%E5%86%B3%E7%AD%96%E6%A0%91.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>线性回归</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#线性回归&quot; id=&quot;markdown-toc-线性回归&quot;&gt;线性回归&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#简介&quot; id=&quot;markdown-toc-简介&quot;&gt;简介&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#一般线性回归&quot; id=&quot;markdown-toc-一般线性回归&quot;&gt;一般线性回归&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#寻找最优模型&quot; id=&quot;markdown-toc-寻找最优模型&quot;&gt;寻找最优模型&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#最小二乘&quot; id=&quot;markdown-toc-最小二乘&quot;&gt;最小二乘：&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#为什么要用最小二乘&quot; id=&quot;markdown-toc-为什么要用最小二乘&quot;&gt;为什么要用最小二乘&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#求解最小二乘&quot; id=&quot;markdown-toc-求解最小二乘&quot;&gt;求解最小二乘&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#正规方程组的求法&quot; id=&quot;markdown-toc-正规方程组的求法&quot;&gt;正规方程组的求法&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#广义逆矩阵伪逆&quot; id=&quot;markdown-toc-广义逆矩阵伪逆&quot;&gt;广义逆矩阵(伪逆):&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#梯度下降算法&quot; id=&quot;markdown-toc-梯度下降算法&quot;&gt;梯度下降算法&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#岭回归&quot; id=&quot;markdown-toc-岭回归&quot;&gt;岭回归&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#随机梯度下降&quot; id=&quot;markdown-toc-随机梯度下降&quot;&gt;随机梯度下降&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#局部加权回归&quot; id=&quot;markdown-toc-局部加权回归&quot;&gt;局部加权回归&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#缩减特征&quot; id=&quot;markdown-toc-缩减特征&quot;&gt;缩减特征&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#方向导数&quot; id=&quot;markdown-toc-方向导数&quot;&gt;方向导数&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#梯度的理解&quot; id=&quot;markdown-toc-梯度的理解&quot;&gt;梯度的理解&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;线性回归&quot;&gt;线性回归&lt;/h1&gt;

&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;最简单的一种机器学习模型，这个其实在高中（还是初中？）的时候我们就已经学过了，只不过那个时候觉的没什么用，也就大多数还给老师了！
先来一个例子，来来简单的说说它！
假设我们有一个经调查得到的数据集，内容是关于俄勒冈州波特兰地区47间出租公寓的面积与价格之间的关系表：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有了这样的数据，我们怎样才能预测波特兰地区其他出租公寓的价格，比如推如果一开始选的点就是最低点，那随机梯度下降将会怎么工作 答：会保持选的点就是最佳参数，这是因为那个偏导数为0（联系2次函数）
导出一个从面积得出价格的函数。这就转化为一个回归的问题：利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;通俗的说就是，给定一定量的现有数据，用这些数据来拟合出一个函数，然后对新的数据进行拟合，就可以得出一个函数值，这个值就作为预测值。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下面我们结合上面的例子，先画出其数据的点
&lt;img src=&quot;https://raw.githubusercontent.com/yzhihao/notes-LSJU-machine-learning/master/resource/chapter02_image01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后我们用这些数据来拟合一条直线，然后如果给我们一个新的数据，只知道他多少平方米，这个时候我们代入那个函数h（x）=θ*x+b(θ，b是参数，x是自变量)，得到预测值，就可以作为这个房子的预测价格了！（线性回归就是这样，看！多简单是吧！）&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;当然，整体上很简单，但细节我们还是要抠的，下面我们讲下细节和他的推广！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;一般线性回归&quot;&gt;一般线性回归&lt;/h2&gt;

&lt;p&gt;上面我们讨论了单个属性的回归，现在我们来讨论多个属性（n个）属性的回归。
下面给出公式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其实也是同样简单，我们只需要按照最简单的1个属性那样理解它就可以了，反正我是这样干的！现在有了目标函数，我们的目标是找到能预测最准的函数，那该怎么找能，就引出下下文：&lt;/p&gt;

&lt;h2 id=&quot;寻找最优模型&quot;&gt;寻找最优模型&lt;/h2&gt;

&lt;p&gt;我们这样想，有了上面的目标函数，我们最关键的是求出那些参数是吧，那现在我们能不能转变一个方向，看看从另一个方式，得到那些最优的参数，先看个式子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个叫成本函数，具体其他成本函数讲解可以看我的&lt;a href=&quot;https://yzhihao.github.io/machine%20learning/2017/01/18/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7-%E4%B8%80.html&quot;&gt;上一篇博文&lt;/a&gt;,好了，为什么，肯定很多人跟我一样，一眼看到这个式子的就想问为什么？为什么是平方差？为什么是误差平方和而不是绝对值或其他损失函数？为什么前面要加个1/2？下面一个一个解释:&lt;/p&gt;

&lt;h3 id=&quot;最小二乘&quot;&gt;最小二乘：&lt;/h3&gt;

&lt;p&gt;首先解释一下，上面那个成本函数是最小二乘回归模型中常见的最小二乘成本函数,最小二乘又是什么？
最小二乘（LS）问题是这样一类优化问题，目标函数是若干项的平方和，每一项具有形式，具体形式如下：&lt;img src=&quot;https://www.zhihu.com/equation?tex=f%28x%29%3D%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%7B%5Cleft%28+a_%7Bi%7D%5E%7BT%7Dx-b_%7Bi%7D+%5Cright%29%5E%7B2%7D+%7D+&quot; alt=&quot;&quot; /&gt;
或者如下：
&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Csum_%7Bi%3D1%7D%5E%7Bk%7D%5Cleft%28y_%7Bi%7D-%5Chat%7Bf%7D+%28x_%7Bi%7D%2C%5Ctheta+%29%5Cright%29%5E%7B2%7D&quot; alt=&quot;&quot; /&gt;
其中y是真值，
&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Chat%7Bf%7D%28x%2C%5Ctheta+%29&quot; alt=&quot;&quot; /&gt;
是估计值，式1和式2是一样的，只是用的符号不同，式1中的x对应式2中的θ ，即优化中要求的变量。
说下为什么在这里我们要为前面添加一个1/2，因为在之后的求导中能更简单的化简而且不会对结果产生影响！&lt;/p&gt;

&lt;p&gt;最小二乘法的二乘是什么:简单地说,最小二乘的思想就是要使得观测点和估计点的距离的平方和达到最小.这里的“二乘”指的是用平方来度量观测点与估计点的远近（在古汉语中“平方”称为“二乘”）,“最小”指的是参数的估计值要保证各个观测点与估计点的距离的平方和达到最小..
为什么要二乘:因为观测点和估计点之差可正可负,简单求和可能将很大的误差抵消掉,只有平方和才能反映二者在总体上的接近程度.&lt;/p&gt;

&lt;h3 id=&quot;为什么要用最小二乘&quot;&gt;为什么要用最小二乘&lt;/h3&gt;

&lt;p&gt;为什么使用最小二乘成本函数J？这样合理吗？有那么多别的指标，比如预测值与实际值之差的绝对值、四次方等，为什么偏偏选择差的平方作为优化指标？我们将从一系列基于概率的假设中推出最小二乘回归的合理性。&lt;/p&gt;

&lt;p&gt;首先我们得复习一下线性回归的模型及假设：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ε(i) ∼ N(0, σ2)，随机误差ε服从正态分布（高斯分布）
ε(i) are distributed IID，随机误差ε是独立同分布的
于是可以获得目标变量的条件概率分布：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R5.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;整个训练集的似然函数，与对数似然函数分别为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R6.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因此，最大化对数似然函数，也就相当于最小化,于是，我们发现，圈着的这个式子正是成本函数J(θ)的定义式。&lt;/p&gt;

&lt;p&gt;综上，可以看出，在关于训练数据的概率假设中，最小二乘回归与θθ的最大似然估计一致。也正是因为最小二乘回归其实是再做最大似然估计，所以我们才会强调最小二乘是一种“很自然”的方法。（不过，概率假设并不是证明“最小二乘是一种非常易用的、合理的求解过程”这一结论的必要条件，这只是众多假设中的一种，最小二乘在这种假设下合理，除此之外还有其他假设也可以证明这一结论。）&lt;/p&gt;

&lt;h2 id=&quot;求解最小二乘&quot;&gt;求解最小二乘&lt;/h2&gt;
&lt;p&gt;有了成本函数，我们下一步自然要求解最小的成本函数，找到最优的参数，所以这里就转变成为了求最小值的问题。在这里我就介绍两种方法吧，至于牛顿法，拟牛顿法，坐标法和他们的推广就下次再讲吧！&lt;/p&gt;

&lt;h3 id=&quot;正规方程组的求法&quot;&gt;正规方程组的求法&lt;/h3&gt;
&lt;p&gt;这个很简单。就是我们平时学的求解一个函数的通用方法，直接求导，然后使得导数等于0，求得驻点，最后得到最小值！对于上面的成本函数的求解如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R7.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;得到结果是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R8.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;中间的求解过程有点点复杂。我们主要要记住那个结论的式子。然后改怎么记呢？这里给出一个小小的tips（我也是网上看到的），这个结果有个简单的记法(可以这样记，但一旦有人问这个结果的来历，可不能这样回答)：Xθ= y  =&amp;gt;  X^T&lt;em&gt;Xθ= X^T&lt;/em&gt;y  =&amp;gt;  θ= (X^T X)^ -1*X^Ty&lt;/p&gt;

&lt;p&gt;讲到正规方程组，然后再讲讲伪拟和岭回归!&lt;/p&gt;

&lt;h3 id=&quot;广义逆矩阵伪逆&quot;&gt;广义逆矩阵(伪逆):&lt;/h3&gt;

&lt;p&gt;什么是广义逆矩阵，请看下图：
&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;梯度下降算法&quot;&gt;梯度下降算法&lt;/h2&gt;

&lt;p&gt;介绍完上面的正规方程组，下面来看下另一种比较简单的优化算法–梯度下降，这个算法很重要，在机器学习领域，很多地方都用到，包括那些现在比较火的深度神经网络的求解！&lt;/p&gt;

&lt;p&gt;首先看下式子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R9.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
[a表示的是步长或者说是学习率（learning rate）]&lt;/p&gt;

&lt;p&gt;好了，怎么理解？在直观上，我们可以这样理解，看下图，一开始的时候我们随机站在一个点，把他看成一座山，每一步，我们都以下降最多的路线来下山，那么，在这个过程中我们到达山底（最优点）是最快的，而上面的a，它决定了我们“向下山走”时每一步的大小，过小的话收敛太慢，过大的话可能错过最小值）。这是一种很自然的算法，每一步总是寻找使J下降最“陡”的方向（就像找最快下山的路一样）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/grendt_xiajian.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当然了，我们直观上理解了之后，接下来肯定是从数学的角度，我们可以这样想，先想在低维的时候，比如二维，我们要找到最小值，其实可以是这样的方法，具体化到1元函数中时，梯度方向首先是沿着曲线的切线的，然后取切线向上增长的方向为梯度方向，2元或者多元函数中，梯度向量为函数值f对每个变量的导数，该向量的方向就是梯度的方向，当然向量的大小也就是梯度的大小。现在假设我们要求函数的最值，采用梯度下降法，结合如图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R10.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如图所示，我们假设函数是y=x^2+1,那么如何使得这个函数达到最小值呢，简单的理解，就是对x求导，得到y‘=1/2*x，然后有梯度下降的方式，如果初始值是（0的左边）负值,那么这是导数也是负值，用梯度下降的公式，使得x更加的靠近0,如果是正值的时候同理！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下面是两种梯度下降的方式:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;batch gradient descent 批量梯度下降:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R11.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;stochastic gradient descent (incremental gradient descent) 随机梯度下降&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R12.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;岭回归&quot;&gt;岭回归&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linghuigui.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;随机梯度下降&quot;&gt;随机梯度下降&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;值得注意的是，随机梯度下降可能永远都不会收敛于最小值点，参数θ将在J(θ)最小值附近持续摆动。不过，在实践中，最小值附近的解通常都足够接近最小值。另外，在随机梯度下降的实际操作中，随着迭代步骤的进行，我们会慢慢减小α的值至0，这样也可以保证参数收敛于全局最小值，而不是在其附近持续摆动&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;问1：如果一开始选的点就是最低点，那随机梯度下降将会怎么工作&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;答1：会保持选的点就是最佳参数，这是因为那个偏导数为0（联系2次函数）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;问2：梯度下降的公式是怎么来的&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;答2：理解在2次函数的时候来理解，就是参数减去导数的值，然后更新参数，来自：coursera机器学习&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;问3：批量和随机梯度的本质区别是什么&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;答4：就是成本函数的不同，批量是计算把所有的数据都误差和，然后求导得，随机的成本函数是随机拿一条数据来作为误差，然后求导&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;局部加权回归&quot;&gt;局部加权回归&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;通常情况下的线性拟合不能很好地预测所有的值，因为它容易导致欠拟合（under fitting），比如数据集是一个钟形的曲线。而多项式拟合能拟合所有数据，但是在预测新样本的时候又会变得很糟糕，因为它导致数据的过拟合（overfitting），不符合数据真实的模型。&lt;/li&gt;
  &lt;li&gt;线性回归的推广，就是在求参的时候不同，可以得到多个”子模型“，但模型同样是线性的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;首先在局部加权回归中，上面的损失函数变为
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R13.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R14.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;函数中的τ称作带宽（bandwidth）（或波长）参数，它控制了权值随距离下降的速率。如果τ取值较小，则会得到一个较窄的钟形曲线，这意味着离给定查询点x较远的训练样本x(i)的权值（对查询点xx附近训练样本的拟合的影响）将下降的非常快；而τ较大时，则会得到一个较为平缓的曲线，于是查询点附近的训练样本的权重随距离而下降的速度就会相对比较慢。&lt;/p&gt;

&lt;p&gt;若直接求解得到最终的参数求解式子是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R15.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面从图来直观感受局部加权回归和普通回归的不同：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;普通回归&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R16.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;局部加权回归&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/linear_R17.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;缩减特征&quot;&gt;缩减特征&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;求解的时候都要做特征缩减&lt;/li&gt;
  &lt;li&gt;为了使得随机梯度下降工作的更好，一般要把轮廓变为差不多圆形，就要用到特征缩放。&lt;/li&gt;
  &lt;li&gt;方法：就是(x-（均值）)/（最大到最小的范围）&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/learn/machine-learning/supplement/CTA0D/gradient-descent-in-practice-i-feature-scaling&quot;&gt;具体看课件&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;si is the range of values (max - min), or si is the standard deviation.除数可以是标准差，也可以是极差&lt;/li&gt;
  &lt;li&gt;这个预处理操作只有在确信不同的输入特征有不同的数值范围（或计量单位）时才有意义，但要注意预处理操作的重要性几乎等同于学习算法本身。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;方向导数&quot;&gt;方向导数&lt;/h3&gt;
&lt;p&gt;自变量是多个标量，或者理解成一个多维的向量。那么，函数随自变量的变化怎么刻画呢？一个方法，就是衡量函数在给定方向上的变化率，这就是方向导数。方向导数的特例，就是函数随各个自变量（标量）的变化率，即函数的偏导数，也就是函数沿各个坐标轴正方向的方向导数。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/36301367&quot;&gt;理解方向导数和&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;梯度的理解&quot;&gt;梯度的理解&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;在个偏导数的方向就是其梯度的方向，这也是变化最快的方向。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;看高数下册
&lt;a href=&quot;http://blog.csdn.net/lotus___/article/details/20546259#comments&quot;&gt;详数学推导&lt;/a&gt;
最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《统计学习方法》-李航&lt;br /&gt;
《机器学习》-周志华&lt;br /&gt;
《机器学习实战》-Peter Harrington&lt;br /&gt;
斯坦福大学公开课-机器学习&lt;br /&gt;
网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201702161&quot; data-title=&quot;linear_R&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Thu, 16 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/16/%E5%9B%9E%E5%BD%92-%E7%AE%80%E5%8D%95%E5%88%86%E7%B1%BB.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/16/%E5%9B%9E%E5%BD%92-%E7%AE%80%E5%8D%95%E5%88%86%E7%B1%BB.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>机器学习有关的数学基础知识-概率</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#机器学习有关的数学基础知识-概率&quot; id=&quot;markdown-toc-机器学习有关的数学基础知识-概率&quot;&gt;机器学习有关的数学基础知识-概率&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#条件概率&quot; id=&quot;markdown-toc-条件概率&quot;&gt;条件概率&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#贝叶斯概率&quot; id=&quot;markdown-toc-贝叶斯概率&quot;&gt;贝叶斯概率&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#离散型连续型随机变量&quot; id=&quot;markdown-toc-离散型连续型随机变量&quot;&gt;离散型/连续型随机变量&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#常见的离散型随机变量分布&quot; id=&quot;markdown-toc-常见的离散型随机变量分布&quot;&gt;常见的离散型随机变量分布&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#0-1分布贝努利分布&quot; id=&quot;markdown-toc-0-1分布贝努利分布&quot;&gt;0-1分布/贝努利分布&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#二项分布&quot; id=&quot;markdown-toc-二项分布&quot;&gt;二项分布&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#泊松分布&quot; id=&quot;markdown-toc-泊松分布&quot;&gt;泊松分布.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#二项分布和泊松分布&quot; id=&quot;markdown-toc-二项分布和泊松分布&quot;&gt;二项分布和泊松分布&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#几何分布&quot; id=&quot;markdown-toc-几何分布&quot;&gt;几何分布&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#分布函数&quot; id=&quot;markdown-toc-分布函数&quot;&gt;分布函数&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#概率密度和离散型随机变量&quot; id=&quot;markdown-toc-概率密度和离散型随机变量&quot;&gt;概率密度和离散型随机变量&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#均匀分布&quot; id=&quot;markdown-toc-均匀分布&quot;&gt;均匀分布&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#指数分布&quot; id=&quot;markdown-toc-指数分布&quot;&gt;指数分布&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#高斯分布&quot; id=&quot;markdown-toc-高斯分布&quot;&gt;高斯分布&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#正态分布的用途&quot; id=&quot;markdown-toc-正态分布的用途&quot;&gt;正态分布的用途：&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#中心极限定理&quot; id=&quot;markdown-toc-中心极限定理&quot;&gt;中心极限定理&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#联合概率和边缘概率&quot; id=&quot;markdown-toc-联合概率和边缘概率&quot;&gt;联合概率和边缘概率&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#概率论中的独立同分布请分别解释独立同分布及独立同分布&quot; id=&quot;markdown-toc-概率论中的独立同分布请分别解释独立同分布及独立同分布&quot;&gt;概率论中的独立同分布?请分别解释独立、同分布及独立同分布.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#联合分布&quot; id=&quot;markdown-toc-联合分布&quot;&gt;联合分布&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#二元高斯分布&quot; id=&quot;markdown-toc-二元高斯分布&quot;&gt;二元高斯分布&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#期望&quot; id=&quot;markdown-toc-期望&quot;&gt;期望&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#极大似然估计&quot; id=&quot;markdown-toc-极大似然估计&quot;&gt;极大似然估计&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;机器学习有关的数学基础知识-概率&quot;&gt;机器学习有关的数学基础知识-概率&lt;/h1&gt;

&lt;h2 id=&quot;条件概率&quot;&gt;条件概率&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;当A,B都代表是一个事件的时候，条件概率的计算：&lt;code class=&quot;highlighter-rouge&quot;&gt;p(AB)=P(B)P(A|B)&lt;/code&gt;。这个是高中就学过的，不多说！&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;贝叶斯概率&quot;&gt;贝叶斯概率&lt;/h2&gt;
&lt;p&gt;学习机器学习，就不得不学贝叶斯这个东西啦，首先，不要怕，他就是一个条件概率，表面上理解起来很简单！&lt;/p&gt;

&lt;p&gt;要学习贝叶斯概率，首先就是要知道全概率公式。全概率公式如下：
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/machine_sta2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不要着急，如果理解不了下面有例子。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;贝叶斯概率分布由分子就是条件概率计算结果，分布就是全概率的就算结果。如下图：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/machine_sta1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;下面来好好看看这个公式：若&lt;code class=&quot;highlighter-rouge&quot;&gt;P(A|B) = P(A)P(B|A) / P(B)&lt;/code&gt;，则&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;P(A)：先验概率。即：在的得到新数据前某一假设的概率。
P(A|B)：后验概率。即：在看到新数据后，要计算的该假设的概率。
P(B|A)：似然度。即：在该假设下，得到这一数据的概率。
P(B)：标准化常量。即：在任何假设下得到这一数据的概率。&lt;/p&gt;

&lt;p&gt;好了上例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/machine_sta3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/machine_sta4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;离散型连续型随机变量&quot;&gt;离散型/连续型随机变量&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;随机变量X：为一映射,其自变量具有随机性，就是一个函数，注意：自变量是事件，因变量是事件发生的概率&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;若随机变量X的取值为有限个或可数,就称X离散,自变量-事件离散。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;常见的离散型随机变量分布&quot;&gt;常见的离散型随机变量分布&lt;/h2&gt;

&lt;h3 id=&quot;0-1分布贝努利分布&quot;&gt;0-1分布/贝努利分布&lt;/h3&gt;

&lt;p&gt;随机变量X的只可能取0，1 两个值，只有两个可能结果的试验，故称为&lt;strong&gt;两点分布&lt;/strong&gt;有时也称为&lt;strong&gt;贝努利分布&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;可以理解为只有一次实验，两种可能的值的分布&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;二项分布&quot;&gt;二项分布&lt;/h3&gt;

&lt;p&gt;就是k重伯努利实验的分布中，p发生K次的概率&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意，0-1分布/贝努利分布是二项分布的一种特殊情况，就是n=1的时候&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;泊松分布&quot;&gt;泊松分布.&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;如果某事件以固定强度λ,随机且独立地出现，该事件在单位时间内出现的次数（个数）可以看成是服从泊松分布.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;例如：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    某人一天内收到的微信的数量
    来到某公共汽车站的乘客
    某放射性物质发射出的粒子
    显微镜下某区域中的白血球
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;二项分布和泊松分布&quot;&gt;二项分布和泊松分布&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;
即 当 n &amp;gt;10, p &amp;lt; 0.1 时 , 二项分布 B ( n , p ) 可以用泊松分布pi( np ) 来近似.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在这里，可以这样看：就是当事件多样性多，概率都较低的时候就是泊松分布，否则就是二项分布&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;几何分布&quot;&gt;几何分布&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;在重复多次的贝努里试验中, 试验进行到某种结果出现第一次为止此时的试验总次数服从几何分布. 如：射击, 首次击中目标时射击的次数;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;分布函数&quot;&gt;分布函数&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;就是关于随机变量的函数，也就是关于x&amp;lt;某个值(在离散型表示的就是边界，在连续表示的就是某一个点)的函数&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;一般地，离散型随机变量的分布函数为阶梯函数，&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;离散型和连续型分布函数的理解见&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;概率密度和离散型随机变量&quot;&gt;概率密度和离散型随机变量&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;两个是相对应的，其性质是相对应的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;两个是一样的，但随机变量表示离散时的事件概率，概率密度表示在某个值的概率。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;随机变量就是：事件到概率的映射，密度函数也一样，只不过是极限&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;随机变量函数就是用随机变量做自变量&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;连续型结合直线上的例子，注意的是F(x)表示的是概率，面积总和为1，F（x）表示的是概率密度可以大于1，这个值大小满足积分为1，并大于0就可，可以用&lt;strong&gt;课件：概率密度和连续型变量的例1&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;F(x)一定是一个连续函数&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;均匀分布&quot;&gt;均匀分布&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;直观理解：x落到a，b等长即落入中的的任意子度等区间上是可能的.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;概率计算就可以推导出是长度之比&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;指数分布&quot;&gt;指数分布&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;概率密度函数是一个指数阶的&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重要的性质，是无记忆性的，这个性质就是唯一的。也就是说看是不是服从指数分布就可以通过是否有无记忆性来指出&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;打电话的例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/machine_sta6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
答案：
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/machine_sta7.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;高斯分布&quot;&gt;高斯分布&lt;/h2&gt;
&lt;p&gt;关于高斯分布的性质如下图：
&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一般的高斯分布可以转化（(x-u)/(方差)）为标准正太分布，然后再去查表算概率值&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;正态分布的用途&quot;&gt;正态分布的用途：&lt;/h3&gt;
&lt;p&gt;自然界和人类社会中很多现象可以看做正态分布&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;如: 人的生理尺寸(身高、体重);
医学检验指标(红细胞数、血小板);
测量误差;等等
多个随机变量的和可以用正态分布来近似
如: 注册MOOC的某位同学完成所有作业的时间;
二项分布; 等等
(By 中心极限定理)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;中心极限定理&quot;&gt;中心极限定理&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;中心极限定理是概率论中的一组定理。中央极限定理说明，大量相互独立的随机变量，其均值的分布以正态分布为极限。这组定理是数理统计学和误差分析的理论基础，指出了大量随机变量之和近似服从正态分布的条件。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/HistPropOfHeads.png/300px-HistPropOfHeads.png&quot; alt=&quot;&quot; /&gt;
本图描绘了多次抛掷硬币实验中出现正面的平均比率，每次实验均抛掷了大量硬币。&lt;/p&gt;

&lt;h2 id=&quot;联合概率和边缘概率&quot;&gt;联合概率和边缘概率&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;条件概率和联合概率的区别，看例子&lt;strong&gt;例5，离散型多元概率&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而对于条件概率和联合概率的区别请看下面的例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;//TODO待截图&lt;/p&gt;

&lt;h2 id=&quot;概率论中的独立同分布请分别解释独立同分布及独立同分布&quot;&gt;概率论中的独立同分布?请分别解释独立、同分布及独立同分布.&lt;/h2&gt;

&lt;p&gt;(1)独立就是每次抽样之间是没有关系的,不会相互影响&lt;/p&gt;

&lt;p&gt;就像我抛色子每次抛到几就是几这就是独立的&lt;/p&gt;

&lt;p&gt;但若我要两次抛的和大于8,其余的不算,那么第一次抛和第二次抛就不独立了,因为第二次抛的时候结果是和第一次相关的&lt;/p&gt;

&lt;p&gt;(2)同分布的意思就是每次抽样,样本都服从同样的一个分布&lt;/p&gt;

&lt;p&gt;抛色子每次得到任意点数的概率都是1/6,这就是同分布的&lt;/p&gt;

&lt;p&gt;但若我第一次抛一个六面的色子,第二次抛一个正12面体的色子,就不再是同分布了&lt;/p&gt;

&lt;p&gt;(3)独立同分布,也叫i,i,d,就是每次抽样之间独立而且同分布的意思&lt;/p&gt;

&lt;p&gt;追问：&lt;/p&gt;

&lt;p&gt;同分布是指服从同一分布函数么？是的。&lt;/p&gt;

&lt;h2 id=&quot;联合分布&quot;&gt;联合分布&lt;/h2&gt;

&lt;p&gt;随机变量X和Y的联合分布函数是设(X,Y)是二维随机变量，对于任意实数x,y，二元函数：F(x,y) = P{(X&amp;lt;=x) 交 (Y&amp;lt;=y)} =&amp;gt; P(X&amp;lt;=x, Y&amp;lt;=y)称为二维随机变量(X,Y)的分布函数。&lt;/p&gt;

&lt;h2 id=&quot;二元高斯分布&quot;&gt;二元高斯分布&lt;/h2&gt;

&lt;p&gt;*　关于二元的条件和边际分布，请查看慕课&lt;/p&gt;

&lt;p&gt;*　注意边际分布和条件分布也是一个一元的高斯分布。&lt;/p&gt;

&lt;h2 id=&quot;期望&quot;&gt;期望&lt;/h2&gt;
&lt;p&gt;probability_math&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;连续型的期望可以类比离散型的期望，不过就是一个是求和，一个是积分&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;极大似然估计&quot;&gt;极大似然估计&lt;/h2&gt;

&lt;p&gt;先上一个例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/probability_math.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;答：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/probability_math1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;就是先给出一定的样本结果，通过结果来极大的估计参数值,需要注意的是，这里是知道分布而求参数（与EM算法要区别开），使得得到这样结果的可能性最大&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果是离散型的就是随机事件的概率，如果是连续型的可能就是一个参数&lt;strong&gt;具体看课件：极大似然估计&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;给出连续型和离散型的标准定义：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/probability_math2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/probability_math3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;再举个例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/probability_math4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/probability_math5.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其实对L(θ)取对数将其变成连加的H(θ)还有一个原因：通常L(θ)中每个p(xi; θ)都很小，许多很小的数字相乘起来在计算机里很容易造成浮点数下溢，所以对其取对数将其变成连加的&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;讲到极大似然就想起EM算法，他们之间有很大的联系&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;EM算法是为了解决“最大似然估计”中更复杂的情形而存在的。
这里“极大似然估计中更复杂的情形”是什么情形呢？
我们知道极大似然估计是求解实现结果的最佳参数θ，但极大似然估计需要面临的概率分布只有一个或者知道结果是通过哪个概率分布实现的，只不过你不知道这个概率分布的参数。而如果概率分布有多个呢或者你不知道结果是通过哪个概率分布实现的？于是别说去确定“这些概率分布”的最佳参数了，我们连最终结果是根据哪个概率分布得出来的都不知道，这就是EM算法要面临的情况了。有关EM算法更多看我的那篇博文&lt;a href=&quot;&quot;&gt;EM算法&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;http://wenku.baidu.com/link?url=Bh9Zhx3xPnT_yLtWfe6GHgUugl3W78iF2qVBvoo8q1BBhcJzsrdmYWqJo5wgfKsBjSY_7QqsagHx2vwZnMKyPJl3dl0xY_5Wue-XhyjMQT3&quot;&gt;混合概率模型&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《深度学习》-Bengio&lt;br /&gt;
《统计学习方法》-李航&lt;br /&gt;
《机器学习》-周志华&lt;br /&gt;
《机器学习实战》-Peter Harrington&lt;br /&gt;
斯坦福大学公开课-机器学习&lt;br /&gt;
网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 14 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%89%E5%85%B3%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E6%A6%82%E7%8E%87.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%89%E5%85%B3%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E6%A6%82%E7%8E%87.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>机器学习有关的数学基础知识-线代</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#机器学习有关的数学基础知识-线代&quot; id=&quot;markdown-toc-机器学习有关的数学基础知识-线代&quot;&gt;机器学习有关的数学基础知识-线代&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#方差标准差协方差&quot; id=&quot;markdown-toc-方差标准差协方差&quot;&gt;方差，标准差，协方差&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#为什么需要协方差&quot; id=&quot;markdown-toc-为什么需要协方差&quot;&gt;为什么需要协方差？&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#协方差矩阵&quot; id=&quot;markdown-toc-协方差矩阵&quot;&gt;协方差矩阵&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#正定负定矩阵&quot; id=&quot;markdown-toc-正定负定矩阵&quot;&gt;正定，负定矩阵&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#特征分解&quot; id=&quot;markdown-toc-特征分解&quot;&gt;特征分解&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#奇异值分解&quot; id=&quot;markdown-toc-奇异值分解&quot;&gt;奇异值分解&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#奇异值分解和特征分解几何意义&quot; id=&quot;markdown-toc-奇异值分解和特征分解几何意义&quot;&gt;奇异值分解和特征分解几何意义&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;机器学习有关的数学基础知识-线代&quot;&gt;机器学习有关的数学基础知识-线代&lt;/h1&gt;

&lt;h2 id=&quot;方差标准差协方差&quot;&gt;方差，标准差，协方差&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;为什么需要协方差&quot;&gt;为什么需要协方差？&lt;/h3&gt;

&lt;p&gt;标准差和方差一般是用来描述一维数据的，但现实生活我们常常遇到含有多维数据的数据集，最简单的 大家上学时免不了要统计多个学科的考试成绩。面对这样的数据集，我们当然可以按照每一维独立的计算其方差，但是通常我们还想了解更多，比如，一个男孩子的 猥琐程度跟他受女孩子欢迎程度是否存在一些联系啊，嘿嘿~协方差就是这样一种用来度量两个随机变量关系的统计量&lt;/p&gt;

&lt;h3 id=&quot;协方差矩阵&quot;&gt;协方差矩阵&lt;/h3&gt;

&lt;p&gt;理解协方差矩阵的关键就在于牢记&lt;strong&gt;它计算的是不同维度之间的协方差，而不是不同样本之间，&lt;/strong&gt;拿到一个样本矩阵，我们最先要明确的就是一行是一个样本还是一个维度，心中明确这个整个计算过程就会顺流而下，这么一来就不会迷茫了&lt;/p&gt;

&lt;p&gt;举个例子：&lt;/p&gt;

&lt;p&gt;问题：
有一组数据（如下），分别为二维向量，这四个数据对应的协方差矩阵是多少？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/math_L1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;解答：
由于数据是二维的，所以协方差矩阵是一个2&lt;em&gt;2的矩阵，矩阵的每个元素为：
元素(i,j) = (第 i 维所有元素 - 第 i 维的均值) * (第 j 维所有元素 - 第 j 维的均值) 。
其中「&lt;/em&gt;」代表向量内积符号，即两个向量求内积，对应元素相乘之后再累加。
我们首先列出第一维：&lt;/p&gt;

&lt;p&gt;D1: (1,3,4,5) 均值：3.25
D2: (2,6,2,2) 均值：3&lt;/p&gt;

&lt;p&gt;下面计算协方差矩阵第(1,2)个元素：&lt;/p&gt;

&lt;p&gt;元素(1,2)=(1-3.25,3-3.25,4-3.25,5-3.25)*(2-3,6-3,2-3,2-3)=-1&lt;/p&gt;

&lt;p&gt;类似的，我们可以把全部个元素都计算出来：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/math_L2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个题目的最终结果就是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/math_L3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;看完上面的例子，现在来总结以下它的特点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;对角线元素(i,i)为数据第 i 维的方差。&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;非对角线元素(i,j)为第 i 维和第 j 维的协方差。&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;协方差矩阵是对称阵。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;协方差矩阵在二元高斯分布中决定了它的形状，&lt;a href=&quot;http://www.zipperary.com/2014/01/12/covariance/&quot;&gt;详细演示&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在&lt;a href=&quot;&quot;&gt;降维技术&lt;/a&gt;那篇博文中，我们讲述了PCA,和这里的协方差矩阵有极大关系，在&lt;a href=&quot;&quot;&gt;神经网络-基本概念&lt;/a&gt;中，讲述了数据预处理的白化，也是跟协方差矩阵有极大的关系。其实在机器学习中，很多时候，协方差矩阵都扮演着非常重要的角色，在这里就不一一的列出了，我们要好好的理解协方差矩阵的意义，关于它，给出一篇&lt;a href=&quot;http://www.cnblogs.com/nsnow/p/4758202.html&quot;&gt;不错的博文&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;正定负定矩阵&quot;&gt;正定，负定矩阵&lt;/h2&gt;

&lt;p&gt;所有特征值都是正数的矩阵被称为正定；所有特征值都是非负数的矩阵被称为半正定。 同样地，所有特征值都是负数的矩阵被称为负定；所有特征值都是非正数的矩阵被称为半负定。 半正定矩阵受到关注是因为它们保证∀x,x⊤Ax≥0。 此外，正定矩阵还保证x^⊤Ax=0⇒x=0&lt;/p&gt;

&lt;h2 id=&quot;特征分解&quot;&gt;特征分解&lt;/h2&gt;

&lt;p&gt;我相信学过线性代数的小伙伴，一定对特征分解不陌生&lt;/p&gt;

&lt;p&gt;许多数学对象可以通过将它们分解成多个组成部分，或者找到它们的一些属性而更好地理解，这些属性是通用的，而不是由我们选择表示它们的方式引起的。&lt;/p&gt;

&lt;p&gt;例如:整数可以分解为质数。 我们可以用十进制或二进制等不同方式表示整数12，但质因数分解永远是对的12=2×3×3。 从这个表示中我们可以获得一些有用的信息，比如12不能被5整除，或者12的倍数可以被3整除。&lt;/p&gt;

&lt;p&gt;正如我们可以通过分解质因数来发现整数的一些内在性质，我们也可以通过分解矩阵来发现矩阵表示成数组元素时不明显的函数性质。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;特征分解是使用最广的矩阵分解之一，即我们将矩阵分解成一组特征向量和特征值。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;一个变换（或者说矩阵）的特征向量就是这样一种向量，它经过这种特定的变换后保持方向不变，只是进行长度上的伸缩而已。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;特征向量的原始定义：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/math_L4.gif&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以很容易看出，cx是方阵A对向量x进行变换后的结果，显然&lt;strong&gt;cx和x的方向相同。&lt;/strong&gt;而且x是特征向量的话，ax也是特征向量（a是标量且不为零），所以&lt;strong&gt;特征向量不是一个向量而是一个向量族。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;另外，特征值只不过反映了特征向量在变换时的伸缩倍数而已。对一个变换而言，特征向量指明的方向才是很重要的，特征值不那么重要。虽然我们求这两个量时先求出特征值，但&lt;strong&gt;特征向量才是更本质的东西！特征向量是指经过指定变换（与特定矩阵相乘）后不发生方向改变的那些向量，特征值是指在经过这些变换后特征向量的伸缩的倍数,&lt;/strong&gt;也就是说矩阵对某一个向量或某些向量只发生伸缩变换，不对这些向量产生旋转的效果，那么这些向量就称为这个矩阵的特征向量，伸缩的比例就是特征值。&lt;/p&gt;

&lt;p&gt;实际上，上述的一段话既讲了矩阵变换特征值及特征向量的几何意义（图形变换）也讲了其物理含义。物理的含义就是运动的图景：特征向量在一个矩阵的作用下作伸缩运动，伸缩的幅度由特征值确定。特征值大于1，所有属于此特征值的特征向量身形暴长；特征值大于0小于1，特征向量身形猛缩；特征值小于0，特征向量缩过了界，反方向到0点那边去了。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意：常有教科书说特征向量是在矩阵变换下不改变方向的向量，实际上当特征值小于零时，矩阵就会把特征向量完全反方向改变，当然特征向量还是特征向量。我赞同特征向量不改变方向的说法：特征向量永远不改变方向，改变的只是特征值（方向反转特征值为负值了）。特征向量是线性不变量&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;特征向量和特征值可以直接应用于机器学习中,如&lt;a href=&quot;&quot;&gt;PCA&lt;/a&gt;，下面有个简单的例子&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;机器学习中的分类问题，给出178个葡萄酒样本，每个样本含有13个参数，比如酒精度、酸度、镁含量等，这些样本属于3个不同种类的葡萄酒。任务是提取3种葡萄酒的特征，以便下一次给出一个新的葡萄酒样本的时候，能根据已有数据判断出新样本是哪一种葡萄酒。&lt;/p&gt;

&lt;p&gt;原数据有13维，但这之中含有冗余，减少数据量最直接的方法就是降维。做法：把数据集赋给一个178行13列的矩阵R，减掉均值并归一化，它的协方差矩阵&lt;img src=&quot;https://www.zhihu.com/equation?tex=C%3DR%5E%7BT%7DR&quot; alt=&quot;&quot; /&gt;C是13行13列的矩阵，对C进行特征分解，对角化&lt;img src=&quot;https://www.zhihu.com/equation?tex=C%3DUDU%5E%7BT%7D+&quot; alt=&quot;&quot; /&gt; ，其中U是特征向量组成的矩阵D是特征之组成的对角矩阵，并按由大到小排列。然后，另R’ =RU，就实现了数据集在特征向量这组正交基上的投影。嗯，重点来了，R’中的数据列是按照对应特征值的大小排列的，后面的列对应小特征值，去掉以后对整个数据集的影响比较小。比如，现在我们直接去掉后面的7列，只保留前6列，就完成了降维。这个降维方法叫&lt;strong&gt;PCA（Principal Component Analysis）&lt;/strong&gt;。降维以后分类错误率与不降维的方法相差无几，但需要处理的数据量减小了一半（不降维需要处理13维，降维后只需要处理6维）。这显示了PCA的威力&lt;/p&gt;

&lt;h2 id=&quot;奇异值分解&quot;&gt;奇异值分解&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://nbviewer.jupyter.org/github/zlotus/notes-LSJU-machine-learning/blob/master/chapter15.ipynb&quot;&gt;奇异值分解&lt;/a&gt;和上面所讲的特征分解有很大的关系，而我的理解是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;不是所有的矩阵都能对角化（对称矩阵总是可以），而所有矩阵总是可以做奇异值分解的。那么多类型的矩阵，我们居然总是可以从一个统一且简单的视角去看它，我们就会感叹奇异值分解是多么奇妙了！&lt;strong&gt;提取任何矩阵的主要特征，比如在推荐系统中用到&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;协方差矩阵（或X^TX）的奇异值分解结果和特征值分解结果一致。所以在pca中，svd是一种实现方式&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;奇异值分解和特征分解几何意义&quot;&gt;奇异值分解和特征分解几何意义&lt;/h3&gt;

&lt;p&gt;奇异值分解的含义是，把一个矩阵A看成线性变换（当然也可以看成是数据矩阵或者样本矩阵），那么这个线性变换的作用效果是这样的，&lt;strong&gt;我们可以在原空间找到一组标准正交基V，同时可以在像空间找到一组标准正交基U，我们知道，看一个矩阵的作用效果只要看它在一组基上的作用效果即可，&lt;/strong&gt;在内积空间上，我们更希望看到它在一组标准正交基上的作用效果。而矩阵A在标准正交基V上的作用效果恰好可以表示为在U的对应方向上只进行纯粹的伸缩！这就大大简化了我们对矩阵作用的认识，因为我们知道，我们面前不管是多么复杂的矩阵，它在某组
标准正交基上的作用就是在另外一组标准正交基上进行伸缩而已。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;更加详细的讲述请看：&lt;a href=&quot;http://blog.csdn.net/redline2005/article/details/24100293&quot;&gt;奇异值的意义&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;特征分解也是这样的，也可以简化我们对矩阵的认识。对于可对角化的矩阵，该线性变换的作用就是将某些方向（特征向量方向）在该方向上做伸缩。&lt;/p&gt;

&lt;p&gt;有了上述认识，当我们要看该矩阵对任一向量x的作用效果的时候，在特征分解的视角下，我们可以把x往特征向量方向上分解，然后每个方向上做伸缩，最后再把结果加起来即可；在奇异值分解的视角下，我们可以把x往V方向上分解，然后将各个分量分别对应到U方向上做伸缩，最后把各个分量上的结果加起来即可。&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《深度学习》-Bengio&lt;br /&gt;
《统计学习方法》-李航&lt;br /&gt;
《机器学习》-周志华&lt;br /&gt;
《机器学习实战》-Peter Harrington&lt;br /&gt;
斯坦福大学公开课-机器学习&lt;br /&gt;
网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201701181&quot; data-title=&quot;feature engineering&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Mon, 13 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%89%E5%85%B3%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E7%BA%BF%E4%BB%A3.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%89%E5%85%B3%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E7%BA%BF%E4%BB%A3.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>集成学习(一)_Boosting</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#集成学习一boosting&quot; id=&quot;markdown-toc-集成学习一boosting&quot;&gt;集成学习(一)–Boosting&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#集成学习分类&quot; id=&quot;markdown-toc-集成学习分类&quot;&gt;集成学习分类&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#boosting&quot; id=&quot;markdown-toc-boosting&quot;&gt;Boosting&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#adaboost&quot; id=&quot;markdown-toc-adaboost&quot;&gt;AdaBoost&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#adaboost算法的思想&quot; id=&quot;markdown-toc-adaboost算法的思想&quot;&gt;Adaboost算法的思想&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#adaboost算法的步骤&quot; id=&quot;markdown-toc-adaboost算法的步骤&quot;&gt;Adaboost算法的步骤&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#例子&quot; id=&quot;markdown-toc-例子&quot;&gt;例子&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#前向分布算法&quot; id=&quot;markdown-toc-前向分布算法&quot;&gt;前向分布算法&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#提升树&quot; id=&quot;markdown-toc-提升树&quot;&gt;提升树&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#提升树模型&quot; id=&quot;markdown-toc-提升树模型&quot;&gt;提升树模型&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#提升树算法&quot; id=&quot;markdown-toc-提升树算法&quot;&gt;提升树算法&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#回归问题的提升树算法&quot; id=&quot;markdown-toc-回归问题的提升树算法&quot;&gt;回归问题的提升树算法&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#提升树例子&quot; id=&quot;markdown-toc-提升树例子&quot;&gt;提升树例子：&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#xgboost&quot; id=&quot;markdown-toc-xgboost&quot;&gt;xgboost&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#boosting-注意和总结&quot; id=&quot;markdown-toc-boosting-注意和总结&quot;&gt;Boosting 注意和总结&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;集成学习一boosting&quot;&gt;集成学习(一)–Boosting&lt;/h1&gt;

&lt;p&gt;一句话概述Adaboost算法的话就是：把多个简单的分类器结合起来形成个复杂的分类器。也就是“三个臭皮匠顶一个诸葛亮”的道理。&lt;/p&gt;

&lt;p&gt;下面先来一个简单的认识：&lt;/p&gt;

&lt;p&gt;如下图所示：
在D1这个数据集中有两类数据“+”和“-”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于这个数据集，你会发现，用简单分类器，不管是这么分，都无法很好的分类&lt;/p&gt;

&lt;p&gt;我们这样分：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;或者这样分：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总有误分类点存在；
那么如果我们把上面三种分发集合起来呢？像下面这样：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;会发现把上面三个弱分类器组合起来会变成下面这个分类器：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting5.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这样一来用这个分类器就可以完美的分类数据了。
可以说这就是集成学习的整体思想！&lt;/p&gt;

&lt;p&gt;是不是十分简单粗暴？好了，下面我们就正经的说下&lt;strong&gt;集成学习：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;集成学习的一般结构：先生成一组“个体学习器”，再用某种策略将他们结合起来。&lt;/li&gt;
  &lt;li&gt;集成学习分为&lt;strong&gt;同质（同种类型学习器）和异质（不同类型学习器）&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;集成学习通过将多个学习器进行结合，常可以获得比单一学习器显著优越的泛化性能，这对“弱学习器”（指泛化性能略优于随机猜测的学习器）尤为明显。&lt;strong&gt;要想获得好的集成，个体学习器应该“好而不同”，即个体学习器要有一定的准确性，并且要有多样性。但是准确性与多样性通常会产生冲突，因为个体学习器往往是为解决同一个问题训练出来的，不可能存在相互独立。如何产生好而不同的学习器是学习研究的核心。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;集成学习分类&quot;&gt;集成学习分类&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;个体学习器之间存在强依赖关系、必须&lt;strong&gt;串行生成的序列化方法。（Boosting）&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;个体学习器之间不存在强依赖关系、可&lt;strong&gt;同时生成的并行化方法。（Bagging和RF）&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;既然集成学习分为Boosting，Bagging和RF。那下面我们就从这些分类中讲，在这篇博文中，我会讲下Boosting的代表：AdaBoost和提升树，讲下Bagging的代表：随机森林。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;boosting&quot;&gt;Boosting&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Boosting是一族将弱学习器提升为强学习器的算法。工作机制如下：
    &lt;ul&gt;
      &lt;li&gt;先从初始训练集中&lt;strong&gt;训练出一个基学习器，再根据基学习器的表现对训练样本进行调整，使得先前基学习器做的的训练样本在后继受到更多的关注，&lt;/strong&gt;然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学习器的数目达到实现指定的值T，最终将这T个学习器进行加权结合。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;adaboost&quot;&gt;AdaBoost&lt;/h3&gt;

&lt;h4 id=&quot;adaboost算法的思想&quot;&gt;Adaboost算法的思想&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Adaboost给每一个训练数据添加“权值”，且最初这个权值是平均分配的。然后在之后的步骤中，&lt;strong&gt;提高那些被前一轮弱分类器错误分类样本的权值，并降低那些被正确分类样本的权值&lt;/strong&gt;，这样一来，那些没有得到正确分类的数据，由于其权值的加大而受到&lt;strong&gt;后一轮弱分类器的更大关注&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Adaboost给&lt;strong&gt;每一个弱分类器添加“权值”&lt;/strong&gt;，且采取多数表决的方法组合弱分类器。具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用；减少分类误差率大的弱分类器的权值，使其在表决中起较小的作用。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Adaboost的巧妙之处就在于它将这些想法自然且有效地实现在一种算法里。&lt;/p&gt;

&lt;h4 id=&quot;adaboost算法的步骤&quot;&gt;Adaboost算法的步骤&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;然后对上面的步骤做一些说明：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;步骤1假设训练数据集具有均匀的分布，即每个训练样本在基本分类器的学习中作用相同。这一假设保证了第1步中能用在原始数据上学习弱分类器G1(x)。&lt;/li&gt;
  &lt;li&gt;步骤2反复学习弱分类器，在每一轮m= 1, 2, …, M顺次地执行下列操作：
    &lt;ul&gt;
      &lt;li&gt;a: 使用当期分布Dm加权的训练数据集，学习基本分类器Gm(x)。&lt;/li&gt;
      &lt;li&gt;b: 计算基本分类器Gm(x)在加权训练数据集上的分类误差率：&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting7.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里，wmi表示第m轮中第i个实例的权值，且：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting8.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这表明，Gm(x)在加权的训练数据集上的分类误差率是被Gm(x)误分类样本的权值之和，由此可以看出数据权值分布Dm与弱分类器Gm(x)的分类误差率的关系。
c: 计算弱分类器Gm(x)的系数am，am表示Gm(x)在最终分类器中的重要性。由式8.2可知，当em &amp;lt;= 1/2时，am &amp;gt;=0，并且am随em的减小而增大，所以分类误差率越小的弱分类器在最终分类器中的作用越大。
d: 更新训练数据的权值分布为下一轮做准备。式8.4可以写成：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting9.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由此可知，被弱分类器Gm(x)误分类样本的权值得以扩大，而被正确分类样本的权值却得以缩小。两相比较，误分类样本的权值被放大&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting10.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;倍。
因此，误分类样本在下一轮学习中起更大的作用。
而，“不改变所给的训练数据，而不断改变训练数据的权值分布，使得训练数据在若分类器的学习中起不同的作用”就是Adaboost的一个特点。&lt;/p&gt;

&lt;p&gt;步骤3中通过线性组合f(x)实现M个弱分类器的加权表决。系数am表示了弱分类器Gm(x)的重要性，这里，所有am之和并不为1。f(x)的符号决定实例x的类，f(x)的绝对值表示分类的确信度。“利用弱分类器的线性组合构建最终分类器”是Adaboost的另一个特点。&lt;/p&gt;

&lt;h4 id=&quot;例子&quot;&gt;例子&lt;/h4&gt;
&lt;p&gt;讲完上面的基本概念，我们直接上《统计学习方法》的例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting11.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;给定上面这张训练数据表所示的数据，假设弱分类器由&lt;code class=&quot;highlighter-rouge&quot;&gt;x&amp;lt;v或x&amp;gt;v&lt;/code&gt;产生，其阈值v使该分类器在训练数据集上的分类误差率最低，试用Adaboost算法学习一个强分类器。&lt;/p&gt;

&lt;p&gt;解：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1. 令m = 1
则初始化数据权值分布：
Dm = (wm1, wm2,..., wm10)，即：D1 = (w11, w12, ..., w110)
wmi = 0.1， i = 1, 2,..., 10，即：w1i = 0.1， i = 1, 2, ..., 10
a:用下面的方式从v=1.5遍历到v=9.5
    for( v=1.5;v&amp;lt;=9.5; v++) {
        if(x &amp;lt; v) G1(x)=1;
        elseif (x &amp;gt; v) G1(x) = -1;
    }
    并统计v取各个值使得误差率(误差率的计算方法是：所有误分类点的权值之和)。
    然后发现，当v取2.5时，误分类点为x=6, 7, 8，其权值和为0.3，误差率最低，此时，当前弱分类器为：

    G1(x) 在训练数据集上的误差率e1= P(G1(xi) != yi) = 0.3
b:计算G1(x)的系数：a1 =(1/2) log [(1-e1)/e1] = 0.4236
c:更新训练数据的权值分布：
    D2=  (w21, w22, ...,w210)
    w2i= (w1i/Z1)exp(-a1yiG1(xi))，i = 1, 2,..., 10
    于是
    D2 = (0.0715, 0.0715, 0.0715, 0.0715,0.0715, 0.0715, 0.1666, 0.1666, 0.1666, 0.0715)
    f1(x) = 0.4236G1(x)
    分类器sign[f1(x)]在训练数据集上有3个误分类点。

2. 令m = 2，做和上一步同上的操作。
    发现在权值分布为D2的训练数据上，v = 8.5时误差率最低，此时：
    当前弱分类器为：
    误差率是e2 = 0.2143
    a2= 0.6496
    于是
    权值分布为：D3 =(0.0455, 0.0455, 0.0455, 0.1667, 0.1667, 0.1667, 0.1060, 0.1060, 0.1060,0.0455)
    f2(x)= 0.4236G1(x) + 0.6496G2(x)
    分类器sign[f2(x)]在训练数据集上有3个误分类点。
3. 令m = 3。
    所以在权值分布为D3的训练数据上，v =5.5时分类误差率最低，此时的弱分类器为：

    G3(x)在训练样本上的误差率为e3= 0.1820
    a3= 0.7514
    于是
    权值分布为：D4 =(0.125, 0.125, 0.125, 0.102, 0.102, 0.102, 0.065, 0.065, 0.065, 0.125)
    f3(x)= 0.4236G1(x) + 0.6496G2(x) + 0.7514G3(x)
    因为分类器sign[f3(x)]在训练数据集上的误分类点个数为0.
于是最终分类器为：
G(x)= sign[f3(x)] = sign[0.4236G1(x) + 0.6496G2(x)+ 0.7514G3(x)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以说，通过这个例子，我们教好的理解了Adaboost的大致思想。&lt;/p&gt;

&lt;h3 id=&quot;前向分布算法&quot;&gt;前向分布算法&lt;/h3&gt;

&lt;p&gt;AdaBoost算法还有另一个解释，即可以认为AdaBoost算法是模型为加法模型、损失函数为指数函数、学习算法为前向分步算法时的二类分类学习方法。
前向分步算法(forward stagewise algorithm)&lt;/p&gt;

&lt;p&gt;加法模型：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting12.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，b为基函数，r为基函数的参数，beta为基函数的系数。
前向分步算法同时求解从m=1到M所有参数的优化问题简化为逐次求解各个参数的优化问题.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting13.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意：前向分步算法与AdaBoost是等价的。&lt;/p&gt;

&lt;h3 id=&quot;提升树&quot;&gt;提升树&lt;/h3&gt;

&lt;p&gt;提升树是以分类树或回归树为基本分类器的提升方法。提升树被认为是统计学习中性能最好的方法之一。&lt;/p&gt;

&lt;h4 id=&quot;提升树模型&quot;&gt;提升树模型&lt;/h4&gt;

&lt;p&gt;提升方法实际采用加法模型(即基函数的线性组合)与前向分步算法。以决策树为基函数的提升方法称为提升树(boosting tree)。对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树。
基本分类器&lt;code class=&quot;highlighter-rouge&quot;&gt;x&amp;lt;v或x&amp;gt;v&lt;/code&gt;，可以看作是由一个根结点直接连接两个叶结点的简单决策树，即所谓的决策树桩(decision stump)。
提升树模型可以表示为决策树的加法模型:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting14.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，T表示决策树，theta为决策树的参数，M为树的个数。&lt;/p&gt;

&lt;h4 id=&quot;提升树算法&quot;&gt;提升树算法&lt;/h4&gt;

&lt;p&gt;提升树算法采用前向分步算法。首先确定初始提升树f0(x)=0，第m步的模型是&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting15.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，fm-1(x)为当前模型，通过经验风险极小化确定下一棵决策树的参数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting16.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不同问题的提升树学习算法主要区别在于使用的损失函数不同。包括用平方误差损失函数的回归问题，用指数损失函数的分类问题，以及用一般损失函数的一般决策问题。
对于二类分类问题，提升树算法只需将AdaBoost算法8.1中的基本分类器限制为二类分类树即可，是AdaBoost算法的特殊情况。&lt;/p&gt;

&lt;h4 id=&quot;回归问题的提升树算法&quot;&gt;回归问题的提升树算法&lt;/h4&gt;

&lt;p&gt;当采用平方误差损失函数时，&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting17.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在前向分步算法的第m步，损失变为，&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting18.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中是当前模型拟合数据的残差(residual)。
所以对回归问题的提升树算法来说，求解经验风险极小化的问题只需简单地拟合当前模型的残差。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting19.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;梯度提升算法（GBDT）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;提升树利用加法模型与前向分步算法实现学习的优化过程。当损失函数是平方损失和指数损失函数时。每一步优化是很简单的。但对一般损失函数而言，往往每一步优化并不那么容易。针对这一问题，Freidmao提出了梯度提升(gradient boosting)算法。&lt;strong&gt;这是利用最速下降法的近似方法，其关键是利用损失函数的负梯度在当前模型的值:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting20.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;作为回归问题提升树算法中的残差的近似值，拟合一个回归树。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting21.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;算法第1步初始化，估计使损失函数极小化的常数值，它是只有一个根结点的树，即&lt;code class=&quot;highlighter-rouge&quot;&gt; x&amp;gt;c 和 x&amp;lt;c；&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;第2 (a)步计算损失函数的负梯度在当前模型的值，将它作为残差的估计。对于平方损失函数，它就是通常所说的残差；对
于一般损失函数，它就是残差的近似值。&lt;/p&gt;

&lt;p&gt;第2 (b)步估计回归树叶结点区域，以拟合残差的近似值&lt;/p&gt;

&lt;p&gt;第2 (c)步利用线性搜索估计叶结点区域的值，使损失函数极小化&lt;/p&gt;

&lt;p&gt;第2 (d)步更新回归树。&lt;/p&gt;

&lt;p&gt;第3步得到输出的最终模型。&lt;/p&gt;

&lt;h4 id=&quot;提升树例子&quot;&gt;提升树例子：&lt;/h4&gt;

&lt;p&gt;还是《统计学习方法》的那个例子，直接上截图（逃）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting22.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting23.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Boosting24.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;xgboost&quot;&gt;xgboost&lt;/h3&gt;

&lt;p&gt;xgboost是在GBDT的基础上对boosting算法进行的改进，内部决策树使用的是回归树,它和GBDT大体类似就不细讲了，但XGBoost风靡Kaggle、天池、DataCastle、Kesci等国内外数据竞赛平台，是比赛夺冠的必备大杀器。所以还是挺常用的，所以这里说下：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;xgboost相比传统gbdt有何不同？xgboost为什么快？xgboost如何支持并行？&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;传统GBDT以&lt;strong&gt;CART作为基分类器，xgboost还支持线性分类器，&lt;/strong&gt;这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。&lt;/li&gt;
  &lt;li&gt;传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。&lt;/li&gt;
  &lt;li&gt;xgboost在代价函数里&lt;strong&gt;加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，&lt;/strong&gt;这也是xgboost优于传统GBDT的一个特性。&lt;/li&gt;
  &lt;li&gt;Shrinkage（缩减），相当于学习速率（xgboost中的eta）。xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点。（补充：传统GBDT的实现也有学习速率）&lt;/li&gt;
  &lt;li&gt;列抽样（column subsampling）。xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。&lt;/li&gt;
  &lt;li&gt;对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。&lt;/li&gt;
  &lt;li&gt;xgboost工具支持并行。boosting不是一种串行的结构吗?怎么并行的？注意xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。xgboost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。&lt;/li&gt;
  &lt;li&gt;可并行的近似直方图算法。树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以xgboost还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;xgboost使用经验总结&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;多类别分类时，类别需要从0开始编码&lt;/li&gt;
  &lt;li&gt;Watchlist不会影响模型训练。&lt;/li&gt;
  &lt;li&gt;类别特征必须编码，因为xgboost把特征默认都当成数值型的&lt;/li&gt;
  &lt;li&gt;调参：Notes on Parameter Tuning 以及 Complete Guide to Parameter Tuning in XGBoost (with codes in Python)&lt;/li&gt;
  &lt;li&gt;训练的时候，为了结果可复现，记得设置随机数种子。&lt;/li&gt;
  &lt;li&gt;XGBoost的特征重要性是如何得到的？某个特征的重要性（feature score），等于它被选中为树节点分裂特征的次数的和，比如特征A在第一次迭代中（即第一棵树）被选中了1次去分裂树节点，在第二次迭代被选中2次…..那么最终特征A的feature score就是 1+2+….&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;boosting-注意和总结&quot;&gt;Boosting 注意和总结&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;需要注意的是Boosting算法在训练的每一轮都要检查当前生成的基学习器是否满足基本条件（检查基分类器是否比随机猜测好），一旦条件不满足，当前基学习器被抛弃掉，学习过程停止。在这种情形下，初始设置的学习轮数T也许还远远未达到，可能导致最终集成中只包含很少的基学习器而导致性能不佳。若采用“重采样”，则可以获得“重启动”机会避免过早停止。即在抛弃不满足条件的当前基学习器之后，根据当前的分布重新对训练样本进行采样，再基于新的采样结果重新训练出基学习器，从而使得学习过程可以持续到预制的T轮。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;从&lt;strong&gt;“偏差-方差”分解的角度看，Boosting主要关注降低偏差，&lt;/strong&gt;因此基于泛化性能相当弱学习器能构建出很强的集成。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《统计学习方法》-李航&lt;br /&gt;
《机器学习》-周志华&lt;br /&gt;
《机器学习实战》-Peter Harrington&lt;br /&gt;
斯坦福大学公开课-机器学习&lt;br /&gt;
网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201702111&quot; data-title=&quot;Booting&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Sat, 11 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/11/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0_Boosting.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/11/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0_Boosting.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>集成学习(二)_Bagging</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;目录&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;集成学习二bagging&quot;&gt;集成学习(二)–Bagging&lt;/h1&gt;

&lt;p&gt;上一篇博文我们讲了Boosting,这篇博文我们接着讲Bagging，主要讲解随机森林算法，通过这个算法来了解Bagging。&lt;/p&gt;

&lt;h3 id=&quot;bagging类算法&quot;&gt;Bagging类算法&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Bagging是“并行式”集成学习方法中最著名的代表，基于我们之前介绍的自主采样法。给定包含m个样本的数据集，随机取出一个样本放入采样机，再将样本放回初始数据集，使得下次采样仍有可能被选中，经过m次随机采样，得到m个样本的数据集，初始数据集中约63.2%出现在采样集中。注意：&lt;strong&gt;有放回的抽样&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;我们采样出T个&lt;strong&gt;含m个训练样本的采样集&lt;/strong&gt;，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在对预测输出进行结合的时候，Bagging通常对分类任务采用&lt;strong&gt;简单投票法&lt;/strong&gt;,回归任务采用简单平均法，&lt;strong&gt;若遇到相同票数则随机选择一个或者根据投票置信度来选择。&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;训练一个Bagging集成与直接使用基学习算法训练一个学习器复杂度同阶，说明是一个高效的集成算法，与标准AdaBoost只适用于二分类任务不同，Bagging可以不经修改的用于多分类、回归等任务。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;随机森林的定义&quot;&gt;随机森林的定义&lt;/h3&gt;

&lt;p&gt;随机森林，指的是利用多棵树对样本进行训练并预测的一种分类器。该分类器最早由Leo Breiman和Adele Cutler提出，并被注册成了商标。简单来说，随机森林就是由多棵CART（Classification And Regression Tree）构成的。&lt;strong&gt;对于每棵树，它们使用的训练集是从总的训练集中有放回采样出来的，这意味着，总的训练集中的有些样本可能多次出现在一棵树的训练集中，也可能从未出现在一棵树的训练集中。&lt;/strong&gt;在训练每棵树的节点时，使用的特征是从所有特征中按照一定比例随机地无放回的抽取的，根据Leo Breiman的建议，假设总的特征数量为M，这个比例可以是sqrt(M),1/2sqrt(M),2sqrt(M)。&lt;/p&gt;

&lt;h2 id=&quot;随机森林random-forestrf和bagging&quot;&gt;随机森林（Random Forest，RF）和Bagging&lt;/h2&gt;

&lt;p&gt;随机森林是Bagging的一个扩展变体。RF在以决策树为基学习器，构建Bagging的基础上，进一步在决策树的训练过程中引入了随机属性选择。&lt;/p&gt;

&lt;p&gt;具体来说，传统的决策树在选择划分属性的时候是在当前节点的属性集合中选择一个最优属性，而在RF中，对基决策树的每个节点，先从该节点的属性集中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最优属性用于划分。&lt;/p&gt;

&lt;p&gt;这里的参数k控制了随机性的引入程度，若令k=d，则基决策树的构建与传统决策树相同；&lt;/p&gt;

&lt;p&gt;若k=1，则随机选择一个属性进行划分；一般情况下推荐k=log_2 d&lt;/p&gt;

&lt;p&gt;随机森林简单，容易实现，计算开销小，令人惊奇的是，在很多现实任务中展现出强大的性能，誉为“代表集成学习技术水平的方法”。&lt;/p&gt;

&lt;p&gt;可以看出，随机森林对Bagging只做了微小的改动,但是与Bagging中基学习器的“多样性”仅通过样本扰动（通过对初始训练集采样）而来不同，随机森林中基学习器的多样性不仅来自于样本扰动，还来自于属性扰动，这就使得最终集成的泛化性能可以通过个体学习器之间的差异度的增加而进一步提升。&lt;/p&gt;

&lt;p&gt;随机森林的收敛性与bagging相似，随机森林其实性能很差，随着个体学习器增加，会收敛到更低泛化性能。&lt;/p&gt;

&lt;p&gt;随机森林训练效率通常优于bagging，因为在个体决策树的构建过程中，bagging使用的是“确定型”决策树，需要考虑全部属性，但是随机森林使用的是“随机型”只需要考虑一个属性集合。&lt;/p&gt;

&lt;h3 id=&quot;随机森林算法的具体步骤&quot;&gt;随机森林算法的具体步骤&lt;/h3&gt;

&lt;p&gt;** 利用随机森林的训练过程如下：**&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;给定训练集S，测试集T，特征维数F。确定参数：使用到的CART的数量t，每棵树的深度d，每个节点使用到的特征数量f，终止条件：节点上最少样本数s，节点上最少的信息增益m&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于第1-t棵树，i=1-t：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;从S中有放回的抽取大小和S一样的训练集S(i)，作为根节点的样本，从根节点开始训练&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果当前节点上达到终止条件，则设置当前节点为叶子节点&lt;strong&gt;，如果是分类问题，该叶子节点的预测输出为当前节点样本集合中数量最多的那一类c(j)，概率p为c(j)占当前样本集的比例；如果是回归问题，预测输出为当前节点样本集各个样本值的平均值&lt;/strong&gt;。然后继续训练其他节点。如果当前节点没有达到终止条件，则从F维特征中无放回的随机选取f维特征。利用这f维特征，寻找分类效果最好的一维特征k及其阈值th，当前节点上样本第k维特征小于th的样本被划分到左节点，其余的被划分到右节点。继续训练其他节点。有关分类效果的评判标准在后面会讲。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重复(2)(3)直到所有节点都训练过了或者被标记为叶子节点。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重复(2),(3),(4)直到所有CART都被训练过。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;** 利用随机森林的预测过程如下：**&lt;/p&gt;

&lt;p&gt;对于第1-t棵树，i=1-t：&lt;/p&gt;

&lt;p&gt;(1)从当前树的根节点开始，根据当前节点的阈值th，判断是进入左节点(&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;th)还是进入右节点(&amp;gt;=th&lt;/code&gt;)，直到到达，某个叶子节点，并输出预测值。&lt;/p&gt;

&lt;p&gt;(2)重复执行(1)直到所有t棵树都输出了预测值。&lt;strong&gt;如果是分类问题，则输出为所有树中预测概率总和最大的那一个类，即对每个c(j)的p进行累计；如果是回归问题，则输出为所有树的输出的平均值。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;随机森林工作原理解释的一个简单例子&quot;&gt;随机森林工作原理解释的一个简单例子：&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：这里讲的是随机森林的原理，而不是真正就这样生成的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;　　描述：根据已有的训练集已经生成了对应的随机森林，随机森林如何利用某一个人的年龄（Age）、性别（Gender）、教育情况（Highest Educational Qualification）、工作领域（Industry）以及住宅地（Residence）共5个字段来预测他的收入层次。&lt;/p&gt;

&lt;p&gt;　　收入层次 :&lt;/p&gt;

&lt;p&gt;　　　　Band 1 : Below $40,000&lt;/p&gt;

&lt;p&gt;　　　　Band 2: $40,000 – 150,000&lt;/p&gt;

&lt;p&gt;　　　　Band 3: More than $150,000&lt;/p&gt;

&lt;p&gt;　　随机森林中每一棵树都可以看做是一棵CART（分类回归树），这里假设森林中有5棵CART树，总特征个数N=5，我们取m=1（这里假设每个CART树对应一个不同的特征）。&lt;/p&gt;

&lt;p&gt;　　CART 1 : Variable Age&lt;/p&gt;

&lt;p&gt;　　&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Bagging1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;　　CART 2 : Variable Gender&lt;/p&gt;

&lt;p&gt;　　　　&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Bagging2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;　　CART 3 : Variable Education&lt;/p&gt;

&lt;p&gt;　　　　&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Bagging3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;　　CART 4 : Variable Residence&lt;/p&gt;

&lt;p&gt;　　　　&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Bagging4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;　　CART 5 : Variable Industry&lt;/p&gt;

&lt;p&gt;　　　　&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Bagging5.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;　　我们要预测的某个人的信息如下：&lt;/p&gt;

&lt;p&gt;　　1. Age : 35 years ; 2. Gender : Male ; 3. Highest Educational Qualification : Diploma holder; 4. Industry : Manufacturing; 5. Residence : Metro.&lt;/p&gt;

&lt;p&gt;　　根据这五棵CART树的分类结果，我们可以针对这个人的信息建立收入层次的分布情况：&lt;/p&gt;

&lt;p&gt;　　　　&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/Bagging6.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;　　最后，我们得出结论，这个人的收入层次70%是一等，大约24%为二等，6%为三等，所以最终认定该人属于一等收入层次（小于$40,000）。&lt;/p&gt;

&lt;h2 id=&quot;用途&quot;&gt;用途&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;随机森林的最佳使用实例之一是特征选择（feature selection）。尝试许多决策树变量（variations）带来的副产品之一是，你可以检验每棵树中哪个变量最相关/无关。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;随机森林也很擅长分类任务。它能用于对具有多个可能值的类别进行预测，也能被校准来输出概率。需要注意的是过拟合（overfitting）。随机森林可能容易过拟合，尤其是使用相对小型的数据集时。如果你的模型在我们的测试集中表现“太好”，就应该怀疑过拟合了。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;　我发现随机森林——不像其他算法——在学习分类变量或分类变量和真实变量的结合时真的很有效。高基数的分类变量处理起来很棘手，因此随机森林会大有帮助。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;随机森林的优点&quot;&gt;随机森林的优点&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在数据集上表现良好&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在当前的很多数据集上，相对其他算法有着很大的优势&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;它能够处理很高维度（feature很多）的数据，并且不用做特征选择&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在训练完后，它能够给出哪些feature比较重要&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在创建随机森林的时候，对generlization error使用的是无偏估计&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;训练速度快&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在训练过程中，能够检测到feature间的互相影响&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;容易做成并行化方法&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;实现比较简单&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;随机森林比较简单，下面就再用网上的（Python实现）例子来结束对它的讲解：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/u013066730/article/details/54311635&quot;&gt;python自带的随机森林&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《统计学习方法》-李航&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;《机器学习》-周志华&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;《机器学习实战》-Peter Harrington&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;斯坦福大学公开课-机器学习&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;

&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201702112&quot; data-title=&quot;bagging&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;

&lt;!-- 多说评论框 end --&gt;

&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;

&lt;script type=&quot;text/javascript&quot;&gt;

var duoshuoQuery = {short_name:&quot;yzhhome&quot;};

  (function() {

    var ds = document.createElement('script');

    ds.type = 'text/javascript';ds.async = true;

    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';

    ds.charset = 'UTF-8';

    (document.getElementsByTagName('head')[0] 

     || document.getElementsByTagName('body')[0]).appendChild(ds);

  })();

  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Sat, 11 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/11/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0_Bagging.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/11/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0_Bagging.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>模型选择与评价，降维</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#模型指标&quot; id=&quot;markdown-toc-模型指标&quot;&gt;模型指标&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#评价分类器性能指标之aucroc&quot; id=&quot;markdown-toc-评价分类器性能指标之aucroc&quot;&gt;评价分类器性能指标之AUC、ROC&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#引子&quot; id=&quot;markdown-toc-引子&quot;&gt;引子&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#roc&quot; id=&quot;markdown-toc-roc&quot;&gt;ROC&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#如何画roc曲线&quot; id=&quot;markdown-toc-如何画roc曲线&quot;&gt;如何画ROC曲线&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#auc值的计算&quot; id=&quot;markdown-toc-auc值的计算&quot;&gt;AUC值的计算&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#为什么使用roc&quot; id=&quot;markdown-toc-为什么使用roc&quot;&gt;为什么使用ROC&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#降维技术&quot; id=&quot;markdown-toc-降维技术&quot;&gt;降维技术&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#pca&quot; id=&quot;markdown-toc-pca&quot;&gt;PCA&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#pca预处理&quot; id=&quot;markdown-toc-pca预处理&quot;&gt;PCA预处理&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#pca算法&quot; id=&quot;markdown-toc-pca算法&quot;&gt;PCA算法&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#所以-pca-的一般步骤是&quot; id=&quot;markdown-toc-所以-pca-的一般步骤是&quot;&gt;所以 PCA 的一般步骤是:&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#svd奇异值分解&quot; id=&quot;markdown-toc-svd奇异值分解&quot;&gt;SVD（奇异值分解）&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#举例&quot; id=&quot;markdown-toc-举例&quot;&gt;举例：&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#factor-analysis因子分析&quot; id=&quot;markdown-toc-factor-analysis因子分析&quot;&gt;Factor Analysis（因子分析）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#ica独立成分分析&quot; id=&quot;markdown-toc-ica独立成分分析&quot;&gt;ICA（独立成分分析）&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#鸡尾酒宴会问题&quot; id=&quot;markdown-toc-鸡尾酒宴会问题&quot;&gt;鸡尾酒宴会问题&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#ica算法的前处理步骤&quot; id=&quot;markdown-toc-ica算法的前处理步骤&quot;&gt;ICA算法的前处理步骤&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#ica算法&quot; id=&quot;markdown-toc-ica算法&quot;&gt;ICA算法&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#iac应用&quot; id=&quot;markdown-toc-iac应用&quot;&gt;IAC应用&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#小结&quot; id=&quot;markdown-toc-小结&quot;&gt;小结&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;模型指标&quot;&gt;模型指标&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;正确率 = 提取出的正确信息条数 /  提取出的信息条数&lt;/li&gt;
  &lt;li&gt;召回率 = 提取出的正确信息条数 /  样本中的信息条数&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;两者取值在0和1之间，数值越接近1，查准率或查全率就越高。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;F值  = 正确率 * 召回率 * 2 / (正确率 + 召回率) （F 值即为正确率和召回率的调和平均值）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;不妨举这样一个例子：某池塘有1400条鲤鱼，300只虾，300只鳖。现在以捕鲤鱼为目的。撒一大网，逮着了700条鲤鱼，200只虾，100只鳖。那么，这些指标分别如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;正确率 = 700 / (700 + 200 + 100) = 70%
召回率 = 700 / 1400 = 50%
F值 = 70% * 50% * 2 / (70% + 50%) = 58.3%
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;不妨看看如果把池子里的所有的鲤鱼、虾和鳖都一网打尽，这些指标又有何变化：&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;正确率 = 1400 / (1400 + 300 + 300) = 70%
-召回率 = 1400 / 1400 = 100%
F值 = 70% * 100% * 2 / (70% + 100%) = 82.35%
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;　　由此可见，正确率是评估捕获的成果中目标成果所占得比例；召回率，顾名思义，就是从关注领域中，召回目标类别的比例；而F值，则是综合这二者指标的评估指标，用于综合反映整体的指标。&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;评价分类器性能指标之aucroc&quot;&gt;评价分类器性能指标之AUC、ROC&lt;/h2&gt;

&lt;h3 id=&quot;引子&quot;&gt;引子&lt;/h3&gt;

&lt;p&gt;假设有下面两个分类器，哪个好？（样本中有A类样本90个，B 类样本10个。）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/roc_auc3.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;分类器C1把所有的测试样本都分成了A类，分类器C2把A类的90个样本分对了70个，B类的10个样本分对了5个。&lt;/p&gt;

&lt;p&gt;则C1的分类精度为 90%，C2的分类精度为75%，但直觉上，我们感觉C2更有用些。但是依照正确率来衡量的话，那么肯定C1的效果好一点。那么这和我们认为的是不一致的。也就是说，有些时候，仅仅依靠正确率是不妥当的。&lt;/p&gt;

&lt;p&gt;我们还需要一个评价指标，&lt;strong&gt;能客观反映对正样本、负样本综合预测的能力，还要考虑消除样本倾斜的影响（其实就是归一化之类的思想，实际中很重要，比如pv总是远远大于click），这就是auc指标能解决的问题。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;roc&quot;&gt;ROC&lt;/h3&gt;

&lt;p&gt;为了理解auc，我们需要先来弄懂ROC。
先来看一个普遍的二分类问题的结果，预测值和实际值有4种组合情况，看下面的表格：
&lt;img src=&quot;http://7xkmkg.com1.z0.glb.clouddn.com/svm005.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;注意这里就只有两个分类，所以FN就表示的是分错的pos类，同理FP就表示的是分错的neg类&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们定义一个变量：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/roc_auc1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;看图也就可以知道：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;TPR表示的就是预测正确且实际分类为正的数量 与 所有正样本的数量的比例。–实际的正样本中，正确预测的比例是多少？&lt;/li&gt;
  &lt;li&gt;FPR表示的是预测错误且实际分类为负的数量 与所有负样本数量的比例。 –实际的负样本当中，错误预测的比例是多少？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;下面来看一则对话来理解recell，accuracy和precison：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;What percent of your predictions were correct?
You answer: the &quot;accuracy&quot; was (TP+TN)/ALL
What percent of the positive cases did you catch?
You answer: the &quot;recall&quot; TP/(TP+FN)
What percent of positive predictions were correct?
You answer: the &quot;precision&quot; was TP/(TP+FP)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以代入到上面的两个分类器当中，可以得到下面的表格（分类器C1）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/roc_auc4.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;TPR = FPR = 1.0&lt;/p&gt;

&lt;p&gt;分类器C2：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/roc_auc2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;TPR = 0.78， FPR = 0.5&lt;/p&gt;

&lt;p&gt;那么，以TPR为纵坐标，FPR为横坐标画图，可以得到：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://7xkmkg.com1.z0.glb.clouddn.com/svm006.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图中蓝色表示C1分类器，绿色表示C2分类器。可以知道，这个时候绿色的点比较靠近左上角，可以看做是分类效果较好。所以评估标准改为离左上角近的是好的分类器（考虑了正负样本的综合分类能力）。&lt;/p&gt;

&lt;p&gt;一连串这样的点构成了一条曲线，该曲线就是ROC曲线。而ROC曲线下的面积就是AUC（Area under the curve of ROC）。这就是AUC指标的由来。&lt;/p&gt;

&lt;h3 id=&quot;如何画roc曲线&quot;&gt;如何画ROC曲线&lt;/h3&gt;

&lt;p&gt;对于一个特定的分类器和测试数据集，显然只能得到一个分类结果，即一组FPR和TPR结果，而要得到一个曲线，我们实际上需要一系列FPR和TPR的值才能得到这样的曲线，这又是如何得到的呢？&lt;/p&gt;

&lt;p&gt;可以通过分类器的一个重要功能“概率输出”，即表示分类器认为某个样本具有多大的概率属于正样本（或负样本），来动态调整一个样本是否属于正负样本（还记得当时阿里比赛的时候有一个表示被判定为正样本的概率的列么？）&lt;/p&gt;

&lt;p&gt;假如我们已经得到了所有样本的概率输出（属于正样本的概率），现在的问题是如何改变这个阈值（概率输出）？我们根据每个测试样本属于正样本的概率值从大到小排序。下图是一个示例，图中共有20个测试样本，“Class”一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本），“Score”表示每个测试样本属于正样本的概率。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://static.oschina.net/uploads/img/201411/03210218_wDRH.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接下来，我们从高到低，依次将“Score”值作为阈值，当测试样本属于正样本的概率大于或等于这个阈值时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。每次选取一个不同的阈值，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。这样一来，我们一共得到了20组FPR和TPR的值，将它们画在ROC曲线的结果如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://static.oschina.net/uploads/img/201411/03210223_awZE.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当我们将阈值设置为1和0时，分别可以得到ROC曲线上的(0,0)和(1,1)两个点。将这些(FPR,TPR)对连接起来，就得到了ROC曲线。当阈值取值越多，ROC曲线越平滑。&lt;/p&gt;

&lt;p&gt;–在阿里比赛的时候还以为ROC是没用的！！！真的是有眼无珠啊！！！还是有疑惑的是：如何根据ROC来判定结果的好换呢？看哪个分类器更加接近左上角吧。同时，可以根据ROC来确定划定正样本的概率边界选择在哪里比较合适！！！原来是这样！！！&lt;/p&gt;

&lt;h1 id=&quot;auc值的计算&quot;&gt;AUC值的计算&lt;/h1&gt;
&lt;p&gt;AUC（Area Under Curve）被定义为ROC曲线下的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。使用AUC值作为评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而作为一个数值，对应AUC更大的分类器效果更好。&lt;/p&gt;

&lt;h3 id=&quot;为什么使用roc&quot;&gt;为什么使用ROC&lt;/h3&gt;

&lt;p&gt;既然已经这么多评价标准，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。下图是ROC曲线和Precision-Recall曲线的对比：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://static.oschina.net/uploads/img/201411/03210228_yobH.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在上图中，(a)和(c)为ROC曲线，(b)和(d)为Precision-Recall曲线。(a)和(b)展示的是分类其在原始测试集（正负样本分布平衡）的结果，(c)和(d)是将测试集中负样本的数量增加到原来的10倍后，分类器的结果。可以明显的看出，ROC曲线基本保持原貌，而Precision-Recall曲线则变化较大。&lt;/p&gt;

&lt;h2 id=&quot;降维技术&quot;&gt;降维技术&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;在我们解决机器学习的问题时,常常要从维度上做文章。有时候我们需要增维, 比如 kernel methods 就可以在高纬度上重构样本从而解决样本在低维上不的线性不可分问题(高斯 kernel 甚至可以把样本在无穷维上展开)。有时候我们又需要降维,因为我们是三维生物,我们最多只能理解三维世界, 所以想要看看手头的数据, 就必须把它们降到三维以内; 另外,往往很多特征没什么用处, 我们可以可以通过降维或者特征工程的手段来把它们剔除,降低计算复杂度。&lt;/li&gt;
  &lt;li&gt;在这篇文章中，我主要讲解PCA，Factor Analysis，和Independent Component Analysis。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pca&quot;&gt;PCA&lt;/h3&gt;

&lt;h4 id=&quot;pca预处理&quot;&gt;PCA预处理&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;PCA算法，不过通常在PCA算法运行前，我们需要对数据进行预处理——对数据的期望及方差进行标准化&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;整体的数据的期望设为0&lt;/li&gt;
  &lt;li&gt;各个分量用统一的标准定义，（如一个人的身高，体重…）&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;注意，这PCA将白了就是线代中特征分解的应用，所以特征分解要懂，了解可以看下这篇博文&lt;a href=&quot;&quot;&gt;特征分解&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;pca算法&quot;&gt;PCA算法&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;PCA 希望可以找到那 些最重要的维度(假设 k 个重要维度,&lt;code class=&quot;highlighter-rouge&quot;&gt;k&amp;lt;m&lt;/code&gt;),然后把 X 映射到这些重要维度上,用这 k 个映射系数作为新的 feature 于是样本们就被降低到了 k 维上。&lt;/li&gt;
  &lt;li&gt;假设我们有 N 个样本,每个为 m 维,即 ,怎样定义重要维度呢?假设 u(一个 m 维向量)是一个重要维度,令 u 把 X 射成 这样的 N 个点,u 之所以重要,因为新生成的 N 个点的方差是最大的,于是样本间的差异性就被保存了下来, 我们还是可以在新的样本空间里做聚类,分类等操作。所以 PCA 背后的优化问题其实是,&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bdea8aa03480ba7a0dbd983fe0a19983_b.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;所以-pca-的一般步骤是&quot;&gt;所以 PCA 的一般步骤是:&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;将数据正规化为零期望以及单位化方差；&lt;/li&gt;
  &lt;li&gt;对样本数据的协方差矩阵(covariance matrix)做计算，得到特征值&lt;/li&gt;
  &lt;li&gt;特征值 (eigen values) 排序&lt;/li&gt;
  &lt;li&gt;top­k 特征值对应的特征向量 (eigen vectors) 找出来&lt;/li&gt;
  &lt;li&gt;把 X 映射到这 k 个特征向量上&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;svd奇异值分解&quot;&gt;SVD（奇异值分解）&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;他是另一种实现PCA的另一种说法&lt;/li&gt;
  &lt;li&gt;可以将数据映射到低维空间，常用于从有噪声数据中抽取相关特征。&lt;/li&gt;
  &lt;li&gt;详细讲解可以看另一个博文：&lt;a href=&quot;&quot;&gt;奇异值分解&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;特征分解和奇异值分解：不是所有的矩阵都能对角化（对称矩阵总是可以），而所有矩阵总是可以做奇异值分解的。所以因为这个，导致的是在PCA中，他们两者的是一样的（在这里就是同一个东西），因为协方差矩阵是对称的，然后再其他方面，SVD有更加广泛的应用，比如：在推荐算法方面，可以使得数据集更易使用，简单计算，这个详见《机器学习实战》中SVD分解那一章&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;举例&quot;&gt;举例：&lt;/h3&gt;

&lt;p&gt;注意一开始的数据是三维的：
&lt;img src=&quot;https://pic1.zhimg.com/v2-2c913935c3acc821664ee54b26b857bc_b.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;经过PCA之后的图：
&lt;img src=&quot;https://pic3.zhimg.com/v2-8da1c89de80399a83370d4dc292fe9fa_b.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;factor-analysis因子分析&quot;&gt;Factor Analysis（因子分析）&lt;/h2&gt;

&lt;p&gt;Factor Analysis: FA 的思想与 PCA 其实很相似,假设高维度上的观测结果 X 其实是由低维 度上的 factors 来支配的。打个比方,笔者身边有一大群妹子,每个妹子都有很多的参数,例 如,身高,体重,肺活量,皮肤,眼睛大小,脸蛋形状,发型,性格等 8 个参数… 笔者经过大 量的调查研究把每个妹子在每个 feature 上都打了从 1­到10 的分数(10 分最高),然后就在纠 结,到底要对哪个下手呢?于是就想把妹子们做个 ranking,但是只能 rank 一维的数据呀,于 是就在想能不能把妹子的 8 个 feature 抽象成一个终极打分 ­­ 美貌。于是做了如下的假设:
&lt;img src=&quot;https://pic3.zhimg.com/v2-fc4f334fe9df83dc27ff9dad99fd7f92_b.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设每个妹子都有一个终极打分 z(一维),这个分数将会通过一个固定的映射到八个维度 上,然后加上 bias 修正,再加上一些误差(误差保证尽管俩妹子得分一样,也可以春兰秋菊 各有千秋),于是就得到了八维打分 X。这个过程的原理可以让下面这俩图来解释一下: 首先强行把一维的数据搬到二维平面的一条直线上,再加上噪声,bias,于是就 得到了红圈里的一个二维的数据,把二维想象成八维就重构了妹子们的参数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8b717c199cb9cb0614f511f6c1a600a7_b.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有了这个模型,我们就可以就用 EM(expectation­maxminization) 来估算 , 估算过程比较复杂,一句话讲就是通过调整这些参数,令 P(X) 出现的概率最大。 模型确定下来,就可以算出妹子们的最终得分 z, 排个序, 就可以从容地选择了! 继续看下蛋卷图&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a19fd559890c5df2842539ff2db05b65_b.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面比较简略的讲述了一下因子分析，下面再通过一个简单例子，来表述因子分析背后的思想。&lt;/p&gt;

&lt;p&gt;假设我们有m=5个2维的样本点x(i)（两个特征），如下：
&lt;img src=&quot;http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557474219.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那么按照因子分析的理解，样本点的生成过程如下：&lt;/p&gt;

&lt;p&gt;1、 我们首先认为在1维空间（这里k=1），存在着按正态分布生成的m个点z(i)，如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557499070.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;均值为0，方差为1。&lt;/p&gt;

&lt;p&gt;2、 然后使用某个&lt;img src=&quot;http://images.cnblogs.com/cnblogs_com/jerrylead/201105/20110511155749989.png&quot; alt=&quot;&quot; /&gt;将一维的z映射到2维，图形表示如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://images.cnblogs.com/cnblogs_com/jerrylead/201105/20110511155750367.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3、 之后加上&lt;img src=&quot;http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557505874.png&quot; alt=&quot;&quot; /&gt;，即将所有点的横坐标移动u1，纵坐标移动u2，将直线移到一个位置，使得直线过点u，原始左边轴的原点现在为u（红色点）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557566675.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然而，样本点不可能这么规则，在模型上会有一定偏差，因此我们需要将上步生成的点做一些扰动（误差），扰动&lt;img src=&quot;http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557598820.png&quot; alt=&quot;&quot; /&gt;。&lt;/p&gt;

&lt;p&gt;4、 加入扰动后，我们得到黑色样本x(i)如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558042959.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;5、 其中由于z和&lt;img src=&quot;http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558052860.png&quot; alt=&quot;&quot; /&gt;的均值都为0，因此u也是原始样本点（黑色点）的均值。&lt;/p&gt;

&lt;p&gt;由以上的直观分析，我们知道了因子分析其实就是认为高维样本点实际上是由低维样本点经过高斯分布、线性变换、误差扰动生成的，因此高维数据可以使用低维来表示。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在我们这篇博文中，我们只讲了降维方面，其实因子分析也是一个模型，但在这里不讲了，推荐一篇博文，有兴趣可以看下：&lt;a href=&quot;http://blog.csdn.net/littleqqqqq/article/details/50899717&quot;&gt;因子分析 &lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;ica独立成分分析&quot;&gt;ICA（独立成分分析）&lt;/h2&gt;

&lt;p&gt;PCA是一种数据降维的方法，但是只对符合高斯分布的样本点比较有效，那么对于其他分布的样本，有没有主元分解的方法呢？来，下面我们来讲一个叫做独自成分分析的降维方式！&lt;/p&gt;

&lt;h3 id=&quot;鸡尾酒宴会问题&quot;&gt;鸡尾酒宴会问题&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;n个人，n个麦克风。从n个麦克风得到一组数据：&lt;img src=&quot;https://danieljyc.github.io/img/1402665034566.png&quot; alt=&quot;&quot; /&gt;。其中：i 表示采样的时间顺序，也就是说共得到了 m 组采样，每一组采样都是 n 维的。&lt;/li&gt;
  &lt;li&gt;我们的目标是单单从这 m 组采样数据中分辨出每个人说话的信号s。有 n 个信号源 ，&lt;img src=&quot;https://danieljyc.github.io/img/1402665183196.png&quot; alt=&quot;&quot; /&gt;,s&lt;strong&gt;相互独立。&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;A 是一个未知的混合矩阵（mixing matrix），用来组合叠加信号 s。&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;我们可以得到：
&lt;img src=&quot;https://danieljyc.github.io/img/1402665269996.png&quot; alt=&quot;&quot; /&gt;
    &lt;blockquote&gt;
      &lt;p&gt;其中， x 不是一个向量，是一个矩阵&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;其中每个列向量
&lt;img src=&quot;https://danieljyc.github.io/img/1402665319894.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://danieljyc.github.io/img/1402665355695.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A 和 s 都是未知的，x 是已知的，我们要想办法根据 x 来推出 s。这个过程也称作为盲信号分离。
&lt;img src=&quot;https://danieljyc.github.io/img/1402665589103.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://danieljyc.github.io/img/1402665596364.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;最终得到：
&lt;img src=&quot;https://danieljyc.github.io/img/1402665627938.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$s_{(i)}^{j}$：表示speaker j 在时刻i发出的信号。
对于此，我们需要知道两个量才能求出另外一个，下面我们进一步分析。&lt;/p&gt;

&lt;h3 id=&quot;ica算法的前处理步骤&quot;&gt;ICA算法的前处理步骤&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;中心化：也就是求 x 均值，然后让所有 x 减去均值，这一步与 PCA 一致。&lt;/li&gt;
  &lt;li&gt;漂白：目的是为了让x相互独立。将 x 乘以一个矩阵变成 (其协方差矩阵是$I$)。
&lt;img src=&quot;https://danieljyc.github.io/img/1402667667616.png&quot; alt=&quot;&quot; /&gt;
其中，&lt;img src=&quot;https://danieljyc.github.io/img/1402667709919.png&quot; alt=&quot;&quot; /&gt;
其中使用特征值分解来得到 E（特征向量矩阵）和 D（特征值对角矩阵） ，计算公式为
&lt;img src=&quot;https://danieljyc.github.io/img/1402667761686.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;ica算法&quot;&gt;ICA算法&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;我们假定每$s_i$有概率密度$p_s$，那么给定时刻原信号的联合分布就是
&lt;img src=&quot;https://danieljyc.github.io/img/1402666306377.png&quot; alt=&quot;&quot; /&gt;
    &lt;blockquote&gt;
      &lt;p&gt;注：每个人发出的声音信号s各自独立。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;然后，我们就可以求得p(x)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;现在，我们需要知道p(s)和w，才能求得p(x)。
首先，我们假设s 的累积分布函数符合 sigmoid 函数
&lt;img src=&quot;https://danieljyc.github.io/img/1402666520656.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这就是 s 的密度函数。这里 s 是实数。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;然后，我们就剩下W了。我们用最大似然估计的方法求解。
使用前面得到的 x 的概率密度函数，得
&lt;img src=&quot;https://danieljyc.github.io/img/1402666734641.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://danieljyc.github.io/img/1402666874964.png&quot; alt=&quot;&quot; /&gt;
最终，我们求得：
&lt;img src=&quot;https://danieljyc.github.io/img/1402666911972.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;其中α是梯度上升速率，人为指定。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;迭代求出 W 后，我们也可以还原出原始信号：&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;iac应用&quot;&gt;IAC应用&lt;/h3&gt;
&lt;p&gt;如果把麦克风x换成采集脑电波的电极，信号源s就代表大脑独立进程：心跳、眨眼等。通过将信号x减去心跳、眨眼等无用信号，我们就可以得到大脑内部信号。&lt;/p&gt;

&lt;h3 id=&quot;小结&quot;&gt;小结&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;ICA 的盲信号分析领域的一个强有力方法，也是求非高斯分布数据隐含因子的方法。&lt;/li&gt;
  &lt;li&gt;ICA和PCA对比：&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;ICA: 从之前我们熟悉的样本-特征角度看，我们使用 ICA 的前提条件是，认为样本数据由独立非高斯分布的隐含因子产生，隐含因子个数等于特征数。更适合用来还原信号（因为信号比较有规律，经常不是高斯分布的）。
PCA : 认为特征是由 k 个正交的特征（也可看作是隐含因子）生成的。更适合用来降维（用那么多特征干嘛，k 个正交的即可）
有时候也需要组合两者一起使用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;最后：在这篇博文笔记中，我们学习了一些特征工程的方法，AOC和AUC，还有一些具体的降维技术，这些都是比较基础的，还有很多没有讲到的，现在先不讲了把，以后有机会再说（逃）&lt;/p&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《统计学习方法》-李航&lt;br /&gt;
《机器学习》-周志华&lt;br /&gt;
《机器学习实战》-Peter Harrington&lt;br /&gt;
斯坦福大学公开课-机器学习&lt;br /&gt;
网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;20170211011&quot; data-title=&quot;feature_engen&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Sat, 11 Feb 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/11/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7-%E4%BA%8C.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/02/11/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7-%E4%BA%8C.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>机器学习基础概念</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#机器学习基础概念&quot; id=&quot;markdown-toc-机器学习基础概念&quot;&gt;机器学习基础概念&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#过拟合和欠拟合&quot; id=&quot;markdown-toc-过拟合和欠拟合&quot;&gt;过拟合和欠拟合&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#偏差方差权衡&quot; id=&quot;markdown-toc-偏差方差权衡&quot;&gt;偏差/方差权衡&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#模型复杂程度和偏差方差权衡&quot; id=&quot;markdown-toc-模型复杂程度和偏差方差权衡&quot;&gt;模型复杂程度和偏差/方差权衡&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#what-is-the-difference-between-bias-variance-and-underfitting-overfitting&quot; id=&quot;markdown-toc-what-is-the-difference-between-bias-variance-and-underfitting-overfitting&quot;&gt;What is the difference between (bias variance) and (underfitting overfitting)?&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#正则化&quot; id=&quot;markdown-toc-正则化&quot;&gt;正则化&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#误差验证-评估方法&quot; id=&quot;markdown-toc-误差验证-评估方法&quot;&gt;误差验证-评估方法&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#kl散度&quot; id=&quot;markdown-toc-kl散度&quot;&gt;KL散度&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;机器学习基础概念&quot;&gt;机器学习基础概念&lt;/h1&gt;

&lt;h2 id=&quot;过拟合和欠拟合&quot;&gt;过拟合和欠拟合&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;过拟合（overfitting）：学习能力过强，以至于把训练样本所包含的不太一般的特性都学到了。
欠拟合（underfitting）：学习能太差，训练样本的一般性质尚未学好。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在周志华教授的《机器学习》中有个比较的类比：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering9.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面在那一个真实的例子：
如果我们有6个数据，我们选择用怎么样的回归曲线对它拟合呢？看下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering10.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;可以发现得到的直线y=b+a*x 并不能较为准确的描述训练数据的形态，我们说这不是一个良好的拟合。这也叫做欠拟合&lt;/li&gt;
  &lt;li&gt;如果我们再加入一个特征值 x^2，得到y=a+b*x+c *x^2于是我们得到一个稍好的拟合&lt;/li&gt;
  &lt;li&gt;最后我们直接用五阶多项式去拟合，发现对于训练样本可以很好的拟合，但是这样的模型对预测往往效果不是非常好，这叫做过拟合（overfitting）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在这里我们可以发现，原来&lt;strong&gt;过拟合和欠拟合和模型复杂度是相关的&lt;/strong&gt;，具体描述如下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering11.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;好了，应该了解什么叫欠拟合和过拟合了吧！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;当然，为了防止过拟合，也会有&lt;strong&gt;cross validation，正则化，dropout&lt;/strong&gt;等等方法，以后会一一介绍。&lt;/p&gt;

&lt;h2 id=&quot;偏差方差权衡&quot;&gt;偏差/方差权衡&lt;/h2&gt;

&lt;p&gt;　　偏差-方差分解是解释学习器泛化性能的重要工具。在学习算法中，偏差指的是预测的期望值与真实值的偏差，方差则是每一次预测值与预测值得期望之间的差均方，当然还有任务本身的噪音。实际上，偏差体现了学习器预测的准确度，而方差体现了学习器预测的稳定性。噪声表达当前任务在任何学习算法所能达到的泛化误差的下界，通过对泛化误差的进行分解。可以得到：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;期望泛化误差=方差+偏差+噪声&lt;/li&gt;
  &lt;li&gt;偏差刻画学习器的拟合能力&lt;/li&gt;
  &lt;li&gt;方差体现学习器的稳定性&lt;/li&gt;
  &lt;li&gt;噪音刻画了问题本身的难度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;方差和偏差具有矛盾性，这就是常说的偏差-方差窘伪境（bias-variance dilamma），随着训练程度的提升，期望预测值与真实值之间的差异越来越小，即偏差越来越小，但是另一方面，随着训练程度加大，学习算法对数据集的波动越来越敏感，方差值越来越大。换句话说：在欠拟合时，偏差主导泛化误差，而训练到一定程度后，偏差越来越小，方差主导了泛化误差。因此训练也不要贪杯，适度辄止。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering12.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;（最上面的线是泛化误差）&lt;/p&gt;

&lt;h2 id=&quot;模型复杂程度和偏差方差权衡&quot;&gt;模型复杂程度和偏差/方差权衡&lt;/h2&gt;

&lt;p&gt;我们在偏差与方差间都会做出权衡。如果我们的模型过于简单，只有很少的几个参数，那么它可能存在着较大的偏差（但是方差较小）；如果过于复杂而含有非常多的参数，那么模型可能会存在较大的方差（但是偏差较小）&lt;/p&gt;

&lt;h2 id=&quot;what-is-the-difference-between-bias-variance-and-underfitting-overfitting&quot;&gt;What is the difference between (bias variance) and (underfitting overfitting)?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://stats.stackexchange.com/questions/263635/what-is-the-difference-between-bias-variance-and-underfitting-overfitting&quot;&gt;参考文章&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;All are metrics to find the best model: You would like to have an unbiased minimum variance estimator related to the validation interval - and thus neither over nor underfitted. But how to balance these metrics is up to your application / context.&lt;/p&gt;

&lt;p&gt;Bias: The error you have for certain even if you can use an infinite number of cases / records. Usually you try to get unbiased models.&lt;/p&gt;

&lt;p&gt;Variance / Significance: Relates to the probability that the true relationships between your variables are trivial (e.g. zero) and your model sees an accidental and purely randomly generated data pattern. Variance and bias are usually independent.&lt;/p&gt;

&lt;p&gt;Overfitting: Is related to the variance, but it’s not the same. If you have a large data matrix you may fit a model with a large number of covariats and many parameters may have a small variance. Nevertheless if you split off 20% of the training material and make a prediction with your model on that validation data, the model may predict worse. That’s overfitting: Your model fitted relationships, which aren’t randomly within your full data set, but aren’t systematic and stable 伪for extrapolations outside the training data set.&lt;/p&gt;

&lt;p&gt;Underfitting goes usually with a biased distribution of your residuals: Your model is insufficiently specified. (Relationship between target and covariat is quadratic, but you fit linear). Underfitting can result in a bias, but doesn’t have to do. In any case it results in a non-minimal variance.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;一般而言&lt;strong&gt;高偏差意味着欠拟合，高方差意味着过拟合,但是他们并不是直接相等&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;正则化&quot;&gt;正则化&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;书上说&lt;strong&gt;正则化是模型选择的一种方式&lt;/strong&gt;，但其实我更赞同它的直接目的是防止过拟合！不过我们做的一切都是为了建立选出一个更好的模型是吧！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;正则化的目的：防止过拟合！&lt;/li&gt;
  &lt;li&gt;正则化的本质：约束（限制）要优化的参数。&lt;/li&gt;
  &lt;li&gt;正则化实现方式：在Cost function误差函数中添加惩罚项&lt;/li&gt;
  &lt;li&gt;正则化的缺点：正则化防止过拟合，但引入正则化可能会引起“too much regularization”&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;问：&lt;/strong&gt;对于正则化，优点是使模型“简单”–》这”简单”怎么理解？
&lt;strong&gt;答：&lt;/strong&gt;引用李航老师书中的那段话：正则化符合奥卡姆剃刀 (Occam’s razor)原理。奥卡姆剃刀原理应用于模型选择时变为以下想法：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的模型，也就是应 该选择的模型。从贝叶斯估计的角度来看，正则化项对应于模型的先验概率。可以假设复杂的模型有较大的先验概率，简单的模型有较小的先验概率。&lt;/p&gt;

&lt;p&gt;还是通过例子来描述和理解：下面选自斯坦福大学机器学习公开课
下面是对房子的面积特征和价格的拟合&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;合适的拟合：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering16.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;过拟合：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering17.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;直观来看，如果我们想解决这个例子中的过拟合问题，最好能将x3,x4的影响消除，也就是让θ3≈0,θ4≈0.
假设我们对θ3,θ4进行惩罚，并且令其很小，一个简单的办法就是给原有的Cost function()加上两个略大惩罚项，例如：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering18.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:aut伪o%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这样在最小化Cost function的时候，θ3≈0,θ4≈0.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering19.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了使正则化运作良好，我们应当注意一些方面，应该去选择一个不错的正则化参数 λ 。当我们以后讲到多重选择时我们将讨论一种方法来自动选择正则化参数 λ，为了使用正则化，那么我们就可以让他们避免过度拟合了。&lt;/p&gt;

&lt;h2 id=&quot;误差验证-评估方法&quot;&gt;误差验证-评估方法&lt;/h2&gt;

&lt;p&gt;最后说下误差验证评估方法，主要包括以下3种&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;保留交叉验证&lt;/strong&gt;，也叫作&lt;strong&gt;留出法&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;从全部的训练数据 S中随机选择 中随机选择 s的样例作为训练集 train，剩余的 作为测试集 作为测试集 test。&lt;/li&gt;
      &lt;li&gt;通过对测试集训练 ，得到假设函数或者模型 。&lt;/li&gt;
      &lt;li&gt;在测试集对每一个样本根据假设函数或者模型，得到训练集的类标，求出分类正确率。&lt;/li&gt;
      &lt;li&gt;选择具有最大分类率的模型或者假设&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;k折交叉验证 k-fold cross validation&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;将全部训练集 S分成 k个不相交的子集，假设 S中的训练样例个数为 m，那么每一个子 集有 m/k 个训练样例，相应的子集称作 {s1,s2,…,sk}。&lt;/li&gt;
      &lt;li&gt;每次从分好的子集中里面，拿出一个作为测试集，其它k-1个作为训练集&lt;/li&gt;
      &lt;li&gt;根据训练训练出模型或者假设函数。&lt;/li&gt;
      &lt;li&gt;把这个模型放到测试集上，得到分类率。&lt;/li&gt;
      &lt;li&gt;计算k次求得的分类率的平均值，作为该模型或者假设函数的真实分类率。
  这个方法充分利用了所有样本。但计算比较繁琐，需要训练k次，测试k次。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;当然，交叉验证中有一个比较特殊的情况—-&lt;strong&gt;留一法&lt;/strong&gt;
留一法就是每次只留下一个样本做测试集（也就是当上面的k==m的情况），其它样本做训练集，如果有k个样本，则需要训练k次，测试k次。留一发计算最繁琐，但样本利用率最高。适合于小样本的情况。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们希望评估的是用整个数据集S训练出的模型。但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比S小，这必然会引入一些因训 练样本规模不同而导致的估计偏差。留一法受训练样本规模变化的影响较小，但计算复杂度又太高了。 这就引出下面的自助法&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;自助法&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;自助法的基本思想是：给定包含m个样本的数据集S，每次随机从S 中挑选一个样本，将其拷贝放入S’，然后再将该样本放回初始数据集S 中，使得该样本在下次采样时仍有可能被采到。&lt;/li&gt;
      &lt;li&gt;重复执行m 次，就可以得到了包含m个样本的数据集S’。可以得知在m次采样中，样本始终不被采到的概率取极限为：&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering20.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这样，通过自助采样，初始样本集S中大约有36.8%的样本没有出现在S’中，于是可以将S’作为训练集，S-S’作为测试集。自助法在数据集较小，难以有效划分训练集/测试集时很有用，但由于自助法产生的数据集（随机抽样）改变了初始数据集的分布，因此引入n了估计偏差。在初始数据集足够时，留出法和交叉验证法更加常用，我也是最常用交叉验证的。&lt;/p&gt;

&lt;h3 id=&quot;kl散度&quot;&gt;KL散度&lt;/h3&gt;

&lt;p&gt;相对熵（relative entropy）又称为KL散度（Kullback–Leibler divergence，简称KLD），信息散度（information divergence），信息增益（information gain）。 
KL散度是两个概率分布P和Q差别的非对称性的度量。&lt;/p&gt;

&lt;p&gt;KL散度是用来度量使用基于Q的编码来编码来自P的样本平均所需的额外的比特个数。 典型情况下，P表示数据的真实分布，Q表示数据的理论分布，模型分布，或P的近似分布。&lt;/p&gt;

&lt;p&gt;根据shannon的信息论，给定一个字符集的概率分布，我们可以设计一种编码，使得表示该字符集组成的字符串平均需要的比特数最少。假设这个字符集是X，对x∈X，其出现概率为P(x)，那么其最优编码平均需要的比特数等于这个字符集的熵：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;H(X)=∑x∈XP(x)log[1/P(x)]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在同样的字符集上，假设存在另一个概率分布Q(X)。如果用概率分布P(X)的最优编码（即字符x的编码长度等于log[1/P(x)]），来为符合分布Q(X)的字符编码，那么表示这些字符就会比理想情况多用一些比特数。KL-divergence就是用来衡量这种情况下平均每个字符多用的比特数，因此可以用来衡量两个分布的距离。即：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DKL(Q||P)=∑x∈XQ(x)[log(1/P(x))] - ∑x∈XQ(x)[log[1/Q(x)]]=∑x∈XQ(x)log[Q(x)/P(x)]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;由于-log(u)是凸函数，因此有下面的不等式&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DKL(Q||P) = -∑x∈XQ(x)log[P(x)/Q(x)] = E[-logP(x)/Q(x)] ≥ -logE[P(x)/Q(x)] = -　　log∑x∈XQ(x)P(x)/Q(x) = 0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;即KL-divergence始终是大于等于0的。当且仅当两分布相同时，KL-divergence等于0。&lt;/p&gt;

&lt;p&gt;===========================&lt;/p&gt;

&lt;p&gt;举一个实际的例子吧：比如有四个类别，一个方法A得到四个类别的概率分别是&lt;code class=&quot;highlighter-rouge&quot;&gt;0.1,0.2,0.3,0.4&lt;/code&gt;。另一种方法B（或者说是事实情况）是得到四个类别的概率分别是&lt;code class=&quot;highlighter-rouge&quot;&gt;0.4,0.3,0.2,0.1&lt;/code&gt;,那么这两个分布的KL-&lt;code class=&quot;highlighter-rouge&quot;&gt;Distance(A,B)=0.1*log(0.1/0.4)+0.2*log(0.2/0.3)+0.3*log(0.3/0.2)+0.4*log(0.4/0.1)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这个里面有正的，有负的，可以证明KL-Distance()&amp;gt;=0.&lt;/p&gt;

&lt;p&gt;从上面可以看出， KL散度是不对称的。即KL-Distance(A,B)!=KL-Distance(B,A)&lt;/p&gt;

&lt;p&gt;KL散度是不对称的，当然，如果希望把它变对称，&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Ds(p1, p2) = [D(p1, p2) + D(p2, p1)] / 2.&lt;/code&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 19 Jan 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/01/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/01/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>Pandas基础</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#pandas基础&quot; id=&quot;markdown-toc-pandas基础&quot;&gt;Pandas基础&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#创建pandas结构&quot; id=&quot;markdown-toc-创建pandas结构&quot;&gt;创建Pandas结构&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#pandas-选择数据&quot; id=&quot;markdown-toc-pandas-选择数据&quot;&gt;Pandas 选择数据&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#pandas处理缺失值和填充值&quot; id=&quot;markdown-toc-pandas处理缺失值和填充值&quot;&gt;Pandas处理缺失值和填充值&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#pandas导入导出&quot; id=&quot;markdown-toc-pandas导入导出&quot;&gt;Pandas导入导出&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#pandas-plot-出图&quot; id=&quot;markdown-toc-pandas-plot-出图&quot;&gt;Pandas plot 出图&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;pandas基础&quot;&gt;Pandas基础&lt;/h1&gt;

&lt;p&gt;如果用 python 的列表和字典来作比较, 那么可以说 Numpy 是列表形式的，没有数值标签，而 Pandas 就是字典形式。Pandas是基于Numpy构建的，让Numpy为中心的应用变得更加简单。&lt;/p&gt;

&lt;p&gt;要使用pandas，首先需要了解他主要两个数据结构：Series和DataFrame。&lt;/p&gt;

&lt;h2 id=&quot;创建pandas结构&quot;&gt;创建Pandas结构&lt;/h2&gt;

&lt;p&gt;Series的 创建：&lt;code class=&quot;highlighter-rouge&quot;&gt;s = pd.Series([1,3,6,np.nan,44,1])&lt;/code&gt;建立的结果如下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;”””
0     1.0
1     3.0
2     6.0
3     NaN
4    44.0
5     1.0
dtype: float64
“””&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Series的字符串表现形式为：&lt;strong&gt;索引在左边，值在右边。由于我们没有为数据指定索引。于是会自动创建一个0到N-1（N为长度）的整数型索引。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;DataFrame 的创建：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dates = pd.date_range('20160101',periods=6)
df = pd.DataFrame(np.random.randn(6,4),index=dates,columns=['a','b','c','d'])

print(df)
&quot;&quot;&quot;
				   a         b         c         d
2016-01-01 -0.253065 -2.071051 -0.640515  0.613663
2016-01-02 -1.147178  1.532470  0.989255 -0.499761
2016-01-03  1.221656 -2.390171  1.862914  0.778070
2016-01-04  1.473877 -0.046419  0.610046  0.204672
2016-01-05 -1.584752 -0.700592  1.487264 -1.778293
2016-01-06  0.633675 -1.414157 -0.277066 -0.442545
&quot;&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DataFrame是一个表格型的数据结构，它包含有一组有序的列，每列可以是不同的值类型（数值，字符串，布尔值等）。DataFrame既有行索引也有列索引， 它可以被看做由Series组成的大字典。&lt;/p&gt;

&lt;p&gt;我们可以根据每一个不同的索引来挑选数据, 比如挑选 b 的元素:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;df2.index&lt;/code&gt;:表示的是列的序号，&lt;code class=&quot;highlighter-rouge&quot;&gt;df2.columns&lt;/code&gt;表示的是行的序号。还有一些关于DataFrame的小细节，一些属性请看&lt;a href=&quot;https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/3-1-pd-intro/&quot;&gt;这篇文章&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;pandas-选择数据&quot;&gt;Pandas 选择数据&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;df['A']&lt;/code&gt;或者&lt;code class=&quot;highlighter-rouge&quot;&gt;df[0:3]&lt;/code&gt;，这里就可以当作是map来使用就可以了，如果没有特别的设置键的话就是&lt;code class=&quot;highlighter-rouge&quot;&gt;0,1,2...&lt;/code&gt;这样的。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;loc&lt;/code&gt;：同样我们可以使用标签来选择数据 loc, 本例子主要通过标签名字选择&lt;strong&gt;某一行数据&lt;/strong&gt;， 或者通过选择某行或者所有行（:代表所有行）然后选其中某一列或几列数据。，&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;print(df.loc['20130102'])
&quot;&quot;&quot;
A    4
B    5
C    6
D    7
Name: 2013-01-02 00:00:00, dtype: int64
&quot;&quot;&quot;

print(df.loc[:,['A','B']])
&quot;&quot;&quot;
			 A   B
2013-01-01   0   1
2013-01-02   4   5
2013-01-03   8   9
2013-01-04  12  13
2013-01-05  16  17
2013-01-06  20  21
&quot;&quot;&quot;

print(df.loc['20130102',['A','B']])
&quot;&quot;&quot;
A    4
B    5
Name: 2013-01-02 00:00:00, dtype: int64
&quot;&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;iloc&lt;/code&gt;：另外我们可以采用位置进行选择 iloc, 在这里我们可以通过位置选择在不同情况下所需要的数据例如选某一个，连续选或者跨行选等操作。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;print(df.iloc[3,1])
# 13

print(df.iloc[3:5,1:3])
&quot;&quot;&quot;
			 B   C
2013-01-04  13  14
2013-01-05  17  18
&quot;&quot;&quot;

print(df.iloc[[1,3,5],1:3])
&quot;&quot;&quot;
			 B   C
2013-01-02   5   6
2013-01-04  13  14
2013-01-06  21  22

&quot;&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ix&lt;/code&gt;：当然也可以使用混合在使用，比如&lt;code class=&quot;highlighter-rouge&quot;&gt;df.ix[:3,['A','C']]&lt;/code&gt;表示的就是：其中选择’A’和’C’的两列，并选择前三行的数据。&lt;/p&gt;

&lt;p&gt;同时，可以实验判断来截取数据，&lt;code class=&quot;highlighter-rouge&quot;&gt;df[df.A&amp;gt;8]&lt;/code&gt;表示的就是大于8的数据。&lt;/p&gt;

&lt;h2 id=&quot;pandas处理缺失值和填充值&quot;&gt;Pandas处理缺失值和填充值&lt;/h2&gt;

&lt;p&gt;有时候我们导入或处理数据, 会产生一些空的或者是 NaN 数据,如何删除或者是填补这些 NaN 数据是一个问题：&lt;/p&gt;

&lt;p&gt;建立了一个6X4的矩阵数据并且把两个位置置为空.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dates = pd.date_range('20130101', periods=6)
df = pd.DataFrame(np.arange(24).reshape((6,4)),index=dates, columns=['A','B','C','D'])
df.iloc[0,1] = np.nan
df.iloc[1,2] = np.nan
&quot;&quot;&quot;
			 A     B     C   D
2013-01-01   0   NaN   2.0   3
2013-01-02   4   5.0   NaN   7
2013-01-03   8   9.0  10.0  11
2013-01-04  12  13.0  14.0  15
2013-01-05  16  17.0  18.0  19
2013-01-06  20  21.0  22.0  23	np.any(df.isnull()) == True  
# True
&quot;&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果想直接去掉有 NaN 的行或列, 可以使用 dropna&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;df.dropna(
	axis=0,     # 0: 对行进行操作; 1: 对列进行操作
	how='any'   # 'any': 只要存在 NaN 就 drop 掉; 'all': 必须全部是 NaN 才 drop 
	) 
&quot;&quot;&quot;
			 A     B     C   D
2013-01-03   8   9.0  10.0  11
2013-01-04  12  13.0  14.0  15
2013-01-05  16  17.0  18.0  19
2013-01-06  20  21.0  22.0  23
&quot;&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果是将 NaN 的值用其他值代替, 比如代替成 0:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;df.fillna(value=0)
&quot;&quot;&quot;
			 A     B     C   D
2013-01-01   0   0.0   2.0   3
2013-01-02   4   5.0   0.0   7
2013-01-03   8   9.0  10.0  11
2013-01-04  12  13.0  14.0  15
2013-01-05  16  17.0  18.0  19
2013-01-06  20  21.0  22.0  23
&quot;&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;判断是否有缺失数据 &lt;code class=&quot;highlighter-rouge&quot;&gt;NaN&lt;/code&gt;, 为 &lt;code class=&quot;highlighter-rouge&quot;&gt;True&lt;/code&gt; 表示缺失数据:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;df.isnull()
&quot;&quot;&quot;
				A      B      C      D
2013-01-01  False   True  False  False
2013-01-02  False  False   True  False
2013-01-03  False  False  False  False
2013-01-04  False  False  False  False
2013-01-05  False  False  False  False
2013-01-06  False  False  False  False
&quot;&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;检测在数据中是否存在 &lt;code class=&quot;highlighter-rouge&quot;&gt;NaN&lt;/code&gt;, 如果存在就返回 &lt;code class=&quot;highlighter-rouge&quot;&gt;True&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;np.any(df.isnull()) == True 
# True
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;pandas导入导出&quot;&gt;Pandas导入导出&lt;/h2&gt;

&lt;p&gt;pandas可以读取与存取的资料格式有很多种，像csv、excel、json、html与pickle等…&lt;/p&gt;

&lt;p&gt;读取csv：&lt;code class=&quot;highlighter-rouge&quot;&gt;data = pd.read_csv('students.csv')&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;将资料存取成pickle：&lt;code class=&quot;highlighter-rouge&quot;&gt;data.to_pickle('student.pickle')&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;pandas-plot-出图&quot;&gt;Pandas plot 出图&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.plot()&lt;/code&gt;就是直接画出折线图的一种图，当然，Pandas提供了很多重画图的api，不意义说明。&lt;/p&gt;

</description>
        <pubDate>Thu, 19 Jan 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//python/2017/01/19/Pandas%E5%9F%BA%E7%A1%80.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//python/2017/01/19/Pandas%E5%9F%BA%E7%A1%80.html</guid>
        
        <category>Machine Learning</category>
        
        <category>Python</category>
        
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>数据处理，特征工程</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#特征工程模型评价与选择一&quot; id=&quot;markdown-toc-特征工程模型评价与选择一&quot;&gt;特征工程，模型评价与选择（一）&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#获取数据&quot; id=&quot;markdown-toc-获取数据&quot;&gt;获取数据&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#数据清洗data-cleaning&quot; id=&quot;markdown-toc-数据清洗data-cleaning&quot;&gt;数据清洗（Data Cleaning）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#特征工程feature-engineering&quot; id=&quot;markdown-toc-特征工程feature-engineering&quot;&gt;特征工程（Feature Engineering）&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#特征提取与特征选择&quot; id=&quot;markdown-toc-特征提取与特征选择&quot;&gt;特征提取与特征选择&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#简单实践&quot; id=&quot;markdown-toc-简单实践&quot;&gt;简单实践&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#卡方检验&quot; id=&quot;markdown-toc-卡方检验&quot;&gt;卡方检验&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#信息量&quot; id=&quot;markdown-toc-信息量&quot;&gt;信息量&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#信息增益&quot; id=&quot;markdown-toc-信息增益&quot;&gt;信息增益&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#互信息&quot; id=&quot;markdown-toc-互信息&quot;&gt;互信息&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#编码方式&quot; id=&quot;markdown-toc-编码方式&quot;&gt;编码方式&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#numerical-features数值化特征&quot; id=&quot;markdown-toc-numerical-features数值化特征&quot;&gt;Numerical Features（数值化特征）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#装箱&quot; id=&quot;markdown-toc-装箱&quot;&gt;装箱&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#离散特征&quot; id=&quot;markdown-toc-离散特征&quot;&gt;离散特征：&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#1-排序特征&quot; id=&quot;markdown-toc-1-排序特征&quot;&gt;1. 排序特征：&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#特征工程&quot; id=&quot;markdown-toc-特征工程&quot;&gt;特征工程&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#编码方式-1&quot; id=&quot;markdown-toc-编码方式-1&quot;&gt;编码方式&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#numerical-features数值化特征-1&quot; id=&quot;markdown-toc-numerical-features数值化特征-1&quot;&gt;Numerical Features（数值化特征）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#装箱-1&quot; id=&quot;markdown-toc-装箱-1&quot;&gt;装箱&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#离散特征-1&quot; id=&quot;markdown-toc-离散特征-1&quot;&gt;离散特征：&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#1-排序特征-1&quot; id=&quot;markdown-toc-1-排序特征-1&quot;&gt;1. 排序特征：&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#计数特征&quot; id=&quot;markdown-toc-计数特征&quot;&gt;计数特征&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#类别特征编码&quot; id=&quot;markdown-toc-类别特征编码&quot;&gt;类别特征编码&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#交叉特征&quot; id=&quot;markdown-toc-交叉特征&quot;&gt;交叉特征:&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#缺失值填充难点&quot; id=&quot;markdown-toc-缺失值填充难点&quot;&gt;缺失值填充–难点&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#计数特征-1&quot; id=&quot;markdown-toc-计数特征-1&quot;&gt;计数特征&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#类别特征编码-1&quot; id=&quot;markdown-toc-类别特征编码-1&quot;&gt;类别特征编码&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#交叉特征-1&quot; id=&quot;markdown-toc-交叉特征-1&quot;&gt;交叉特征:&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#缺失值填充难点-1&quot; id=&quot;markdown-toc-缺失值填充难点-1&quot;&gt;缺失值填充–难点&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;特征工程模型评价与选择一&quot;&gt;特征工程，模型评价与选择（一）&lt;/h1&gt;

&lt;h2 id=&quot;获取数据&quot;&gt;获取数据&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;这部分途径有很多很多，在这篇博文不讲，下次有机伪会我会讲下我学习网络爬虫来获取数据的学习经历！&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;数据清洗data-cleaning&quot;&gt;数据清洗（Data Cleaning）&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;当有了数据，我们可以统计一下各个变量的缺失值情况&lt;/li&gt;
  &lt;li&gt;然后对缺失部分进行处理，如果是连续变量，可以采用预测模型，例如 Age，可以找到类似的数据群体，然后取最多的，或者最多群体的平均值。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;特征工程feature-engineering&quot;&gt;特征工程（Feature Engineering）&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;特征工程就是选择一些表示典型特征的数据，来替代原始数据作为模型的输入，进而得到比较好的输出效果。&lt;/li&gt;
  &lt;li&gt;连续数据做一下归一化，即把大范围变化的数据范围缩小至 0～1 或者 －1～1 之间。然后把不相关的变量 （丢）drop 掉。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;因为一个老是说概念可能会不那么清晰，在这篇文章中有例子详解&lt;a href=&quot;http://blog.jobbole.com/74951/&quot;&gt;推荐系统例子&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;还有这篇博文&lt;a href=&quot;http://www.jianshu.com/p/35135ab0a627&quot;&gt;特征工程怎么做&lt;/a&gt;也值得借鉴&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下面直接上图，在大体上对特征工程有个大概了解！&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;特征提取与特征选择&quot;&gt;特征提取与特征选择&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;特征提取：&lt;/strong&gt;特征选择也叫特征子集选择 ( FSS , Feature Subset Selection ) 。是指从已有的M个特征(Feature)中选择N个特征使得系统的特定指标最优化，是从原始特征中选择出一些最有效特征以降低数据集维度的过程,是提高学习算法性能的一个重要手段,也是模式识别中关键的数据预处理步骤。对于一个学习算法来说,好的学习样本是训练模型的关键。.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;特征选择：&lt;/strong&gt;特征提取是计算机视觉和图像处理中的一个概念。它指的是使用计算机提取图像信息，决定每个图像的点是否属于一个图像特征。特征提取的结果是把图像上的点分为不同的子集，这些子集往往属于孤立的点、连续的曲线或者连续的区域。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;提取就是通过降维技术来抽出主要信息//是计算机视觉的概念，通过映射实现，可以理解为高维的映射到低维，不删除具体特征，而是舍去那些通过映射后不能代表原来主要信息的数据
选择就要舍去一些特征，拿到整体主要特征//要删除一些特征&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;二者是直接关联的关系.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;　　一般认为, 特征选择是指在拿到一堆原始数据的伪时候，选取有用的feature，以备进行机器学习使用。
　　比如你拿到的是文本信息，那么里面的单词就是原始数据了， 那么你要考虑的是，数字保留不保留？大小写要不要区分？一些常用词比如of, on, by之类的要不要扔掉？等等。对于图像处理和视频处理也有一套相应的规范和实践。通过下面即将要讲的方法，就可以知道怎么来选择特征和舍去特征。&lt;br /&gt;
　　而特征提取（extract），比如咋做图像识别的时候，由于一个像素表示一个特征的话，现在的照片随随便便就1024*1024像素的，这时候我们就要通过特征提取的方法来抽出最能代表这张照片的主要信息。特征提取（extract）的方法有很多，主要有PCA,PCA的SVD,ICA,还有因子分析（Fachor Analysis）这些讲起来会比较复杂，所以下次要独立一篇再讲一遍（其实也是我现在还没有很好的掌握这些方法-逃。。。）&lt;/p&gt;

&lt;h3 id=&quot;简单实践&quot;&gt;简单实践&lt;/h3&gt;
&lt;p&gt;　　讲到特征选择，最近有看下天池的一个比赛:&lt;a href=&quot;https://tianchi.shuju.aliyun.com/getStart/introduction.htm?spm=5176.100066.333.1.1Ar5Ir&amp;amp;raceId=231576&quot;&gt;Repeat Buyers Prediction&lt;/a&gt;，也是现在大三大佬们的大数据作业，任务就是根据用户3个月在天猫的行为日志，建立用户的品牌偏好，并预测他们在将来一个月内对品牌下商品的购买行为。在作业中老师给的特征只是用户之前的行为，所以最终效果真的有点差，百分之五点多的准确率，百分之五点多的召回率，百分之五点多的f1得分，嗯，我纯靠猜都可能比它强吧。。。&lt;br /&gt;
　　所以我去下载了下官网的数据，做了下数据的简单可视化，在用户的年龄段（age range）和性别（gender）方面是很大影响的，具体图如下&lt;a href=&quot;&quot;&gt;&lt;/a&gt;
然后还有就是商品的类别和品牌也应该是有有影响的（这个想想就能理解了吧），但由于给我的数据量太大了，本来想做可视化折线图的，运行他就，效果也不明显也就放弃了。&lt;br /&gt;
　　具体经过特征添加后的最终结果，我想应该会在&lt;strong&gt;回归&lt;/strong&gt;那篇讲讲（之后写）&lt;/p&gt;

&lt;h3 id=&quot;卡方检验&quot;&gt;卡方检验&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;卡方值和卡方检验其实在我们高中的时候就学过了，想想是吧！但是那个时候觉得它并没有什么卵用，也就早“还给老师”。其实也很简单，&lt;strong&gt;卡方值检验就是检验A,B事物之间的相关程度&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;先直接推荐一篇博文，结合例子，很好理解：&lt;a href=&quot;http://www.blogjava.net/zhenandaci/archive/2008/08/31/225966.html&quot;&gt;卡方检验&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;在我的项目中，有用到卡方检验来提取特征词，然后来减少无关特征，达到特征选择的目的，实践证明，确实好用！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;信息量&quot;&gt;信息量&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;首先先说下信息量的问题，一条信息的信息量跟这个信息能解答的问题的不确定性有关。能解答的问题越不确定，这条信息的信息量越大，也就是说这条信息的熵越大。–咦，说好的信息量，怎么又来了个信息熵的呢？好吧，说说信息熵&lt;/li&gt;
  &lt;li&gt;信息熵也叫香农熵（信息论之父——克劳德·香农，在 1948 年提出“ 信息熵解决了信息的度量问题），就是用来衡量信息量的大小。熵这个字出自与热力学，表示系统混乱的程度，在信息论中我们用信息熵来表示信息的大小。简单理解信息的不确定性越大，信息熵就越大，信息的不确定性越小，信息熵也就越小。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;　　嗯，有点抽象，那就来结合例子来理解：–以下例子来自《数学之美》（是本好书）。&lt;/p&gt;

&lt;p&gt;　　假设我错过了某年的世界杯比赛，现在要去问一个知道比赛结果的朋友“哪支球队最终获得世界杯冠军”？他要求我猜，猜完会告诉我是对还是错，但我每猜一次就要给他一块钱。那么我需要付给他多少钱才能知道谁是冠军？我可以把球队编号，从1到32，然后问“冠军的球队在1-16号中吗？”。假如他告诉我对了，我就问“冠军的球队在1-8号中吗？”。如果他告诉我不对，我就自然就知道冠军队在9-16号中。这样我只需要猜5次就可以知道哪支球队是冠军了。所以，“谁是世界杯冠军”这个问题的答案的信息量只值5块钱。&lt;br /&gt;
  香农用“比特”（bit）来作为信息量的单位。像上边“谁是世界杯冠军”这个问题的答案的信息量是5比特。如果是64支球队，“谁是世界杯冠军”这个问题的答案的信息量就是6比特，因为我还要多猜一次。&lt;br /&gt;
　　对足球了解的朋友看到这有疑问了，他觉得他不需要5次来猜。因为他知道巴西，西班牙，德国等这些强队夺冠的可能性比日本，韩国等球队大的多。所以他可以先把强队分成一组，剩下的其它队伍一组。然后问冠军是否在夺冠热门组里边。重复这样的过程，根据夺冠的概率对剩下的候选球队分组，直至找到冠军队。这样也许三次或四此就猜出结果了。因此，当每支球队夺冠的可能性（概率）不一样时，“谁是世界杯冠军”这个问题的答案的信息量比5比特少。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;　　香农指出，“谁是世界杯冠军”这个问题的答案的信息量是：&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;H = -(p1*log(p1) + p2 * log(p2) + ... + p32 * log(32))&lt;/code&gt;, 其中log是以2为底数的对数，以下本文中的log都是以2为底的对数，下边不再特别说明。这就是衡量信息量多少的公式，它的单位是比特。之所以称为熵是因为它的定义形式和热力学的熵有很大的相似性。对于一个随机变量X的信息熵的定义公式为：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;H(X)＝-∑P(xi)logP(xi)&lt;/code&gt;，其中xi是随机变量X的可能取值。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;应该比较好懂了吧，我就是这样看懂的&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;信息熵计算：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;信息熵图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering3.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到，在p=0.5（意味着在二元中概率事件发生概率相等的情况下）的时候熵值是最大的，也就是说这个时候是是确定性最低的，最混乱的。（延伸到在足球的例子中的意思就是每个队的获胜概率都相等的时候，那个时候信息量（熵）最大，你就越难猜那个队会赢）&lt;/p&gt;

&lt;h3 id=&quot;信息增益&quot;&gt;信息增益&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;说完信息熵，之后我们来说说信息增益，但说信息增益之前，我们说下条件熵&lt;/li&gt;
  &lt;li&gt;条件熵表示在已知第二个随机变量 X 下第一个随机变量 Y 信息熵的大小。条件上用 &lt;code class=&quot;highlighter-rouge&quot;&gt;H(Y|X)&lt;/code&gt; 表示&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering4.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;咦，看到上面式子就想起条件概率，其实，&lt;strong&gt;条件熵可以类比条件概率，他表示：在随机变量 X 的基础上我们引入随机变量 Y，假设 Y 和 X 有一定的关系。那么 Y 的信息熵会相对减小。&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;条件熵还是很好理解的吧！不理解吗？还是结合足球的例子，比如你知道其中一个队是铁定不会赢的了，那你要现在要猜那个队会赢，那个难度就下降了是吧，因为信息熵下降了！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;知道条件熵之后，信息增益就很简单了，他就是：&lt;code class=&quot;highlighter-rouge&quot;&gt;g(X,Y) = H(X) – H(X|Y)&lt;/code&gt;，表示的就是条件熵和原来熵的差值&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;嗯，概念就讲到这里，之后我会写决策树的博文，到时还会复习一下信息熵。介绍一下信息增益比的概念&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;关于信息论对ML的一些概念，可以看下&lt;a href=&quot;https://segmentfault.com/a/1190000000641079&quot;&gt;这篇博文&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;互信息&quot;&gt;互信息&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;测量训练数据中xi与y的相关度。该算法可能会使得我们选择的都是与标签y强相关的特征值。在实践中，我们通常选择能够表示xi与y间的互信息（mutual information）&lt;/li&gt;
  &lt;li&gt;互信息(Mutual Information)是度量两个事件集合之间的相关性(mutual dependence)。意义就是：由于事件A发生与事件B发生相关联而提供的信息量。&lt;/li&gt;
  &lt;li&gt;数学公式：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering5.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;应该不难理解，但这里有一个问题：&lt;br /&gt;
　　&lt;strong&gt;问：&lt;/strong&gt;《数学之美》 上面 互信息 的公式是：I(X;Y)=H(X)-H(X|Y)；又看到 《统计学习方法》 上有一个 信息增益 的公式：G(D,A)=H(D)-H(D|A)。这不是一样吗？难道互信息就是信息增益？&lt;br /&gt;
　　&lt;strong&gt;答：&lt;/strong&gt;IG（信息增益）有两种定义。。一般IG是指KL散度（相对熵）
但在Desicion Tree（决策树）的IG一般是指KL散度的期望，然后正好就是互信息了，其实我想就简单理解并记住计算互信息的公式，然后在机器学习中信息增益是一种特殊的情况，就是她是KL散度的期望。
先看p对q的相对熵为
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering6.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后是KL散度的期望=互信息&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering7.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;总结：&lt;/strong&gt;其实信息论要讲起来是一门挺深的课。而我是想用最简单的方式理解最多的知识，可能讲的比较粗略，有兴趣的小伙伴可以看看信息论的书！
最后，用一张图结束:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering8.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;编码方式&quot;&gt;编码方式&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;one-hot编码：&lt;/strong&gt;大多使用一些线性的算法，它的稀疏格式是记忆友好的(便于存储)，注意去掉第一列避免共线性
&lt;strong&gt;哈希编码：&lt;/strong&gt;它是对固定长度的数组进行 Onehot 编码，它避免极度稀疏的数据，但可能会产生冲突
&lt;strong&gt;标签编码：&lt;/strong&gt;它给每个类一个独一无二的数字化 ID,它对于对于&lt;strong&gt;非线性的基于树模型&lt;/strong&gt;的算法很有用，它不增加维度
&lt;strong&gt;Count 编码:Replace categorical variables with their count in the train set&lt;/strong&gt;,它对线性或非线性的算法都适用，对对异常值敏感，&lt;strong&gt;Replace unseen variables with &lt;code class=&quot;highlighter-rouge&quot;&gt;1&lt;/code&gt;&lt;/strong&gt;
&lt;strong&gt;LabelCount 编码:Rank categorical variables by count in train set&lt;/strong&gt;,对线性或非线性算法都适用,它对异常值不敏感&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在这里讲述的是常见的几种编码方式，其实还有其他的各种不同的编码，具体请看&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;numerical-features数值化特征&quot;&gt;Numerical Features（数值化特征）&lt;/h2&gt;

&lt;p&gt;Can be more readily fed into algorithms，Can constitute floats, counts, numbers and Easier to impute missing data.&lt;/p&gt;

&lt;h2 id=&quot;装箱&quot;&gt;装箱&lt;/h2&gt;
&lt;p&gt;把数字化变量放入箱中,并用 bin-ID 编码,用分位数装箱是很实用的,甚至可以用模型找出可选的箱
可以优雅的找到训练集范围外的变量&lt;/p&gt;

&lt;h3 id=&quot;离散特征&quot;&gt;离散特征：&lt;/h3&gt;

&lt;p&gt;特征离散化有两种划分方式:一种是等值划分(按照值域均分),另一种是等量划分
(按照样本数均分)。我们对 numeric 类型的特征采用了等量划分的离散化方式:先将每
一维特征按照数值大小排序,然后均匀地划分为 10 个区间,即离散化为 1~10。&lt;/p&gt;

&lt;h3 id=&quot;1-排序特征&quot;&gt;1. 排序特征：&lt;/h3&gt;

&lt;h2 id=&quot;特征工程&quot;&gt;特征工程&lt;/h2&gt;
&lt;p&gt;坊间戏言“特征没做好,参数调到老”,机器学习大牛 Andrew Ng 也说过“‘Applied
machine learning’is basically feature engineering”,可见特征工程的重要性,我们要在在这部分投入了大量的时间和精力。下面先讲讲怎么来对特征进行处理&lt;/p&gt;

&lt;h2 id=&quot;编码方式-1&quot;&gt;编码方式&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;one-hot编码：&lt;/strong&gt;大多使用一些线性的算法，它的稀疏格式是记忆友好的(便于存储)，注意去掉第一列避免共线性
&lt;strong&gt;哈希编码：&lt;/strong&gt;它是对固定长度的数组进行 Onehot 编码，它避免极度稀疏的数据，但可能会产生冲突
&lt;strong&gt;标签编码：&lt;/strong&gt;它给每个类一个独一无二的数字化 ID,它对于对于&lt;strong&gt;非线性的基于树模型&lt;/strong&gt;的算法很有用，它不增加维度
&lt;strong&gt;Count 编码:Replace categorical variables with their count in the train set&lt;/strong&gt;,它对线性或非线性的算法都适用，对对异常值敏感，&lt;strong&gt;Replace unseen variables with &lt;code class=&quot;highlighter-rouge&quot;&gt;1&lt;/code&gt;&lt;/strong&gt;
&lt;strong&gt;LabelCount 编码:Rank categorical variables by count in train set&lt;/strong&gt;,对线性或非线性算法都适用,它对异常值不敏感&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在这里讲述的是常见的几种编码方式，其实还有其他的各种不同的编码，具体请看&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;numerical-features数值化特征-1&quot;&gt;Numerical Features（数值化特征）&lt;/h2&gt;

&lt;p&gt;Can be more readily fed into algorithms，Can constitute floats, counts, numbers and Easier to impute missing data.&lt;/p&gt;

&lt;h2 id=&quot;装箱-1&quot;&gt;装箱&lt;/h2&gt;
&lt;p&gt;把数字化变量放入箱中,并用 bin-ID 编码,用分位数装箱是很实用的,甚至可以用模型找出可选的箱
可以优雅的找到训练集范围外的变量&lt;/p&gt;

&lt;h3 id=&quot;离散特征-1&quot;&gt;离散特征：&lt;/h3&gt;

&lt;p&gt;特征离散化有两种划分方式:一种是等值划分(按照值域均分),另一种是等量划分
(按照样本数均分)。我们对 numeric 类型的特征采用了等量划分的离散化方式:先将每
一维特征按照数值大小排序,然后均匀地划分为 10 个区间,即离散化为 1~10。&lt;/p&gt;

&lt;h3 id=&quot;1-排序特征-1&quot;&gt;1. 排序特征：&lt;/h3&gt;

&lt;p&gt;排序特征对异常数据都有较强的鲁棒性,使得模型更加稳定,降低过拟合的风险。&lt;/p&gt;

&lt;h3 id=&quot;计数特征&quot;&gt;计数特征&lt;/h3&gt;

&lt;p&gt;前面已经对特征进行了离散化,以 uid 为 1 的样本为这次就讲到这里吧，之后我会继续写好下面的博文，希望在写博文的同时，可以加深理解，一起加油！！！例,离散化后它的特征是
5,3,1,3,3,3,2,4,3,2,5,3,2,3,2…2,2,2,2,2,2,2,可以进一步统计离散特征中 1~10 出现的次数
n i (i=1,2,…,10),即可得到一个 10 维计数特征。基于这 10 维特征训练了 xgboost 分类器,线
上得分是 0.58 左右,说明这 10 维特征具有不错的判别性。&lt;/p&gt;

&lt;h3 id=&quot;类别特征编码&quot;&gt;类别特征编码&lt;/h3&gt;

&lt;p&gt;赛题数据含有 93 维类别特征,很多算法(如逻辑回归,SVM)只能处理数值型特征,
这种情况下需要对类别特征进行编码,我们采用了 One-Hot 编码,得到了 01 特征,解决
了分类器不能处理类别特征的问题。&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;当不清楚这个编码的时候，你就很有可能会犯错误，例如颜色属性可能会用{1,2,3}表示{红，绿，蓝}。这里存在两个问题：首先，对于一个数学模型，这意味着某种意义上红色和绿色比和蓝色更“相似”（因为&lt;/td&gt;
      &lt;td&gt;1-3&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;1-2&lt;/td&gt;
      &lt;td&gt;）。除非你的类别拥有排序的属性（比如铁路线上的站），这样可能会误导你的模型。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;交叉特征&quot;&gt;交叉特征:&lt;/h3&gt;

&lt;p&gt;交叉特征算是特征工程中非常重要的方法之一了，交叉特征是一种很独特的方式，它将两个或更多的类别属性组合成一个。当组合的特征要比单个特征更好时，这是一项非常有用的技术。数学上来说，是对类别特征的所有可能值进行交叉相乘。&lt;/p&gt;

&lt;p&gt;假如拥有一个特征A，A有两个可能值{A1,A2}。拥有一个特征B，存在{B1,B2}等可能值。然后，A&amp;amp;B之间的交叉特征如下：{(A1,B1),(A1,B2),(A2,B1),(A2,B2)}，并且你可以给这些组合特征取任何名字。但是需要明白每个组合特征其实代表着A和B各自信息协同作用。&lt;/p&gt;

&lt;p&gt;一个更好地诠释好的交叉特征的实例是类似于(经度,纬度)。一个相同的经度对应了地图上很多的地方，纬度也是一样。但是一旦你将经度和纬度组合到一起，它们就代表了地理上特定的一块区域，区域中每一部分是拥有着类似的特性。&lt;/p&gt;

&lt;h2 id=&quot;缺失值填充难点&quot;&gt;缺失值填充–难点&lt;/h2&gt;

&lt;p&gt;排序特征对异常数据都有较强的鲁棒性,使得模型更加稳定,降低过拟合的风险。&lt;/p&gt;

&lt;h3 id=&quot;计数特征-1&quot;&gt;计数特征&lt;/h3&gt;

&lt;p&gt;前面已经对特征进行了离散化,以 uid 为 1 的样本为例,离散化后它的特征是
5,3,1,3,3,3,2,4,3,2,5,3,2,3,2…2,2,2,2,2,2,2,可以进一步统计离散特征中 1~10 出现的次数
n i (i=1,2,…,10),即可得到一个 10 维计数特征。基于这 10 维特征训练了 xgboost 分类器,线
上得分是 0.58 左右,说明这 10 维特征具有不错的判别性。&lt;/p&gt;

&lt;h3 id=&quot;类别特征编码-1&quot;&gt;类别特征编码&lt;/h3&gt;

&lt;p&gt;赛题数据含有 93 维类别特征,很多算法(如逻辑回归,SVM)只能处理数值型特征,
这种情况下需要对类别特征进行编码,我们采用了 One-Hot 编码,得到了 01 特征,解决
了分类器不能处理类别特征的问题。&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;当不清楚这个编码的时候，你就很有可能会犯错误，例如颜色属性可能会用{1,2,3}表示{红，绿，蓝}。这里存在两个问题：首先，对于一个数学模型，这意味着某种意义上红色和绿色比和蓝色更“相似”（因为&lt;/td&gt;
      &lt;td&gt;1-3&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;1-2&lt;/td&gt;
      &lt;td&gt;）。除非你的类别拥有排序的属性（比如铁路线上的站），这样可能会误导你的模型。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;交叉特征-1&quot;&gt;交叉特征:&lt;/h3&gt;

&lt;p&gt;交叉特征算是特征工程中非常重要的方法之一了，交叉特征是一种很独特的方式，它将两个或更多的类别属性组合成一个。当组合的特征要比单个特征更好时，这是一项非常有用的技术。数学上来说，是对类别特征的所有可能值进行交叉相乘。&lt;/p&gt;

&lt;p&gt;假如拥有一个特征A，A有两个可能值{A1,A2}。拥有一个特征B，存在{B1,B2}等可能值。然后，A&amp;amp;B之间的交叉特征如下：{(A1,B1),(A1,B2),(A2,B1),(A2,B2)}，并且你可以给这些组合特征取任何名字。但是需要明白每个组合特征其实代表着A和B各自信息协同作用。&lt;/p&gt;

&lt;p&gt;一个更好地诠释好的交叉特征的实例是类似于(经度,纬度)。一个相同的经度对应了地图上很多的地方，纬度也是一样。但是一旦你将经度和纬度组合到一起，它们就代表了地理上特定的一块区域，区域中每一部分是拥有着类似的特性。&lt;/p&gt;

&lt;h2 id=&quot;缺失值填充难点-1&quot;&gt;缺失值填充–难点&lt;/h2&gt;
&lt;p&gt;。损失函数是   f (X)和Y的非负实值函数，记作L(Y, f (X)) .
在李航博士《统计学习方法》中有很详细的介绍，我就偷偷懒，就直接贴下那篇图片好啦，然后简单说明下（哈哈，逃。。）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering13.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;损失函数的期望是
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering14.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;期望风险Rexp(f)是模型关于联合分布的期望损失，经验风险Remp(f)是模型关于训练样本集的平均损失（也就是概率中是实验数据越大，越能代表一般规律）。根据大数定律，当样本容量N趋于无穷时，经验风险趋于期望风险。所以一个很自然的想法是用经验风险估计期望风险。但是，由于现实中训练样本数目有限，甚至很小，所以用经验风险估计期望风险常常并不理想，要对经验风险进行一定的矫正.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Machine Learning/feature_engineering15.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;当样本容量足够大时，经验风险最小化能保证有很好的学习效果。例：极大似然估计(maximum likelihood estimation)。但是，当样本容量很小时，经验风险最小化学习的效果就未必很好，会产“过拟合(over-fitting)”现象.这就引出下面的正则化。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;参考资料：&lt;/p&gt;

&lt;p&gt;《统计学习方法》-李航&lt;br /&gt;
《机器学习》-周志华&lt;br /&gt;
《机器学习实战》-Peter Harrington&lt;br /&gt;
斯坦福大学公开课-机器学习&lt;br /&gt;
网上的各位大牛的博文&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201701181&quot; data-title=&quot;feature engineering&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Wed, 18 Jan 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/01/18/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7-%E4%B8%80.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//machine%20learning/2017/01/18/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7-%E4%B8%80.html</guid>
        
        <category>Machine Learning</category>
        
        <category>AI</category>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>numpy基础</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#numpy基础&quot; id=&quot;markdown-toc-numpy基础&quot;&gt;numpy基础&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#array-的几个属性&quot; id=&quot;markdown-toc-array-的几个属性&quot;&gt;array 的几个属性:&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#numpy-的创建-array&quot; id=&quot;markdown-toc-numpy-的创建-array&quot;&gt;Numpy 的创建 array&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#array的基础运算&quot; id=&quot;markdown-toc-array的基础运算&quot;&gt;array的基础运算&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#numpy-的索引&quot; id=&quot;markdown-toc-numpy-的索引&quot;&gt;Numpy 的索引&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#numpy-array-合并和分割&quot; id=&quot;markdown-toc-numpy-array-合并和分割&quot;&gt;Numpy array 合并和分割&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;numpy基础&quot;&gt;numpy基础&lt;/h1&gt;

&lt;h2 id=&quot;array-的几个属性&quot;&gt;array 的几个属性:&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ndim&lt;/code&gt;：维度&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;shape&lt;/code&gt;：行数和列数&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;size&lt;/code&gt;：元素个数&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;调用方式，比如： &lt;code class=&quot;highlighter-rouge&quot;&gt;array = np.array([[1,2,3],[2,3,4]])  array.ndim&lt;/code&gt;（array是一个对象，输出是2）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;numpy-的创建-array&quot;&gt;Numpy 的创建 array&lt;/h2&gt;

&lt;p&gt;最简单：&lt;code class=&quot;highlighter-rouge&quot;&gt;a = np.array([2,23,4])&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;创建全零数组：&lt;code class=&quot;highlighter-rouge&quot;&gt;a = np.zeros((3,4)) # 数据全为0，3行4列&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;创建全1数组：&lt;code class=&quot;highlighter-rouge&quot;&gt;a = np.ones((3,4),dtype = np.int)   # 数据为1，3行4列，数据类型是整型&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;用 arange 创建连续数组:：&lt;code class=&quot;highlighter-rouge&quot;&gt;a = np.arange(10,20,2) # 10-19 的数据，2步长&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;dtype：表示的是数据类型，也就是数组元素的数据类型&lt;/p&gt;

&lt;p&gt;numpy数据类型dtype转换,numpy中的数据类型转换，不能直接改原数据的dtype!因为这样会导致数组长度的改变，只能用函数astype()函数，详细见&lt;a href=&quot;http://www.mamicode.com/info-detail-1180317.html&quot;&gt;这篇博文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;指定数据 dtype的创建数组：&lt;code class=&quot;highlighter-rouge&quot;&gt;a = np.array([2,23,4],dtype=np.int)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;reshape&lt;/code&gt; 改变数据的形状：&lt;code class=&quot;highlighter-rouge&quot;&gt;a = np.arange(12).reshape((3,4))    # 3行4列，0到11&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;”””
array([[ 0,  1,  2,  3],
      [ 4,  5,  6,  7],
      [ 8,  9, 10, 11]])
“””&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;需要注意的是：&lt;strong&gt;通过reshape生成的新数组和原始数组公用一个内存，也就是说，假如更改一个数组的元素，另一个数组也将发生改变。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;array的基础运算&quot;&gt;array的基础运算&lt;/h2&gt;

&lt;p&gt;其实就像一个数组，需要注意的是&lt;code class=&quot;highlighter-rouge&quot;&gt;c=a*b&lt;/code&gt;是对应元素相乘，并不是矩阵相乘，&lt;code class=&quot;highlighter-rouge&quot;&gt;c=b**2&lt;/code&gt;表示的是各个元素都变成原来的平方。而矩阵的相乘是&lt;code class=&quot;highlighter-rouge&quot;&gt;c_dot = np.dot(a,b)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;当&lt;code class=&quot;highlighter-rouge&quot;&gt;axis&lt;/code&gt;的值为0的时候，将会以列作为查找单元， 当axis的值为1的时候，将会以行作为查找单元。比如&lt;code class=&quot;highlighter-rouge&quot;&gt;print(&quot;min =&quot;,np.min(a,axis=1))&lt;/code&gt;是所有行中的最小值，也就是说有多少行就有多少个其所在行的最小值。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;np.argmin(A) &lt;/code&gt;和 &lt;code class=&quot;highlighter-rouge&quot;&gt;np.argmax(A) &lt;/code&gt;两个函数分别对应着求矩阵中最小元素和最大元素的&lt;strong&gt;索引。&lt;/strong&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;A.mean()&lt;/code&gt;是求均值的;&lt;code class=&quot;highlighter-rouge&quot;&gt;np.sort(A)&lt;/code&gt;表示的是仅针对每一行进行从小到大排序操作&lt;/p&gt;

&lt;h2 id=&quot;numpy-的索引&quot;&gt;Numpy 的索引&lt;/h2&gt;

&lt;p&gt;在元素列表或者数组中，我们可以用如同a[2]一样的表示方法，同样的，在Numpy中也有相对应的表示方法。&lt;/p&gt;

&lt;p&gt;二维：&lt;code class=&quot;highlighter-rouge&quot;&gt;A[2]&lt;/code&gt;表示A的第三行所有元素，A[1, 1]表示单个元素。当然，如果要对array进行切片的话，用如下：&lt;code class=&quot;highlighter-rouge&quot;&gt;A[1, 1:3]&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;numpy-array-合并和分割&quot;&gt;Numpy array 合并和分割&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;np.vstack((A,B)&lt;/code&gt;是上下合并，即对括号中的两个整体进行对应操作。&lt;code class=&quot;highlighter-rouge&quot;&gt;np.hstack((A,B)) &lt;/code&gt;是一种左右合并&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;np.split(A, 2, axis=1)&lt;/code&gt;纵向分割也就是在纵向对等分为两份，也就是;&lt;code class=&quot;highlighter-rouge&quot;&gt;print(np.split(A, 3, axis=0))&lt;/code&gt;横向分割，也就是横向对等分为三分。注意：split（）只能对等分，如果不对等就会报错。如果要不对等分配，应该用这个函数&lt;code class=&quot;highlighter-rouge&quot;&gt;array_split()&lt;/code&gt;,例如&lt;code class=&quot;highlighter-rouge&quot;&gt;np.array_split(A, 3, axis=1)&lt;/code&gt;表示的是纵向分为不对等的三分&lt;/p&gt;

</description>
        <pubDate>Wed, 18 Jan 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//python/2017/01/18/numpy%E5%9F%BA%E7%A1%80.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//python/2017/01/18/numpy%E5%9F%BA%E7%A1%80.html</guid>
        
        <category>Machine Learning</category>
        
        <category>Python</category>
        
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Matplotlib基础</title>
        <description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论，建议用电脑看&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#matplotlib基础&quot; id=&quot;markdown-toc-matplotlib基础&quot;&gt;Matplotlib基础&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#基本用法&quot; id=&quot;markdown-toc-基本用法&quot;&gt;基本用法&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#设置坐标轴&quot; id=&quot;markdown-toc-设置坐标轴&quot;&gt;设置坐标轴&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#图例&quot; id=&quot;markdown-toc-图例&quot;&gt;图例&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;matplotlib基础&quot;&gt;Matplotlib基础&lt;/h1&gt;

&lt;h2 id=&quot;基本用法&quot;&gt;基本用法&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import matplotlib.pyplot as plt #使用import导入模块matplotlib.pyplot，并简写成plt 
import numpy as np # 使用import导入模块numpy，并简写成np

x = np.linspace(-1, 1, 50) #使用np.linspace定义x：范围是(-1,1);个数是50. 仿真一维数据组(x ,y)表示曲线1.
y = 2*x + 1


plt.figure()# 使用plt.figure定义一个图像窗口.
plt.plot(x, y)# 使用plt.plot画(x ,y)曲线.
plt.show()# 使用plt.show显示图像.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;得到的图片如下：&lt;/p&gt;

&lt;p&gt;Matplotlib&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;plt.plot(x, y1, color='red', linewidth=1.0, linestyle='--')&lt;/code&gt;# 曲线的宽度(linewidth)为1.0；曲线的类型(linestyle)为虚线. 使用plt.show显示图像,需要注意的就是这些属性。&lt;/p&gt;

&lt;h2 id=&quot;设置坐标轴&quot;&gt;设置坐标轴&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;plt.xlim((-1, 2))&lt;/code&gt;#设置x坐标轴范围：(-1, 2)；
&lt;code class=&quot;highlighter-rouge&quot;&gt;plt.ylim((-2, 3))&lt;/code&gt;#设置y坐标轴范围：(-2, 3)；
&lt;code class=&quot;highlighter-rouge&quot;&gt;plt.xlabel('I am x')&lt;/code&gt;#设置x坐标轴名称：’I am x’
&lt;code class=&quot;highlighter-rouge&quot;&gt;plt.ylabel('I am y')&lt;/code&gt;#设置y坐标轴名称：’I am y’&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;plt.yticks([-2, -1.8, -1, 1.22, 3],[r'$really\ bad$', r'$bad$', r'$normal$', r'$good$', r'$really\ good$'])&lt;/code&gt;#使用&lt;code class=&quot;highlighter-rouge&quot;&gt;plt.yticks&lt;/code&gt;设置y轴刻度以及名称：刻度为[-2, -1.8, -1, 1.22, 3]；对应刻度的名称为[‘really bad’,’bad’,’normal’,’good’, ‘really good’].&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;new_ticks = np.linspace(-1, 2, 5) plt.xticks(new_ticks)&lt;/code&gt;：np.linspace定义范围以及个数：范围是(-1,2);个数是5. 使用print打印出新定义的范围. 使用plt.xticks设置x轴刻度：范围是(-1,2);个数是5.&lt;/p&gt;

&lt;h2 id=&quot;图例&quot;&gt;图例&lt;/h2&gt;

&lt;p&gt;legend将要显示的信息来自于上面代码中的 label. 所以我们只需要简单写下一下代码, plt 就能自动的为我们添加图例，也就是lengend加上图例&lt;/p&gt;

&lt;p&gt;参数 loc=’upper right’ 表示图例将添加在图中的右上角.&lt;/p&gt;

&lt;p&gt;l1, = plt.plot(x, y2, label=’linear line’)
l2, = plt.plot(x, y1, color=’red’, linewidth=1.0, linestyle=’–’, label=’square line’)
plt.legend(loc=’upper right’)&lt;/p&gt;

&lt;p&gt;其实matplotlib大部分都是api，而这些东西我们可以在用到的时候在查下，不用都一个一个的记住，提供&lt;a href=&quot;https://morvanzhou.github.io/tutorials/data-manipulation/plt/&quot;&gt;这个教程&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Mon, 16 Jan 2017 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//python/2017/01/16/Matplotlib.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//python/2017/01/16/Matplotlib.html</guid>
        
        <category>Machine Learning</category>
        
        <category>Python</category>
        
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>再见2016，你好2017</title>
        <description>&lt;h1 id=&quot;再见2016你好2017&quot;&gt;再见2016，你好2017&lt;/h1&gt;

&lt;h2 id=&quot;感受2016&quot;&gt;感受2016&lt;/h2&gt;
&lt;p&gt;　　不知道要怎么样开头，就以老套路：时光荏苒，如白马过隙，日月如梭，有多少的逝者如斯。。。2016年就要过去了，其实在之前，写总结这种事情我好像不太“感冒”，因为没什么好总结？，或者又是总结的不好？，还是主要因为懒？应该是因为懒吧！所以今天我也要写下2016的总结，时光太长，只能长话短说了！
2016发生了很多事情，与我相关的，与我不相关的，常浮现脑海的，或者是“沉入”脑海。总之，一切似乎都过去了，但要好像还没有过去。。。&lt;/p&gt;

&lt;p&gt;　　今年发生太多似乎与我无关却又牵动我心的事，举一两个让我印象较为深刻的事。5月，同是广工15级的同学，见义勇为，和盗贼斗争，多么不幸的是，他倒下了，再也没有站起来。。那个时候，在准备转专业和工作室考核的我，很忙，本不打算去参加追悼会的，在那天，我背着书包，带着很多的书，准备去图书馆复习，然而，当我骑单车到那个岔路口的时候，还是不自觉的转向了追悼会的现场，就这样，背着沉重的书包，似乎内心也被它压着，站着，悲痛着，也思考着。我想，很多人说，盲目的见义勇为多么的不理智，但我觉得，很多时候，我们并没有想那么多，只是正义可能会让我们做出了可能是冲动的决定而已，希望那个同龄英雄的亲人可以慢慢好起来！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/life/say2016_2.jpg&quot; alt=&quot;header1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;　　同样是5月，印象比较深刻的是杨绛先生的离世，从高中开始，我就一直认为钱钟书是我最爱的作家，甚至没有之一。黑色幽默式的风格，让人惊叹的比喻，滑稽而又直指关键的写作风格，应该说，《围城》是让我爱上钱钟书先生的开始，而其他作品又让我爱上他的全部。杨绛先生是他的夫人，同时又是大家，当然也有所了解，看过一些杨绛先生的《我们仨》，写的真的很好！大家离世，真是我们读者巨大损失！&lt;/p&gt;
&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/life/say2016_4.jpg&quot; alt=&quot;header1&quot; /&gt;
 &lt;/div&gt;

&lt;h2 id=&quot;难忘2016&quot;&gt;难忘2016&lt;/h2&gt;
&lt;p&gt;　　今年对我来说，改变了很多。&lt;/p&gt;

&lt;p&gt;　　首先要感谢自己，感谢自己通过努力转到计算机，感谢一开始作为外院的我通过所有工作室的笔试面试，感谢自己做了两个考核并进入topview工作室，感谢自己暑假在工作室努力拼搏，感谢自己可以通过努力拿到二等奖金，感谢自己可以找好自己的方向–(大数据挖掘，人工智能），虽然很苦逼，但是很开心。感谢自己可以经常思考，感谢自己可以坚持读书，坚持每天的跑步或者打球并在院运会拿到1500米的金牌。感谢自己没有让那些爱我的人和我爱的人失望太多！&lt;/p&gt;
&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/life/say2016_1.jpg&quot; alt=&quot;header1&quot; /&gt;
坚持奔跑着，向远方进发
&lt;/div&gt;

&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/life/say2016_5.jpg&quot; alt=&quot;header1&quot; /&gt;
还记得那次轰趴吗？和你们的开始
&lt;/div&gt;

&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/life/say2016_6.jpg&quot; alt=&quot;header1&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;　　但是也有很多的不足，不足在没有努力的奋斗，不足在成为手机党，宁愿对着手机发呆，也不愿放下手机，更多思考！不足在英语没有好好的学，导致6级考试很多不会。不足在大一的时候班长没有做的很好，没有做好社团的干事，辩论队队员，甚至很少时间和他们一起。不足的是大二没有很好的规划时间，没有参加很多有意义的活动！&lt;/p&gt;
&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/life/say2016_3.jpg&quot; alt=&quot;header1&quot; /&gt;
 &lt;/div&gt;
&lt;p&gt;　　2016，来到新的班，新的环境，遇到了很多好人，感谢你们，我又很不喜欢孤独，有你们在身边，真好！2016，我从虐别人到被别人虐，算了不说这个了。。，以后的路，我会走好的，会开心的，会幸福的！
再见2016，你好2017，新的一年，希望有更多难忘的事！&lt;/p&gt;

&lt;p&gt;　　关于AI，2016，我选择了智能化这个方向，有工作室的项目，有自己的拼搏，我相信，一步一步来，那些一开始就什么深度学习的都是在耍流氓！嗯，我会变的很强的。&lt;/p&gt;

&lt;p&gt;　　2016的最后，引用习大大的几句话：１.天上不会掉馅饼，努力奋斗才能使梦想成真　２.大家撸起袖子加油干，我们就一定走好这一代人的长征路&lt;/p&gt;

&lt;h2 id=&quot;2017&quot;&gt;2017&lt;/h2&gt;

&lt;p&gt;　　你好，我们开始吧！&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201701011&quot; data-title=&quot;say2016&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Mon, 21 Nov 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//life/2016/11/21/2016%E6%80%BB%E7%BB%93.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//life/2016/11/21/2016%E6%80%BB%E7%BB%93.html</guid>
        
        <category>Life</category>
        
        
        <category>Life</category>
        
      </item>
    
      <item>
        <title>NOSQL基础</title>
        <description>&lt;p&gt;#NOSQL基础&lt;/p&gt;

&lt;p&gt;今天开始，我会将我NOSQL数据库学习的学习笔记和学习感悟写成一篇篇的文章。我会尽量的把它做的详细。来吧，一起奔向非关系型数据存储的海洋！&lt;/p&gt;

&lt;h2 id=&quot;基础概念&quot;&gt;基础概念&lt;/h2&gt;

&lt;p&gt;NoSql，全称是 Not Only Sql,指的是非关系型的数据库。下一代数据库主要解决几个要点：非关系型的、分布式的、开源的、水平可扩展的.&lt;/p&gt;

&lt;h3 id=&quot;现在开发的特点3v和3高&quot;&gt;现在开发的特点：3V和3高&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;3V:海量Volume;多样Variety;实时Velocity&lt;/li&gt;
  &lt;li&gt;3高:高并发;高可扩;高性能&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;nosql的数据模型&quot;&gt;NOSQL的数据模型&lt;/h2&gt;

&lt;h3 id=&quot;聚合模型&quot;&gt;聚合模型&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;KV键值（redis主要存储方式）&lt;/li&gt;
  &lt;li&gt;bson：类型与json储存（mongodb的储存方式）&lt;/li&gt;
  &lt;li&gt;列族：顾名思义，是按列存储数据的。最大的特点是方便存储结构化和半结构化数据，方便做数据压缩，对针对某一列或者某几列的查询有非常大的IO优势。&lt;/li&gt;
  &lt;li&gt;图形&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;nosql的分类&quot;&gt;NOSQL的分类&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;KV键值：redis&lt;/li&gt;
  &lt;li&gt;文档型数据库(bson格式比较多)：典型介绍：MongoDB
    &lt;blockquote&gt;
      &lt;p&gt;MongoDB 是一个基于分布式文件存储的数据库。由 C++ 语言编写。旨在为 WEB 应用提供可扩展的高性能数据存储解决方案。
MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。（期待一起学习）&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;列存储数据库:HBase;分布式文件系统&lt;/li&gt;
  &lt;li&gt;图关系数据库&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;cap原理&quot;&gt;CAP原理：&lt;/h2&gt;

&lt;h3 id=&quot;传统的acid&quot;&gt;传统的ACID&lt;/h3&gt;
&lt;p&gt;ACID，是指在关系型传统数据库管理系统（DBMS）中事务所具有的四个特性：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A (Atomicity) 原子性：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。&lt;/li&gt;
  &lt;li&gt;C (Consistency) 一致性：在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。&lt;/li&gt;
  &lt;li&gt;I (Isolation) 独立性：两个事务的执行是互不干扰的，一个事务不可能看到其他事务运行时，中间某一时刻的数据。&lt;/li&gt;
  &lt;li&gt;D (Durability) 持久性：在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;cap原则&quot;&gt;CAP原则&lt;/h3&gt;

&lt;p&gt;在非关系型数据库中，并不存在事务的acid，甚至，有些数据库是对事务弱支持的（像redis），但&lt;strong&gt;分布式数据库中(包括传统)&lt;/strong&gt;中有CAP原则。CAP原则又称CAP定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;C:Consistency（强一致性）：分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A:Availability（可用性）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（简单理解就是那些数据保持可以比用户使用。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;P:Partition tolerance（分区容错性）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。&lt;/p&gt;
    &lt;blockquote&gt;
      &lt;p&gt;CAP理论就是说在&lt;strong&gt;分布式存储系统&lt;/strong&gt;中，最多只能实现上面的两点。而由于当前的网络硬件肯定会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的。所以我们只能在一致性和可用性之间进行权衡，没有NoSQL系统能同时保证这三点。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;CAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，
最多只能同时较好的满足两个。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;因此，根据 CAP 原理将 NoSQL 数据库分成了满足 CA 原则、满足 CP 原则和满足 AP 原则三 大类：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;CA - 单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大。&lt;/li&gt;
  &lt;li&gt;CP - 满足一致性，分区容忍必的系统，通常性能不是特别高。&lt;/li&gt;
  &lt;li&gt;AP - 满足可用性，分区容忍性的系统，通常可能对一致性要求低一些。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;当然，在有些博文中，他们多于分布式数据库中有自己的观点，这些观点也不无道理，如&lt;a href=&quot;http://blog.sina.com.cn/s/blog_7ca579910101irjw.html&quot;&gt;NOSQL都是实现A，而少满足C&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;cap的3进2&quot;&gt;CAP的3进2&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;CAP理论就是说在&lt;strong&gt;分布式存储系统&lt;/strong&gt;中，最多只能实现上面的两点。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;C:强一致性 A：高可用性 P：分布式容忍性&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;CA 传统Oracle数据库&lt;/li&gt;
  &lt;li&gt;AP 大多数网站架构的选择&lt;/li&gt;
  &lt;li&gt;CP Redis、Mongodb&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;一致性和可用性之间取一个平衡。多余大多数web应用，其实并不需要强一致性。因此牺牲C换取P，这是目前分布式数据库产品的方向&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;一致性与可用性的决择&quot;&gt;一致性与可用性的决择&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;对于web2.0网站来说，&lt;strong&gt;关系数据库&lt;/strong&gt;的很多主要特性却往往无用武之地&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;数据库事务一致性需求
　　很多web实时系统并不要求严格的数据库事务，对读一致性的要求很低， 有些场合对写一致性要求并不高。允许实现最终一致性。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;数据库的写实时性和读实时性需求
　　对关系数据库来说，插入一条数据之后立刻查询，是肯定可以读出来这条数据的，但是对于很多web应用来说，并不要求这么高的实时性，比方说发一条消息之 后，过几秒乃至十几秒之后，我的订阅者才看到这条动态是完全可以接受的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对复杂的SQL查询，特别是多表关联查询的需求 
　　任何大数据量的web系统，都非常忌讳多个大表的关联查询，以及复杂的数据分析类型的报表查询，特别是SNS类型的网站，从需求以及产品设计角 度，就避免了这种情况的产生。往往更多的只是单表的主键查询，以及单表的简单条件分页查询，SQL的功能被极大的弱化了。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;base&quot;&gt;base&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;定义：BASE就是为了解决关系数据库强一致性引起的问题而引起的可用性降低而提出的解决方案。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;BASE其实是下面三个术语的缩写：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;基本可用（Basically Available）&lt;/li&gt;
  &lt;li&gt;软状态（Soft state）&lt;/li&gt;
  &lt;li&gt;最终一致（Eventually consistent）&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;它的思想是通过让系统放松对某一时刻数据一致性的要求来换取系统整体伸缩性和性能上改观。为什么这么说呢，缘由就在于大型系统往往由于地域分布和极高性能的要求，不可能采用分布式事务来完成这些指标，要想获得这些指标，我们必须采用另外一种方式来完成，这里BASE就是解决这个问题的办法&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;分布式系统集群&quot;&gt;分布式系统，集群&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;分布式：不同的多台服务器上面部署不同的服务模块（工程），他们之间通过Rpc/Rmi之间通信和调用，对外提供服务和组内协作。&lt;/li&gt;
  &lt;li&gt;集群：不同的多台服务器上面部署相同的服务模块，通过分布式调度软件进行统一的调度，对外提供服务和访问。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201611211&quot; data-title=&quot;NOSQL-base&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Mon, 21 Nov 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//database/2016/11/21/NOSQL%E5%9F%BA%E7%A1%80.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//database/2016/11/21/NOSQL%E5%9F%BA%E7%A1%80.html</guid>
        
        <category>nosql</category>
        
        <category>database</category>
        
        
        <category>database</category>
        
      </item>
    
      <item>
        <title>读《目送》</title>
        <description>&lt;h1 id=&quot;读目送&quot;&gt;读《目送》&lt;/h1&gt;

&lt;p&gt;看过许多的散文书，比较喜欢是还是余秋雨的《文化苦旅》和这本《目送》，也许那许多深深的含义我并不清楚，但，文字已经足够吸引我了。目送是龙应台先生的代表作，很多篇写的真的很好，比较平凡的感悟，却又是那么的亲近。当然，她的其他书，比如《孩子，你慢慢来》也是很不错的，可以一读。下面写下我比较喜欢的几篇，当然，正在温故，还会补充。随便提一下：龙应台是女作家！&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Reading/lookback2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;目送&quot;&gt;目送&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;经典的一篇&lt;/strong&gt;
我慢慢地、慢慢地了解到，所谓父女母子一场，只不过意味着，你和他的缘分就是今生今世不断地在目送他的背影渐行渐远。你站在小路的这一端，看着他逐渐消失在小路转弯的地方，而且，他用背影默默告诉你：不必追。&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Reading/lookback1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;年轻的我，正想要四方闯荡，在与家人离别的时候，感触总是缺少那么一点。只是每次与家人离别都能感受到他们的不舍，和在外时他们那种想念。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;不相信&quot;&gt;（不）相信&lt;/h2&gt;
&lt;p&gt;　　曾经相信过爱情，后来知道，原来爱情必须转化为亲情才可能持久，但是转化为亲情的爱情，犹如化入杯水中的冰块──它还是冰块吗？&lt;br /&gt;
　　这篇是我很喜欢的一篇，整篇都是经典，除了谈论爱国的，整篇都能产生共鸣，对于正义，理想主义，对于海枯石烂，对于文明，现实不就是想书中说的那那样吗？我们每个人，在某个阶段，之前的天真，真的会慢慢消散！比如我：在上大学之前和之后很多想法都不一样了，以前不相信或完全感受不到读书能干嘛？但上了大学才深深的感受到它真的能改变人的命运！以前不相信有些东西失去了就再也回不来的心疼，现在只想拼命的抓住那些在乎的东西。&lt;/p&gt;

&lt;h2 id=&quot;什么&quot;&gt;什么&lt;/h2&gt;
&lt;p&gt;这种愚钝，会跟着你一生一世。在人生的某些方面，你永远是那最后“知道”的人。譬如，年过五十，苍茫独行间，忽然惊觉，咦，怎么这么多的朋友在读佛经？他们在找什么我不知道的东西？&lt;/p&gt;

&lt;p&gt;凡事都有定期、天下万物都有定时&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;很喜欢的一篇，但我觉得，很多事，就算你最晚才知道，也许，也是一种幸福。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;如果&quot;&gt;如果&lt;/h2&gt;

&lt;p&gt;他曾经是个眼睛如小鹿、被母亲疼爱的少年，心里怀着莺飞草长的轻快欢欣，期盼自己长大，幻想人生大开大合的种种方式。唯一他没想到的方式，却来临了，战争像突来的飓风把他连根拔起，然后恶意弃置于陌生的荒地。在那里，他成为时代的孤儿，堕入社会底层，从此一生流离，半生坎坷。当他垂垂老时，他可以回乡了，山河仍在，春天依旧，只有父母的坟，在太深的草里，老年僵硬的膝盖，无法跪拜。乡里，已无故人。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;很多人喜欢的一篇，然而我并不是很懂那些被迫赶去台湾的老（军）人，想起《亮剑》，当楚云飞临离开大陆飞向台湾的时候，他抓取了地上的一堆泥土，感叹道：这次离开，不知道什么时候才能回来了。。。这也许是对故土的一种怀念。只可惜，很想出国的我不是太懂那种浓烈的感情，也许，以后就会懂了吧！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;胭脂&quot;&gt;胭脂&lt;/h2&gt;
&lt;p&gt;她曾经是个多么耽溺于美的女人啊。六十五岁的时候，突然去纹了眉和眼线，七十岁的时候，还问我她该不该去隆鼻。多少次，她和我一起站在梳妆镜前，她说：“女儿，你要化妆。女人，就是要漂亮。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;很赞同那种爱美的心态，几乎每个人都是外貌主义，虽然人的样貌参差不齐，但每个人都应该好好打理自己的外在，那是一种形象，不要求要有多麽的惊艳，但最起码要做到整洁！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;寒色&quot;&gt;寒色&lt;/h2&gt;

&lt;p&gt;家，一不小心就变成一个没有温暖、只有压迫的地方。外面的世界固然荒凉，但是家却可以更寒冷。一个人固然寂寞，两个人孤灯下无言相对却可以更寂寞。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;还是那句：吾心安处是吾乡&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;幸福&quot;&gt;幸福&lt;/h2&gt;
&lt;p&gt;幸福就是，生活中不必时时恐惧。&lt;br /&gt;
幸福就是，寻常的日子依旧。&lt;br /&gt;
安全感+认同感+真实感=幸福&lt;br /&gt;
多简单，多复杂，多容易，多艰难。&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;阐述了幸福，虽然写的很平常，但很真实。在幸福的时候，尽情的享受吧，在不幸福的时候，想想身边的拥有，自己还是很富足的。另外，很多时候，一种最直接的方法是对比。不要为没有鞋而感到不幸福，因为，这是世界还有好多根本没有脚的人。以此类推（真是理科生的思维），又会有什么让你真正不幸福的呢？很少吧！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;冬一九一八&quot;&gt;冬，一九一八&lt;/h2&gt;

&lt;p&gt;人生本来就是旅程。夫妻、父子、父女一场，情再深，义再厚，也是电光石火，青草叶上一点霹水，只是，在我们心中，有万分不舍：那撑伞的人啊，自已是离乱时代的孤儿，委屈了自己，成全了别人。儿女的感恩、妻子的思念，他已惘然。我们只好相信：蜡烛烧完了，烛光，在我们心里，陪着我们，继续旅程。在一条我们看不见、但是与我们的旅途平行的路上，爸爸，请慢慢走。白日依山尽，黄河人海流。欲穷千里目，更上一层楼。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在分离的时候，在白首之时，总是各种感叹。如果人生是旅程，那么，请多留恋途中的美景，和在旅途上一起的那些人。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201611202&quot; data-title=&quot;lookback&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Sun, 20 Nov 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//reading/2016/11/20/%E8%AF%BB%E7%9B%AE%E9%80%81.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//reading/2016/11/20/%E8%AF%BB%E7%9B%AE%E9%80%81.html</guid>
        
        <category>Reading</category>
        
        <category>Life</category>
        
        
        <category>Reading</category>
        
      </item>
    
      <item>
        <title>哥伦比亚的倒影</title>
        <description>&lt;h1 id=&quot;哥伦比亚的倒影&quot;&gt;哥伦比亚的倒影&lt;/h1&gt;

&lt;p&gt;在这个星期看的书比较杂，看了木心哥伦比亚的倒影，在书的开始还是很不错的。有很多的感慨都能共鸣，感觉作者就在眼前，一起交谈。但随着看的页数的增长，我的热情却在下降。特别是后面的上海赋，在我看来，有点无聊了。后面的就没有怎么看了，下面是我认为比较经典的几篇，推荐阅读！&lt;/p&gt;

&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Reading/lounmbil1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;童年随之而去&quot;&gt;童年随之而去&lt;/h2&gt;

&lt;p&gt;孩子的知识圈，应是该懂的懂，不该懂的不懂，这就形成了童年的幸福。我的儿时，那是该懂的不懂，不该懂的却懂了些，这就弄出许多至今也未必能解脱的困惑来。&lt;/p&gt;

&lt;p&gt;“有人会捞得的，就是沉了，将来有人会捞起来的。只要不碎就好——吃吧，不要想了，吃完了进舱来喝热茶……这种事以后多着呢。”
最后一句很轻很轻，什么意思？
现在回想起来，真是可怕的预言，我的一生中，确实多的是这种事，比越窑的盌，珍贵百倍千倍万倍的物和人，都已一一脱手而去，有的甚至是碎了的。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;感：说的很对，孩童的世界，很天真，很无知，很无谓，很单纯。。。有时候觉得，越长大，懂得越多，却越胆小！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;导管人生&quot;&gt;导管人生&lt;/h2&gt;
&lt;p&gt;常以为人是一个容器，盛着快乐，盛着悲哀，但人不是容器，人是导管，快乐流过，悲哀流过，导管只是导管。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;感：快乐和悲伤，都会慢慢流过，人的一生，好长有好短！多一天平凡的活着，去感受世界的美好，那样我们就可以多赚一天了！恩，快去感受这个世界吧，旅游吧，流浪吧，尝试去经历各种新的事务吧！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;##竹秀&lt;/p&gt;

&lt;p&gt;人害怕寂寞，害怕到无耻的程度。换言之，人的某些无耻行径是由于害怕寂寞而做出来的。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;想起毛姆《月亮与六便士》的一句话：恐惧使人们变得残酷无情。谈到寂寞，想起林丹的出轨事件。。。可以看看&lt;a href=&quot;http://open.163.com/movie/2015/9/R/H/MB0RRVMUG_MB0RSGCRH.html&quot;&gt;TED重新认识出轨&lt;/a&gt;。真是寂寞产生无耻。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;论美貌&quot;&gt;论美貌&lt;/h2&gt;

&lt;p&gt;唯有极度高超的智慧，才足以取代美貌。美貌是给蠢人和懒人的，所以天才往往秃顶，嗓子也不太好&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;既然丑，那还不好好读书，其实给我的感觉是：上帝是公平的，大多数没有拥有美貌的拥有温柔，善良，贤惠。而大多数拥有美貌的却总会缺少那些优点。当然，肯定有例外，只是遇到的太少了吧（哭。。）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201611201&quot; data-title=&quot;cloumb&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Sun, 20 Nov 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//reading/2016/11/20/%E5%93%A5%E4%BC%A6%E6%AF%94%E4%BA%9A%E7%9A%84%E5%80%92%E5%BD%B1.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//reading/2016/11/20/%E5%93%A5%E4%BC%A6%E6%AF%94%E4%BA%9A%E7%9A%84%E5%80%92%E5%BD%B1.html</guid>
        
        <category>Reading</category>
        
        <category>Life</category>
        
        
        <category>Reading</category>
        
      </item>
    
      <item>
        <title>深入浅出mybatis（三）：拦截器，动态sql，缓存</title>
        <description>&lt;h1 id=&quot;深入浅出mybatis三拦截器和动态sql&quot;&gt;深入浅出mybatis（三）：拦截器和动态sql&lt;/h1&gt;

&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#深入浅出mybatis三拦截器和动态sql&quot; id=&quot;markdown-toc-深入浅出mybatis三拦截器和动态sql&quot;&gt;深入浅出mybatis（三）：拦截器和动态sql&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mybatis拦截器&quot; id=&quot;markdown-toc-mybatis拦截器&quot;&gt;mybatis拦截器&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#动态sql&quot; id=&quot;markdown-toc-动态sql&quot;&gt;动态sql&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#批量删除&quot; id=&quot;markdown-toc-批量删除&quot;&gt;批量删除：&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#批量增加&quot; id=&quot;markdown-toc-批量增加&quot;&gt;批量增加：&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#批量更新&quot; id=&quot;markdown-toc-批量更新&quot;&gt;批量更新&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#缓存&quot; id=&quot;markdown-toc-缓存&quot;&gt;缓存&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mybatis拦截器&quot;&gt;mybatis拦截器&lt;/h2&gt;

&lt;p&gt;###mybatis的拦截器实现分页（动态代理）
拦截sql语句来实现分页:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;拦截什么样的对象（以page作为参数传入；page对象）&lt;/li&gt;
  &lt;li&gt;拦截对象什么行为&lt;/li&gt;
  &lt;li&gt;什么时候拦截 （在prepareStatement的时候拦截）
（源码）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;###具体过程&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;RoutingStatementHandler&lt;/li&gt;
  &lt;li&gt;通过RoutingStatementHandler对象的属性delegate找到statement实现类BaseStatementHandler&lt;/li&gt;
  &lt;li&gt;通过BaseStatementHandler类的反射得到对象的MappedStatement对象&lt;/li&gt;
  &lt;li&gt;通过MappedStatement的属性getID得到配置文件sql语句的ID&lt;/li&gt;
  &lt;li&gt;通过BaseStatementHandler属性的到原始sql语句&lt;/li&gt;
  &lt;li&gt;拼接分页sql&lt;/li&gt;
  &lt;li&gt;需要查询总数的sql&lt;/li&gt;
  &lt;li&gt;通过拦截Connection对象得到PrepareStatement对象&lt;/li&gt;
  &lt;li&gt;得到对应的参数&lt;/li&gt;
  &lt;li&gt;把参数设到prepareStatement对象里的？（该？号在配置文件以#{}形式存在，mybatis会把它转为？号）&lt;/li&gt;
  &lt;li&gt;执行改sql语句&lt;/li&gt;
  &lt;li&gt;得到总数&lt;/li&gt;
  &lt;li&gt;把属性值为新的sql&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;动态sql&quot;&gt;动态sql&lt;/h2&gt;

&lt;h3 id=&quot;批量删除&quot;&gt;批量删除：&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;delete from
		study_material
		where
		subject_id=#{subject.id} and web_id=#{webTitle.id}
		and id in(
  		&amp;lt;foreach collection=&quot;idlist&quot; item=&quot;item&quot; separator=&quot;,&quot;&amp;gt;
  			#{item}
  		&amp;lt;/foreach&amp;gt;
  	)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;批量增加&quot;&gt;批量增加：&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;insert into
		study_material(id,web_id,M_name,M_resource_url,M_upload_date,subject_id) values
		&amp;lt;foreach collection=&quot;list&quot; item=&quot;item&quot; separator=&quot;,&quot;&amp;gt;
			(#{item.id},#{item.webTitle.id},#{item.name},#{item.resourceUrl},#{item.uploadDate},#{item.subject.id})
		&amp;lt;/foreach&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;批量更新&quot;&gt;批量更新&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;foreach collection=&quot;list&quot; item=&quot;item&quot; index=&quot;index&quot; open=&quot;&quot; close=&quot;&quot; separator=&quot;;&quot;&amp;gt;
				update test 
				&amp;lt;set&amp;gt;
				  test=${item.test}+1
				&amp;lt;/set&amp;gt;
				where id = ${item.id}
		 &amp;lt;/foreach&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;item:循环体中的具体对象。支持属性的点路径访问，如item.age,item.info.details。
具体说明：在list和数组中是其中的对象，在map中是value。
该参数为必选。&lt;/li&gt;
  &lt;li&gt;collection:要做foreach的对象，作为入参时，List&amp;lt;?&amp;gt;对象默认用list代替作为键，数组对象有array代替作为键，Map对象没有默认的键。当然在作为入参时可以使用@Param(“keyName”)来设置键，设置keyName后，list,array将会失效。 除了入参这种情况外，还有一种作为参数对象的某个字段的时候。举个例子：
    &lt;blockquote&gt;
      &lt;p&gt;如果User有属性List ids。入参是User对象，那么这个collection = “ids”
如果User有属性Ids ids;其中Ids是个对象，Ids有个属性List id;入参是User对象，那么collection = “ids.id”
上面只是举例，具体collection等于什么，就看你想对那个元素做循环。
该参数为必选。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;separator:元素之间的分隔符，例如在in()的时候，separator=”,”会自动在元素中间用“,“隔开，避免手动输入逗号导致sql错误，如in(1,2,)这样。该参数可选。&lt;/li&gt;
  &lt;li&gt;open:foreach代码的开始符号，一般是(和close=”)”合用。常用在in(),values()时。该参数可选。&lt;/li&gt;
  &lt;li&gt;close:foreach代码的关闭符号，一般是)和open=”(“合用。常用在in(),values()时。该参数可选。&lt;/li&gt;
  &lt;li&gt;index:在list和数组中,index是元素的序号，在map中，index是元素的key，该参数可选。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;缓存&quot;&gt;缓存&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/luanlouis/article/details/41280959&quot;&gt;mybatis缓存&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 13 Nov 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//java/2016/11/13/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmybatis%E4%B8%89.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//java/2016/11/13/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmybatis%E4%B8%89.html</guid>
        
        <category>java</category>
        
        <category>web</category>
        
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>深入浅出mybatis（二）操作数据库</title>
        <description>&lt;h1 id=&quot;深入浅出mybatis二操作数据库&quot;&gt;深入浅出mybatis（二）操作数据库&lt;/h1&gt;

&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#深入浅出mybatis二操作数据库&quot; id=&quot;markdown-toc-深入浅出mybatis二操作数据库&quot;&gt;深入浅出mybatis（二）操作数据库&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mybatis与jdbc&quot; id=&quot;markdown-toc-mybatis与jdbc&quot;&gt;mybatis与JDBC&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mybatis之sqlsession&quot; id=&quot;markdown-toc-mybatis之sqlsession&quot;&gt;Mybatis之SqlSession&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#过程的讲解&quot; id=&quot;markdown-toc-过程的讲解&quot;&gt;过程的讲解&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#跟踪mybatis操作数据库&quot; id=&quot;markdown-toc-跟踪mybatis操作数据库&quot;&gt;跟踪mybatis操作数据库&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mybatis之sqlsession-template&quot; id=&quot;markdown-toc-mybatis之sqlsession-template&quot;&gt;Mybatis之SqlSession template&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mybatis接口式编程&quot; id=&quot;markdown-toc-mybatis接口式编程&quot;&gt;mybatis接口式编程&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#首先先看下接口式编程的要求&quot; id=&quot;markdown-toc-首先先看下接口式编程的要求&quot;&gt;首先先看下接口式编程的要求&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#接口式编程原理&quot; id=&quot;markdown-toc-接口式编程原理&quot;&gt;接口式编程原理&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mybatis与jdbc&quot;&gt;mybatis与JDBC&lt;/h2&gt;
&lt;p&gt;我们知道mybatis可以看成是对jdbc的一种封装。二为什么要封装和封装什么呢？如下&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;使用数据库连接池对连接进行管理&lt;/li&gt;
  &lt;li&gt;SQL语句统一存放到配置文件&lt;/li&gt;
  &lt;li&gt;SQL语句变量和传入参数的映射以及动态SQL&lt;/li&gt;
  &lt;li&gt;动态SQL语句的处理&lt;/li&gt;
  &lt;li&gt;对数据库操作结果的映射和结果缓存&lt;/li&gt;
  &lt;li&gt;SQL语句的重复&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;在之后我们会一一来聊聊这些封装的具体细节！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;mybatis之sqlsession&quot;&gt;Mybatis之SqlSession&lt;/h2&gt;
&lt;p&gt;谈到mybatis，一开始我们接触的应该就是SqlSession吧。当然，现在我们项目用的比较多的是SqlSessionTemplate（对SqlSession等做了封装）。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先：SqlSession的作用：&lt;br /&gt;
    &lt;ol&gt;
      &lt;li&gt;向SQL语句传入参数&lt;/li&gt;
      &lt;li&gt;执行SQL语句&lt;/li&gt;
      &lt;li&gt;获取执行SQL语句的结果&lt;/li&gt;
      &lt;li&gt;事物的控制&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;如何得到SqlSession：&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;分三步：
    1. 通过配置文件获取数据库连接相关信息:&lt;br /&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Reader reader = Resources.getResourceAsReader(&quot;com/yezhihao/www/config/Configuration.xml&quot;)&lt;/code&gt;;&lt;br /&gt;
    2. 通过配置信息构建SqlSessionFactory&lt;br /&gt;
    &lt;code class=&quot;highlighter-rouge&quot;&gt;SqlSessionFactory sqlSessionFactory = new SqlSessioFactoryBuilder.build(reader)&lt;/code&gt;&lt;br /&gt;
    3. 通过SqlSessionFactory打开数据库会话&lt;br /&gt;
    &lt;code class=&quot;highlighter-rouge&quot;&gt;SqlSession sqlSession = sqlSeesionFactory.openSession()&lt;/code&gt;&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在很多mybatis的初级教程中，上面的都是mybatis入门级代码，但对于我们来说，不能单单限于入门级。所以下面说下其原理。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;过程的讲解&quot;&gt;过程的讲解&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Reader reader = Resources.getResourceAsReader(&quot;com/yezhihao/www/config/Configuration.xml&quot;)&lt;/code&gt;这句话中就是配置文件的读入，任何框架的初始化，无非是加载自己运行时所需要的配置信息，源码没有聊的。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SqlSessionFactory sqlSessionFactory = new SqlSessioFactoryBuilder.build(reader)&lt;/code&gt;这句话中，建立了sqlSessionFactory，首先这是一种Builder模式应用，会根据情况提供不同的参数，创建不同的sqlSessionFactory。由于构造时参数不定，可以为其创建一个构造器Builder，将SqlSessionFactory的构建过程和表示分开。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;关于Builder模式，推荐大家看《设计模式之禅》&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SqlSession sqlSession = sqlSeesionFactory.openSession()&lt;/code&gt;在这里，我们就跟下源码，看看mybatis是操作数据库是一个怎么样的过程。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;跟踪mybatis操作数据库&quot;&gt;跟踪mybatis操作数据库&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;首先&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; @Override
public SqlSession openSession() {
return openSessionFromDataSource(configuration.getDefaultExecutorType(), null, false);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;我们看到是调用openSessionFromDataSource（）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;然后，我们来看看openSessionFromDataSource（）&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) {
    Transaction tx = null;
    try {
      final Environment environment = configuration.getEnvironment();
      final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);
      tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);
      final Executor executor = configuration.newExecutor(tx, execType);
      return new DefaultSqlSession(configuration, executor, autoCommit);
    } catch (Exception e) {
      closeTransaction(tx); // may have fetched a connection so lets call close()
      throw ExceptionFactory.wrapException(&quot;Error opening session.  Cause: &quot; + e, e);
    } finally {
      ErrorContext.instance().reset();
    }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;（1）获取前面我们加载配置文件的环境信息，并且获取环境信息中配置的数据源。
（2）通过数据源获取一个连接，对连接进行包装代理（通过JDK的代理来实现日志功能）。
（3）设置连接的事务信息（是否自动提交、事务级别），从配置环境中获取事务工厂，事务工厂获取一个新的事务。
（4）传入事务对象获取一个新的执行器，并传入执行器、配置信息等获取一个执行会话对象。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;说白了就是加载对应数据源，创建执行器。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;我们继续跟踪sqlsession执行sql，以&lt;code class=&quot;highlighter-rouge&quot;&gt;UserInfo user = (UserInfo) session.selectOne(&quot;User.selectUser&quot;, &quot;1&quot;);  &lt;/code&gt; 为例。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;进入源码，我们发现在sqlsession这个接口有三个实现类分别是DefaultSqlSession，SqlSessionManager，SqlSessionTemplate（之后会讲）。这里，我们能看到DefaultSqlSession里面有各种各样的SQL执行方法，主要用于SQL操作的对外接口，它会的调用执行器来执行实际的SQL语句。&lt;/p&gt;

&lt;p&gt;进入源码，我们发现&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; @Override
  public &amp;lt;T&amp;gt; T selectOne(String statement, Object parameter) {
    // Popular vote was to return null on 0 results and throw exception on too many.
    List&amp;lt;T&amp;gt; list = this.&amp;lt;T&amp;gt;selectList(statement, parameter);
    if (list.size() == 1) {
      return list.get(0);
    } else if (list.size() &amp;gt; 1) {
      throw new TooManyResultsException(&quot;Expected one result (or null) to be returned by selectOne(), but found: &quot; + list.size());
    } else {
      return null;
    }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;调用的是本类的selectList（）方法
看看：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; @Override
  public &amp;lt;E&amp;gt; List&amp;lt;E&amp;gt; selectList(String statement, Object parameter, RowBounds rowBounds) {
    try {
      MappedStatement ms = configuration.getMappedStatement(statement);
      return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);
    } catch (Exception e) {
      throw ExceptionFactory.wrapException(&quot;Error querying database.  Cause: &quot; + e, e);
    } finally {
      ErrorContext.instance().reset();
    }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;根据SQL的ID到配置信息中找对应的MappedStatement，在之前配置被加载初始化的时候我们看到了系统会把配置文件中的SQL块解析并放到一个MappedStatement里面，并将MappedStatement对象放到一个Map里面进行存放，Map的key值是该SQL块的ID。
调用执行器的query方法，传入MappedStatement对象、SQL参数对象、范围对象（此处为空）和结果处理方式。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;再然后，我们看看query（）方法的执行
    &lt;blockquote&gt;
      &lt;p&gt;对我来说，mybatis的源码不是一般的复杂（哭。。。）找了好久，&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;首先在BaseExecutor，找到相应query（）方法，&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@SuppressWarnings(&quot;unchecked&quot;)
  @Override
  public &amp;lt;E&amp;gt; List&amp;lt;E&amp;gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
    ErrorContext.instance().resource(ms.getResource()).activity(&quot;executing a query&quot;).object(ms.getId());
    if (closed) {
      throw new ExecutorException(&quot;Executor was closed.&quot;);
    }
    if (queryStack == 0 &amp;amp;&amp;amp; ms.isFlushCacheRequired()) {
      clearLocalCache();
    }
    List&amp;lt;E&amp;gt; list;
    try {
      queryStack++;
      list = resultHandler == null ? (List&amp;lt;E&amp;gt;) localCache.getObject(key) : null;
      if (list != null) {
        handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);
      } else {
        list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);
      }
    } finally {
      queryStack--;
    }
    if (queryStack == 0) {
      for (DeferredLoad deferredLoad : deferredLoads) {
        deferredLoad.load();
      }
      // issue #601
      deferredLoads.clear();
      if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) {
        // issue #482
        clearLocalCache();
      }
    }
    return list;
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;在这里，mybatis先会看看在其缓存中有没有相应的数据，如果有就返回，没有的话，通过调用queryFromDatabase（），很明显，命名上就是从数据库查找。进去看下，发现是通过调用doQuery（）来最终执行sql看下doquery()&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  @Override
  public &amp;lt;E&amp;gt; List&amp;lt;E&amp;gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException {
    Statement stmt = null;
    try {
      Configuration configuration = ms.getConfiguration();
      StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql);
      stmt = prepareStatement(handler, ms.getStatementLog());
      return handler.&amp;lt;E&amp;gt;query(stmt, resultHandler);
    } finally {
      closeStatement(stmt);
    }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最后，在PreparedStatementHandler（）中找到了query&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; @Override
  public &amp;lt;E&amp;gt; List&amp;lt;E&amp;gt; query(Statement statement, ResultHandler resultHandler) throws SQLException {
    PreparedStatement ps = (PreparedStatement) statement;
    ps.execute();
    return resultSetHandler.&amp;lt;E&amp;gt; handleResultSets(ps);
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;终于，我们发现了在jdbc中熟悉的代码,在这里，执行了直接操作数据库的语句。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在跟源码的时候发现，mybatis真的封装的很好，看看能不能出个mybatis的整体架构的博文，努力。&lt;/p&gt;

&lt;h2 id=&quot;mybatis之sqlsession-template&quot;&gt;Mybatis之SqlSession template&lt;/h2&gt;
&lt;p&gt;　　SqlSessionTemplate是MyBatis-Spring的核心。这个类负责管理MyBatis的SqlSession,调用MyBatis的SQL方法。SqlSessionTemplate是线程安全的，可以被多个DAO所共享使用。
　　我们在结合spring的时候，我们会发现SqlSessionTemplate是单例的。通过源码我们何以看到 SqlSessionTemplate 实现了SqlSession接口，也就是说我们可以使用SqlSessionTemplate 来代理以往的DefailtSqlSession完成对数据库的操作，但是DefailtSqlSession这个类不是线程安全的，所以这个类不可以被设置成单例模式的。在我们就疑惑了，怎么判断一个类是否为线程安全的。可以移到我的博客&lt;a href=&quot;&quot;&gt;线程安全基础&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;mybatis接口式编程&quot;&gt;mybatis接口式编程&lt;/h2&gt;

&lt;h3 id=&quot;首先先看下接口式编程的要求&quot;&gt;首先先看下接口式编程的要求&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;类的映射：使用接口类的全限定名(包括包名)作为配置文件的namespace，完成类与配置文件的对应关系。&lt;/li&gt;
  &lt;li&gt;方法名：接口方法名与配置文件中将要执行的sql语句的id一样，这样就完成了方法调用的映射。&lt;/li&gt;
  &lt;li&gt;参数类型：接口方法的输入参数类型和配置文件中sql的parameterType的类型相同&lt;/li&gt;
  &lt;li&gt;返回值类型：接口方法的返回值类型和配置文件的resultMap的类型相同&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这样就可以对操作数据库了，是不是很神奇呢？我想你一定会想知道它是怎么实现的吧!不急，在下面我们就好好说说它的原理。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;接口式编程的要求和规范说完之后，我们就来说下它的原理吧。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;接口式编程原理&quot;&gt;接口式编程原理&lt;/h3&gt;
&lt;p&gt;下面，我们就以下面的代码（没有spring结合）作为入口，讲下源码。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;User user = sqlSession.getMapper(User.class);
userList = user.queryUserList();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ol&gt;
  &lt;li&gt;首先是getMapper（）方法，经过系列的中间类，我们终于在MapperRegistry类中找到真正的getMapper的类。代码如下：&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@SuppressWarnings(&quot;unchecked&quot;)
  public &amp;lt;T&amp;gt; T getMapper(Class&amp;lt;T&amp;gt; type, SqlSession sqlSession) {
    final MapperProxyFactory&amp;lt;T&amp;gt; mapperProxyFactory = (MapperProxyFactory&amp;lt;T&amp;gt;) knownMappers.get(type);
    if (mapperProxyFactory == null) {
      throw new BindingException(&quot;Type &quot; + type + &quot; is not known to the MapperRegistry.&quot;);
    }
    try {
      return mapperProxyFactory.newInstance(sqlSession);
    } catch (Exception e) {
      throw new BindingException(&quot;Error getting mapper instance. Cause: &quot; + e, e);
    }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;很明显，首先是根据配置和传入接口产生代理工厂，其中mapperProxy是处理类，然后生成一个代理类，然后返回。为什么sqlSession.getMapper(.class)可以根据传入的参数，返回一个对应的类型，因为泛型，mybatis已经为我们完成了强转。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;在mapperProxy处理类中是怎么进行一系列操作的。先看下源码：&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  @Override
  public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
    if (Object.class.equals(method.getDeclaringClass())) {
      try {
        return method.invoke(this, args);
      } catch (Throwable t) {
        throw ExceptionUtil.unwrapThrowable(t);
      }
    }
    final MapperMethod mapperMethod = cachedMapperMethod(method);
    return mapperMethod.execute(sqlSession, args);
  }

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;上面代码中，首先是无法进入if的，因为没有实现类。然后是调用&lt;code class=&quot;highlighter-rouge&quot;&gt; final MapperMethod mapperMethod = cachedMapperMethod(method);&lt;/code&gt;在这里得到queryUserList（）方法的代理并在下一行&lt;code class=&quot;highlighter-rouge&quot;&gt;mapperMethod.execute(sqlSession, args);&lt;/code&gt;被调用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;最后：Mybatis加载文件时，利用namespace加载了一个class,然后把这个class与代码中传入接口的class进行匹配，方法执行所需要的信息就是来自于已经匹配成功的配置文件中，当结果与配置文件对应上后，调用接口的方法执行sql语句。在这里没什么好学，都是一些简单业务，就不一一演示了。自己跟下源码吧。&lt;code class=&quot;highlighter-rouge&quot;&gt;MapperMethod-&amp;gt;SqlCommand-&amp;gt;...&lt;/code&gt;更下去自然会发现。&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201611132&quot; data-title=&quot;mybatis2&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Sun, 13 Nov 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//java/2016/11/13/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmybatis%E4%BA%8C.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//java/2016/11/13/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmybatis%E4%BA%8C.html</guid>
        
        <category>java</category>
        
        <category>web</category>
        
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>深入浅出mybatis（一）整体架构</title>
        <description>&lt;h1 id=&quot;深入浅出mybatis一整体架构&quot;&gt;深入浅出mybatis（一）整体架构&lt;/h1&gt;

&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#深入浅出mybatis一整体架构&quot; id=&quot;markdown-toc-深入浅出mybatis一整体架构&quot;&gt;深入浅出mybatis（一）整体架构&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dao层&quot; id=&quot;markdown-toc-dao层&quot;&gt;dao层&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mybatis的简介&quot; id=&quot;markdown-toc-mybatis的简介&quot;&gt;mybatis的简介&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mybatis的大致原理对jdbc的优化和封装&quot; id=&quot;markdown-toc-mybatis的大致原理对jdbc的优化和封装&quot;&gt;mybatis的大致原理–对JDBC的优化和封装：&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mybatis主要组件&quot; id=&quot;markdown-toc-mybatis主要组件&quot;&gt;Mybatis主要组件&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#mybatis执行过程&quot; id=&quot;markdown-toc-mybatis执行过程&quot;&gt;mybatis执行过程&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;还记得你当初学的第一个框架吗？很有可能就是mybatis吧。好了，那今天开始，我们来聊聊  mybatis的这个框架吧！&lt;strong&gt;注意：这并不能作为入门教程，只能是复习讨论一起。因为我聊的肯定不会那么系统，毕竟现在比较渣（逃）！&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;既然聊mybatis，作为有追求的程序员，那绝对不能止于表面是吧。所以肯定是要聊思想和聊其原理的。下面就一起学习吧。&lt;/p&gt;

&lt;h2 id=&quot;dao层&quot;&gt;dao层&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;mybatis是orm框架，所以在讲mybatis之前，我想先说明到层的作用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;对象能与数据库交互；&lt;/li&gt;
  &lt;li&gt;能执行sql语句。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;mybatis的简介&quot;&gt;mybatis的简介&lt;/h2&gt;
&lt;p&gt;The MyBatis SQL mapper framework makes it easier to use a relational database with object-oriented applications. MyBatis couples objects with stored procedures or SQL statements using a XML descriptor or annotations. Simplicity is the biggest advantage of the MyBatis data mapper over object relational mapping tools.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;上面是官网的一段话，我觉得it程序员学习还是要多去官网的吧，所以英语还是要学好来的额。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;好了，上面大概说mybatis就是一个简单的ORM框架，他让面向对象的应用和关系型数据库之间的操作变的更加简单，他用xml，或注解或储存过程来对应数据库的操作。而简单，就是mybatis的最大优势。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;我们知道，mybatis其实就是对jdbc进行了封装，然后添加了一些自己特有的功能而已。下面，先从整体上看下mybatis的架构设计是怎么样的：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;mybatis的大致原理对jdbc的优化和封装&quot;&gt;mybatis的大致原理–对JDBC的优化和封装：&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;使用数据库连接池对连接进行管理&lt;/li&gt;
  &lt;li&gt;SQL语句统一存放到配置文件&lt;/li&gt;
  &lt;li&gt;SQL语句变量和传入参数的映射以及动态SQL&lt;/li&gt;
  &lt;li&gt;动态SQL语句的处理&lt;/li&gt;
  &lt;li&gt;对数据库操作结果的映射和结果缓存&lt;/li&gt;
  &lt;li&gt;SQL语句的重复&lt;/li&gt;
&lt;/ol&gt;

&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/java/mybatis1.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:100%;max-width:1020px;&quot; /&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Mybatis的三层功能架构
    &lt;ol&gt;
      &lt;li&gt;API接口层：提供给外部使用的接口API，开发人员通过这些本地API来操纵数据库。接口层一接收到调用请求就会调用数据处理层来完成具体的数据处理。&lt;/li&gt;
      &lt;li&gt;数据处理层：负责具体的SQL查找、SQL解析、SQL执行和执行结果映射处理等。它主要的目的是根据调用的请求完成一次数据库操作。&lt;/li&gt;
      &lt;li&gt;基础支撑层：负责最基础的功能支撑，包括连接管理、事务管理、配置加载和缓存处理，这些都是共用的东西，将他们抽取出来作为最基础的组件。为上层的数据处理层提供最基础的支撑。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mybatis主要组件&quot;&gt;Mybatis主要组件&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Configuration MyBatis所有的配置信息都维持在Configuration对象之中&lt;/li&gt;
  &lt;li&gt;SqlSession 作为MyBatis工作的主要顶层API，表示和数据库交互的会话，完成必要数据库增删改查功能&lt;/li&gt;
  &lt;li&gt;Executor MyBatis执行器，是MyBatis 调度的核心，负责SQL语句的生成和查询缓存的维护&lt;/li&gt;
  &lt;li&gt;StatementHandler 封装了JDBC Statement操作，负责对JDBCstatement的操作，如设置参数、将Statement结果集转换成List集合。&lt;/li&gt;
  &lt;li&gt;ParameterHandler 负责对用户传递的参数转换成JDBC Statement 所需要的参数&lt;/li&gt;
  &lt;li&gt;ResultSetHandler *负责将JDBC返回的ResultSet结果集对象转换成List类型的集合；&lt;/li&gt;
  &lt;li&gt;TypeHandler 负责java数据类型和jdbc数据类型之间的映射和转换&lt;/li&gt;
  &lt;li&gt;MappedStatement MappedStatement维护了一条&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;select|update|delete|insert&amp;gt;&lt;/code&gt;节点的封装&lt;/li&gt;
  &lt;li&gt;SqlSource 负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中，并返回&lt;/li&gt;
  &lt;li&gt;BoundSql 表示动态生成的SQL语句以及相应的参数信息&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mybatis执行过程&quot;&gt;mybatis执行过程&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;加载配置：配置来源于两个地方，一处是配置文件，一处是Java代码的注解，将SQL的配置信息加载成为一个个MappedStatement对象（包括了传入参数映射配置、执行的SQL语句、结果映射配置），存储在内存中。&lt;/li&gt;
  &lt;li&gt;SQL解析：当API接口层接收到调用请求时，会接收到传入SQL的ID和传入对象（可以是Map、JavaBean或者基本数据类型），Mybatis会根据SQL的ID找到对应的MappedStatement，然后根据传入参数对象对MappedStatement进行解析，解析后可以得到最终要执行的SQL语句和参数。&lt;/li&gt;
  &lt;li&gt;SQL执行：将最终得到的SQL和参数拿到数据库进行执行，得到操作数据库的结果。&lt;/li&gt;
  &lt;li&gt;结果映射：将操作数据库的结果按照映射的配置进行转换，可以转换成HashMap、JavaBean或者基本数据类型，并将最终结果返回。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;一张图片&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/java/mybatis2.png&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:100%;max-width:1020px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201611133&quot; data-title=&quot;mybatis1&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Sun, 13 Nov 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//java/2016/11/13/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmybatis%E4%B8%80.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//java/2016/11/13/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmybatis%E4%B8%80.html</guid>
        
        <category>java</category>
        
        <category>web</category>
        
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>浮生六记读后感</title>
        <description>&lt;h1 id=&quot;浮生六记读后感&quot;&gt;浮生六记读后感&lt;/h1&gt;

&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#浮生六记读后感&quot; id=&quot;markdown-toc-浮生六记读后感&quot;&gt;浮生六记读后感&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#多么讨人爱的陈芸&quot; id=&quot;markdown-toc-多么讨人爱的陈芸&quot;&gt;多么讨人爱的陈芸&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#那些让人断肠的爱情&quot; id=&quot;markdown-toc-那些让人断肠的爱情&quot;&gt;那些让人断肠的爱情&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#其他记事&quot; id=&quot;markdown-toc-其他记事&quot;&gt;其他记事&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Reading/shenfu-life1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:100%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一开始看这本书的时候，我的内心是拒绝的，因为沈复不仗义啊，一上来就喂我狗粮。。。，单身狗收到一万点伤害。第一章的恩爱秀的可以，也很暖，甚至可以触发我对未来的她的臆想（逃）。看在他们的情感那么真挚的份上，也就笑着看下去了。看完这本书，谈谈收获吧。&lt;/p&gt;

&lt;h2 id=&quot;多么讨人爱的陈芸&quot;&gt;多么讨人爱的陈芸&lt;/h2&gt;

&lt;p&gt;中国现代著名作家林语堂对沈复之妻陈芸的评价甚高，称之为：“中国文学史及中国历史上一个最可爱的女人。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;为什么这样说呢？我结合网上的一些评论，和自己的理解，给出以下的理由：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;对丈夫的好&lt;br /&gt;
　　一次沈复晚上送亲戚到城外，回来的时候已经饥寒交迫，家里没什么可吃的，此时陈芸偷偷地将沈复拉进房中，原来她早已经为其准备好了热粥和小菜。而当沈复着，芸的堂兄忽然敲门欲进，芸急忙谎称：“已疲乏，将卧矣。”结果还是被发现沈复在闺房中大吃，笑道：“刚才我来要粥，你说没了，原来是藏起来专门给你的如意郎君吃呀？”陈芸大囧，双颊若红霞，躲了起来，众人哗笑。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;这一段就描写了陈芸对沈复无微不至的呵护与关心，对丈夫好的不一般&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;当然，对沈复好体现在方方面面了，上面只是一个明显的例子，总之在第一章，随处可见的是他们的秀恩爱。很多时候都让我猝不及防（哭。。。）&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;多才开明&lt;br /&gt;
　　在书中，随处可见的时，沈复和陈芸的对话。古代的时候，男子唯一出路就是学而优则仕。然整天的学习是很痛苦的吧，所以，他们也会在文学中找各种乐趣，比如互相考题，比如对对子之类的。而如果妻子可以和自己读书作乐，那该是多美好的事。历史上也有很多，比如纳兰描写李清照的“赌书消得泼茶香，当时只道是寻常”，比如纳兰和他的妻子卢氏的那种乐趣。当然还有就是沈复和陈芸了。他们可以说是那么的幸福，然而，他们又都是那么的让人心疼。。。&lt;br /&gt;
　　在书中，还记录了复怂恿芸娘女扮男装去水仙庙观看神诞花照的事。 女扮男装，文学史上常写，大多只有顽皮机灵的女孩子才做，代父从军的女英雄花木兰，求学若渴的小女子祝英台，艳绝天下，冰雪聪明的的郭夫人黄蓉等等。从这里，我们就可以看出陈芸的活泼了可爱了。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;为丈夫寻找小妾&lt;br /&gt;
　　乾隆甲寅七月，沈复从广东回来。有一个朋友带着他新纳的小妾同时归来，邀请沈复夫妇前去做客。陈芸对其妾评价道：“美则美矣，韵犹未也。”就是说漂亮是漂亮，但是没有韵味。还私下对沈复道：如果你要纳妾，那么一定要选择一位既美丽又有韵味的女子。&lt;br /&gt;
　　其实我一开始很不能理解，爱不应该是自私的吗?后来想想，在古代，男子纳妾是很平常的，女人地位是很低下的，也许陈芸知道，自己的丈夫也避免不了要纳妾的，那既然要纳妾，那就应该找一个好点的。而且，确实。沈复虽对陈芸疼爱，但总归还是不排斥甚至想纳妾的。这个在后来，陈芸死后，他打破在死前对陈芸所说感叹也有体现。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;那些让人断肠的爱情&quot;&gt;那些让人断肠的爱情&lt;/h2&gt;
&lt;p&gt;　　快乐的时光经历不久，陈芸因血病而亡。在陈芸离世前，建议沈复在她死后续弦，沈复感叹：“卿果中道相舍，断无再续之理，况‘曾经沧海难为水，除却巫山不是云’耳。&lt;br /&gt;
　　不知道为什么，感觉看着古代那些文人各种秀恩爱的诗后，却总是在不久后就看到他们的离别，阴阳两隔。。。难道真的是秀恩爱，死的快吗？&lt;br /&gt;
　　在高中的时候，有段时间很喜欢纳兰的诗，而他和卢氏的爱情，和之后的他为卢氏写的词，真的很感人！一生一代一双人，争教两处销魂；肠断月明红豆蔻，月似当时，人似当时否？；被酒莫惊春睡重, 赌书消得泼茶 香, 当时只道是寻常；等等等等，那些诗词感觉就像把他们的那些爱呈现在我眼前，同时那些悲痛也传到了我的心里。。。真不愧是千古伤心词人。（当然，纳兰还有很多的词都很有意境，大家可以去看下，推荐！！！）&lt;br /&gt;
　　还有李清照和赵明诚的悲惨爱情，在李清照的词中的寻寻觅觅，冷冷清清，凄凄惨惨戚戚。还有苏轼和王弗，那种十年生死两茫茫！不思量，自难忘。千里孤坟，无处话凄凉。总之，他们都是我比较喜欢的诗人词人，所以他们爱情的悲惨，会让我更加的心疼。但，也许，从另一个角度，他们曾经遇到过自己的真爱，他们也是是那么的幸福的。&lt;/p&gt;

&lt;h2 id=&quot;其他记事&quot;&gt;其他记事&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;《闲情记趣》,是一篇带有抒情性的回忆录和记叙性的散文,文章以生动的笔触、细腻的刻画,记述了作者儿时一些“神游其中,怡然自得”的趣事,为我们展示了一幅幅充满童真童心的童趣图,充分表现了少年儿童丰富的想象力和稚气烂漫的情趣.&lt;/li&gt;
  &lt;li&gt;《浪游记快》就是沈复在平时的一些游记吧，其实游记来说，好像对我不是很大的印象，虽然我平时也很喜欢旅游。可能是写的有些平凡了吧，还是比较喜欢余秋雨的《文化苦旅》，记得在高中的时候，看钱钟书爱上了比喻，看余秋雨爱上了排比。&lt;/li&gt;
  &lt;li&gt;其他两篇，由于是缺少翻译，我也没有怎么去看，在这里就不评论了。&lt;/li&gt;
&lt;/ul&gt;

&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Reading/shenfu-life2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:100%;max-width:1020px;&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201611131&quot; data-title=&quot;shengfu-life&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Sun, 13 Nov 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//reading/2016/11/13/%E6%B5%AE%E7%94%9F%E5%85%AD%E8%AE%B0.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//reading/2016/11/13/%E6%B5%AE%E7%94%9F%E5%85%AD%E8%AE%B0.html</guid>
        
        <category>Reading</category>
        
        <category>Life</category>
        
        
        <category>Reading</category>
        
      </item>
    
      <item>
        <title>spring-boot集成shiro</title>
        <description>&lt;h1 id=&quot;spring-boot集成shiro&quot;&gt;spring-boot集成shiro&lt;/h1&gt;

&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#spring-boot集成shiro&quot; id=&quot;markdown-toc-spring-boot集成shiro&quot;&gt;spring-boot集成shiro&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#shiro简单介绍&quot; id=&quot;markdown-toc-shiro简单介绍&quot;&gt;Shiro简单介绍&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#spring-boot的简单介绍&quot; id=&quot;markdown-toc-spring-boot的简单介绍&quot;&gt;spring-boot的简单介绍&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#spring-boot集成shiro-1&quot; id=&quot;markdown-toc-spring-boot集成shiro-1&quot;&gt;spring-boot集成shiro&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#启用注解和配置shiro生命周期&quot; id=&quot;markdown-toc-启用注解和配置shiro生命周期&quot;&gt;启用注解和配置shiro生命周期&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#shirofilterfactory&quot; id=&quot;markdown-toc-shirofilterfactory&quot;&gt;ShiroFilterFactory&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#securitymanager&quot; id=&quot;markdown-toc-securitymanager&quot;&gt;SecurityManager&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#realm&quot; id=&quot;markdown-toc-realm&quot;&gt;Realm&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#其他配置&quot; id=&quot;markdown-toc-其他配置&quot;&gt;其他配置&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#使用shiro&quot; id=&quot;markdown-toc-使用shiro&quot;&gt;使用shiro&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;shiro简单介绍&quot;&gt;Shiro简单介绍&lt;/h2&gt;
&lt;p&gt;Shiro是Apache下的一个开源项目，我们称之为Apache Shiro。它是一个很易用与Java项目的的安全框架，提供了认证、授权、加密、会话管理，与 Spring Security 一样都是做一个权限的安全框架，但是与Spring Security 相比，在于 Shiro 使用了比较简单易懂易于使用的授权方式。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;在这里强烈建议要先去学习shiro，可以到&lt;a href=&quot;http://jinnianshilongnian.iteye.com/blog/2018398&quot;&gt;开涛的博客&lt;/a&gt;学习&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在这里我默认你是学过shiro的，如果不想敲demo的话。我的github上有&lt;a href=&quot;https://github.com/yzhihao/MyJavaDemo/tree/shiro&quot;&gt;shiro的demo&lt;/a&gt;，欢迎查看。&lt;/p&gt;

&lt;h2 id=&quot;spring-boot的简单介绍&quot;&gt;spring-boot的简单介绍&lt;/h2&gt;
&lt;p&gt;Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can “just run”. We take an opinionated view of the Spring platform and third-party libraries so you can get started with minimum fuss. Most Spring Boot applications need very little Spring configuration.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;上面是spring-boot的官方简介，很明确，spring-boot就是一个让项目配置变的极其简单，达到快速目的的微型框架。如果没有学过spring-boot，没有关系，直接到官网看文档，当然，网上中文文档也一找一大堆。你会发现它是一个很好上手简单方便的框架。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;spring-boot集成shiro-1&quot;&gt;spring-boot集成shiro&lt;/h2&gt;

&lt;p&gt;既然是集成，我会着重的讲下配置的集成，而maven的那些配置,数据库的5张表就不详细说明了。&lt;/p&gt;

&lt;p&gt;在配置之前先说明shiro的核心类&lt;/p&gt;

&lt;h2 id=&quot;启用注解和配置shiro生命周期&quot;&gt;启用注解和配置shiro生命周期&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Bean
	@DependsOn(&quot;lifecycleBeanPostProcessor&quot;)
	public DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator() {

		DefaultAdvisorAutoProxyCreator shiroAutoProxyCreator =
				new DefaultAdvisorAutoProxyCreator();
		shiroAutoProxyCreator.setProxyTargetClass(true);
		return shiroAutoProxyCreator;
	}

	/**
	 *
	 */
	@Bean
	public LifecycleBeanPostProcessor lifecycleBeanPostProcessor() {

		return new LifecycleBeanPostProcessor();
	}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;shirofilterfactory&quot;&gt;ShiroFilterFactory&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;配置ShiroFilterFactory&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	/**
	 * shiro filter
	 */
	@Bean(name = &quot;shiroFilter&quot;)
	public ShiroFilterFactoryBean ShiroFilterFactoryBean() {

		ShiroFilterFactoryBean factoryBean = new ShiroFilterFactoryBean();
		factoryBean.setSecurityManager(defaultWebSecurityManager());
		factoryBean.setFilterChainDefinitionMap(createFilterChainMap());
		factoryBean.setUnauthorizedUrl(&quot;/dongjun/user/unauthorized&quot;);
		factoryBean.setLoginUrl(&quot;/dongjun/login&quot;);
		return factoryBean;
	}

	/**
	 * &amp;lt;p&amp;gt;*：匹配零个或多个字符串
	 * &amp;lt;p&amp;gt;**：匹配路径中的零个或多个路径
	 * &amp;lt;p&amp;gt;url模式匹配顺序是按照在配置中的声明顺序匹配，即从头开始使用第一个匹配的url模式对应的拦截器链
	 */
	private Map&amp;lt;String, String&amp;gt; createFilterChainMap() {
		Map&amp;lt;String, String&amp;gt; map = new LinkedHashMap&amp;lt;&amp;gt;();
		map.put(&quot;//*&quot;, &quot;anon&quot;);
		map.put(&quot;//**&quot;, &quot;roles[super_admin]&quot;);
		map.put(&quot;//**&quot;, &quot;authc&quot;);
		return map;
	}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ShiroFilterFactory，Shiro过滤器工厂类，具体的实现类是：ShiroFilterFactoryBean，此实现类是依赖于SecurityManager安全管理器。&lt;/p&gt;

&lt;h3 id=&quot;securitymanager&quot;&gt;SecurityManager&lt;/h3&gt;
&lt;p&gt;配置SecurityManager&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Bean
	public DefaultWebSecurityManager defaultWebSecurityManager() {

		DefaultWebSecurityManager manager = new DefaultWebSecurityManager();
		manager.setRealm(jdbcAuthenticationRealm());
		return manager;
	}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;SecurityManager,Shiro的安全管理，主要是身份认证的管理，缓存管理，cookie管理，所以在实际开发中我们主要是和SecurityManager进行打交道的，ShiroFilterFactory主要配置好了Filter就可以了。当然SecurityManager并进行身份认证缓存的实现，我们需要进行对应的编码然后进行注入到安全管理器中。&lt;/p&gt;

&lt;h3 id=&quot;realm&quot;&gt;Realm&lt;/h3&gt;
&lt;p&gt;集成spring-boot，直接在application类中写&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
	@Bean
	public JdbcRealm jdbcAuthenticationRealm() {

		JdbcRealm realm = new JdbcRealm();

		HashedCredentialsMatcher credentialsMatcher = new HashedCredentialsMatcher();
		SimpleCredentialsMatcher matcher = new SimpleCredentialsMatcher();
		credentialsMatcher.setHashAlgorithmName(&quot;SHA-256&quot;);
		realm.setDataSource(dataSource());
		realm.setCredentialsMatcher(matcher);
		realm.setAuthenticationCacheName(&quot;shiro.authorizationCache&quot;);
		realm.setAuthenticationQuery(&quot;select password from user where name = ?&quot;);
		realm.setSaltStyle(SaltStyle.NO_SALT);

		/**
		 * 查询用户的角色时只能通过用户的名字查，查询用户的权限时只能通过用户的角色名查
		 */
		realm.setUserRolesQuery(&quot;select role from role where id in &quot; +
				&quot;(select role_id from user_role where user_id in &quot; +
				&quot;(select id from user where name = ?))&quot;);
		realm.setPermissionsQuery(&quot;select permission from permission where id in &quot; +
				&quot;(select permission_id from role_permission where role_id in &quot; +
				&quot;(select id from role where role = ?))&quot;);
		realm.setPermissionsLookupEnabled(true);
		return realm;
	}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Realm,用于身份信息权限信息的验证。&lt;/p&gt;

&lt;h2 id=&quot;其他配置&quot;&gt;其他配置&lt;/h2&gt;
&lt;p&gt;其它的就是缓存管理，记住登录之类的，这些大部分都是需要自己进行简单的实现，然后注入到SecurityManager让Shiro的安全管理器进行管理就好了。&lt;/p&gt;

&lt;h2 id=&quot;使用shiro&quot;&gt;使用shiro&lt;/h2&gt;
&lt;p&gt;直接再controller上加上权限注解，相信学过shiro的同学会懂怎么加的了，这里不一一介绍&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;写在后面，上个星期总体感觉有点堕落啊，时间没有安排好吧。这周开始要好好的写博文学习啦。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201611071&quot; data-title=&quot;shiro-spring-boot&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;

</description>
        <pubDate>Mon, 07 Nov 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//java/2016/11/07/spring-boot%E9%9B%86%E6%88%90shiro.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//java/2016/11/07/spring-boot%E9%9B%86%E6%88%90shiro.html</guid>
        
        <category>java</category>
        
        <category>framework</category>
        
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>一路放声歌唱</title>
        <description>&lt;h1 id=&quot;走夜路请放声歌唱&quot;&gt;走夜路请放声歌唱&lt;/h1&gt;

&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#走夜路请放声歌唱&quot; id=&quot;markdown-toc-走夜路请放声歌唱&quot;&gt;走夜路请放声歌唱&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#感悟&quot; id=&quot;markdown-toc-感悟&quot;&gt;感悟&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#全世界都知道我丢了&quot; id=&quot;markdown-toc-全世界都知道我丢了&quot;&gt;全世界都知道我丢了&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#扫帚的正确使用方法&quot; id=&quot;markdown-toc-扫帚的正确使用方法&quot;&gt;扫帚的正确使用方法&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#没有死的鱼&quot; id=&quot;markdown-toc-没有死的鱼&quot;&gt;没有死的鱼&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#卖猪肉的女儿&quot; id=&quot;markdown-toc-卖猪肉的女儿&quot;&gt;卖猪肉的女儿&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#走夜路请放声歌唱-1&quot; id=&quot;markdown-toc-走夜路请放声歌唱-1&quot;&gt;走夜路请放声歌唱&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#其他书摘&quot; id=&quot;markdown-toc-其他书摘&quot;&gt;其他书摘&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Reading/NightRide1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto%;max-width:1020px;&quot; /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;总体看完，随很多没有仔细的品味，但是觉的里面的文字还是很不错的吧。文字很平凡，但是很多能让我很大的感触，就像发生在身边一样。也可能是因为我是从小在农村长大，很多事情还是有很大的共鸣的。下面是我的一些感悟和书摘:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;感悟&quot;&gt;感悟&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;上篇：时间是最合适的容器，收容我们全部的庞大往事，向深渊坠落。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;全世界都知道我丢了&quot;&gt;全世界都知道我丢了&lt;/h2&gt;
&lt;p&gt;　　她没有安全感，随时都在担心我的安危，是不是其实一直在为失去我而作准备？她知道总有一天会失去我的。她一生都心怀这样的恐惧而活着。并且这悲伤和痛苦不停地积累，日渐沉重。每当她承受不了时，便借由一点点偶然的际遇而全面爆发出来。她发泄似的面向全世界的人跺脚哭诉，让全世界的人都知道我丢了。因为她的痛苦和不安如此强烈巨大，非得全世界的人一起来分担不可。她是最任性的母亲，又是最无奈的母亲&lt;br /&gt;
　　其实一开看到这篇文章的时候，我还是没有什么感觉到，可能是因为我还没有感受到太多父母还有子女之间的那种让我深刻的感触吧。但是后来想想，天下的大多数父母和子女的情感不都是这样吗？从小到大，和父母过的都是是如此的平凡，他们的爱却又如此的伟大。&lt;br /&gt;
　　小时候，各种骗我们的父母，跟他们说自己期末考试成绩考的不赖，骗他们说学校要交费其实是拿去买零食的，甚至不想上学想玩骗他们自己生病了要请假。现在大学，亦或者是工作了，同样也是各种骗我们的父母，骗他们自己有吃有穿不缺钱，骗他们不会胃痛了，身体好了，骗他们压力不大，一切顺利。这些欺骗，如果真的要一个理由的话，那应该就是应为爱吧。&lt;br /&gt;
　　想起龙应台的一段话：我慢慢地、慢慢地了解到，所谓父女母子一场，只不过意味着，你和他的缘分就是今生今世不断地在目送他的背影渐行渐远。你站立在小路的这一端，看着他逐渐消失在小路转弯的地方，而且，他用背影默默告诉你：不必追。&lt;br /&gt;
　　我们和父母或者和亲人，有那么多的离别，那么多的不舍，我觉得，不可避免的分别，我们能做的最好的不是在分离是时候要体现的多么多么的不舍，而是在分别时候的经常联系，他们总是那么的容易感动，电话多打，信息多发，这已是对父母，对家人的最大安慰。前几天外公去世了，外公一生贫苦，没有享受过好的生活。母亲哭到嗓子嘶哑，心疼不已，而我能做的也许并不多，只是好好的读书，挣钱，然后带父母看看这个世界，过上好点的生活。&lt;/p&gt;

&lt;h2 id=&quot;扫帚的正确使用方法&quot;&gt;扫帚的正确使用方法&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;觉的吝啬和珍惜只有一点点的差别&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;　　看到这句的时候，对我的感触还是很大的。想起在高中的时候，有次借书给同学，没有想到过几天他还给我的时候，我的那本原来的崭新平整的新书，突然就到处褶皱，像九十好几的老妪的皱纹搬。鬼知道我的书经历了什么。。。然后从那以后，我他想我借书我都拒绝了。从那以后，我借书也是，借我的羽毛球拍也好，我都是要看好人再借了，也许有的人会觉的这样吝啬，是呀，我对不珍惜我的书，我的球拍是很吝啬呀。而且，我会一直”吝啬“下去的。&lt;/p&gt;

&lt;h2 id=&quot;没有死的鱼&quot;&gt;没有死的鱼&lt;/h2&gt;
&lt;p&gt;　　鱼的身子都被横着切出一道又一道的月亮弯刀口了，还腌了椒盐黄酒之类。而它还活着，被割开的刀口处的肌肉有节奏地在我手指下痉挛。我毫无办法，一遍又一遍用刀把用力砸击它的脑门，砸到后来，脑袋那一块都被完全砸塌下去了，可它仍然活着。遍身的伤口都在痉挛，嘴巴一张一合。&lt;br /&gt;
　　我所能做的，只有一遍一遍地继续砸下去，脑子里只有一个念头：快死吧！快死吧！&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;无言就是对漫长而惨痛死去的鱼的默哀吧。&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;下篇:好像全世界的白天，就是我抬起头来，全世界的黑夜，就是我转身过去&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;卖猪肉的女儿&quot;&gt;卖猪肉的女儿&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;他应该下葬了，从此深深躺在熟悉的泥土之中，再也不会发愁离开和停留的的事情&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;　　在这篇文章中，我想起我的奶奶，我整个家族都是多么想奶奶到处去看看，但是奶奶总是拒绝的，她说：老了，在老家习惯了，那也不去了。。。我总是不能理解，为什么要一直都待在一个四面环山的乡村。难道不是要到这个世界的各个角落看看吗？也许吧，故土难离，牵挂太多，我慢慢就会理解了吧，&lt;/p&gt;

&lt;h2 id=&quot;走夜路请放声歌唱-1&quot;&gt;走夜路请放声歌唱&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;夜行的人啊，黑暗中你们一遍又一遍地经过了些什么呢？在你们身边的那些暗处，有什么被你永远地擦肩而过？那洗衣的少女不曾被你的歌声唤醒，不曾在黑暗中抬起面孔，在草地上支撑起身子，循着歌声记起一切……夜行的人，再唱大声些吧！歌唱爱情吧，歌唱故乡吧！对着黑暗的左边唱，对着黑暗的右边唱，再对着黑暗的前方唱。边唱边大声说：“听到了吗？你听到了吗？”夜行的人，若你不唱歌的话，不惊醒这黑夜的话，就永远也走不出呼蓝别斯了。这重重的森林，这崎岖纤细的山路，这孤独疲惫的心。&lt;/li&gt;
  &lt;li&gt;OK，亲爱的，哪怕后来去到了城市，走夜路时也要大声地唱歌，像喝醉酒的人一样无所顾忌。大声地唱啊，让远方的大棕熊也听到了，静静地起身，为你在遥远的地方让路。你发现街道如此空旷，行人素不相识。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;　　上面的两段话是我觉得很励志的两段。黑暗的夜路我们请放声歌唱吧，用音乐，来驱赶恐惧，驱赶孤独和疲惫。在人生黑暗时期，在低谷的时候，请放声歌唱吧，来驱赶内心的不安和那些悲观。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Reading/NightRide2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:100%;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;其他书摘&quot;&gt;其他书摘&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;像郭大爷那样的年龄，他的生命已不用依靠事物来维持了。他是在依靠生命本身的惯性而缓缓前行。他也不再需要晚餐了，只是需要一种习惯，以使被驯服的生命继续平稳温柔地完结无数个同样的一天。 有没有一次晚餐，我曾与你共度？ 我在这里，说着一些话，写出一些字。但其实一切并不是这样的。我说什么就抹杀了什么，些什么就扭曲了什么。 比如我每写下一个黄昏，就会消失一个黄昏。到头来，只剩那些写下的文字陪伴着我，只有那些文…&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这些，都不是梦。昨天晚上的情景是梦。我梦到以前不停地搬家租房的那些年月，梦见很少的一点点商品稀稀拉拉摆在货架上。梦见我们一家三口安静地围着一盘菜吃饭。 　 生命一直陷落在那些岁月里。将来，见到他以后，我要对他说：“世上竟会有那么多的悲伤。不过没关系的。我最终还是成为了自己最想成为的样子。” –《最坚强的时刻在梦里》&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在戈壁滩上，只需一棵树，就能把大地稳稳地镇在蓝天之下。&lt;/p&gt;

    &lt;!-- 多说评论框 start --&gt;
    &lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201611051&quot; data-title=&quot;NightRide&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
    &lt;!-- 多说评论框 end --&gt;
    &lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
    &lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
(function() {
  var ds = document.createElement('script');
  ds.type = 'text/javascript';ds.async = true;
  ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
  ds.charset = 'UTF-8';
  (document.getElementsByTagName('head')[0] 
   || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
&lt;/script&gt;

    &lt;!-- 多说公共JS代码 end --&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 05 Nov 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//reading/2016/11/05/%E8%B5%B0%E5%A4%9C%E8%B7%AF%E8%AF%B7%E6%94%BE%E5%A3%B0%E6%AD%8C%E5%94%B1.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//reading/2016/11/05/%E8%B5%B0%E5%A4%9C%E8%B7%AF%E8%AF%B7%E6%94%BE%E5%A3%B0%E6%AD%8C%E5%94%B1.html</guid>
        
        <category>Reading</category>
        
        <category>Life</category>
        
        
        <category>Reading</category>
        
      </item>
    
      <item>
        <title>spring4+websocket</title>
        <description>&lt;h1 id=&quot;websocketspring4学习&quot;&gt;WebSocket+spring4学习&lt;/h1&gt;

&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论&lt;/strong&gt;&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#websocketspring4学习&quot; id=&quot;markdown-toc-websocketspring4学习&quot;&gt;WebSocket+spring4学习&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#目录&quot; id=&quot;markdown-toc-目录&quot;&gt;目录&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#websocket是什么&quot; id=&quot;markdown-toc-websocket是什么&quot;&gt;WebSocket是什么？&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#websocket有什么好的地方&quot; id=&quot;markdown-toc-websocket有什么好的地方&quot;&gt;WebSocket有什么好的地方。&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#websocket单独使用的缺陷&quot; id=&quot;markdown-toc-websocket单独使用的缺陷&quot;&gt;websocket单独使用的缺陷&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#spring支持websocket&quot; id=&quot;markdown-toc-spring支持websocket&quot;&gt;spring支持websocket&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#stomp协议和sockjs&quot; id=&quot;markdown-toc-stomp协议和sockjs&quot;&gt;STOMP协议和SockJS&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#websocket的作用&quot; id=&quot;markdown-toc-websocket的作用&quot;&gt;websocket的作用&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#demo的讲解&quot; id=&quot;markdown-toc-demo的讲解&quot;&gt;demo的讲解&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#用或不用sockjs的讲解&quot; id=&quot;markdown-toc-用或不用sockjs的讲解&quot;&gt;用或不用sock.js的讲解&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#首先是重要的websocketconfig&quot; id=&quot;markdown-toc-首先是重要的websocketconfig&quot;&gt;首先是重要的websocketconfig&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#下面我们就来看看同时指定了在连接之后的的信息处理类是systemwebsockethandler这个处理类&quot; id=&quot;markdown-toc-下面我们就来看看同时指定了在连接之后的的信息处理类是systemwebsockethandler这个处理类&quot;&gt;下面我们就来看看同时指定了在连接之后的的信息处理类是systemWebSocketHandler（）这个处理类&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#当然在连接的时候可以设置拦截器也就是handshakeinterceptor&quot; id=&quot;markdown-toc-当然在连接的时候可以设置拦截器也就是handshakeinterceptor&quot;&gt;当然，在连接的时候可以设置拦截器，也就是HandshakeInterceptor&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#最后就是客户端的解析了在demo是websocket_sockjsp&quot; id=&quot;markdown-toc-最后就是客户端的解析了在demo是websocket_sockjsp&quot;&gt;最后就是客户端的解析了，在demo是webSocket_sock.jsp&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#基于stomp协议的订阅发布的demo&quot; id=&quot;markdown-toc-基于stomp协议的订阅发布的demo&quot;&gt;基于stomp协议的订阅发布的demo&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#首先还是websocketconfig&quot; id=&quot;markdown-toc-首先还是websocketconfig&quot;&gt;首先还是WebSocketConfig&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#下来是-greetingcontroller&quot; id=&quot;markdown-toc-下来是-greetingcontroller&quot;&gt;下来是 GreetingController&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#最后就是客户端websocket_stompjsp&quot; id=&quot;markdown-toc-最后就是客户端websocket_stompjsp&quot;&gt;最后就是客户端websocket_stomp.jsp&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#下面附上一张图&quot; id=&quot;markdown-toc-下面附上一张图&quot;&gt;下面附上一张图&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#注意&quot; id=&quot;markdown-toc-注意&quot;&gt;注意&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;websocket是什么&quot;&gt;WebSocket是什么？&lt;/h2&gt;
&lt;p&gt;WebSocket protocol 是HTML5一种新的协议。它实现了浏览器与服务器全双工通信(full-duplex)。一开始的握手需要借助HTTP请求完成。&lt;/p&gt;

&lt;h2 id=&quot;websocket有什么好的地方&quot;&gt;WebSocket有什么好的地方。&lt;/h2&gt;
&lt;p&gt;在浏览器中通过http仅能实现单向的通信,comet可以一定程度上模拟双向通信,但效率较低,并需要服务器有较好的支持; flash中的socket和xmlsocket可以实现真正的双向通信,通过 flex ajax bridge,可以在javascript中使用这两项功能. 可以预见,如果websocket一旦在浏览器中得到实现,将会替代上面两项技术,得到广泛的使用.面对这种状况，HTML5定义了WebSocket协议，能更好的节省服务器资源和带宽并达到实时通讯。&lt;/p&gt;

&lt;h2 id=&quot;websocket单独使用的缺陷&quot;&gt;websocket单独使用的缺陷&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;websocket是一个比较底层的协议，如果实现推送效果，需要写大量代码。&lt;/li&gt;
  &lt;li&gt;在许多的低级浏览器（别ie7,8等）中是不支持websocket的。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;spring支持websocket&quot;&gt;spring支持websocket&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;根据以上两个缺陷，spring给出自己的解决方式&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;一个是stomp，这是一种通信协议，暂时不介绍它，只需要知道是一种更方便更安全的发送消息的库就行了。在实现消息推送的时候，spring借助stomp更简单的实现。解决了第一个问题。&lt;/li&gt;
  &lt;li&gt;一个是借助Sock.Js，在使用websocket的时候，在spring用.withSockJS()一小段就可以完美解决第二个部分低级浏览器不支持的问题。&lt;/li&gt;
  &lt;li&gt;withSockJs，这是什么呢？SockJs是一个WebSocket的通信js库，Spring对这个js库进行了后台的自动支持，也就是说，我们如果使用SockJs，那么我们就不需要对后台进行更多的配置，只需要加上这一句就可以了。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;stomp协议和sockjs&quot;&gt;STOMP协议和SockJS&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;直接使用 WebSocket（SockJS） 就很类似于 使用 TCP 套接字来编写 web 应用；因为没有高层协议，因此就需要我们定义应用间所发送消息的语义，还需要确保 连接的两端都能遵循这些语义；&lt;/li&gt;
  &lt;li&gt;STOMP 在 WebSocket 之上提供了一个基于 帧的线路格式层，用来定义消息语义，使得发消息变得更加简单&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;websocket的作用&quot;&gt;websocket的作用&lt;/h2&gt;
&lt;p&gt;在javaweb开发中，主要是用来做推送用，其他的话不是很了解，若想深入交接websocket，请看一本叫《HTML5 WebSocket权威指南》&lt;/p&gt;

&lt;h1 id=&quot;demo的讲解&quot;&gt;demo的讲解&lt;/h1&gt;
&lt;p&gt;由于在网上spring4 结合websocket的demo有点乱七八槽，很多都是错的，既然这样，那我就自己结合网上，做了一个demo。下面主要是spring结合websocket通过sock.js连接及订阅发布的讲解。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;建议这个时候同时打开我在github的demo，&lt;a href=&quot;https://github.com/yzhihao/MyJavaDemo/tree/websocket&quot;&gt;websocket_demo&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;用或不用sockjs的讲解&quot;&gt;用或不用sock.js的讲解&lt;/h2&gt;

&lt;h3 id=&quot;首先是重要的websocketconfig&quot;&gt;首先是重要的websocketconfig&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;在一开始我们看到&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Configuration
@EnableWebMvc
@EnableWebSocket
public class WebSocketConfig extends WebMvcConfigurerAdapter implements WebSocketConfigurer{}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;这注解三个大致意思是使这个类支持以@Bean的方式加载bean，并且支持springmvc和websocket，不是很准确大致这样，试了一下@EnableWebMvc不加也没什么影响，@Configuration本来就支持springmvc的自动扫描。
然后是继承WebMvcConfigurerAdapter，和实现WebSocketConfigurer。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;下面的注册方法&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
public void registerWebSocketHandlers(WebSocketHandlerRegistry registry)  {
        registry.addHandler(systemWebSocketHandler(), &quot;/websck&quot;).addInterceptors(new HandshakeInterceptor());

        System.out.println(&quot;registed!&quot;);
        registry.addHandler(systemWebSocketHandler(), &quot;/sockjs/websck/info&quot;).addInterceptors(new HandshakeInterceptor())
                .withSockJS();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;在重写的registerWebSocketHandlers方法中，我们可以看到两种注册方式。一个是有.withSockJS()的连接，一个是没有的。同时指定了在连接之后的的信息处理类是systemWebSocketHandler（）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;下面我们就来看看同时指定了在连接之后的的信息处理类是systemwebsockethandler这个处理类&quot;&gt;下面我们就来看看同时指定了在连接之后的的信息处理类是systemWebSocketHandler（）这个处理类&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SystemWebSocketHandler implements WebSocketHandler{}//继承WebSocketHandler

 @Override
    public void afterConnectionEstablished(WebSocketSession session) throws Exception {...//处理连接之后
    
    @Override
    public void handleMessage(WebSocketSession wss, WebSocketMessage&amp;lt;?&amp;gt; wsm) throws Exception {...//处理客户端传来的信息
    
     @Override
    public void handleTransportError(WebSocketSession wss, Throwable thrwbl) throws Exception {...//处理当异常产生
    
    @Override
    public void afterConnectionClosed(WebSocketSession wss, CloseStatus cs) throws Exception {...//处理连接关闭后
    
    @Override
    public boolean supportsPartialMessages() {...
    
    @Override
    public boolean supportsPartialMessages() {...//是否把消息分割成几个handleMessage来处理
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;在这个类中大家还会看到其他两个自定义方法，其实主要是为了业务的逻辑处理也产生的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;当然在连接的时候可以设置拦截器也就是handshakeinterceptor&quot;&gt;当然，在连接的时候可以设置拦截器，也就是HandshakeInterceptor&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;HandshakeInterceptor extends HttpSessionHandshakeInterceptor{...}//在这里的Interceptor继承了HttpSessionHandshakeInterceptor

@Override
	public boolean beforeHandshake(ServerHttpRequest request,
			ServerHttpResponse response, WebSocketHandler wsHandler,
			Map&amp;lt;String, Object&amp;gt; attributes) throws Exception {...//也就是在握手之前处理

@Override
	public void afterHandshake(ServerHttpRequest request,
			ServerHttpResponse response, WebSocketHandler wsHandler,
			Exception ex) {...//也就是在握手之后处理
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;我这里的拦截器只是简单的输出了下日志，久不加详细讲解了&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;最后就是客户端的解析了在demo是websocket_sockjsp&quot;&gt;最后就是客户端的解析了，在demo是webSocket_sock.jsp&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;在connect()方法中，我们可以看到
首先是引入sock.js的支持&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ws= new WebSocket(&quot;ws://localhost:8080/SpringWebSocketPush/websck&quot;);
 ws = new SockJS(&quot;http://localhost:8080/SpringWebSocketPush/sockjs/websck&quot;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;这里创建两个js对象，分别是WebSocket，和SockJS，其中和SockJS是用到了sock.js的支持的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;最后，在浏览器中，我们就可以用这两种方式来进行连接和消息处理了。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;基于stomp协议的订阅发布的demo&quot;&gt;基于stomp协议的订阅发布的demo&lt;/h2&gt;

&lt;h3 id=&quot;首先还是websocketconfig&quot;&gt;首先还是WebSocketConfig&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Configuration
@EnableWebSocketMessageBroker
public class WebSocketConfig extends AbstractWebSocketMessageBrokerConfigurer {
  @Override
  public void configureMessageBroker(MessageBrokerRegistry config) {
      config.enableSimpleBroker(&quot;/topic&quot;, &quot;/queue&quot;);
      config.setApplicationDestinationPrefixes(&quot;/app&quot;);
  }

  @Override
  public void registerStompEndpoints(StompEndpointRegistry registry) {
      registry.addEndpoint(&quot;/hello&quot;).withSockJS();
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;configureMessageBroker，大意是设置消息代理，也就是页面上用js来订阅的地址，也是我们服务器往WebSocket端接收js端发送消息的地址&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;@EnableWebSocketMessageBroker 注解的作用： 能够在 WebSocket 上启用 STOMP&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;registry.addEndpoint(&quot;/hello&quot;).withSockJS();&lt;/code&gt;这个路径与之前发送和接收消息的目的路径有所不同， 这是一个端点，客户端在订阅或发布消息 到目的地址前，要连接该端点，即 用户发送请求 url=’/server/hello’ 与 STOMP server 进行连接，之后再转发到 订阅url；（server== name of your springmvc project ）（干货——端点的作用——客户端在订阅或发布消息 到目的地址前，要连接该端点）&lt;/li&gt;
  &lt;li&gt;configureMessageBroker() 方法：配置了一个 简单的消息代理。如果不重载，默认case下，会自动配置一个简单的 内存消息代理，用来处理 “/topic” 为前缀的消息。但经过重载后，消息代理将会处理前缀为 “/topic” and “/queue” 消息。也就是说，在发布者发布的时候是以/app为前缀的，而订阅者，可以通过以”/topic”, “/queue”为前缀的来接受，具体看下面的controller&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;下来是-greetingcontroller&quot;&gt;下来是 GreetingController&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    @Controller
    public class GreetingController {
        @MessageMapping(&quot;/hello&quot;)
        @SendTo(&quot;/topic/greetings&quot;)
        public Greeting greeting(HelloMessage message) throws Exception {
            System.out.println(&quot;receiving &quot; + message.getName());
            System.out.println(&quot;connecting successfully.&quot;);
            return new Greeting(&quot;Hello, &quot; + message.getName() + &quot;!&quot;);
        }
        
        @SubscribeMapping(&quot;/macro&quot;)
	public Greeting handleSubscription() {
		System.out.println(&quot;this is the @SubscribeMapping('/marco')&quot;);
		Greeting greeting = new Greeting(&quot;i am a msg from SubscribeMapping('/macro').&quot;);
		return greeting;
	}
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;@MessageMapping注解：表示 handleShout()方法能够处理 指定目的地上到达的消息；&lt;/li&gt;
  &lt;li&gt;这个目的地（消息发送目的地url）就是 “/server/app/hello”，其中 “/app” 是 隐含的 ,”/server” 是 springmvc 项目名称；，也就是发布者的发布时候的地址&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt; @SendTo(&quot;/topic/greetings&quot;)&lt;/code&gt;表示的是发布者发送的消息的最终目的，也就是订阅者接受消息是要连接的地址。&lt;/li&gt;
  &lt;li&gt;在第二个方法中@SubsribeMapping注解实现 请求-回应模式&lt;/li&gt;
  &lt;li&gt;@SubscribeMapping注解 的方法来处理 对 “/app/macro” 目的地订阅（与 @MessageMapping类似，”/app” 是隐含的 ）；&lt;/li&gt;
  &lt;li&gt;请求-回应模式与 HTTP GET 的全球-响应模式差不多： 关键区别在于， HTTP GET 请求是同步的，而订阅的全球-回应模式是异步的，这样客户端能够在回应可用时再去处理，而不必等待；&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;最后就是客户端websocket_stompjsp&quot;&gt;最后就是客户端websocket_stomp.jsp&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script type=&quot;text/javascript&quot;&amp;gt;
        var stompClient = null;

        function setConnected(connected) {
            document.getElementById('connect').disabled = connected;
            document.getElementById('disconnect').disabled = !connected;
            document.getElementById('conversationDiv').style.visibility = connected ? 'visible' : 'hidden';
            document.getElementById('response').innerHTML = '';
        }

        function connect() {
            var socket = new SockJS(&quot;&amp;lt;c:url value='/hello'/&amp;gt;&quot;);
            stompClient = Stomp.over(socket);
            stompClient.connect({}, function(frame) {
                setConnected(true);
                console.log('Connected: ' + frame);
                stompClient.subscribe('/topic/greetings', function(greeting){
                    showGreeting(JSON.parse(greeting.body).content);
                });
            });
        }

        function disconnect() {
            if (stompClient != null) {
                stompClient.disconnect();
            }
            setConnected(false);
            console.log(&quot;Disconnected&quot;);
        }

        function sendName() {
            var name = document.getElementById('name').value;
            stompClient.send(&quot;/app/hello&quot;, {}, JSON.stringify({ 'name': name }));
        }

        function showGreeting(message) {
            var response = document.getElementById('response');
            var p = document.createElement('p');
            p.style.wordWrap = 'break-word';
            p.appendChild(document.createTextNode(message));
            response.appendChild(p);
        }
    &amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;对以上代码的 分析（Analysis）：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;以上代码连接“/hello” 端点并发送 ”name“;&lt;/li&gt;
  &lt;li&gt;stompClient.send(“/app/hello”, {}, JSON.stringify({‘name’:name}))： 第一个参数：json 负载消息发送的 目的地； 第二个参数：是一个头信息的Map，它会包含在 STOMP 帧中；第三个参数：负载消息；&lt;/li&gt;
  &lt;li&gt;stomp client 连接地址 和 发送地址不一样的，连接地址为 &lt;c:url value=&quot;/hello&quot;&gt;&lt;/c:url&gt; ==localhost:8080/springmvc_project_name/hello , 而 发送地址为 ‘/app/hello’，这里要当心&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;下面附上一张图&quot;&gt;下面附上一张图&lt;/h3&gt;

&lt;div&gt;
&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/java/websocket1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:100%;max-width:1020px;&quot; /&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;关于stomp，在&lt;a href=&quot;http://m.blog.csdn.net/article/details?id=51914567&quot;&gt;这篇博文&lt;/a&gt;中有详细介绍,可以去看看&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;注意&quot;&gt;注意&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;因为两个demo我把他们合在了一起，在演示不同的方式的时候要记得修改websocketconfig，其实也就是注释和解注释了的。&lt;/li&gt;
  &lt;li&gt;在测试用sock.js的时候，要记得把GreetingController全部注释了。不然会报错。&lt;/li&gt;
  &lt;li&gt;在测试stomp的时候就改&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;其实实现消息的推送和消息还有很多方式。下次会结合消息中间件activeQM来继续讲解。&lt;/p&gt;

    &lt;!-- 多说评论框 start --&gt;
    &lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201610301&quot; data-title=&quot;spring4+websocket&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
    &lt;!-- 多说评论框 end --&gt;
    &lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
    &lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
(function() {
  var ds = document.createElement('script');
  ds.type = 'text/javascript';ds.async = true;
  ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
  ds.charset = 'UTF-8';
  (document.getElementsByTagName('head')[0] 
   || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
&lt;/script&gt;

    &lt;!-- 多说公共JS代码 end --&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 30 Oct 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//java/2016/10/30/websocket.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//java/2016/10/30/websocket.html</guid>
        
        <category>java</category>
        
        <category>web</category>
        
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>仰望月亮，手握六便士</title>
        <description>&lt;h1 id=&quot;仰望月亮手握六便士&quot;&gt;仰望月亮，手握六便士&lt;/h1&gt;

&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;欢迎在文章下方评论&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;目录&lt;/li&gt;
&lt;/ul&gt;

&lt;div&gt;


&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Reading/moon-and-life1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:100%;max-width:1020px;&quot; /&gt;


&lt;/div&gt;

&lt;h2 id=&quot;仰望月亮手握六便士-1&quot;&gt;仰望月亮，手握六便士&lt;/h2&gt;

&lt;p&gt;　　作为一个计算计的理工科男生，很少接触文学性的东西，更多的是逻辑，各种严谨的逻辑思维，在这一个星期读了这本《月亮和六便士》。可能是第一次读，可能我并不能理解那些所谓艺术家心中的想法，也可能是我对艺术的看法很浅薄，所以，整本书是有点看的蒙圈的。在读这本书的时候，其实很多时候是不能理解书中的主人公的想法和作者的想法的。但是，这本书能成为经典，那么必然也肯定有其发光发亮的地方。下面，给出在经过我一个星期的研（xia）读的想法和感悟。&lt;/p&gt;

&lt;h3 id=&quot;对于艺术和理想&quot;&gt;对于艺术和理想&lt;/h3&gt;

&lt;p&gt;　　在这本书一开始就指明了“月亮代表崇高的理想，六便士则是现实的代表”，其实说实话，以我一个理科生的逻辑思维去思考，理解这本书，理解主人公，有点困难。首先先说明，在之前，我对于艺术，觉得它也就是一个普通的东西，没什么好玩的，也就那么一回事，画几张画，之类的。。。在整本书读下来，一开始，我觉我就像一个刚出生的幼儿，而艺术就是一个崭新的世界，我根本不能理解，那种痴迷艺术的心，或书中说的，那种灵魂。我觉得，读完这本书，艺术家变的更加神秘了，艺术变的更加神秘了，更加不能理解一个人可以为了所谓艺术而抛去妻儿，可以为了艺术可以那么的异样。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;　　在读完书，想了挺久，我觉的就像最后一句说的–上帝的磨盘转动很慢 但是却磨得很细。网上查了下，比较赞同一位网友的说法：这句的话作者想表达的是上帝对于思特里克兰德的一种惩罚吧，就是在现实生活中思特里克兰德抛弃妻儿，对勃朗什的抛弃等等一系列的惩罚。在一方面思特里克兰德代表那些追求独立和自由，追求那种美，最求心的那份远景，那份理想。他们仰望着天空。他代表着那些不顾一切追寻自己的那份灵魂的人。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;　　唯有那些听到自己内心并且愿意为之追求的人，才能获得独立和自由。那些活在世人目光中的人永远不明白为什么有些人会放弃外人看似幸福的生活去追求什么所谓的理想。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;　　但同时，我还想说的是要手握六便士，或者就像温家宝总理说，在仰望天空的同时，也要脚踏实地。我们可以去追求那份理想，但同时也要符合社会本有主流价值观。不能像书中的主人公思特里克兰德，或者其原型高更那样，太过于极端。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;　　读完这本书，对于理想和现实，我们应该各取所需吧。当然，在当下，更多的是那些心中缺失理想，缺少心中的月亮。被现实所”玩弄“，甚至不知道自己要的是什么，远景是什么的年轻人。那些人的话，我相信，在读完这本书的时候应该会有所感悟，在被高更那样的状态震撼的同时，想想自己，自己心中的那些“月亮”。在另一方面，就是那些过于极端的追求所谓的理想，也应该好好的想下，不能为了所谓的理想而丢失一切。以前读过夸父逐日是故事，很多人会觉得夸父多么多么的高大，但其实在我的眼里，那很傻。。。&lt;/p&gt;

&lt;h3 id=&quot;应该被爱的女人&quot;&gt;应该被爱的女人&lt;/h3&gt;

&lt;p&gt;　　首先必须指出毛姆是男性同性恋者（或为双性恋？），和助手暧昧，玩伴众多，歧视女性，是传统道德打击的对象，《月亮与六便士》也可以看做毛姆反对传统道德权威的檄文。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;　　 在书中也可以看到很多地方对女性的一种鄙视，这是我非常反感的。也是非常不赞同的，也许这个和作者有很大的关系。女生在我们眼里应该是好好爱护的，就像一个节目《超级演说家》中陈铭的演讲一样，女人永远都是最佳辩手，尽管她们可能很多时候会有点无理取闹，但她们给出的是那么一颗温柔，天真，又脆弱的心。难道我们不应该好好的爱护吗？&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;　　在这本书中，出现的三个思特里克兰德身边的女人都应该是值得我们所有人尊敬的，她们付出了自己真正的心，在爱面前放下尊严。而思特里克兰德的爱更多是那么的自私。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;　　另外对类似于思特里克兰德的老婆那样的好姑娘（贤良淑德又出得厅堂的英国好媳妇）说上一句公道话：&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;　　如果你不够爱一个人，而他又是一个绝对的月亮主义者的话，请真的要放大眼睛（不是放大瞳孔），谨慎选郎，千万别盲目乱嫁——因为你要么收获一个夏天的六便士满地的繁华，也有可能收获一个冬天的贫困寒冷的孤寂。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/Reading/moon-and-life2.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto!important;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;一些书摘&quot;&gt;一些书摘&lt;/h1&gt;

&lt;h2 id=&quot;导言&quot;&gt;导言：&lt;/h2&gt;

&lt;p&gt;　　1. 月亮代表崇高的理想，六便士则是现实的代表。正如毛姆曾提到过：有些人年轻的时候只看到天上的月亮，却从看不到那六便士。现在我们仍然看到天上的月亮，但我们是站在地上仰望到月光。&lt;/p&gt;

&lt;h2 id=&quot;第一章&quot;&gt;第一章&lt;/h2&gt;

&lt;p&gt;　　1. 在我看来，艺术中最令人感兴趣的就是艺术家的个性；如果艺术家赋有独特的性格，尽管他有一千个缺点，我也可以原谅。&lt;/p&gt;

&lt;h2 id=&quot;第二章&quot;&gt;第二章&lt;/h2&gt;

&lt;p&gt;　　1. 那时候我还不懂女人的一种无法摆脱的恶习——热衷于同任何一个愿意倾听的人讨论自己的私事。&lt;/p&gt;

&lt;h2 id=&quot;第三章&quot;&gt;第三章&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;麦克安德鲁太太和大多数女性的见解相同，认为男人们都是一些没有心肝的畜类，总想丢开倾心爱着他们的女人，但是一旦他真的做出这种事来，更多的过错是在女人这一方面。感情有理智所根本不能理解的理由。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;女人们总是喜欢在她们所爱的人临终前表现得宽宏大量，她们的这种偏好叫我实在难以忍受。有时候我甚至觉得她们不愿意男人寿命太长，就是怕演出这幕好戏的机会拖得太晚。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;有人说灾难不幸可以使人性高贵，这句话并不对；叫人做出高尚行动的有时候反而是幸福得意，灾难不幸在大多数情况下只能使人们变得心胸狭小、报复心更强。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;“为什么你认为美——世界上最宝贵的财富——会同沙滩上的石头一样，一个漫不经心的过路人随随便便就能捡起来？美是一种美妙、奇异的东西，艺术家只有经过灵魂的痛苦折磨才能从宇宙的混沌中塑造出来。在美被创造出以后，它也不是为了叫每个人都能认出来的。要想认识它，一个人必须重复艺术家经历过的一番冒险。他唱给你的是一个美的旋律，要是想在自己的心里重新听一遍，就必须有知识、有敏锐的感觉和想象力。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;第八章&quot;&gt;第八章&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;她对自己的丈夫从来就没有什么感情，过去我认为她爱施特略夫，实际上只是男人的爱抚和生活的安适在女人身上引起的自然反应。大多数女人都把这种反应当做爱情了。这是一种对任何一个人都可能产生的被动的感情，正像藤蔓可以攀附在随便哪株树上一样。因为这种感情可以叫一个女孩子嫁给任何一个需要她的男人，相信日久天长便会对这个人产生爱情，所以世俗的见解便断定了它的力量。但是说到底，这种感情是什么呢？它只不过是对有保障的生活的满足，对拥有家资的骄傲，对有人需要自己沾沾自喜，和对建立起自己的家庭洋洋得意而已；女人们秉性善良、喜爱虚荣，因此便认为这种感情极富于精神价值。但是在冲动的热情前面，这种感情是毫无防卫能力的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在爱这种感情中主要成分是温柔…爱情中需要有一种软弱无力的感觉，要有体贴爱护的要求，有帮助别人、取悦别人的热情——如果不是无私，起码是巧妙地遮掩起来的自私；爱情包含着某种程度的腼腆怯懦。”（174，第三十章）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;“爱情要占据一个人莫大的精力，它要一个人离开自己的生活专门做一个爱人。即使头脑最清晰的人，从道理上他可能知道，在实际中却不会承认爱情有一天会走到尽头。爱情赋予他明知是虚幻的事物以实质形体，他明知道这一切不过是镜花水月，爱它却远远超过了喜爱真实。”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;“它使一个人比原来的自我更丰富了一些，同时又使他比原来的自我更狭小了一些。他不再是一个人，他成了追求某一个他不了解的目的的一件事物、一个工具。爱情从来免不了多愁善感…”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;女人对一个仍然爱着她、可是她已经不再爱的男人可以表现得比任何人都残忍；她对他不只不仁慈，而且根本不能容忍，她成了一团毫无理智的怒火。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;女人们不断为了爱情而自寻短见，但是一般说来她们总是做得很小心，不让自杀成为事实。通常这只是为了引起她们情人的怜悯或者恐怖而作的一个姿态。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;第九章&quot;&gt;第九章&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;“人们动不动就谈美，实际上对这个词并不理解；这个词已经使用得太滥失去了原有的力量；因为成千上万的琐碎事物都分享了“美”的称号，这个词已经被剥夺掉它的崇高含义了。什么东西人们都用美来形容，当他们面对面地遇到真正的美时，反而认不出它来了。他们用以掩饰自己毫无价值的思想的虚假夸大使他们的感受力变得迟钝不堪，人们已经失掉了他们用之过滥的赏识能力。”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;一个恶棍的性格如果刻画得完美而又合乎逻辑，对于创作者是具有一种魅惑的力量的，尽管从法律和秩序的角度看，他决不该对恶棍有任何欣赏的态度。说不定作家在创作恶棍时实际上是在满足他内心深处的一种天性，因为在文明社会中，风俗礼仪迫使这种天性隐匿到潜意识的最隐秘的底层下；给予他虚构的人物以血肉之躯，也就是使他那一部分无法表露的自我有了生命。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;作家更关心的是了解人性，而不是判断人性。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;女人可以原谅男人对她的伤害，但是永远不能原谅他对她做出的牺牲。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;我们每个人生在世界上都是孤独的。每个人都被囚禁在一座铁塔里，只能靠一些符号同别人传达自己的思想；而这些符号并没有共同的价值，因此它们的意义是模糊的、不确定的。我们非常可怜地想把自己心中的财富传送给别人，但是他们却没有接受这些财富的能力。因此我们只能孤独地行走，尽管身体互相依傍却并不在一起，既不了解别人也不能为别人所了解。我们好像住在异国的人，对于这个国家的语言懂得非常少，虽然我们有各种美妙的、深奥的事情要说，却只能局限于会话手册上那几句陈腐、平庸的话。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;小说之所以不真实正在这里。一般说来，爱情在男人身上只不过是一个插曲，是日常生活中许多事务中的一件事，但是小说却把爱情夸大了，给予它一个违反生活真实性的重要的地位。尽管也有很少数男人把爱情当作世界上的头等大事，但这些人常常是一些索然寡味的人；即便对爱情感到无限兴趣的女人，对这类男子也不太看得起。女人会被这样的男人吸引，会被他们奉承得心花怒放，但是心里却免不了有一种不安的感觉——这些人是一种可怜的生物。男人们即使在恋爱的短暂期间，也不停地干一些别的事分散自己的心思：赖以维持生计的事务吸引了他们的注意力；他们沉湎于体育活动；他们还可能对艺术感到兴趣。在大多数情况下，他们把自己的不同活动分别安排在不同的间隔里，在进行一种活动时，可以暂时把另一种完全排除。他们有本领专心致志进行当时正在从事的活动；如果一种活动受到另一种侵犯，他们会非常恼火。作为坠入情网的人来说，男人同女人的区别是：女人能够整天整夜谈恋爱，而男人却只能有时有晌儿地干这种事。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;第十一章&quot;&gt;第十一章&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;有一些男人，慈悲的天意注定叫他们终生做个单身汉，但是他们有的人由于任性，有的人由于拗不过环境，却违背了上帝的意旨。再没有谁比这种结了婚的单身汉更叫人可怜了。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;第十二章&quot;&gt;第十二章&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;机缘把他们随便抛掷到一个环境中，而他们却一直思念着一处他们自己也不知道坐落在何处的家乡。在出生的地方他们好像是过客；从孩提时代就非常熟悉的浓荫郁郁的小巷，同小伙伴游戏其中的人烟稠密的街衢，对他们来说都不过是旅途中的一个宿站。 这种人在自己的亲友中可能终生落落寡合，在他们唯一熟悉的环境里也始终孑身独处。也许正是在本乡本土的这种陌生感才逼着他们远游异乡，寻找一处永恒定居的寓所。说不定在他们内心深处仍然隐伏着多少世代前祖先的习性和癖好，从而叫这些彷徨者再回到他们祖先在远古就已离开的土地。 有时候一个人偶然到了一个地方，会神秘地感觉到这正是自己栖身之所，是他一直在寻找的家园。于是他就在这些从未寓目的景物里，在从不相识的人群中定居下来，倒好像这里的一切都是他从小就熟稔的一样。 他在这里终于找到了宁静。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;第十三章&quot;&gt;第十三章&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;有人认为劳动的幸福是句空话，对我说来可不是这样。我深深感到这句话的重要意义。我是个很幸福的人。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;恐惧使人们变得残酷无情&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;第十四章&quot;&gt;第十四章&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;上帝的磨盘转动很慢 但是却磨得很细&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;《圣经》上的另一句话也到了我的唇边，但是我却控制着自己，没有说出来，因为我知道牧师不喜欢俗人侵犯他们的领域，他们认为这是有渎神明的。我的亨利叔叔在威特斯台柏尔教区做了二十七年牧师，遇到这种机会就会说：魔鬼要干坏事总可以引证《圣经》。他一直忘不了一个先令就可以买十三只大牡蛎的日子。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;

&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201610291&quot; data-title=&quot;the moon and the life&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;

&lt;!-- 多说评论框 end --&gt;

&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;

&lt;script type=&quot;text/javascript&quot;&gt;


var duoshuoQuery = {short_name:&quot;yzhhome&quot;};


  (function() {


    var ds = document.createElement('script');


    ds.type = 'text/javascript';ds.async = true;


    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';


    ds.charset = 'UTF-8';


    (document.getElementsByTagName('head')[0] 


     || document.getElementsByTagName('body')[0]).appendChild(ds);


  })();


  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Sat, 29 Oct 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//reading/2016/10/29/%E6%9C%88%E4%BA%AE%E5%92%8C%E5%85%AD%E4%BE%BF%E5%A3%AB.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//reading/2016/10/29/%E6%9C%88%E4%BA%AE%E5%92%8C%E5%85%AD%E4%BE%BF%E5%A3%AB.html</guid>
        
        <category>Reading</category>
        
        <category>Life</category>
        
        
        <category>Reading</category>
        
      </item>
    
      <item>
        <title>java内部类（二）：原理实现</title>
        <description>&lt;h1 id=&quot;内部类二原理实现&quot;&gt;内部类（二）原理实现&lt;/h1&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#内部类二原理实现&quot; id=&quot;markdown-toc-内部类二原理实现&quot;&gt;内部类（二）原理实现&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#私有内部类--在方法之间定义的内部类非静态&quot; id=&quot;markdown-toc-私有内部类--在方法之间定义的内部类非静态&quot;&gt;私有内部类 —— 在方法之间定义的内部类，非静态&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#私有内部类的两个特点&quot; id=&quot;markdown-toc-私有内部类的两个特点&quot;&gt;私有内部类的两个特点：&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#内部原理&quot; id=&quot;markdown-toc-内部原理&quot;&gt;内部原理：&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#静态内部类----在方法间定义的内部类静态&quot; id=&quot;markdown-toc-静态内部类----在方法间定义的内部类静态&quot;&gt;静态内部类  ——  在方法间定义的内部类，静态&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#局部内部类--在方法中定义的内部类&quot; id=&quot;markdown-toc-局部内部类--在方法中定义的内部类&quot;&gt;局部内部类 —— 在方法中定义的内部类&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;私有内部类--在方法之间定义的内部类非静态&quot;&gt;私有内部类 —— 在方法之间定义的内部类，非静态&lt;/h2&gt;

&lt;h3 id=&quot;私有内部类的两个特点&quot;&gt;私有内部类的两个特点：&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;在外部类的作用范围内可以任意创建内部类对象，即使内部类是私有的(私有内部类)。即内部类对包围它的外部类可见。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//代码1：内部类对外部类可见   
class Outer{   
     //创建私有内部类对象   
     public Inner in=new Inner();   
     //私有内部类   
     private class Inner{   
          ...   
     }   
}  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;在内部类中可以访问其外部类的所有域，即使是私有域。即外部类对内部类可见。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//代码2：外部类对内部类可见   
class Outer{   
       //外部类私有数据域   
       private int data=0;   
       //内部类   
       class Inner{   
           void print(){   
                 //内部类访问外部私有数据域   
                 System.out.println(data);   
           }    
       }   
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;问题来了：上面两个特点到底如何办到的呢？内部类的”内部”到底发生了什么？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;内部原理&quot;&gt;内部原理：&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;其实，内部类是Java编译器一手操办的。虚拟机并不知道内部类与常规类有什么不同。 编译器是如何瞒住虚拟机的呢？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;对内部类进行编译后发现有两个class文件：Outer.class 和Outer$Inner.class 。这说明内部类Inner仍然被编译成一个独立的类(Outer$Inner.class)，而不是Outer类的某一个域。 虚拟机运行的时候，也是把Inner作为一种常规类来处理的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;但问题来了，即然是两个常规类，为什么他们之间可以互相访问私有域那(最开始提到的两个内部类特点)？这就要问问编译器到底把这两个类编译成什么东西了。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;我们利用reflect反射机制来探查了一下内部类编译后的情况（关于探查类内部机制的代码提供在下面的附件里Reflect.java）。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        (1)、编译代码1生成 Outer$Inner.class 文件后使用 ReflectUtil.reflect(&quot;Outer$Inner&quot;) 对内部类Inner进行反射。运行结果 发现了三个隐含的成分：          

//反编译1  
class Outer$Inner   
{   
        Outer$Inner(Outer,Outer$Inner);  //包可见构造器   
        private Outer$Inner(Outer);   //私有构造器将设置this$0域   
        final Outer this$0;   //外部类实例域this$0  
}  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;　　好了，现在我们可以解释上面的第一个内部类特点了： 为什么外部类可以创建内部类的对象？并且内部类能够方便的引用到外部类对象?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;首先编译器将外、内部类编译后放在同一个包中。在内部类中附加一个包可见构造器。这样， 虚拟机运行Outer类中Inner in=new Inner(); 实际上调用的是包可见构造： new Outer$Inner(this,null)。因此即使是private内部类，也会通过隐含的包可见构造器成功的获得私有内部类的构造权限。&lt;/li&gt;
  &lt;li&gt;再者，Outer$Inner类中有一个指向外部类Outer的引用this$0，那么通过这个引用就可以方便的得到外部类对象中可见成员。但是Outer类中的private成员是如何访问到的呢？这就要看看下面Outer.class文件中的秘密了。&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      (2)、编译代码2生成 Outer.class文件，然后使用 ReflectUtil.reflect(&quot;Outer&quot;) 对外部类Outer进行反射 。 运行结果 发现一个隐含成分如下：

//反编译2  
class Outer   
{   
          static int access$0(Outer);  //静态方法，返回值是外部类私有域 data 的值。   
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;　　现在可以解释第二个特点了：为什么内部类可以引用外部类的私有域？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;原因的关键就在编译器在外围类中添加了静态方法access$0。 它将返回值作为参数传递给他的对象域data。这样内部类Inner中的打印语句：&lt;code class=&quot;highlighter-rouge&quot;&gt;System.out.println(data);&lt;/code&gt;实际上运行的时候调用的是：&lt;code class=&quot;highlighter-rouge&quot;&gt;System.out.println(this$0.access$0(Outer));&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总结一下编译器对类中内部类做的手脚吧：&lt;/p&gt;

&lt;p&gt;(1)  在内部类中偷偷摸摸的创建了包可见构造器，从而使外部类获得了创建权限。&lt;/p&gt;

&lt;p&gt;(2)  在外部类中偷偷摸摸的创建了访问私有变量的静态方法，从而 使 内部类获得了访问权限。&lt;/p&gt;

&lt;p&gt;这样，类中定义的内部类无论私有，公有，静态都可以被包围它的外部类所访问。&lt;/p&gt;

&lt;h2 id=&quot;静态内部类----在方法间定义的内部类静态&quot;&gt;静态内部类  ——  在方法间定义的内部类，静态&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;内部类也有静态的区别，这就是静态内部类，我们来看看代码：&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;package&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;   
&lt;span class=&quot;p&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;代码&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;：静态内部类对外部变量的引用&lt;/span&gt;   
&lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;     
        &lt;span class=&quot;n&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;           
        &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;创建静态内部类对象&lt;/span&gt;   
    &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Inner&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Inner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;     
    &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;静态&lt;/span&gt;   
    &lt;span class=&quot;n&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Inner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;     
        &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;   
                         &lt;span class=&quot;nf&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;   &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;如果&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;不是静态变量，这里将无法通过编译。&lt;/span&gt;   
                &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;   
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;     
  
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;静态内部类和私有内部类最大的区别在于，静态内部类中无法引用到其外围类的非静态成员。这是为什么？我们还是来看看静态内部类Outer$Inner中发生了什么吧？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//反编译3  
class Outer$Inner   
{   
      private Outer$Inner();   
      Outer$Inner(hr.test.Outer$Inner);   
}  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;　　与上面私有内部类反编译1比较发现，少了一个指向外围类对象的引用final Outer this$0; 也就是说静态内部类无法得到其外围类对象的引用，那么自然也就无法访问外围类的非静态成员了。因此，静态内部类只能访问其外围类的静态成员，除此之外与非静态内部类没有任何区别。&lt;/p&gt;

&lt;h2 id=&quot;局部内部类--在方法中定义的内部类&quot;&gt;局部内部类 —— 在方法中定义的内部类&lt;/h2&gt;

&lt;p&gt;　　方法内部类也有两个特点&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;方法中的内部类没有访问修饰符， 即方法内部类对包围它的方法之外的任何东西都不可见。&lt;/li&gt;
  &lt;li&gt;方法内部类只能够访问该方法中的局部变量，所以也叫局部内部类。而且这些局部变量一定要是final修饰的常量。&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Outter{   
      public void outMethod(){   
             final int beep=0;   
             class Inner{   
                   //使用beep   
             }   
             Inner in=new Inner();   
      }   
}  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;　　&lt;strong&gt;这又是为什么呢？&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;我们首先对Outter类进行反射发现，Outter中再也没有返回私有域的隐藏方法了。&lt;/li&gt;
  &lt;li&gt;对Inner类的反射发现，Inner类内部多了一个对beep变量的备份隐藏域：final int val$i;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;我们可以这样解释Inner类中的这个备份常量域，首先当JVM运行到需要创建Inner对象之后，Outter类已经全部运行完毕，这是垃圾回收机制很有可能释放掉局部变量beep。那么Inner类到哪去找beep变量呢？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;编译器又出来帮我们解决了这个问题，他在Inner类中创建了一个beep的备份 ，也就是说即使Ouuter中的beep被回收了，Inner中还有一个备份存在，自然就不怕找不到了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;但是问题又来了。如果Outter中的beep不停的在变化那。那岂不是也要让备份的beep变量无时无刻的变化。为了保持局部变量与局部内部类中备份域保持一致。 编译器不得不规定死这些局部域必须是常量，一旦赋值不能再发生变化了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;　　所以为什么局部内部类应用外部方法的域必须是常量域的原因所在了。&lt;/p&gt;

&lt;p&gt;&lt;!-- 多说评论框 start --&gt;&lt;/p&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201610232&quot; data-title=&quot;deep-learning-innerclass of java（1）&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//java/2016/10/23/deep-learning-innerclass-of-java.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//java/2016/10/23/deep-learning-innerclass-of-java.html</guid>
        
        <category>java</category>
        
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>java内部类（一）：特点和作用</title>
        <description>&lt;h1 id=&quot;java内部类一特点和作用&quot;&gt;java内部类（一）：特点和作用&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;目录&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;先提分类&quot;&gt;先提分类&lt;/h2&gt;

&lt;p&gt;分类：&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;(1) 在类中定义一个类(常规内部类，静态内部类)&lt;/p&gt;

&lt;p&gt;(2) 在方法中定义一个类(局部内部类，匿名内部类)&lt;/p&gt;

&lt;h2 id=&quot;下面逐个进行讲解&quot;&gt;下面逐个进行讲解：&lt;/h2&gt;

&lt;h3 id=&quot;常规内部类或成员内部类&quot;&gt;常规内部类或成员内部类&lt;/h3&gt;

&lt;h4 id=&quot;定义&quot;&gt;定义：&lt;/h4&gt;

&lt;p&gt;在方法与方法之间定义的普通的一个类。&lt;/p&gt;

&lt;h4 id=&quot;特点&quot;&gt;特点&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;可以把类定义为私有内部类，即修饰符外private。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;在java的外部普通类是不可以用private修饰的，不然编译不通过，下面是eclipse中的报错信息，不信可以去试试。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Illegal modifier for the class XXX; only public, abstract &amp;amp; final are permitted&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在外部类的作用范围内可以任意创建内部类对象，即使内部类是私有的(私有内部类)。即内部类对包围它的外部类可见。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在内部类中可以访问其外部类的所有域，即使是私有域。即外部类对内部类可见。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;内部类中不能定义静态成员变量。这个是和静态内部类的区别之一。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;内部类是Java编译器一手操办的。虚拟机并不知道内部类与常规类有什么不同。这一点会在我的下一篇博文中进行验证，如果你很想知道如何验证，请移步：&lt;a href=&quot;https://yzhihao.github.io/java/2016/10/23/deep-learning-innerclass-of-java.html&quot;&gt;java内部类（一）:内部类原理&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;作用&quot;&gt;作用&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;写在前面：&lt;/strong&gt;下面的每一个作用我都写了demo，请移步到我的github：&lt;a href=&quot;https://github.com/yzhihao/MyJavaDemo/tree/BaseJava/src&quot;&gt;常规内部类四大作用&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;注意：下面的四大作用分别对应文件夹：innerclass1-4&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;内部类可以很好的实现隐藏。一般的非内部类，是不允许有 private 与protected权限的，但内部类可以，这样就实现了除了本身的外部类的其他类都不能访问该内部类。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;内部类拥有外围类的所有元素的访问权限，这也是常规内部类的特点&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以实现多重继承。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以避免修改接口而实现同一个类中两种同名方法的调用。即若你要继承和实现的接口中都有你要覆写的方法，而且方法名一样，这是你有不能修改方法名的话，就可以用内部类解决问题。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;记得在网上看过：内部类和可以实现多个接口是解决java单继承的不足的方式，当然，这个在我们的第三四个作用总就有明显的提到这样的作用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;静态内部类&quot;&gt;静态内部类：&lt;/h3&gt;

&lt;h4 id=&quot;定义-1&quot;&gt;定义：&lt;/h4&gt;

&lt;p&gt;在方法和方法之间定义的一个带有static的静态内部类。&lt;/p&gt;

&lt;h4 id=&quot;特点-1&quot;&gt;特点：&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;只能访问外部类的静态成员。这是由Java语法中”静态方法不能直接访问非静态成员”所限定。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以创建静态变量。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;生成（new）一个静态内部类不需要外部类成员：这是静态内部类和成员内部类的区别。静态内部类的对象可以直接生成：Outer.Inner in=new Outer.Inner()；而不需要通过生成外部类对象来生成。这样实际上使静态内部类成为了一个顶级类。可以定义私有静态内部类。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;下面是一个静态内部类的特点详解，代码演示&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;package&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;devin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;



&lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MyMain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;woobo&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;X001&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;静态内部类可以用&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;protected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;private&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;修饰&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Person&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

        &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;静态内部类中可以定义静态或者非静态的成员&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;address&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;China&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;



        &lt;span class=&quot;n&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;as&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mail&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;kongbowoo@yahoo.com.cn&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;内部类公有成员&lt;/span&gt;



        &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

            &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;不能直接访问外部类的非静态成员&lt;/span&gt;



            &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;静态内部类不能访问外部类的非静态成员&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;包括非静态变量和非静态方法&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;nf&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;只能直接访问外部类的静态成员&lt;/span&gt;



            &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;静态内部类只能访问外部类的静态成员&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;包括静态变量和静态方法&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;nf&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Inner &quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;访问本内部类成员。&lt;/span&gt;

        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;



    &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;printInfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;Person&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;person&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Person&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;



        &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;外部类访问内部类的非静态成员&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;实例化内部类即可&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;person&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;



        &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mail&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;不可访问&lt;/span&gt;

        &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);//&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;不可访问&lt;/span&gt;

        &lt;span class=&quot;nf&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;person&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;可以访问内部类的私有成员&lt;/span&gt;



        &lt;span class=&quot;nf&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Person&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;外部类访问内部类的静态成员：内部类&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;静态成员&lt;/span&gt;

        &lt;span class=&quot;nf&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;person&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mail&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;可以访问内部类的公有成员&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;



    &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;MyMain&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;staticTest&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MyMain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;staticTest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;printInfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;作用-1&quot;&gt;作用：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;静态内部类的作用都是建立在其特点之上的，其实在大部分时间来说，还是很不常用的在网上我查过了许多。总体来说，记住他的特点。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;下面介绍几个具体作用：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;在设计模式的单例模式中，有一种单例模式的实现是IODH，他是利用静态内部类在初始类的初始化时就加载的原理。具体什么是IODH,网上有一大把，自己查。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在某些特殊的情况下，少了这个静态内部 类还真是不行。如在进行代码程序测试的时候，如果在每一个Java源文件中都设置一个主方法(主方法是某个应用程序的入口，必须具有)，那么会出现很多额 外的代码。而且最主要的时这段主程序的代码对于Java文件来说，只是一个形式，其本身并不需要这种主方法。但是少了这个主方法又是万万不行的。在这种情 况下，就可以将主方法写入到静态内部类中，从而不用为每个Java源文件都设置一个类似的主方法。这对于代码测试是非常有用的。在一些中大型的应用程序开 发中，则是一个常用的技术手段。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在很多框架的源码或者jdk的源码中，会涉及到静态内部类的话，就要是作为工具类，然后把访问限制到最大。比如在ConcurrentHashMap 中HashEntry。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;局部内部类&quot;&gt;局部内部类&lt;/h3&gt;

&lt;h4 id=&quot;定义-2&quot;&gt;定义：&lt;/h4&gt;

&lt;p&gt;　　就是在方法中定义的类。&lt;/p&gt;

&lt;h4 id=&quot;特点-2&quot;&gt;特点：&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;该内部类没有任何的访问控制权限&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;外围类看不见方法中的局部内部类的，但是局部内部类可以访问外围类的任何成员。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;方法体中可以访问局部内部类，但是访问语句必须在定义局部内部类之后。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;局部内部类只能访问方法体中的常量，即用final修饰的成员。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;作用-2&quot;&gt;作用：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;根据其特点可以得出其作用。基本上没有怎么用吧。能力有限。。。如有任何见解，可以评论，。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;匿名内部类&quot;&gt;匿名内部类&lt;/h3&gt;

&lt;h4 id=&quot;定义-3&quot;&gt;定义：&lt;/h4&gt;

&lt;p&gt;　　匿名内部类也就是没有名字的内部类，正因为没有名字，所以匿名内部类只能使用一次，它通常用来简化代码编写。但使用匿名内部类还有个前提条件：必须继承一个父类或实现一个接口。&lt;/p&gt;

&lt;h4 id=&quot;特点和实例&quot;&gt;特点和实例&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;实例1:不使用匿名内部类来实现抽象方法&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
abstract class Person {

    public abstract void eat();

}



class Child extends Person {

    public void eat() {

        System.out.println(&quot;eat something&quot;);

    }

}



public class Demo {

    public static void main(String[] args) {

        Person p = new Child();

        p.eat();

    }

}

运行结果：eat something

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;可以看到，我们用Child继承了Person类，然后实现了Child的一个实例，将其向上转型为Person类的引用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;但是，如果此处的Child类只使用一次，那么将其编写为独立的一个类岂不是很麻烦？&lt;/p&gt;

&lt;p&gt;这个时候就引入了匿名内部类。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;实例2：匿名内部类的基本实现&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
abstract class Person {

    public abstract void eat();

}

 

public class Demo {

    public static void main(String[] args) {

        Person p = new Person() {

            public void eat() {

                System.out.println(&quot;eat something&quot;);

            }

        };

        p.eat();

    }

}

运行结果：eat something

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;可以看到，我们直接将抽象类Person中的方法在大括号中实现了,这样便可以省略一个类的书写。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;并且，匿名内部类还能用于接口上&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;实例3：在接口上使用匿名内部类&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
interface Person {

    public void eat();

}

 

public class Demo {

    public static void main(String[] args) {

        Person p = new Person() {

            public void eat() {

                System.out.println(&quot;eat something&quot;);

            }

        };

        p.eat();

    }

}

运行结果：eat something

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;由上面的例子可以看出，只要一个类是抽象的或是一个接口，那么其子类中的方法都可以使用匿名内部类来实现&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;最常用的情况就是在多线程的实现上，因为要实现多线程必须继承Thread类或是继承Runnable接口&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;实例4：Thread类的匿名内部类实现&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
public class Demo {

    public static void main(String[] args) {

        Thread t = new Thread() {

            public void run() {

                for (int i = 1; i &amp;lt;= 5; i++) {

                    System.out.print(i + &quot; &quot;);

                }

            }

        };

        t.start();

    }

}

运行结果：1 2 3 4 5



&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;实例5：Runnable接口的匿名内部类实现&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
public class Demo {

    public static void main(String[] args) {

        Runnable r = new Runnable() {

            public void run() {

                for (int i = 1; i &amp;lt;= 5; i++) {

                    System.out.print(i + &quot; &quot;);

                }

            }

        };

        Thread t = new Thread(r);

        t.start();

    }

}

运行结果：1 2 3 4 5

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;!-- 多说评论框 start --&gt;

&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201610231&quot; data-title=&quot;learning-innerclass of java（1）&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;

&lt;!-- 多说评论框 end --&gt;

&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;

&lt;script type=&quot;text/javascript&quot;&gt;

var duoshuoQuery = {short_name:&quot;yzhhome&quot;};

  (function() {

    var ds = document.createElement('script');

    ds.type = 'text/javascript';ds.async = true;

    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';

    ds.charset = 'UTF-8';

    (document.getElementsByTagName('head')[0] 

     || document.getElementsByTagName('body')[0]).appendChild(ds);

  })();

  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Sun, 23 Oct 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//java/2016/10/23/learning-innerclass-of-java.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//java/2016/10/23/learning-innerclass-of-java.html</guid>
        
        <category>java</category>
        
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>welcome to my blog</title>
        <description>&lt;h1 id=&quot;my-blog&quot;&gt;My blog&lt;/h1&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#my-blog&quot; id=&quot;markdown-toc-my-blog&quot;&gt;My blog&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#新开博客激动不已&quot; id=&quot;markdown-toc-新开博客激动不已&quot;&gt;新开博客，激动不已&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#博客文章&quot; id=&quot;markdown-toc-博客文章&quot;&gt;博客文章&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#主题&quot; id=&quot;markdown-toc-主题&quot;&gt;主题&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#读书笔记&quot; id=&quot;markdown-toc-读书笔记&quot;&gt;读书笔记&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#一篇文字&quot; id=&quot;markdown-toc-一篇文字&quot;&gt;一篇文字&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#个人博客有关技术&quot; id=&quot;markdown-toc-个人博客有关技术&quot;&gt;个人博客有关技术&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#托管&quot; id=&quot;markdown-toc-托管&quot;&gt;托管&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#git-github&quot; id=&quot;markdown-toc-git-github&quot;&gt;git-github&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#web前端&quot; id=&quot;markdown-toc-web前端&quot;&gt;web前端&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#评论&quot; id=&quot;markdown-toc-评论&quot;&gt;评论&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#其他&quot; id=&quot;markdown-toc-其他&quot;&gt;其他&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;新开博客激动不已&quot;&gt;新开博客，激动不已&lt;/h2&gt;
&lt;p&gt;不务正业的我，搞了一个自己的个人博客。其实在弄这个博客的时候也没有想那么多，就觉得可以拿来吹牛逼。但是差不多做完了，才发现原来可以但不止于吹牛逼，很多灵光乍现。下面来说下最终觉得这个做博客系统的目的：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;吹牛逼是自然，毕竟是自己做的，但还是要&lt;em&gt;Stay hungry,Stay foolish&lt;/em&gt;，不然很容易被大神鄙视的。&lt;/li&gt;
  &lt;li&gt;既然是博客系统，做出来了，那它就应该像一条鞭条，时刻鞭策自己，该好好写写文章，博文和学习笔记了。博文系统不能做出来像个花瓶一样，而是时时出新知，多写博文。&lt;/li&gt;
  &lt;li&gt;自己写的文章，不应该像古时候那些未出嫁的姑娘，而是应该大胆的给别看，博文不是那些藏有很多见不得人秘密的日记，博文是用来干嘛的，不就是用来给别人看的嘛？不然留着腐败遗弃吗？&lt;/li&gt;
  &lt;li&gt;最后，博文要经受的起考验，在写文章的时候要有点料，不是用来瞎逼逼的。这样也激励我好好学习，写出来的东西才不会被别人扔鸡蛋。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;注意：文章下有评论模块，欢迎留言，可支持github，Facebook，twitter登录&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;博客文章&quot;&gt;博客文章&lt;/h2&gt;

&lt;h3 id=&quot;主题&quot;&gt;主题&lt;/h3&gt;
&lt;p&gt;  我想，在这个系统中，不应该仅限于计算机的技术学习或文章，而同时很重要的是那些生活的感悟。在广工大作为一个工科男的我，虽然没有语文课，虽然很少时间可以接触纯文学的东西，跟不用说是做到&lt;strong&gt;文思如尿崩&lt;/strong&gt;的境界。但我是想做一个文艺一点的程序员的，至少也要是伪文艺吧（脸红）。&lt;/p&gt;

&lt;h3 id=&quot;读书笔记&quot;&gt;读书笔记&lt;/h3&gt;
&lt;p&gt;  在这里就要好好写好那些生活感想，然后是分享读书笔记。把那些日常看的书的名言记录下来。下面分享一个高中写的不知道什么东西。鬼知道我那时候经历了什么，可以写的让人“毛骨悚然”。&lt;/p&gt;

&lt;h3 id=&quot;一篇文字&quot;&gt;一篇文字&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;  乐：早上的流光带出了太阳。睁开双眼，目光寻觅着时间。踉踉跄跄的起来，到卫生间悠闲的刷牙，洗脸，搞好个人卫生。来到饭堂，吃完早餐，走在校道上，天上浓云飞扬，大风吹起，黄叶铺了一地。面前的老树吐新芽，枯木开了花，道路两旁是姹紫嫣红的花，几滴露珠吹过，玉露从花中惊落，在空中舞落，飘飘然而乐。有几只蝴蝶在花间飞舞，好像是在寻觅那些最美好的回忆，想起《庄子》中的“庄周梦蝶”，如果我可以庄子那样，变成一只轻飘的蝴蝶，即使在梦中，那么我会在这些红花中享受自己的轻松，直至离去。 小鸟正在歌唱，歌声合着春风，感觉自然的音律真是奇妙无比。只是不知道为什么在沐春时节黄了满地，可能是因为让生机再现，所以让旧叶归根吧。&lt;br /&gt;
  走过校道，并没有下雨，周遭朦胧的轻雾带着淡淡的暗香，从中拂过。像风来竹林，风过也，竹不留声；又像雁过寒潭，雁过也，潭不留影；其实最像小鸟从空中飞过，没有留下一丝痕迹，只是暗香沾衣湿。&lt;br /&gt;
  春风吹，似剪刀，自然把一棵棵裁制成“活力”，碧玉妆成树树高。春光照耀大地，绿了整个周遭。几分春雨飘零，让梅园春路又舔了新花，花动满园春色！梅园，冷艳的梅花已不屑与万红争妍，桃花依旧绽开，流水依然缓缓，只有夭娇曲径，逢迎闲人！&amp;lt;hr&amp;gt;
  悲：风也啸啸，雨也啸啸，落花风雨，又过一宵。顶着沉重的一道浅壑，进入了又一天生活，打理好装束，慢慢下楼，白驹过隙，来到饭堂，吃过早餐，什么也没有发生，只是外面的啼鸟依然悲凉。撑伞迈步于校道，飞红万点，知道春将伤逝，只愁如飞红海。都说少年不知愁滋味，更应尽兴晚归，识尽愁滋味，欲说却休，泪先流，好似雨水，雨越下越大。。。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;个人博客有关技术&quot;&gt;个人博客有关技术&lt;/h2&gt;

&lt;h3 id=&quot;托管&quot;&gt;托管&lt;/h3&gt;
&lt;p&gt;如您所见，这个博客是用github-page加上jekyll做的静态博客系统。如果您也想做这样的博客的话。请看下面所涉及技术。&lt;/p&gt;

&lt;h3 id=&quot;git-github&quot;&gt;git-github&lt;/h3&gt;
&lt;p&gt;因为是托管在github上，所以git和github还是要学好的，这点我写了一个文章，可以一起学习,地址是：&lt;a href=&quot;https://yzhihao.github.io/tools/2016/10/01/learning-git.html&quot;&gt;git-github学习&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;web前端&quot;&gt;web前端&lt;/h3&gt;
&lt;p&gt;web前端的知识，包括html，css，js，jQuery，bootstrap等。这些起码是要大概了解的，其实，我也是web后端的，这些前端的知识很虚。最低要求应该是简单会用基础。&lt;/p&gt;

&lt;h3 id=&quot;评论&quot;&gt;评论&lt;/h3&gt;
&lt;p&gt;评论的话，我是用到的是Comm(ent|it)，具体的用法在这里：&lt;a href=&quot;https://commentit.io/&quot;&gt;commentit&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;其他&quot;&gt;其他&lt;/h3&gt;
&lt;p&gt;比如分享，查询，模块是属于原jekyll主题的，我直接拿来用了。&lt;/p&gt;

&lt;!-- 多说评论框 start --&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;201610191&quot; data-title=&quot;welcome to my blog&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Wed, 19 Oct 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//life/2016/10/19/welcome-to-my-bolg.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//life/2016/10/19/welcome-to-my-bolg.html</guid>
        
        <category>Life</category>
        
        
        <category>Life</category>
        
      </item>
    
      <item>
        <title>learning git</title>
        <description>&lt;h1 id=&quot;gitgithub学习&quot;&gt;git–github学习&lt;/h1&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#gitgithub学习&quot; id=&quot;markdown-toc-gitgithub学习&quot;&gt;git–github学习&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#首先什么是github什么是git&quot; id=&quot;markdown-toc-首先什么是github什么是git&quot;&gt;首先什么是github，什么是git。&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#几个概念&quot; id=&quot;markdown-toc-几个概念&quot;&gt;几个概念：&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#git的一些常用命令&quot; id=&quot;markdown-toc-git的一些常用命令&quot;&gt;git的一些常用命令&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#文件操作&quot; id=&quot;markdown-toc-文件操作&quot;&gt;文件操作&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#分支&quot; id=&quot;markdown-toc-分支&quot;&gt;分支&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#连接远程操作&quot; id=&quot;markdown-toc-连接远程操作&quot;&gt;连接远程操作&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#ssh网络服务传输协议&quot; id=&quot;markdown-toc-ssh网络服务传输协议&quot;&gt;ssh网络服务传输协议&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#版本回退&quot; id=&quot;markdown-toc-版本回退&quot;&gt;版本回退&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#分支冲突&quot; id=&quot;markdown-toc-分支冲突&quot;&gt;分支（冲突）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#冲突操作&quot; id=&quot;markdown-toc-冲突操作&quot;&gt;冲突操作&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#githubpage学习&quot; id=&quot;markdown-toc-githubpage学习&quot;&gt;githubpage学习&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#最后&quot; id=&quot;markdown-toc-最后&quot;&gt;最后&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;首先什么是github什么是git&quot;&gt;首先什么是github，什么是git。&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;git是一个版本控制工具，是一个系统，在windows下就是一个软件。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;github是一个用git做版本控制的项目托管平台，是一个网站。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;想快速入门的话可以先查看是一个(包括文件&lt;strong&gt;上传下拉，分支操作&lt;/strong&gt;)&lt;a href=&quot;http://note.youdao.com/share/?id=29b306d4f3c6ac93c1f9713f7442d2a6&amp;amp;type=note#/&quot;&gt;网上入门学习笔记&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;网上教程也有一堆，推荐的话还是廖雪峰老师的:&lt;a href=&quot;http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/&quot;&gt;git教程&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;几个概念&quot;&gt;几个概念：&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;工作区（Working Directory）：就是你在电脑里能看到的目录下的工作区间。&lt;/li&gt;
  &lt;li&gt;版本库（Repository）：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。&lt;/li&gt;
  &lt;li&gt;Git的版本分为两大部分，一是：称为stage（或者叫index）的暂存区；还有就是分支,创建仓库时会默认创建master分支。&lt;/li&gt;
  &lt;li&gt;什么是分支：每次的提交到版本库，都有一个记录，Git都把它们串成一条时间线，这条时间线就是一个分支。在Git里，有个主分支，即master分支。&lt;/li&gt;
  &lt;li&gt;当我用git add …时，是讲工作区的提交到版本库的暂存区。&lt;/li&gt;
  &lt;li&gt;当我们用git commit -m … 时，是提交到版本库的当前分支。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/tools/git1.jpg&quot; alt=&quot;header1&quot; style=&quot;height:auto!important;width:auto!important;max-width:1020px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;git的一些常用命令&quot;&gt;git的一些常用命令&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;git init 创建一个仓库&lt;/li&gt;
  &lt;li&gt;git add (folder_name) 将文件提交到暂存区，当folder_name被替换成.的时候，即git add . 表示将所有文件提交到暂存区。&lt;/li&gt;
  &lt;li&gt;git commit -m (“txt”) 将暂存区文件提交到当前分支。&lt;/li&gt;
  &lt;li&gt;git remote add (respority_name url) 添加一个远程连接。&lt;/li&gt;
  &lt;li&gt;git push （respority_name branch） 将当前分支提交到远程仓库。&lt;/li&gt;
  &lt;li&gt;git remote -v 查看远程仓库的地址&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;git pull （respority_name branch）将远程仓库的某个分支拉下
&lt;strong&gt;注意：git pull可以看成是git fetch加上git merge两个命令&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;git branch 查看所有分支。&lt;/li&gt;
  &lt;li&gt;git checkout branch_name 切换分支。&lt;/li&gt;
  &lt;li&gt;可以用add添加文件到暂存区。代码如下：&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git add file1.txt//增加file1.txt文件
git add file2.txt file3.txt//增加file1.txt，file3.txt文件
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;git clone  respority_url 克隆远程仓库。
    &lt;blockquote&gt;
      &lt;p&gt;也会创建一个新的仓库，并自动将github上的分支设为远端分支。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;文件操作&quot;&gt;文件操作&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;cat filename 查看文件（没有此文件的话不会新建）&lt;/li&gt;
  &lt;li&gt;vi  filename  操作文件（没有此文件的话会新建）
    &lt;blockquote&gt;
      &lt;p&gt;退出编辑文件操作按esc健后：
&lt;code class=&quot;highlighter-rouge&quot;&gt;：wq表示退出保存， :q!表示不保存单单退出&lt;/code&gt;&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;git rm –cached * -r   删除所有缓冲区（已在分支上）的文件&lt;/li&gt;
  &lt;li&gt;git rm name 删除文件&lt;/li&gt;
  &lt;li&gt;输入 touch .gitignore 在文件夹就生成了一个“.gitignore”文件。
    &lt;blockquote&gt;
      &lt;ul&gt;
        &lt;li&gt;gitignore”文件表示你不想push到github上去的配置文件。&lt;/li&gt;
        &lt;li&gt;如果对.gitignore文件内容语法有什么疑问，可以查看这个博客：&lt;a href=&quot;http://www.cnblogs.com/eddy-he/archive/2012/03/08/git_ignore_file.html&quot;&gt;.gitignore文件详解&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;touch name 单纯新增文件&lt;/li&gt;
  &lt;li&gt;git checkout – name 删除文件后把本地版本库的回复到文件夹中&lt;/li&gt;
  &lt;li&gt;git rm –cached * -r   删除所有缓冲区的文件，*表示通配符，这里可以统配其他文件。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果对文件删除操作比较生疏，可以查看这篇博文：&lt;a href=&quot;http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013758392816224cafd33c44b4451887cc941e6716805c000&quot;&gt;文件删除&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;分支&quot;&gt;分支&lt;/h2&gt;
&lt;p&gt;总结创建与合并分支命令如下：
&lt;strong&gt;只有commit之后才能操作分支&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;删除远程的分支：git push origin :（分支名）
查看分支：git branch&lt;/p&gt;

&lt;p&gt;创建分支：git branch name&lt;/p&gt;

&lt;p&gt;切换分支：git checkout name&lt;/p&gt;

&lt;p&gt;创建+切换分支：git checkout –b name&lt;/p&gt;

&lt;p&gt;合并某分支到当前分支：git merge name&lt;/p&gt;

&lt;p&gt;git reflog用来记录你的每一次命令&lt;/p&gt;

&lt;p&gt;删除分支：git branch –d name&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;合并就是时间线的合并&lt;/li&gt;
  &lt;li&gt;vi (folder_name)修改文件&lt;/li&gt;
  &lt;li&gt;用esc健：wq就是保存退出&lt;/li&gt;
  &lt;li&gt;冲突发生在同一文件名上&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;连接远程操作&quot;&gt;连接远程操作&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;git remote remove 链接名   -&amp;gt;移除存在的连接&lt;/li&gt;
  &lt;li&gt;git push remote :&lt;branch&gt;  -&amp;gt;移除远程分支&lt;/branch&gt;&lt;/li&gt;
  &lt;li&gt;git remote -v 详细查看连接信息。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ssh网络服务传输协议&quot;&gt;ssh网络服务传输协议&lt;/h3&gt;
&lt;p&gt;有了ssh之后就可以使用ssh协议来传输。&lt;/p&gt;

&lt;h2 id=&quot;版本回退&quot;&gt;版本回退&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;git log查看之前的版本（自打开一个 ）&lt;/li&gt;
  &lt;li&gt;git reflog 看所有之前的commit操作（自从仓库创建算起）&lt;/li&gt;
  &lt;li&gt;git reset –hard HEAD^ 回退到上一个版本&lt;/li&gt;
  &lt;li&gt;git reset –hard 3628164 后面7位版本号，这样可以回退到任意版本&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;关于版本回退，也可看查看这篇博文：&lt;a href=&quot;http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013744142037508cf42e51debf49668810645e02887691000&quot;&gt;版本回退&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;分支冲突&quot;&gt;分支（冲突）&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;如果对git的分支的概念及其内容有疑问，请看这里：&lt;a href=&quot;http://www.open-open.com/lib/view/open1328069889514.html#articleHeader15&quot;&gt;git分支&lt;/a&gt;&lt;br /&gt;
如果对git的分支冲突解决，请看廖老师的：&lt;a href=&quot;http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001375840202368c74be33fbd884e71b570f2cc3c0d1dcf000&quot;&gt;解决冲突&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;冲突操作&quot;&gt;冲突操作&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;合并某分支到当前分支：git merge name&lt;/li&gt;
  &lt;li&gt;告诉我们冲突的内容：git status&lt;/li&gt;
  &lt;li&gt;git log –graph命令可以看到分支合并图。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;githubpage学习&quot;&gt;githubpage学习&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;在githubpage学习中，这个网页本身就是githubpage的一个静态博客。
在用githubpage编写博客时，最常用的就是githubpage加jekyll进行创建属于自己的博客。&lt;/li&gt;
  &lt;li&gt;在jekll中有许许多多的模板，模板的github地址在&lt;a href=&quot;https://github.com/jekyll/jekyll/wiki/Configuration&quot;&gt;Jekyll  github地址&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;最后&quot;&gt;最后&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://yzhihao.github.io/static/img/blog/tools/git.jpg&quot; alt=&quot;header&quot; style=&quot;height:100%;width:100%;&quot; /&gt;&lt;/p&gt;

&lt;!-- 多说评论框 start --&gt;
&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;20161011&quot; data-title=&quot;learning git&quot; data-url=&quot;&quot;&gt;&lt;/div&gt;
&lt;!-- 多说评论框 end --&gt;
&lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var duoshuoQuery = {short_name:&quot;yzhhome&quot;};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  &lt;/script&gt;

&lt;!-- 多说公共JS代码 end --&gt;
</description>
        <pubDate>Sat, 01 Oct 2016 08:00:00 +0800</pubDate>
        <link>http://localhost:4000https://yzhihao.github.io//tools/2016/10/01/learning-git.html</link>
        <guid isPermaLink="true">http://localhost:4000https://yzhihao.github.io//tools/2016/10/01/learning-git.html</guid>
        
        <category>tools</category>
        
        
        <category>tools</category>
        
      </item>
    
  </channel>
</rss>
